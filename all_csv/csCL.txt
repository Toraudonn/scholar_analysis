2017-03-28T14:05:58Z|2017-03-27T15:13:49Z|http://arxiv.org/abs/1703.09137v1|http://arxiv.org/pdf/1703.09137v1|Where to put the Image in an Image Caption Generator|put imag imag caption generat|When a neural language model is used for caption generation, the image information can be fed to the neural network either by directly incorporating it in a recurrent neural network -- conditioning the language model by injecting image features -- or in a layer following the recurrent neural network -- conditioning the language model by merging the image features. While merging implies that visual features are bound at the end of the caption generation process, injecting can bind the visual features at a variety stages. In this paper we empirically show that late binding is superior to early binding in terms of different evaluation metrics. This suggests that the different modalities (visual and linguistic) for caption generation should not be jointly encoded by the RNN; rather, the multimodal integration should be delayed to a subsequent stage. Furthermore, this suggests that recurrent neural networks should not be viewed as actually generating text, but only as encoding it for prediction in a subsequent layer.|neural languag model use caption generat imag inform fed neural network either direct incorpor recurr neural network condit languag model inject imag featur layer follow recurr neural network condit languag model merg imag featur merg impli visual featur bound end caption generat process inject bind visual featur varieti stage paper empir show late bind superior earli bind term differ evalu metric suggest differ modal visual linguist caption generat joint encod rnn rather multimod integr delay subsequ stage furthermor suggest recurr neural network view actual generat text onli encod predict subsequ layer|['Marc Tanti', 'Albert Gatt', 'Kenneth P. Camilleri']|['cs.NE', 'cs.CL', 'cs.CV']
2017-03-28T14:05:58Z|2017-03-27T13:11:33Z|http://arxiv.org/abs/1703.09046v1|http://arxiv.org/pdf/1703.09046v1|Bootstrapping a Lexicon for Emotional Arousal in Software Engineering|bootstrap lexicon emot arous softwar engin|Emotional arousal increases activation and performance but may also lead to burnout in software development. We present the first version of a Software Engineering Arousal lexicon (SEA) that is specifically designed to address the problem of emotional arousal in the software developer ecosystem. SEA is built using a bootstrapping approach that combines word embedding model trained on issue-tracking data and manual scoring of items in the lexicon. We show that our lexicon is able to differentiate between issue priorities, which are a source of emotional activation and then act as a proxy for arousal. The best performance is obtained by combining SEA (428 words) with a previously created general purpose lexicon by Warriner et al. (13,915 words) and it achieves Cohen's d effect sizes up to 0.5.|emot arous increas activ perform may also lead burnout softwar develop present first version softwar engin arous lexicon sea specif design address problem emot arous softwar develop ecosystem sea built use bootstrap approach combin word embed model train issu track data manual score item lexicon show lexicon abl differenti issu prioriti sourc emot activ act proxi arous best perform obtain combin sea word previous creat general purpos lexicon warrin et al word achiev cohen effect size|['Mika V. Mäntylä', 'Nicole Novielli', 'Filippo Lanubile', 'Maëlick Claes', 'Miikka Kuutila']|['cs.SE', 'cs.CL']
2017-03-28T14:05:58Z|2017-03-27T11:15:58Z|http://arxiv.org/abs/1703.09013v1|http://arxiv.org/pdf/1703.09013v1|A Sentence Simplification System for Improving Relation Extraction|sentenc simplif system improv relat extract|In this demo paper, we present a text simplification approach that is directed at improving the performance of state-of-the-art Open Relation Extraction (RE) systems. As syntactically complex sentences often pose a challenge for current Open RE approaches, we have developed a simplification framework that performs a pre-processing step by taking a single sentence as input and using a set of syntactic-based transformation rules to create a textual input that is easier to process for subsequently applied Open RE systems.|demo paper present text simplif approach direct improv perform state art open relat extract system syntact complex sentenc often pose challeng current open approach develop simplif framework perform pre process step take singl sentenc input use set syntact base transform rule creat textual input easier process subsequ appli open system|['Christina Niklaus', 'Bernhard Bermeitinger', 'Siegfried Handschuh', 'André Freitas']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-26T23:48:06Z|http://arxiv.org/abs/1703.08885v1|http://arxiv.org/pdf/1703.08885v1|Question Answering from Unstructured Text by Retrieval and Comprehension|question answer unstructur text retriev comprehens|Open domain Question Answering (QA) systems must interact with external knowledge sources, such as web pages, to find relevant information. Information sources like Wikipedia, however, are not well structured and difficult to utilize in comparison with Knowledge Bases (KBs). In this work we present a two-step approach to question answering from unstructured text, consisting of a retrieval step and a comprehension step. For comprehension, we present an RNN based attention model with a novel mixture mechanism for selecting answers from either retrieved articles or a fixed vocabulary. For retrieval we introduce a hand-crafted model and a neural model for ranking relevant articles. We achieve state-of-the-art performance on W IKI M OVIES dataset, reducing the error by 40%. Our experimental results further demonstrate the importance of each of the introduced components.|open domain question answer qa system must interact extern knowledg sourc web page find relev inform inform sourc like wikipedia howev well structur difficult util comparison knowledg base kbs work present two step approach question answer unstructur text consist retriev step comprehens step comprehens present rnn base attent model novel mixtur mechan select answer either retriev articl fix vocabulari retriev introduc hand craft model neural model rank relev articl achiev state art perform iki ovi dataset reduc error experiment result demonstr import introduc compon|['Yusuke Watanabe', 'Bhuwan Dhingra', 'Ruslan Salakhutdinov']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-26T20:02:44Z|http://arxiv.org/abs/1703.08864v1|http://arxiv.org/pdf/1703.08864v1|Learning Simpler Language Models with the Delta Recurrent Neural Network   Framework|learn simpler languag model delta recurr neural network framework|Learning useful information across long time lags is a critical and difficult problem for temporal neural models in tasks like language modeling. Existing architectures that address the issue are often complex and costly to train. The Delta Recurrent Neural Network (Delta-RNN) framework is a simple and high-performing design that unifies previously proposed gated neural models. The Delta-RNN models maintain longer-term memory by learning to interpolate between a fast-changing data-driven representation and a slowly changing, implicitly stable state. This requires hardly any more parameters than a classical simple recurrent network. The models outperform popular complex architectures, such as the Long Short Term Memory (LSTM) and the Gated Recurrent Unit (GRU) and achieve state-of-the art performance in language modeling at character and word levels and yield comparable performance at the subword level.|learn use inform across long time lag critic difficult problem tempor neural model task like languag model exist architectur address issu often complex cost train delta recurr neural network delta rnn framework simpl high perform design unifi previous propos gate neural model delta rnn model maintain longer term memori learn interpol fast chang data driven represent slowli chang implicit stabl state requir hard ani paramet classic simpl recurr network model outperform popular complex architectur long short term memori lstm gate recurr unit gru achiev state art perform languag model charact word level yield compar perform subword level|['Alexander G. Ororbia II', 'Tomas Mikolov', 'David Reitter']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-26T00:30:38Z|http://arxiv.org/abs/1703.08748v1|http://arxiv.org/pdf/1703.08748v1|LEPOR: An Augmented Machine Translation Evaluation Metric|lepor augment machin translat evalu metric|Machine translation (MT) was developed as one of the hottest research topics in the natural language processing (NLP) literature. One important issue in MT is that how to evaluate the MT system reasonably and tell us whether the translation system makes an improvement or not. The traditional manual judgment methods are expensive, time-consuming, unrepeatable, and sometimes with low agreement. On the other hand, the popular automatic MT evaluation methods have some weaknesses. Firstly, they tend to perform well on the language pairs with English as the target language, but weak when English is used as source. Secondly, some methods rely on many additional linguistic features to achieve good performance, which makes the metric unable to replicate and apply to other language pairs easily. Thirdly, some popular metrics utilize incomprehensive factors, which result in low performance on some practical tasks. In this thesis, to address the existing problems, we design novel MT evaluation methods and investigate their performances on different languages. Firstly, we design augmented factors to yield highly accurate evaluation.Secondly, we design a tunable evaluation model where weighting of factors can be optimised according to the characteristics of languages. Thirdly, in the enhanced version of our methods, we design concise linguistic feature using POS to show that our methods can yield even higher performance when using some external linguistic resources. Finally, we introduce the practical performance of our metrics in the ACL-WMT workshop shared tasks, which show that the proposed methods are robust across different languages.|machin translat mt develop one hottest research topic natur languag process nlp literatur one import issu mt evalu mt system reason tell us whether translat system make improv tradit manual judgment method expens time consum unrepeat sometim low agreement hand popular automat mt evalu method weak first tend perform well languag pair english target languag weak english use sourc second method reli mani addit linguist featur achiev good perform make metric unabl replic appli languag pair easili third popular metric util incomprehens factor result low perform practic task thesi address exist problem design novel mt evalu method investig perform differ languag first design augment factor yield high accur evalu second design tunabl evalu model weight factor optimis accord characterist languag third enhanc version method design concis linguist featur use pos show method yield even higher perform use extern linguist resourc final introduc practic perform metric acl wmt workshop share task show propos method robust across differ languag|['Lifeng Han']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-25T15:37:09Z|http://arxiv.org/abs/1703.08705v1|http://arxiv.org/pdf/1703.08705v1|Comparing Rule-Based and Deep Learning Models for Patient Phenotyping|compar rule base deep learn model patient phenotyp|Objective: We investigate whether deep learning techniques for natural language processing (NLP) can be used efficiently for patient phenotyping. Patient phenotyping is a classification task for determining whether a patient has a medical condition, and is a crucial part of secondary analysis of healthcare data. We assess the performance of deep learning algorithms and compare them with classical NLP approaches.   Materials and Methods: We compare convolutional neural networks (CNNs), n-gram models, and approaches based on cTAKES that extract pre-defined medical concepts from clinical notes and use them to predict patient phenotypes. The performance is tested on 10 different phenotyping tasks using 1,610 discharge summaries extracted from the MIMIC-III database.   Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The average F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our model having an F1-score up to 37 points higher than alternative approaches. We additionally assess the interpretability of our model by presenting a method that extracts the most salient phrases for a particular prediction.   Conclusion: We show that NLP methods based on deep learning improve the performance of patient phenotyping. Our CNN-based algorithm automatically learns the phrases associated with each patient phenotype. As such, it reduces the annotation complexity for clinical domain experts, who are normally required to develop task-specific annotation rules and identify relevant phrases. Our method performs well in terms of both performance and interpretability, which indicates that deep learning is an effective approach to patient phenotyping based on clinicians' notes.|object investig whether deep learn techniqu natur languag process nlp use effici patient phenotyp patient phenotyp classif task determin whether patient medic condit crucial part secondari analysi healthcar data assess perform deep learn algorithm compar classic nlp approach materi method compar convolut neural network cnns gram model approach base ctake extract pre defin medic concept clinic note use predict patient phenotyp perform test differ phenotyp task use discharg summari extract mimic iii databas result cnns outperform phenotyp algorithm task averag score model ppv sensit model score point higher altern approach addit assess interpret model present method extract salient phrase particular predict conclus show nlp method base deep learn improv perform patient phenotyp cnn base algorithm automat learn phrase associ patient phenotyp reduc annot complex clinic domain expert normal requir develop task specif annot rule identifi relev phrase method perform well term perform interpret indic deep learn effect approach patient phenotyp base clinician note|['Sebastian Gehrmann', 'Franck Dernoncourt', 'Yeran Li', 'Eric T. Carlson', 'Joy T. Wu', 'Jonathan Welt', 'John Foote Jr.', 'Edward T. Moseley', 'David W. Grant', 'Patrick D. Tyler', 'Leo Anthony Celi']|['cs.CL', 'cs.AI', 'cs.NE', 'stat.ML']
2017-03-28T14:05:58Z|2017-03-25T14:56:27Z|http://arxiv.org/abs/1703.08701v1|http://arxiv.org/pdf/1703.08701v1|Morphological Analysis for the Maltese Language: The Challenges of a   Hybrid System|morpholog analysi maltes languag challeng hybrid system|Maltese is a morphologically rich language with a hybrid morphological system which features both concatenative and non-concatenative processes. This paper analyses the impact of this hybridity on the performance of machine learning techniques for morphological labelling and clustering. In particular, we analyse a dataset of morphologically related word clusters to evaluate the difference in results for concatenative and nonconcatenative clusters. We also describe research carried out in morphological labelling, with a particular focus on the verb category. Two evaluations were carried out, one using an unseen dataset, and another one using a gold standard dataset which was manually labelled. The gold standard dataset was split into concatenative and non-concatenative to analyse the difference in results between the two morphological systems.|maltes morpholog rich languag hybrid morpholog system featur concaten non concaten process paper analys impact hybrid perform machin learn techniqu morpholog label cluster particular analys dataset morpholog relat word cluster evalu differ result concaten nonconcaten cluster also describ research carri morpholog label particular focus verb categori two evalu carri one use unseen dataset anoth one use gold standard dataset manual label gold standard dataset split concaten non concaten analys differ result two morpholog system|['Claudia Borg', 'Albert Gatt']|['cs.CL', 'I.2.7']
2017-03-28T14:05:58Z|2017-03-25T04:25:21Z|http://arxiv.org/abs/1703.08646v1|http://arxiv.org/pdf/1703.08646v1|Simplifying the Bible and Wikipedia Using Statistical Machine   Translation|simplifi bibl wikipedia use statist machin translat|"I started this work with the hope of generating a text synthesizer (like a musical synthesizer) that can imitate certain linguistic styles. Most of the report focuses on text simplification using statistical machine translation (SMT) techniques. I applied MOSES to a parallel corpus of the Bible (King James Version and Easy-to-Read Version) and that of Wikipedia articles (normal and simplified). I report the importance of the three main components of SMT---phrase translation, language model, and recording---by changing their weights and comparing the resulting quality of simplified text in terms of METEOR and BLEU. Toward the end of the report will be presented some examples of text ""synthesized"" into the King James style."|start work hope generat text synthes like music synthes imit certain linguist style report focus text simplif use statist machin translat smt techniqu appli mose parallel corpus bibl king jame version easi read version wikipedia articl normal simplifi report import three main compon smt phrase translat languag model record chang weight compar result qualiti simplifi text term meteor bleu toward end report present exampl text synthes king jame style|['Yohan Jo']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-24T19:45:24Z|http://arxiv.org/abs/1703.08581v1|http://arxiv.org/pdf/1703.08581v1|Sequence-to-Sequence Models Can Directly Transcribe Foreign Speech|sequenc sequenc model direct transcrib foreign speech|We present a recurrent encoder-decoder deep neural network architecture that directly translates speech in one language into text in another. The model does not explicitly transcribe the speech into text in the source language, nor does it require supervision from the ground truth source language transcription during training. We apply a slightly modified sequence-to-sequence with attention architecture that has previously been used for speech recognition and show that it can be repurposed for this more complex task, illustrating the power of attention-based models. A single model trained end-to-end obtains state-of-the-art performance on the Fisher Callhome Spanish-English speech translation task, outperforming a cascade of independently trained sequence-to-sequence speech recognition and machine translation models by 1.8 BLEU points on the Fisher test set. In addition, we find that making use of the training data in both languages by multi-task training sequence-to-sequence speech translation and recognition models with a shared encoder network can improve performance by a further 1.4 BLEU points.|present recurr encod decod deep neural network architectur direct translat speech one languag text anoth model doe explicit transcrib speech text sourc languag doe requir supervis ground truth sourc languag transcript dure train appli slight modifi sequenc sequenc attent architectur previous use speech recognit show repurpos complex task illustr power attent base model singl model train end end obtain state art perform fisher callhom spanish english speech translat task outperform cascad independ train sequenc sequenc speech recognit machin translat model bleu point fisher test set addit find make use train data languag multi task train sequenc sequenc speech translat recognit model share encod network improv perform bleu point|['Ron J. Weiss', 'Jan Chorowski', 'Navdeep Jaitly', 'Yonghui Wu', 'Zhifeng Chen']|['cs.CL', 'cs.LG', 'stat.ML']
2017-03-28T14:06:02Z|2017-03-24T17:55:33Z|http://arxiv.org/abs/1703.08537v1|http://arxiv.org/pdf/1703.08537v1|Crowdsourcing Universal Part-Of-Speech Tags for Code-Switching|crowdsourc univers part speech tag code switch|Code-switching is the phenomenon by which bilingual speakers switch between multiple languages during communication. The importance of developing language technologies for codeswitching data is immense, given the large populations that routinely code-switch. High-quality linguistic annotations are extremely valuable for any NLP task, and performance is often limited by the amount of high-quality labeled data. However, little such data exists for code-switching. In this paper, we describe crowd-sourcing universal part-of-speech tags for the Miami Bangor Corpus of Spanish-English code-switched speech. We split the annotation task into three subtasks: one in which a subset of tokens are labeled automatically, one in which questions are specifically designed to disambiguate a subset of high frequency words, and a more general cascaded approach for the remaining data in which questions are displayed to the worker following a decision tree structure. Each subtask is extended and adapted for a multilingual setting and the universal tagset. The quality of the annotation process is measured using hidden check questions annotated with gold labels. The overall agreement between gold standard labels and the majority vote is between 0.95 and 0.96 for just three labels and the average recall across part-of-speech tags is between 0.87 and 0.99, depending on the task.|code switch phenomenon bilingu speaker switch multipl languag dure communic import develop languag technolog codeswitch data immens given larg popul routin code switch high qualiti linguist annot extrem valuabl ani nlp task perform often limit amount high qualiti label data howev littl data exist code switch paper describ crowd sourc univers part speech tag miami bangor corpus spanish english code switch speech split annot task three subtask one subset token label automat one question specif design disambigu subset high frequenc word general cascad approach remain data question display worker follow decis tree structur subtask extend adapt multilingu set univers tagset qualiti annot process measur use hidden check question annot gold label overal agreement gold standard label major vote three label averag recal across part speech tag depend task|['Victor Soto', 'Julia Hirschberg']|['cs.CL']
2017-03-28T14:06:02Z|2017-03-24T17:13:08Z|http://arxiv.org/abs/1703.08513v1|http://arxiv.org/pdf/1703.08513v1|Interactive Natural Language Acquisition in a Multi-modal Recurrent   Neural Architecture|interact natur languag acquisit multi modal recurr neural architectur|The human brain is one of the most complex dynamic systems that enables us to communicate in natural language. We have a good understanding of some principles underlying natural languages and language processing, some knowledge about socio-cultural conditions framing acquisition, and some insights about where activity is occurring in the brain. However, we were not yet able to understand the behavioural and mechanistic characteristics for natural language and how mechanisms in the brain allow to acquire and process language.   In an effort to bridge the gap between insights from behavioural psychology and neuroscience, the goal of this paper is to contribute a computational understanding of the appropriate characteristics that favour language acquisition, in a brain-inspired neural architecture. Accordingly, we provide concepts and refinements in cognitive modelling regarding principles and mechanisms in the brain - such as the hierarchical abstraction of context - in a plausible recurrent architecture. On this basis, we propose neurocognitively plausible model for embodied language acquisition from real world interaction of a humanoid robot with its environment. The model is capable of learning language production grounded in both, temporal dynamic somatosensation and vision. In particular, the architecture consists of a continuous time recurrent neural network, where parts have different leakage characteristics and thus operate on multiple timescales for every modality and the association of the higher level nodes of all modalities into cell assemblies. Thus, this model features hierarchical concept abstraction in sensation as well as concept decomposition in production, multi-modal integration, and self-organisation of latent representations.|human brain one complex dynam system enabl us communic natur languag good understand principl natur languag languag process knowledg socio cultur condit frame acquisit insight activ occur brain howev yet abl understand behaviour mechanist characterist natur languag mechan brain allow acquir process languag effort bridg gap insight behaviour psycholog neurosci goal paper contribut comput understand appropri characterist favour languag acquisit brain inspir neural architectur accord provid concept refin cognit model regard principl mechan brain hierarch abstract context plausibl recurr architectur basi propos neurocognit plausibl model embodi languag acquisit real world interact humanoid robot environ model capabl learn languag product ground tempor dynam somatosens vision particular architectur consist continu time recurr neural network part differ leakag characterist thus oper multipl timescal everi modal associ higher level node modal cell assembl thus model featur hierarch concept abstract sensat well concept decomposit product multi modal integr self organis latent represent|['Stefan Heinrich', 'Stefan Wermter']|['cs.CL', 'q-bio.NC']
2017-03-28T14:06:02Z|2017-03-24T15:40:19Z|http://arxiv.org/abs/1703.08471v1|http://arxiv.org/pdf/1703.08471v1|Batch-normalized joint training for DNN-based distant speech recognition|batch normal joint train dnn base distant speech recognit|Improving distant speech recognition is a crucial step towards flexible human-machine interfaces. Current technology, however, still exhibits a lack of robustness, especially when adverse acoustic conditions are met. Despite the significant progress made in the last years on both speech enhancement and speech recognition, one potential limitation of state-of-the-art technology lies in composing modules that are not well matched because they are not trained jointly. To address this concern, a promising approach consists in concatenating a speech enhancement and a speech recognition deep neural network and to jointly update their parameters as if they were within a single bigger network. Unfortunately, joint training can be difficult because the output distribution of the speech enhancement system may change substantially during the optimization procedure. The speech recognition module would have to deal with an input distribution that is non-stationary and unnormalized. To mitigate this issue, we propose a joint training approach based on a fully batch-normalized architecture. Experiments, conducted using different datasets, tasks and acoustic conditions, revealed that the proposed framework significantly overtakes other competitive solutions, especially in challenging environments.|improv distant speech recognit crucial step toward flexibl human machin interfac current technolog howev still exhibit lack robust especi advers acoust condit met despit signific progress made last year speech enhanc speech recognit one potenti limit state art technolog lie compos modul well match becaus train joint address concern promis approach consist concaten speech enhanc speech recognit deep neural network joint updat paramet within singl bigger network unfortun joint train difficult becaus output distribut speech enhanc system may chang substanti dure optim procedur speech recognit modul would deal input distribut non stationari unnorm mitig issu propos joint train approach base fulli batch normal architectur experi conduct use differ dataset task acoust condit reveal propos framework signific overtak competit solut especi challeng environ|['Mirco Ravanelli', 'Philemon Brakel', 'Maurizio Omologo', 'Yoshua Bengio']|['cs.CL', 'cs.LG']
2017-03-28T14:06:02Z|2017-03-24T14:49:58Z|http://arxiv.org/abs/1703.08544v1|http://arxiv.org/pdf/1703.08544v1|D.TRUMP: Data-mining Textual Responses to Uncover Misconception Patterns|trump data mine textual respons uncov misconcept pattern|An important, yet largely unstudied, problem in student data analysis is to detect misconceptions from students' responses to open-response questions. Misconception detection enables instructors to deliver more targeted feedback on the misconceptions exhibited by many students in their class, thus improving the quality of instruction. In this paper, we propose D.TRUMP, a new natural language processing-based framework to detect the common misconceptions among students' textual responses to short-answer questions. We propose a probabilistic model for students' textual responses involving misconceptions and experimentally validate it on a real-world student-response dataset. Experimental results show that D.TRUMP excels at classifying whether a response exhibits one or more misconceptions. More importantly, it can also automatically detect the common misconceptions exhibited across responses from multiple students to multiple questions; this property is especially important at large scale, since instructors will no longer need to manually specify all possible misconceptions that students might exhibit.|import yet larg unstudi problem student data analysi detect misconcept student respons open respons question misconcept detect enabl instructor deliv target feedback misconcept exhibit mani student class thus improv qualiti instruct paper propos trump new natur languag process base framework detect common misconcept among student textual respons short answer question propos probabilist model student textual respons involv misconcept experiment valid real world student respons dataset experiment result show trump excel classifi whether respons exhibit one misconcept import also automat detect common misconcept exhibit across respons multipl student multipl question properti especi import larg scale sinc instructor longer need manual specifi possibl misconcept student might exhibit|['Joshua J. Michalenko', 'Andrew S. Lan', 'Richard G. Baraniuk']|['stat.ML', 'cs.CL']
2017-03-28T14:06:02Z|2017-03-24T14:40:31Z|http://arxiv.org/abs/1703.08428v1|http://arxiv.org/abs/1703.08428v1|Calendar.help: Designing a Workflow-Based Scheduling Agent with Humans   in the Loop|calendar help design workflow base schedul agent human loop|Although information workers may complain about meetings, they are an essential part of their work life. Consequently, busy people spend a significant amount of time scheduling meetings. We present Calendar.help, a system that provides fast, efficient scheduling through structured workflows. Users interact with the system via email, delegating their scheduling needs to the system as if it were a human personal assistant. Common scheduling scenarios are broken down using well-defined workflows and completed as a series of microtasks that are automated when possible and executed by a human otherwise. Unusual scenarios fall back to a trained human assistant who executes them as unstructured macrotasks. We describe the iterative approach we used to develop Calendar.help, and share the lessons learned from scheduling thousands of meetings during a year of real-world deployments. Our findings provide insight into how complex information tasks can be broken down into repeatable components that can be executed efficiently to improve productivity.|although inform worker may complain meet essenti part work life consequ busi peopl spend signific amount time schedul meet present calendar help system provid fast effici schedul structur workflow user interact system via email deleg schedul need system human person assist common schedul scenario broken use well defin workflow complet seri microtask autom possibl execut human otherwis unusu scenario fall back train human assist execut unstructur macrotask describ iter approach use develop calendar help share lesson learn schedul thousand meet dure year real world deploy find provid insight complex inform task broken repeat compon execut effici improv product|['Justin Cranshaw', 'Emad Elwany', 'Todd Newman', 'Rafal Kocielnik', 'Bowen Yu', 'Sandeep Soni', 'Jaime Teevan', 'Andrés Monroy-Hernández']|['cs.HC', 'cs.AI', 'cs.CL']
2017-03-28T14:06:02Z|2017-03-24T09:32:23Z|http://arxiv.org/abs/1703.08324v1|http://arxiv.org/pdf/1703.08324v1|Are crossing dependencies really scarce?|cross depend realli scarc|The syntactic structure of a sentence can be modelled as a tree, where vertices correspond to words and edges indicate syntactic dependencies. It has been claimed recurrently that the number of edge crossings in real sentences is small. However, a baseline or null hypothesis has been lacking. Here we quantify the amount of crossings of real sentences and compare it to the predictions of a series of baselines. We conclude that crossings are really scarce in real sentences. Their scarcity is unexpected by the hubiness of the trees. Indeed, real sentences are close to linear trees, where the potential number of crossings is maximized.|syntact structur sentenc model tree vertic correspond word edg indic syntact depend claim recurr number edg cross real sentenc small howev baselin null hypothesi lack quantifi amount cross real sentenc compar predict seri baselin conclud cross realli scarc real sentenc scarciti unexpect hubi tree inde real sentenc close linear tree potenti number cross maxim|['Ramon Ferrer-i-Cancho', 'Carlos Gomez-Rodriguez', 'J. L. Esteban']|['physics.soc-ph', 'cond-mat.stat-mech', 'cs.CL', 'physics.data-an']
2017-03-28T14:06:02Z|2017-03-24T08:46:48Z|http://arxiv.org/abs/1703.08314v1|http://arxiv.org/pdf/1703.08314v1|Interacting Conceptual Spaces I : Grammatical Composition of Concepts|interact conceptu space grammat composit concept|The categorical compositional approach to meaning has been successfully applied in natural language processing, outperforming other models in mainstream empirical language processing tasks. We show how this approach can be generalized to conceptual space models of cognition. In order to do this, first we introduce the category of convex relations as a new setting for categorical compositional semantics, emphasizing the convex structure important to conceptual space applications. We then show how to construct conceptual spaces for various types such as nouns, adjectives and verbs. Finally we show by means of examples how concepts can be systematically combined to establish the meanings of composite phrases from the meanings of their constituent parts. This provides the mathematical underpinnings of a new compositional approach to cognition.|categor composit approach mean success appli natur languag process outperform model mainstream empir languag process task show approach general conceptu space model cognit order first introduc categori convex relat new set categor composit semant emphas convex structur import conceptu space applic show construct conceptu space various type noun adject verb final show mean exampl concept systemat combin establish mean composit phrase mean constitu part provid mathemat underpin new composit approach cognit|['Joe Bolt', 'Bob Coecke', 'Fabrizio Genovese', 'Martha Lewis', 'Dan Marsden', 'Robin Piedeleu']|['cs.LO', 'cs.CL']
2017-03-28T14:06:02Z|2017-03-23T22:20:45Z|http://arxiv.org/abs/1703.08244v1|http://arxiv.org/pdf/1703.08244v1|TokTrack: A Complete Token Provenance and Change Tracking Dataset for   the English Wikipedia|toktrack complet token proven chang track dataset english wikipedia|We present a dataset that contains every instance of all tokens (~ words) ever written in undeleted, non-redirect English Wikipedia articles until October 2016, in total 13,545,349,787 instances. Each token is annotated with (i) the article revision it was originally created in, and (ii) lists with all the revisions in which the token was ever deleted and (potentially) re-added and re-deleted from its article, enabling a complete and straightforward tracking of its history. This data would be exceedingly hard to create by an average potential user as it is (i) very expensive to compute and as (ii) accurately tracking the history of each token in revisioned documents is a non-trivial task. Adapting a state-of-the-art algorithm, we have produced a dataset that allows for a range of analyses and metrics, already popular in research and going beyond, to be generated on complete-Wikipedia scale; ensuring quality and allowing researchers to forego expensive text-comparison computation, which so far has hindered scalable usage. We show how this data enables, on token-level, computation of provenance, measuring survival of content over time, very detailed conflict metrics, and fine-grained interactions of editors like partial reverts, re-additions and other metrics, in the process gaining several novel insights.|present dataset contain everi instanc token word ever written undelet non redirect english wikipedia articl octob total instanc token annot articl revis origin creat ii list revis token ever delet potenti ad delet articl enabl complet straightforward track histori data would exceed hard creat averag potenti user veri expens comput ii accur track histori token revis document non trivial task adapt state art algorithm produc dataset allow rang analys metric alreadi popular research go beyond generat complet wikipedia scale ensur qualiti allow research forego expens text comparison comput far hinder scalabl usag show data enabl token level comput proven measur surviv content time veri detail conflict metric fine grain interact editor like partial revert addit metric process gain sever novel insight|['Fabian Flöck', 'Kenan Erdogan', 'Maribel Acosta']|['cs.CL']
2017-03-28T14:06:02Z|2017-03-23T16:46:00Z|http://arxiv.org/abs/1703.08136v1|http://arxiv.org/pdf/1703.08136v1|Visually grounded learning of keyword prediction from untranscribed   speech|visual ground learn keyword predict untranscrib speech|"During language acquisition, infants have the benefit of visual cues to ground spoken language. Robots similarly have access to audio and visual sensors. Recent work has shown that images and spoken captions can be mapped into a meaningful common space, allowing images to be retrieved using speech and vice versa. In this setting of images paired with untranscribed spoken captions, we consider whether computer vision systems can be used to obtain textual labels for the speech. Concretely, we use an image-to-words multi-label visual classifier to tag images with soft textual labels, and then train a neural network to map from the speech to these soft targets. We show that the resulting speech system is able to predict which words occur in an utterance---acting as a spoken bag-of-words classifier---without seeing any parallel speech and text. We find that the model often confuses semantically related words, e.g. ""man"" and ""person"", making it even more effective as a semantic keyword spotter."|dure languag acquisit infant benefit visual cue ground spoken languag robot similar access audio visual sensor recent work shown imag spoken caption map meaning common space allow imag retriev use speech vice versa set imag pair untranscrib spoken caption consid whether comput vision system use obtain textual label speech concret use imag word multi label visual classifi tag imag soft textual label train neural network map speech soft target show result speech system abl predict word occur utter act spoken bag word classifi without see ani parallel speech text find model often confus semant relat word man person make even effect semant keyword spotter|['Herman Kamper', 'Shane Settle', 'Gregory Shakhnarovich', 'Karen Livescu']|['cs.CL', 'cs.CV']
2017-03-28T14:06:02Z|2017-03-23T16:45:22Z|http://arxiv.org/abs/1703.08135v1|http://arxiv.org/pdf/1703.08135v1|An embedded segmental k-means model for unsupervised segmentation and   clustering of speech|embed segment mean model unsupervis segment cluster speech|Unsupervised segmentation and clustering of unlabelled speech are core problems in zero-resource speech processing. Most competitive approaches lie at methodological extremes: some follow a Bayesian approach, defining probabilistic models with convergence guarantees, while others opt for more efficient heuristic techniques. Here we introduce an approximation to a segmental Bayesian model that falls in between, with a clear objective function but using hard clustering and segmentation rather than full Bayesian inference. Like its Bayesian counterpart, this embedded segmental k-means model (ES-KMeans) represents arbitrary-length word segments as fixed-dimensional acoustic word embeddings. On English and Xitsonga data, ES-KMeans outperforms a leading heuristic method in word segmentation, giving similar scores to the Bayesian model while being five times faster with fewer hyperparameters. However, there is a trade-off in cluster purity, with the Bayesian model's purer clusters yielding about 10% better unsupervised word error rates.|unsupervis segment cluster unlabel speech core problem zero resourc speech process competit approach lie methodolog extrem follow bayesian approach defin probabilist model converg guarante opt effici heurist techniqu introduc approxim segment bayesian model fall clear object function use hard cluster segment rather full bayesian infer like bayesian counterpart embed segment mean model es kmean repres arbitrari length word segment fix dimension acoust word embed english xitsonga data es kmean outperform lead heurist method word segment give similar score bayesian model five time faster fewer hyperparamet howev trade cluster puriti bayesian model purer cluster yield better unsupervis word error rate|['Herman Kamper', 'Karen Livescu', 'Sharon Goldwater']|['cs.CL', 'cs.LG']
2017-03-28T14:06:07Z|2017-03-23T15:57:23Z|http://arxiv.org/abs/1703.08120v1|http://arxiv.org/pdf/1703.08120v1|Recurrent and Contextual Models for Visual Question Answering|recurr contextu model visual question answer|We propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the Visual7W dataset. Motivated by divergent trends in model complexities in the literature, we explore the balance between model expressiveness and simplicity by studying incrementally more complex architectures. We start with LSTM-encoding of input questions and answers; build on this with context generation by LSTM-encodings of neural image and question representations and attention over images; and evaluate the diversity and predictive power of our models and the ensemble thereof. All models are evaluated against a simple baseline inspired by the current state-of-the-art, consisting of involving simple concatenation of bag-of-words and CNN representations for the text and images, respectively. Generally, we observe marked variation in image-reasoning performance between our models not obvious from their overall performance, as well as evidence of dataset bias. Our standalone models achieve accuracies up to $64.6\%$, while the ensemble of all models achieves the best accuracy of $66.67\%$, within $0.5\%$ of the current state-of-the-art for Visual7W.|propos seri recurr contextu neural network model multipl choic visual question answer visualw dataset motiv diverg trend model complex literatur explor balanc model express simplic studi increment complex architectur start lstm encod input question answer build context generat lstm encod neural imag question represent attent imag evalu divers predict power model ensembl thereof model evalu simpl baselin inspir current state art consist involv simpl concaten bag word cnn represent text imag respect general observ mark variat imag reason perform model obvious overal perform well evid dataset bias standalon model achiev accuraci ensembl model achiev best accuraci within current state art visualw|['Abhijit Sharang', 'Eric Lau']|['cs.CL', 'cs.CV']
2017-03-28T14:06:07Z|2017-03-23T15:15:26Z|http://arxiv.org/abs/1703.08098v1|http://arxiv.org/pdf/1703.08098v1|An overview of embedding models of entities and relationships for   knowledge base completion|overview embed model entiti relationship knowledg base complet|Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform knowledge base completion, i.e., predict whether a relationship not in the knowledge base is likely to be true. This article presents an overview of embedding models of entities and relationships for knowledge base completion, with up-to-date experimental results on two standard evaluation tasks of link prediction (i.e. entity prediction) and triple classification.|knowledg base real world fact entiti relationship use resourc varieti natur languag process task howev becaus knowledg base typic incomplet use abl perform knowledg base complet predict whether relationship knowledg base like true articl present overview embed model entiti relationship knowledg base complet date experiment result two standard evalu task link predict entiti predict tripl classif|['Dat Quoc Nguyen']|['cs.CL', 'cs.AI', 'cs.IR']
2017-03-28T14:06:07Z|2017-03-25T00:00:00Z|http://arxiv.org/abs/1703.08088v2|http://arxiv.org/abs/1703.08088v2|Rapid-Rate: A Framework for Semi-supervised Real-time Sentiment Trend   Detection in Unstructured Big Data|rapid rate framework semi supervis real time sentiment trend detect unstructur big data|Commercial establishments like restaurants, service centres and retailers have several sources of customer feedback about products and services, most of which need not be as structured as rated reviews provided by services like Yelp, or Amazon, in terms of sentiment conveyed. For instance, Amazon provides a fine-grained score on a numeric scale for product reviews. Some sources, however, like social media (Twitter, Facebook), mailing lists (Google Groups) and forums (Quora) contain text data that is much more voluminous, but unstructured and unlabelled. It might be in the best interests of a business establishment to assess the general sentiment towards their brand on these platforms as well. This text could be pipelined into a system with a built-in prediction model, with the objective of generating real-time graphs on opinion and sentiment trends. Although such tasks like the one described about have been explored with respect to document classification problems in the past, the implementation described in this paper, by virtue of learning a continuous function rather than a discrete one, offers a lot more depth of insight as compared to document classification approaches. This study aims to explore the validity of such a continuous function predicting model to quantify sentiment about an entity, without the additional overhead of manual labelling, and computational preprocessing & feature extraction. This research project also aims to design and implement a re-usable document regression pipeline as a framework, Rapid-Rate, that can be used to predict document scores in real-time.|commerci establish like restaur servic centr retail sever sourc custom feedback product servic need structur rate review provid servic like yelp amazon term sentiment convey instanc amazon provid fine grain score numer scale product review sourc howev like social media twitter facebook mail list googl group forum quora contain text data much volumin unstructur unlabel might best interest busi establish assess general sentiment toward brand platform well text could pipelin system built predict model object generat real time graph opinion sentiment trend although task like one describ explor respect document classif problem past implement describ paper virtu learn continu function rather discret one offer lot depth insight compar document classif approach studi aim explor valid continu function predict model quantifi sentiment entiti without addit overhead manual label comput preprocess featur extract research project also aim design implement usabl document regress pipelin framework rapid rate use predict document score real time|['Vineet John']|['cs.CL', '68T50']
2017-03-28T14:06:07Z|2017-03-23T14:20:52Z|http://arxiv.org/abs/1703.08084v1|http://arxiv.org/pdf/1703.08084v1|Multimodal Compact Bilinear Pooling for Multimodal Neural Machine   Translation|multimod compact bilinear pool multimod neural machin translat|In state-of-the-art Neural Machine Translation, an attention mechanism is used during decoding to enhance the translation. At every step, the decoder uses this mechanism to focus on different parts of the source sentence to gather the most useful information before outputting its target word. Recently, the effectiveness of the attention mechanism has also been explored for multimodal tasks, where it becomes possible to focus both on sentence parts and image regions. Approaches to pool two modalities usually include element-wise product, sum or concatenation. In this paper, we evaluate the more advanced Multimodal Compact Bilinear pooling method, which takes the outer product of two vectors to combine the attention features for the two modalities. This has been previously investigated for visual question answering. We try out this approach for multimodal image caption translation and show improvements compared to basic combination methods.|state art neural machin translat attent mechan use dure decod enhanc translat everi step decod use mechan focus differ part sourc sentenc gather use inform befor output target word recent effect attent mechan also explor multimod task becom possibl focus sentenc part imag region approach pool two modal usual includ element wise product sum concaten paper evalu advanc multimod compact bilinear pool method take outer product two vector combin attent featur two modal previous investig visual question answer tri approach multimod imag caption translat show improv compar basic combin method|['Jean-Benoit Delbrouck', 'Stephane Dupont']|['cs.CL']
2017-03-28T14:06:07Z|2017-03-23T13:48:45Z|http://arxiv.org/abs/1703.08068v1|http://arxiv.org/pdf/1703.08068v1|Sequential Recurrent Neural Networks for Language Modeling|sequenti recurr neural network languag model|Feedforward Neural Network (FNN)-based language models estimate the probability of the next word based on the history of the last N words, whereas Recurrent Neural Networks (RNN) perform the same task based only on the last word and some context information that cycles in the network. This paper presents a novel approach, which bridges the gap between these two categories of networks. In particular, we propose an architecture which takes advantage of the explicit, sequential enumeration of the word history in FNN structure while enhancing each word representation at the projection layer through recurrent context information that evolves in the network. The context integration is performed using an additional word-dependent weight matrix that is also learned during the training. Extensive experiments conducted on the Penn Treebank (PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a significant reduction of the perplexity when compared to state-of-the-art feedforward as well as recurrent neural network architectures.|feedforward neural network fnn base languag model estim probabl next word base histori last word wherea recurr neural network rnn perform task base onli last word context inform cycl network paper present novel approach bridg gap two categori network particular propos architectur take advantag explicit sequenti enumer word histori fnn structur enhanc word represent project layer recurr context inform evolv network context integr perform use addit word depend weight matrix also learn dure train extens experi conduct penn treebank ptb larg text compress benchmark ltcb corpus show signific reduct perplex compar state art feedforward well recurr neural network architectur|['Youssef Oualil', 'Clayton Greenberg', 'Mittul Singh', 'Dietrich Klakow']|['cs.CL']
2017-03-28T14:06:07Z|2017-03-23T13:00:14Z|http://arxiv.org/abs/1703.08052v1|http://arxiv.org/pdf/1703.08052v1|Dynamic Bernoulli Embeddings for Language Evolution|dynam bernoulli embed languag evolut|Word embeddings are a powerful approach for unsupervised analysis of language. Recently, Rudolph et al. (2016) developed exponential family embeddings, which cast word embeddings in a probabilistic framework. Here, we develop dynamic embeddings, building on exponential family embeddings to capture how the meanings of words change over time. We use dynamic embeddings to analyze three large collections of historical texts: the U.S. Senate speeches from 1858 to 2009, the history of computer science ACM abstracts from 1951 to 2014, and machine learning papers on the Arxiv from 2007 to 2015. We find dynamic embeddings provide better fits than classical embeddings and capture interesting patterns about how language changes.|word embed power approach unsupervis analysi languag recent rudolph et al develop exponenti famili embed cast word embed probabilist framework develop dynam embed build exponenti famili embed captur mean word chang time use dynam embed analyz three larg collect histor text senat speech histori comput scienc acm abstract machin learn paper arxiv find dynam embed provid better fit classic embed captur interest pattern languag chang|['Maja Rudolph', 'David Blei']|['stat.ML', 'cs.CL']
2017-03-28T14:06:07Z|2017-03-23T11:02:47Z|http://arxiv.org/abs/1703.08002v1|http://arxiv.org/pdf/1703.08002v1|A network of deep neural networks for distant speech recognition|network deep neural network distant speech recognit|Despite the remarkable progress recently made in distant speech recognition, state-of-the-art technology still suffers from a lack of robustness, especially when adverse acoustic conditions characterized by non-stationary noises and reverberation are met. A prominent limitation of current systems lies in the lack of matching and communication between the various technologies involved in the distant speech recognition process. The speech enhancement and speech recognition modules are, for instance, often trained independently. Moreover, the speech enhancement normally helps the speech recognizer, but the output of the latter is not commonly used, in turn, to improve the speech enhancement. To address both concerns, we propose a novel architecture based on a network of deep neural networks, where all the components are jointly trained and better cooperate with each other thanks to a full communication scheme between them. Experiments, conducted using different datasets, tasks and acoustic conditions, revealed that the proposed framework can overtake other competitive solutions, including recent joint training approaches.|despit remark progress recent made distant speech recognit state art technolog still suffer lack robust especi advers acoust condit character non stationari nois reverber met promin limit current system lie lack match communic various technolog involv distant speech recognit process speech enhanc speech recognit modul instanc often train independ moreov speech enhanc normal help speech recogn output latter common use turn improv speech enhanc address concern propos novel architectur base network deep neural network compon joint train better cooper thank full communic scheme experi conduct use differ dataset task acoust condit reveal propos framework overtak competit solut includ recent joint train approach|['Mirco Ravanelli', 'Philemon Brakel', 'Maurizio Omologo', 'Yoshua Bengio']|['cs.CL', 'cs.LG']
2017-03-28T14:06:07Z|2017-03-22T18:20:07Z|http://arxiv.org/abs/1703.07805v1|http://arxiv.org/abs/1703.07805v1|Supervised Typing of Big Graphs using Semantic Embeddings|supervis type big graph use semant embed|We propose a supervised algorithm for generating type embeddings in the same semantic vector space as a given set of entity embeddings. The algorithm is agnostic to the derivation of the underlying entity embeddings. It does not require any manual feature engineering, generalizes well to hundreds of types and achieves near-linear scaling on Big Graphs containing many millions of triples and instances by virtue of an incremental execution. We demonstrate the utility of the embeddings on a type recommendation task, outperforming a non-parametric feature-agnostic baseline while achieving 15x speedup and near-constant memory usage on a full partition of DBpedia. Using state-of-the-art visualization, we illustrate the agreement of our extensionally derived DBpedia type embeddings with the manually curated domain ontology. Finally, we use the embeddings to probabilistically cluster about 4 million DBpedia instances into 415 types in the DBpedia ontology.|propos supervis algorithm generat type embed semant vector space given set entiti embed algorithm agnost deriv entiti embed doe requir ani manual featur engin general well hundr type achiev near linear scale big graph contain mani million tripl instanc virtu increment execut demonstr util embed type recommend task outperform non parametr featur agnost baselin achiev speedup near constant memori usag full partit dbpedia use state art visual illustr agreement extension deriv dbpedia type embed manual curat domain ontolog final use embed probabilist cluster million dbpedia instanc type dbpedia ontolog|['Mayank Kejriwal', 'Pedro Szekely']|['cs.CL', 'cs.AI']
2017-03-28T14:06:07Z|2017-03-22T17:17:16Z|http://arxiv.org/abs/1703.07754v1|http://arxiv.org/pdf/1703.07754v1|Direct Acoustics-to-Word Models for English Conversational Speech   Recognition|direct acoust word model english convers speech recognit|Recent work on end-to-end automatic speech recognition (ASR) has shown that the connectionist temporal classification (CTC) loss can be used to convert acoustics to phone or character sequences. Such systems are used with a dictionary and separately-trained Language Model (LM) to produce word sequences. However, they are not truly end-to-end in the sense of mapping acoustics directly to words without an intermediate phone representation. In this paper, we present the first results employing direct acoustics-to-word CTC models on two well-known public benchmark tasks: Switchboard and CallHome. These models do not require an LM or even a decoder at run-time and hence recognize speech with minimal complexity. However, due to the large number of word output units, CTC word models require orders of magnitude more data to train reliably compared to traditional systems. We present some techniques to mitigate this issue. Our CTC word model achieves a word error rate of 13.0%/18.8% on the Hub5-2000 Switchboard/CallHome test sets without any LM or decoder compared with 9.6%/16.0% for phone-based CTC with a 4-gram LM. We also present rescoring results on CTC word model lattices to quantify the performance benefits of a LM, and contrast the performance of word and phone CTC models.|recent work end end automat speech recognit asr shown connectionist tempor classif ctc loss use convert acoust phone charact sequenc system use dictionari separ train languag model lm produc word sequenc howev truli end end sens map acoust direct word without intermedi phone represent paper present first result employ direct acoust word ctc model two well known public benchmark task switchboard callhom model requir lm even decod run time henc recogn speech minim complex howev due larg number word output unit ctc word model requir order magnitud data train reliabl compar tradit system present techniqu mitig issu ctc word model achiev word error rate hub switchboard callhom test set without ani lm decod compar phone base ctc gram lm also present rescor result ctc word model lattic quantifi perform benefit lm contrast perform word phone ctc model|['Kartik Audhkhasi', 'Bhuvana Ramabhadran', 'George Saon', 'Michael Picheny', 'David Nahamoo']|['cs.CL', 'cs.NE', 'stat.ML']
2017-03-28T14:06:07Z|2017-03-22T15:42:28Z|http://arxiv.org/abs/1703.07713v1|http://arxiv.org/pdf/1703.07713v1|Hierarchical RNN with Static Sentence-Level Attention for Text-Based   Speaker Change Detection|hierarch rnn static sentenc level attent text base speaker chang detect|Traditional speaker change detection in dialogues is typically based on audio input. In some scenarios, however, researchers can only obtain text, and do not have access to raw audio signals. Moreover, with the increasing need of deep semantic processing, text-based dialogue understanding is attracting more attention in the community. These raise the problem of text-based speaker change detection. In this paper, we formulate the task as a matching problem of utterances before and after a certain decision point; we propose a hierarchical recurrent neural network (RNN) with static sentence-level attention. Our model comprises three main components: a sentence encoder with a long short term memory (LSTM)-based RNN, a context encoder with another LSTM-RNN, and a static sentence-level attention mechanism, which allows rich information interaction. Experimental results show that neural networks consistently achieve better performance than feature-based approaches, and that our attention-based model significantly outperforms non-attention neural networks.|tradit speaker chang detect dialogu typic base audio input scenario howev research onli obtain text access raw audio signal moreov increas need deep semant process text base dialogu understand attract attent communiti rais problem text base speaker chang detect paper formul task match problem utter befor certain decis point propos hierarch recurr neural network rnn static sentenc level attent model compris three main compon sentenc encod long short term memori lstm base rnn context encod anoth lstm rnn static sentenc level attent mechan allow rich inform interact experiment result show neural network consist achiev better perform featur base approach attent base model signific outperform non attent neural network|['Zhao Meng', 'Lili Mou', 'Zhi Jin']|['cs.CL']
2017-03-28T14:06:12Z|2017-03-22T10:08:51Z|http://arxiv.org/abs/1703.07588v1|http://arxiv.org/pdf/1703.07588v1|Gate Activation Signal Analysis for Gated Recurrent Neural Networks and   Its Correlation with Phoneme Boundaries|gate activ signal analysi gate recurr neural network correl phonem boundari|In this paper we analyze the gate activation signals inside the gated recurrent neural networks, and find the temporal structure of such signals is highly correlated with the phoneme boundaries. This correlation is further verified by a set of experiments for phoneme segmentation, in which better results compared to standard approaches were obtained.|paper analyz gate activ signal insid gate recurr neural network find tempor structur signal high correl phonem boundari correl verifi set experi phonem segment better result compar standard approach obtain|['Yu-Hsuan Wang', 'Cheng-Tao Chung', 'Hung-yi Lee']|['cs.SD', 'cs.CL', 'cs.LG']
2017-03-28T14:06:12Z|2017-03-22T00:37:33Z|http://arxiv.org/abs/1703.07476v1|http://arxiv.org/pdf/1703.07476v1|Topic Identification for Speech without ASR|topic identif speech without asr|Modern topic identification (topic ID) systems for speech use automatic speech recognition (ASR) to produce speech transcripts, and perform supervised classification on such ASR outputs. However, under resource-limited conditions, the manually transcribed speech required to develop standard ASR systems can be severely limited or unavailable. In this paper, we investigate alternative unsupervised solutions to obtaining tokenizations of speech in terms of a vocabulary of automatically discovered word-like or phoneme-like units, without depending on the supervised training of ASR systems. Moreover, using automatic phoneme-like tokenizations, we demonstrate that a convolutional neural network based framework for learning spoken document representations provides competitive performance compared to a standard bag-of-words representation, as evidenced by comprehensive topic ID evaluations on both single-label and multi-label classification tasks.|modern topic identif topic id system speech use automat speech recognit asr produc speech transcript perform supervis classif asr output howev resourc limit condit manual transcrib speech requir develop standard asr system sever limit unavail paper investig altern unsupervis solut obtain token speech term vocabulari automat discov word like phonem like unit without depend supervis train asr system moreov use automat phonem like token demonstr convolut neural network base framework learn spoken document represent provid competit perform compar standard bag word represent evidenc comprehens topic id evalu singl label multi label classif task|['Chunxi Liu', 'Jan Trmal', 'Matthew Wiesner', 'Craig Harman', 'Sanjeev Khudanpur']|['cs.CL']
2017-03-28T14:06:12Z|2017-03-21T21:36:28Z|http://arxiv.org/abs/1703.07438v1|http://arxiv.org/pdf/1703.07438v1|The NLTK FrameNet API: Designing for Discoverability with a Rich   Linguistic Resource|nltk framenet api design discover rich linguist resourc|A new Python API, integrated within the NLTK suite, offers access to the FrameNet 1.7 lexical database. The lexicon (structured in terms of frames) as well as annotated sentences can be processed programatically, or browsed with human-readable displays via the interactive Python prompt.|new python api integr within nltk suit offer access framenet lexic databas lexicon structur term frame well annot sentenc process programat brows human readabl display via interact python prompt|['Nathan Schneider', 'Chuck Wooters']|['cs.CL']
2017-03-28T14:06:12Z|2017-03-21T08:24:50Z|http://arxiv.org/abs/1703.07090v1|http://arxiv.org/pdf/1703.07090v1|Deep LSTM for Large Vocabulary Continuous Speech Recognition|deep lstm larg vocabulari continu speech recognit|Recurrent neural networks (RNNs), especially long short-term memory (LSTM) RNNs, are effective network for sequential task like speech recognition. Deeper LSTM models perform well on large vocabulary continuous speech recognition, because of their impressive learning ability. However, it is more difficult to train a deeper network. We introduce a training framework with layer-wise training and exponential moving average methods for deeper LSTM models. It is a competitive framework that LSTM models of more than 7 layers are successfully trained on Shenma voice search data in Mandarin and they outperform the deep LSTM models trained by conventional approach. Moreover, in order for online streaming speech recognition applications, the shallow model with low real time factor is distilled from the very deep model. The recognition accuracy have little loss in the distillation process. Therefore, the model trained with the proposed training framework reduces relative 14\% character error rate, compared to original model which has the similar real-time capability. Furthermore, the novel transfer learning strategy with segmental Minimum Bayes-Risk is also introduced in the framework. The strategy makes it possible that training with only a small part of dataset could outperform full dataset training from the beginning.|recurr neural network rnns especi long short term memori lstm rnns effect network sequenti task like speech recognit deeper lstm model perform well larg vocabulari continu speech recognit becaus impress learn abil howev difficult train deeper network introduc train framework layer wise train exponenti move averag method deeper lstm model competit framework lstm model layer success train shenma voic search data mandarin outperform deep lstm model train convent approach moreov order onlin stream speech recognit applic shallow model low real time factor distil veri deep model recognit accuraci littl loss distil process therefor model train propos train framework reduc relat charact error rate compar origin model similar real time capabl furthermor novel transfer learn strategi segment minimum bay risk also introduc framework strategi make possibl train onli small part dataset could outperform full dataset train begin|['Xu Tian', 'Jun Zhang', 'Zejun Ma', 'Yi He', 'Juan Wei', 'Peihao Wu', 'Wenchang Situ', 'Shuai Li', 'Yang Zhang']|['cs.CL']
2017-03-28T14:06:12Z|2017-03-21T04:56:14Z|http://arxiv.org/abs/1703.07055v1|http://arxiv.org/pdf/1703.07055v1|Investigation of Language Understanding Impact for Reinforcement   Learning Based Dialogue Systems|investig languag understand impact reinforc learn base dialogu system|Language understanding is a key component in a spoken dialogue system. In this paper, we investigate how the language understanding module influences the dialogue system performance by conducting a series of systematic experiments on a task-oriented neural dialogue system in a reinforcement learning based setting. The empirical study shows that among different types of language understanding errors, slot-level errors can have more impact on the overall performance of a dialogue system compared to intent-level errors. In addition, our experiments demonstrate that the reinforcement learning based dialogue system is able to learn when and what to confirm in order to achieve better performance and greater robustness.|languag understand key compon spoken dialogu system paper investig languag understand modul influenc dialogu system perform conduct seri systemat experi task orient neural dialogu system reinforc learn base set empir studi show among differ type languag understand error slot level error impact overal perform dialogu system compar intent level error addit experi demonstr reinforc learn base dialogu system abl learn confirm order achiev better perform greater robust|['Xiujun Li', 'Yun-Nung Chen', 'Lihong Li', 'Jianfeng Gao', 'Asli Celikyilmaz']|['cs.CL', 'cs.AI', 'cs.LG']
2017-03-28T14:06:12Z|2017-03-20T11:11:38Z|http://arxiv.org/abs/1703.06676v1|http://arxiv.org/pdf/1703.06676v1|I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation|iti learn text imag synthesi textual data augment|Translating information between text and image is a fundamental problem in artificial intelligence that connects natural language processing and computer vision. In the past few years, performance in image caption generation has seen significant improvement through the adoption of recurrent neural networks (RNN). Meanwhile, text-to-image generation begun to generate plausible images using datasets of specific categories like birds and flowers. We've even seen image generation from multi-category datasets such as the Microsoft Common Objects in Context (MSCOCO) through the use of generative adversarial networks (GANs). Synthesizing objects with a complex shape, however, is still challenging. For example, animals and humans have many degrees of freedom, which means that they can take on many complex shapes. We propose a new training method called Image-Text-Image (I2T2I) which integrates text-to-image and image-to-text (image captioning) synthesis to improve the performance of text-to-image synthesis. We demonstrate that %the capability of our method to understand the sentence descriptions, so as to I2T2I can generate better multi-categories images using MSCOCO than the state-of-the-art. We also demonstrate that I2T2I can achieve transfer learning by using a pre-trained image captioning module to generate human images on the MPII Human Pose|translat inform text imag fundament problem artifici intellig connect natur languag process comput vision past year perform imag caption generat seen signific improv adopt recurr neural network rnn meanwhil text imag generat begun generat plausibl imag use dataset specif categori like bird flower even seen imag generat multi categori dataset microsoft common object context mscoco use generat adversari network gan synthes object complex shape howev still challeng exampl anim human mani degre freedom mean take mani complex shape propos new train method call imag text imag iti integr text imag imag text imag caption synthesi improv perform text imag synthesi demonstr capabl method understand sentenc descript iti generat better multi categori imag use mscoco state art also demonstr iti achiev transfer learn use pre train imag caption modul generat human imag mpii human pose|['Hao Dong', 'Jingqing Zhang', 'Douglas McIlwraith', 'Yike Guo']|['cs.CV', 'cs.CL']
2017-03-28T14:06:12Z|2017-03-20T09:28:38Z|http://arxiv.org/abs/1703.06642v1|http://arxiv.org/pdf/1703.06642v1|Towards a Quantum World Wide Web|toward quantum world wide web|We elaborate a quantum model for corpora of written documents, like the pages forming the World Wide Web. To that end, we are guided by how physicists constructed quantum theory for microscopic entities, which unlike classical objects cannot be fully represented in our spatial theater. We suggest that a similar construction needs to be carried out by linguists and computational scientists, to capture the full meaning content of collections of documental entities. More precisely, we show how to associate a quantum-like 'entity of meaning' to a 'language entity formed by printed documents', considering the latter as the collection of traces that are left by the former, in specific results of search actions that we describe as measurements. In other words, we offer a perspective where a collection of documents, like the Web, is described as the space of manifestation of a more complex entity - the QWeb - which is the object of our modeling, drawing its inspiration from previous studies on operational-realistic approaches to quantum physics and quantum modeling of human cognition and decision-making. We emphasize that a consistent QWeb model needs to account for the observed correlations between words appearing in printed documents, e.g., co-occurrences, as the latter would depend on the 'meaning connections' existing between the concepts that are associated with these words. In that respect, we show that both 'context and interference (quantum) effects' are required to explain the probabilities calculated by counting the relative number of documents containing certain words and co-ocurrrences of words.|elabor quantum model corpora written document like page form world wide web end guid physicist construct quantum theori microscop entiti unlik classic object cannot fulli repres spatial theater suggest similar construct need carri linguist comput scientist captur full mean content collect document entiti precis show associ quantum like entiti mean languag entiti form print document consid latter collect trace left former specif result search action describ measur word offer perspect collect document like web describ space manifest complex entiti qweb object model draw inspir previous studi oper realist approach quantum physic quantum model human cognit decis make emphas consist qweb model need account observ correl word appear print document co occurr latter would depend mean connect exist concept associ word respect show context interfer quantum effect requir explain probabl calcul count relat number document contain certain word co ocurrr word|['Diederik Aerts', 'Jonito Aerts Arguelles', 'Lester Beltran', 'Lyneth Beltran', 'Isaac Distrito', 'Massimiliano Sassoli de Bianchi', 'Sandro Sozzo', 'Tomas Veloz']|['cs.AI', 'cs.CL', 'quant-ph']
2017-03-28T14:06:12Z|2017-03-20T08:19:43Z|http://arxiv.org/abs/1703.06630v1|http://arxiv.org/pdf/1703.06630v1|Automatic Text Summarization Approaches to Speed up Topic Model Learning   Process|automat text summar approach speed topic model learn process|The number of documents available into Internet moves each day up. For this reason, processing this amount of information effectively and expressibly becomes a major concern for companies and scientists. Methods that represent a textual document by a topic representation are widely used in Information Retrieval (IR) to process big data such as Wikipedia articles. One of the main difficulty in using topic model on huge data collection is related to the material resources (CPU time and memory) required for model estimate. To deal with this issue, we propose to build topic spaces from summarized documents. In this paper, we present a study of topic space representation in the context of big data. The topic space representation behavior is analyzed on different languages. Experiments show that topic spaces estimated from text summaries are as relevant as those estimated from the complete documents. The real advantage of such an approach is the processing time gain: we showed that the processing time can be drastically reduced using summarized documents (more than 60\% in general). This study finally points out the differences between thematic representations of documents depending on the targeted languages such as English or latin languages.|number document avail internet move day reason process amount inform effect express becom major concern compani scientist method repres textual document topic represent wide use inform retriev ir process big data wikipedia articl one main difficulti use topic model huge data collect relat materi resourc cpu time memori requir model estim deal issu propos build topic space summar document paper present studi topic space represent context big data topic space represent behavior analyz differ languag experi show topic space estim text summari relev estim complet document real advantag approach process time gain show process time drastic reduc use summar document general studi final point differ themat represent document depend target languag english latin languag|['Mohamed Morchid', 'Juan-Manuel Torres-Moreno', 'Richard Dufour', 'Javier Ramírez-Rodríguez', 'Georges Linarès']|['cs.IR', 'cs.CL']
2017-03-28T14:06:12Z|2017-03-21T17:41:23Z|http://arxiv.org/abs/1703.06585v2|http://arxiv.org/pdf/1703.06585v2|Learning Cooperative Visual Dialog Agents with Deep Reinforcement   Learning|learn cooper visual dialog agent deep reinforc learn|We introduce the first goal-driven training for visual question answering and dialog agents. Specifically, we pose a cooperative 'image guessing' game between two agents -- Qbot and Abot -- who communicate in natural language dialog so that Qbot can select an unseen image from a lineup of images. We use deep reinforcement learning (RL) to learn the policies of these agents end-to-end -- from pixels to multi-agent multi-round dialog to game reward.   We demonstrate two experimental results.   First, as a 'sanity check' demonstration of pure RL (from scratch), we show results on a synthetic world, where the agents communicate in ungrounded vocabulary, i.e., symbols with no pre-specified meanings (X, Y, Z). We find that two bots invent their own communication protocol and start using certain symbols to ask/answer about certain visual attributes (shape/color/style). Thus, we demonstrate the emergence of grounded language and communication among 'visual' dialog agents with no human supervision.   Second, we conduct large-scale real-image experiments on the VisDial dataset, where we pretrain with supervised dialog data and show that the RL 'fine-tuned' agents significantly outperform SL agents. Interestingly, the RL Qbot learns to ask questions that Abot is good at, ultimately resulting in more informative dialog and a better team.|introduc first goal driven train visual question answer dialog agent specif pose cooper imag guess game two agent qbot abot communic natur languag dialog qbot select unseen imag lineup imag use deep reinforc learn rl learn polici agent end end pixel multi agent multi round dialog game reward demonstr two experiment result first saniti check demonstr pure rl scratch show result synthet world agent communic unground vocabulari symbol pre specifi mean find two bot invent communic protocol start use certain symbol ask answer certain visual attribut shape color style thus demonstr emerg ground languag communic among visual dialog agent human supervis second conduct larg scale real imag experi visdial dataset pretrain supervis dialog data show rl fine tune agent signific outperform sl agent interest rl qbot learn ask question abot good ultim result inform dialog better team|['Abhishek Das', 'Satwik Kottur', 'José M. F. Moura', 'Stefan Lee', 'Dhruv Batra']|['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']
2017-03-28T14:06:12Z|2017-03-19T23:42:28Z|http://arxiv.org/abs/1703.06541v1|http://arxiv.org/pdf/1703.06541v1|Native Language Identification using Stacked Generalization|nativ languag identif use stack general|Ensemble methods using multiple classifiers have proven to be the most successful approach for the task of Native Language Identification (NLI), achieving the current state of the art. However, a systematic examination of ensemble methods for NLI has yet to be conducted. Additionally, deeper ensemble architectures such as classifier stacking have not been closely evaluated. We present a set of experiments using three ensemble-based models, testing each with multiple configurations and algorithms. This includes a rigorous application of meta-classification models for NLI, achieving state-of-the-art results on three datasets from different languages. We also present the first use of statistical significance testing for comparing NLI systems, showing that our results are significantly better than the previous state of the art. We make available a collection of test set predictions to facilitate future statistical tests.|ensembl method use multipl classifi proven success approach task nativ languag identif nli achiev current state art howev systemat examin ensembl method nli yet conduct addit deeper ensembl architectur classifi stack close evalu present set experi use three ensembl base model test multipl configur algorithm includ rigor applic meta classif model nli achiev state art result three dataset differ languag also present first use statist signific test compar nli system show result signific better previous state art make avail collect test set predict facilit futur statist test|['Shervin Malmasi', 'Mark Dras']|['cs.CL']
2017-03-28T14:06:16Z|2017-03-19T19:56:25Z|http://arxiv.org/abs/1703.06501v1|http://arxiv.org/pdf/1703.06501v1|Métodos de Otimização Combinatória Aplicados ao Problema de   Compressão MultiFrases|todo de otimiza combinat ria aplicado ao problema de compress multifras|The Internet has led to a dramatic increase in the amount of available information. In this context, reading and understanding this flow of information have become costly tasks. In the last years, to assist people to understand textual data, various Natural Language Processing (NLP) applications based on Combinatorial Optimization have been devised. However, for Multi-Sentences Compression (MSC), method which reduces the sentence length without removing core information, the insertion of optimization methods requires further study to improve the performance of MSC. This article describes a method for MSC using Combinatorial Optimization and Graph Theory to generate more informative sentences while maintaining their grammaticality. An experiment led on a corpus of 40 clusters of sentences shows that our system has achieved a very good quality and is better than the state-of-the-art.|internet led dramat increas amount avail inform context read understand flow inform becom cost task last year assist peopl understand textual data various natur languag process nlp applic base combinatori optim devis howev multi sentenc compress msc method reduc sentenc length without remov core inform insert optim method requir studi improv perform msc articl describ method msc use combinatori optim graph theori generat inform sentenc maintain grammat experi led corpus cluster sentenc show system achiev veri good qualiti better state art|['Elvys Linhares Pontes', 'Thiago Gouveia da Silva', 'Andréa Carneiro Linhares', 'Juan-Manuel Torres-Moreno', 'Stéphane Huet']|['cs.CL']
2017-03-28T14:06:16Z|2017-03-19T19:14:55Z|http://arxiv.org/abs/1703.06492v1|http://arxiv.org/pdf/1703.06492v1|VQABQ: Visual Question Answering by Basic Questions|vqabq visual question answer basic question|Taking image and question as the input of our method, it can output the text-based answer of the query question about the given image, so called Visual Question Answering (VQA). There are two main modules in our algorithm. Given a natural language question about an image, the first module takes the question as input and then outputs the basic questions of the main question, given question. The second module takes the main question, image and these basic questions as input and then outputs the text-based answer of the main question. We formulate the basic questions generation problem as a LASSO optimization problem, and also propose a criterion about how to exploit these basic questions to help answer main question. Our method is evaluated on the challenging VQA dataset, and yields the competitive performance compared to state-of-the-art.|take imag question input method output text base answer queri question given imag call visual question answer vqa two main modul algorithm given natur languag question imag first modul take question input output basic question main question given question second modul take main question imag basic question input output text base answer main question formul basic question generat problem lasso optim problem also propos criterion exploit basic question help answer main question method evalu challeng vqa dataset yield competit perform compar state art|['Jia-Hong Huang', 'Modar Alfadly', 'Bernard Ghanem']|['cs.CV', 'cs.CL']
2017-03-28T14:06:16Z|2017-03-18T20:21:44Z|http://arxiv.org/abs/1703.06345v1|http://arxiv.org/pdf/1703.06345v1|Transfer Learning for Sequence Tagging with Hierarchical Recurrent   Networks|transfer learn sequenc tag hierarch recurr network|Recent papers have shown that neural networks obtain state-of-the-art performance on several different sequence tagging tasks. One appealing property of such systems is their generality, as excellent performance can be achieved with a unified architecture and without task-specific feature engineering. However, it is unclear if such systems can be used for tasks without large amounts of training data. In this paper we explore the problem of transfer learning for neural sequence taggers, where a source task with plentiful annotations (e.g., POS tagging on Penn Treebank) is used to improve performance on a target task with fewer available annotations (e.g., POS tagging for microblogs). We examine the effects of transfer learning for deep hierarchical recurrent networks across domains, applications, and languages, and show that significant improvement can often be obtained. These improvements lead to improvements over the current state-of-the-art on several well-studied tasks.|recent paper shown neural network obtain state art perform sever differ sequenc tag task one appeal properti system general excel perform achiev unifi architectur without task specif featur engin howev unclear system use task without larg amount train data paper explor problem transfer learn neural sequenc tagger sourc task plenti annot pos tag penn treebank use improv perform target task fewer avail annot pos tag microblog examin effect transfer learn deep hierarch recurr network across domain applic languag show signific improv often obtain improv lead improv current state art sever well studi task|['Zhilin Yang', 'Ruslan Salakhutdinov', 'William W. Cohen']|['cs.CL', 'cs.LG']
2017-03-28T14:06:16Z|2017-03-17T17:16:02Z|http://arxiv.org/abs/1703.06108v1|http://arxiv.org/abs/1703.06108v1|Global Entity Ranking Across Multiple Languages|global entiti rank across multipl languag|We present work on building a global long-tailed ranking of entities across multiple languages using Wikipedia and Freebase knowledge bases. We identify multiple features and build a model to rank entities using a ground-truth dataset of more than 10 thousand labels. The final system ranks 27 million entities with 75% precision and 48% F1 score. We provide performance evaluation and empirical evidence of the quality of ranking across languages, and open the final ranked lists for future research.|present work build global long tail rank entiti across multipl languag use wikipedia freebas knowledg base identifi multipl featur build model rank entiti use ground truth dataset thousand label final system rank million entiti precis score provid perform evalu empir evid qualiti rank across languag open final rank list futur research|['Prantik Bhattacharyya', 'Nemanja Spasojevic']|['cs.IR', 'cs.CL', 'cs.SI', 'H.3.1']
2017-03-28T14:06:16Z|2017-03-17T07:53:03Z|http://arxiv.org/abs/1703.05916v1|http://arxiv.org/pdf/1703.05916v1|Construction of a Japanese Word Similarity Dataset|construct japanes word similar dataset|An evaluation of distributed word representation is generally conducted using a word similarity task and/or a word analogy task. There are many datasets readily available for these tasks in English. However, evaluating distributed representation in languages that do not have such resources (e.g., Japanese) is difficult. Therefore, as a first step toward evaluating distributed representations in Japanese, we constructed a Japanese word similarity dataset. To the best of our knowledge, our dataset is the first resource that can be used to evaluate distributed representations in Japanese. Moreover, our dataset contains various parts of speech and includes rare words in addition to common words.|evalu distribut word represent general conduct use word similar task word analog task mani dataset readili avail task english howev evalu distribut represent languag resourc japanes difficult therefor first step toward evalu distribut represent japanes construct japanes word similar dataset best knowledg dataset first resourc use evalu distribut represent japanes moreov dataset contain various part speech includ rare word addit common word|['Yuya Sakaizawa', 'Mamoru Komachi']|['cs.CL']
2017-03-28T14:06:16Z|2017-03-20T00:28:07Z|http://arxiv.org/abs/1703.05908v2|http://arxiv.org/pdf/1703.05908v2|Learning Robust Visual-Semantic Embeddings|learn robust visual semant embed|Many of the existing methods for learning joint embedding of images and text use only supervised information from paired images and its textual attributes. Taking advantage of the recent success of unsupervised learning in deep neural networks, we propose an end-to-end learning framework that is able to extract more robust multi-modal representations across domains. The proposed method combines representation learning models (i.e., auto-encoders) together with cross-domain learning criteria (i.e., Maximum Mean Discrepancy loss) to learn joint embeddings for semantic and visual features. A novel technique of unsupervised-data adaptation inference is introduced to construct more comprehensive embeddings for both labeled and unlabeled data. We evaluate our method on Animals with Attributes and Caltech-UCSD Birds 200-2011 dataset with a wide range of applications, including zero and few-shot image recognition and retrieval, from inductive to transductive settings. Empirically, we show that our framework improves over the current state of the art on many of the considered tasks.|mani exist method learn joint embed imag text use onli supervis inform pair imag textual attribut take advantag recent success unsupervis learn deep neural network propos end end learn framework abl extract robust multi modal represent across domain propos method combin represent learn model auto encod togeth cross domain learn criteria maximum mean discrep loss learn joint embed semant visual featur novel techniqu unsupervis data adapt infer introduc construct comprehens embed label unlabel data evalu method anim attribut caltech ucsd bird dataset wide rang applic includ zero shot imag recognit retriev induct transduct set empir show framework improv current state art mani consid task|['Yao-Hung Hubert Tsai', 'Liang-Kang Huang', 'Ruslan Salakhutdinov']|['cs.CV', 'cs.CL', 'cs.LG']
2017-03-28T14:06:16Z|2017-03-17T03:38:48Z|http://arxiv.org/abs/1703.05880v1|http://arxiv.org/pdf/1703.05880v1|Empirical Evaluation of Parallel Training Algorithms on Acoustic   Modeling|empir evalu parallel train algorithm acoust model|Deep learning models (DLMs) are state-of-the-art techniques in speech recognition. However, training good DLMs can be time consuming especially for production-size models and corpora. Although several parallel training algorithms have been proposed to improve training efficiency, there is no clear guidance on which one to choose for the task in hand due to lack of systematic and fair comparison among them. In this paper we aim at filling this gap by comparing four popular parallel training algorithms in speech recognition, namely asynchronous stochastic gradient descent (ASGD), blockwise model-update filtering (BMUF), bulk synchronous parallel (BSP) and elastic averaging stochastic gradient descent (EASGD), on 1000-hour LibriSpeech corpora using feed-forward deep neural networks (DNNs) and convolutional, long short-term memory, DNNs (CLDNNs). Based on our experiments, we recommend using BMUF as the top choice to train acoustic models since it is most stable, scales well with number of GPUs, can achieve reproducible results, and in many cases even outperforms single-GPU SGD. ASGD can be used as a substitute in some cases.|deep learn model dlms state art techniqu speech recognit howev train good dlms time consum especi product size model corpora although sever parallel train algorithm propos improv train effici clear guidanc one choos task hand due lack systemat fair comparison among paper aim fill gap compar four popular parallel train algorithm speech recognit name asynchron stochast gradient descent asgd blockwis model updat filter bmuf bulk synchron parallel bsp elast averag stochast gradient descent easgd hour librispeech corpora use feed forward deep neural network dnns convolut long short term memori dnns cldnns base experi recommend use bmuf top choic train acoust model sinc stabl scale well number gpus achiev reproduc result mani case even outperform singl gpu sgd asgd use substitut case|['Wenpeng Li', 'BinBin Zhang', 'Lei Xie', 'Dong Yu']|['cs.CL', 'cs.LG', 'cs.SD']
2017-03-28T14:06:16Z|2017-03-17T00:02:42Z|http://arxiv.org/abs/1703.05851v1|http://arxiv.org/pdf/1703.05851v1|Temporal Information Extraction for Question Answering Using Syntactic   Dependencies in an LSTM-based Architecture|tempor inform extract question answer use syntact depend lstm base architectur|"In this paper, we propose to use a set of simple, uniform in architecture LSTM-based models to recover different kinds of temporal relations from text. Using the shortest dependency path between entities as input, the same architecture is used to extract intra-sentence, cross-sentence, and document creation time relations. A ""double-checking"" technique reverses entity pairs in classification, boosting the recall of positive cases and reducing misclassifications between opposite classes. An efficient pruning algorithm resolves conflicts globally. Evaluated on QA-TempEval (SemEval2015 Task 5), our proposed technique outperforms state-of-the-art methods by a large margin."|paper propos use set simpl uniform architectur lstm base model recov differ kind tempor relat text use shortest depend path entiti input architectur use extract intra sentenc cross sentenc document creation time relat doubl check techniqu revers entiti pair classif boost recal posit case reduc misclassif opposit class effici prune algorithm resolv conflict global evalu qa tempev semev task propos techniqu outperform state art method larg margin|['Yuanliang Meng', 'Anna Rumshisky', 'Alexey Romanov']|['cs.IR', 'cs.CL']
2017-03-28T14:06:16Z|2017-03-17T04:03:36Z|http://arxiv.org/abs/1703.05706v2|http://arxiv.org/pdf/1703.05706v2|Improving Document Clustering by Eliminating Unnatural Language|improv document cluster elimin unnatur languag|Technical documents contain a fair amount of unnatural language, such as tables, formulas, pseudo-codes, etc. Unnatural language can be an important factor of confusing existing NLP tools. This paper presents an effective method of distinguishing unnatural language from natural language, and evaluates the impact of unnatural language detection on NLP tasks such as document clustering. We view this problem as an information extraction task and build a multiclass classification model identifying unnatural language components into four categories. First, we create a new annotated corpus by collecting slides and papers in various formats, PPT, PDF, and HTML, where unnatural language components are annotated into four categories. We then explore features available from plain text to build a statistical model that can handle any format as long as it is converted into plain text. Our experiments show that removing unnatural language components gives an absolute improvement in document clustering up to 15%. Our corpus and tool are publicly available.|technic document contain fair amount unnatur languag tabl formula pseudo code etc unnatur languag import factor confus exist nlp tool paper present effect method distinguish unnatur languag natur languag evalu impact unnatur languag detect nlp task document cluster view problem inform extract task build multiclass classif model identifi unnatur languag compon four categori first creat new annot corpus collect slide paper various format ppt pdf html unnatur languag compon annot four categori explor featur avail plain text build statist model handl ani format long convert plain text experi show remov unnatur languag compon give absolut improv document cluster corpus tool public avail|['Myungha Jang', 'Jinho D. Choi', 'James Allan']|['cs.IR', 'cs.CL']
2017-03-28T14:06:16Z|2017-03-16T03:15:22Z|http://arxiv.org/abs/1703.05465v1|http://arxiv.org/pdf/1703.05465v1|Neobility at SemEval-2017 Task 1: An Attention-based Sentence Similarity   Model|neobil semev task attent base sentenc similar model|This paper describes a neural-network model which performed competitively (top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task. Our system employs an attention-based recurrent neural network model that optimizes the sentence similarity. In this paper, we describe our participation in the multilingual STS task which measures similarity across English, Spanish, and Arabic.|paper describ neural network model perform competit top semev cross lingual semant textual similar sts task system employ attent base recurr neural network model optim sentenc similar paper describ particip multilingu sts task measur similar across english spanish arab|['Wenli Zhuang', 'Ernie Chang']|['cs.CL']
2017-03-28T14:06:20Z|2017-03-16T01:06:07Z|http://arxiv.org/abs/1703.05320v1|http://arxiv.org/pdf/1703.05320v1|Legal Question Answering using Ranking SVM and Deep Convolutional Neural   Network|legal question answer use rank svm deep convolut neural network|This paper presents a study of employing Ranking SVM and Convolutional Neural Network for two missions: legal information retrieval and question answering in the Competition on Legal Information Extraction/Entailment. For the first task, our proposed model used a triple of features (LSI, Manhattan, Jaccard), and is based on paragraph level instead of article level as in previous studies. In fact, each single-paragraph article corresponds to a particular paragraph in a huge multiple-paragraph article. For the legal question answering task, additional statistical features from information retrieval task integrated into Convolutional Neural Network contribute to higher accuracy.|paper present studi employ rank svm convolut neural network two mission legal inform retriev question answer competit legal inform extract entail first task propos model use tripl featur lsi manhattan jaccard base paragraph level instead articl level previous studi fact singl paragraph articl correspond particular paragraph huge multipl paragraph articl legal question answer task addit statist featur inform retriev task integr convolut neural network contribut higher accuraci|['Phong-Khac Do', 'Huy-Tien Nguyen', 'Chien-Xuan Tran', 'Minh-Tien Nguyen', 'Minh-Le Nguyen']|['cs.CL', 'cs.AI', '14J30 (Primary)', 'H.3; H.3.3; I.2.7']
2017-03-28T14:06:20Z|2017-03-15T23:34:20Z|http://arxiv.org/abs/1703.05423v1|http://arxiv.org/pdf/1703.05423v1|End-to-end optimization of goal-driven and visually grounded dialogue   systems|end end optim goal driven visual ground dialogu system|End-to-end design of dialogue systems has recently become a popular research topic thanks to powerful tools such as encoder-decoder architectures for sequence-to-sequence learning. Yet, most current approaches cast human-machine dialogue management as a supervised learning problem, aiming at predicting the next utterance of a participant given the full history of the dialogue. This vision is too simplistic to render the intrinsic planning problem inherent to dialogue as well as its grounded nature, making the context of a dialogue larger than the sole history. This is why only chit-chat and question answering tasks have been addressed so far using end-to-end architectures. In this paper, we introduce a Deep Reinforcement Learning method to optimize visually grounded task-oriented dialogues, based on the policy gradient algorithm. This approach is tested on a dataset of 120k dialogues collected through Mechanical Turk and provides encouraging results at solving both the problem of generating natural dialogues and the task of discovering a specific object in a complex picture.|end end design dialogu system recent becom popular research topic thank power tool encod decod architectur sequenc sequenc learn yet current approach cast human machin dialogu manag supervis learn problem aim predict next utter particip given full histori dialogu vision simplist render intrins plan problem inher dialogu well ground natur make context dialogu larger sole histori whi onli chit chat question answer task address far use end end architectur paper introduc deep reinforc learn method optim visual ground task orient dialogu base polici gradient algorithm approach test dataset dialogu collect mechan turk provid encourag result solv problem generat natur dialogu task discov specif object complex pictur|['Florian Strub', 'Harm de Vries', 'Jeremie Mary', 'Bilal Piot', 'Aaron Courville', 'Olivier Pietquin']|['cs.CL']
2017-03-28T14:06:20Z|2017-03-15T21:20:44Z|http://arxiv.org/abs/1703.05390v1|http://arxiv.org/pdf/1703.05390v1|Convolutional Recurrent Neural Networks for Small-Footprint Keyword   Spotting|convolut recurr neural network small footprint keyword spot|Keyword spotting (KWS) constitutes a major component of human-technology interfaces. Maximizing the detection accuracy at a low false alarm (FA) rate, while minimizing the footprint size, latency and complexity are the goals for KWS. Towards achieving them, we study Convolutional Recurrent Neural Networks (CRNNs). Inspired by large-scale state-of-the-art speech recognition systems, we combine the strengths of convolutional layers and recurrent layers to exploit local structure and long-range context. We analyze the effect of architecture parameters, and propose training strategies to improve performance. With only ~230k parameters, our CRNN model yields acceptably low latency, and achieves 97.71% accuracy at 0.5 FA/hour for 5 dB signal-to-noise ratio.|keyword spot kws constitut major compon human technolog interfac maxim detect accuraci low fals alarm fa rate minim footprint size latenc complex goal kws toward achiev studi convolut recurr neural network crnns inspir larg scale state art speech recognit system combin strength convolut layer recurr layer exploit local structur long rang context analyz effect architectur paramet propos train strategi improv perform onli paramet crnn model yield accept low latenc achiev accuraci fa hour db signal nois ratio|['Sercan O. Arik', 'Markus Kliegl', 'Rewon Child', 'Joel Hestness', 'Andrew Gibiansky', 'Chris Fougner', 'Ryan Prenger', 'Adam Coates']|['cs.CL', 'cs.AI', 'cs.LG']
2017-03-28T14:06:20Z|2017-03-15T17:01:20Z|http://arxiv.org/abs/1703.05260v1|http://arxiv.org/pdf/1703.05260v1|InScript: Narrative texts annotated with script information|inscript narrat text annot script inform|This paper presents the InScript corpus (Narrative Texts Instantiating Script structure). InScript is a corpus of 1,000 stories centered around 10 different scenarios. Verbs and noun phrases are annotated with event and participant types, respectively. Additionally, the text is annotated with coreference information. The corpus shows rich lexical variation and will serve as a unique resource for the study of the role of script knowledge in natural language processing.|paper present inscript corpus narrat text instanti script structur inscript corpus stori center around differ scenario verb noun phrase annot event particip type respect addit text annot corefer inform corpus show rich lexic variat serv uniqu resourc studi role script knowledg natur languag process|['Ashutosh Modi', 'Tatjana Anikina', 'Simon Ostermann', 'Manfred Pinkal']|['cs.CL', 'cs.AI']
2017-03-28T14:06:20Z|2017-03-16T08:57:29Z|http://arxiv.org/abs/1703.05123v2|http://arxiv.org/pdf/1703.05123v2|Character-based Neural Embeddings for Tweet Clustering|charact base neural embed tweet cluster|In this paper we show how the performance of tweet clustering can be improved by leveraging character-based neural networks. The proposed approach overcomes the limitations related to the vocabulary explosion in the word-based models and allows for the seamless processing of the multilingual content. Our evaluation results and code are available on-line at https://github.com/vendi12/tweet2vec_clustering|paper show perform tweet cluster improv leverag charact base neural network propos approach overcom limit relat vocabulari explos word base model allow seamless process multilingu content evalu result code avail line https github com vendi tweetvec cluster|['Svitlana Vakulenko', 'Lyndon Nixon', 'Mihai Lupu']|['cs.IR', 'cs.CL']
2017-03-28T14:06:20Z|2017-03-15T12:32:34Z|http://arxiv.org/abs/1703.05122v1|http://arxiv.org/pdf/1703.05122v1|Is this word borrowed? An automatic approach to quantify the likeliness   of borrowing in social media|word borrow automat approach quantifi likeli borrow social media|Code-mixing or code-switching are the effortless phenomena of natural switching between two or more languages in a single conversation. Use of a foreign word in a language; however, does not necessarily mean that the speaker is code-switching because often languages borrow lexical items from other languages. If a word is borrowed, it becomes a part of the lexicon of a language; whereas, during code-switching, the speaker is aware that the conversation involves foreign words or phrases. Identifying whether a foreign word used by a bilingual speaker is due to borrowing or code-switching is a fundamental importance to theories of multilingualism, and an essential prerequisite towards the development of language and speech technologies for multilingual communities. In this paper, we present a series of novel computational methods to identify the borrowed likeliness of a word, based on the social media signals. We first propose context based clustering method to sample a set of candidate words from the social media data.Next, we propose three novel and similar metrics based on the usage of these words by the users in different tweets; these metrics were used to score and rank the candidate words indicating their borrowed likeliness. We compare these rankings with a ground truth ranking constructed through a human judgment experiment. The Spearman's rank correlation between the two rankings (nearly 0.62 for all the three metric variants) is more than double the value (0.26) of the most competitive existing baseline reported in the literature. Some other striking observations are, (i) the correlation is higher for the ground truth data elicited from the younger participants (age less than 30) than that from the older participants, and (ii )those participants who use mixed-language for tweeting the least, provide the best signals of borrowing.|code mix code switch effortless phenomena natur switch two languag singl convers use foreign word languag howev doe necessarili mean speaker code switch becaus often languag borrow lexic item languag word borrow becom part lexicon languag wherea dure code switch speaker awar convers involv foreign word phrase identifi whether foreign word use bilingu speaker due borrow code switch fundament import theori multilingu essenti prerequisit toward develop languag speech technolog multilingu communiti paper present seri novel comput method identifi borrow likeli word base social media signal first propos context base cluster method sampl set candid word social media data next propos three novel similar metric base usag word user differ tweet metric use score rank candid word indic borrow likeli compar rank ground truth rank construct human judgment experi spearman rank correl two rank near three metric variant doubl valu competit exist baselin report literatur strike observ correl higher ground truth data elicit younger particip age less older particip ii particip use mix languag tweet least provid best signal borrow|['Jasabanta Patro', 'Bidisha Samanta', 'Saurabh Singh', 'Prithwish Mukherjee', 'Monojit Choudhury', 'Animesh Mukherjee']|['cs.CL']
2017-03-28T14:06:20Z|2017-03-15T04:57:17Z|http://arxiv.org/abs/1703.04929v1|http://arxiv.org/pdf/1703.04929v1|SyntaxNet Models for the CoNLL 2017 Shared Task|syntaxnet model conll share task|"We describe a baseline dependency parsing system for the CoNLL2017 Shared Task. This system, which we call ""ParseySaurus,"" uses the DRAGNN framework [Kong et al, 2017] to combine transition-based recurrent parsing and tagging with character-based word representations. On the v1.3 Universal Dependencies Treebanks, the new system outpeforms the publicly available, state-of-the-art ""Parsey's Cousins"" models by 3.47% absolute Labeled Accuracy Score (LAS) across 52 treebanks."|describ baselin depend pars system conll share task system call parseysaurus use dragnn framework kong et al combin transit base recurr pars tag charact base word represent univers depend treebank new system outpeform public avail state art parsey cousin model absolut label accuraci score las across treebank|['Chris Alberti', 'Daniel Andor', 'Ivan Bogatyy', 'Michael Collins', 'Dan Gillick', 'Lingpeng Kong', 'Terry Koo', 'Ji Ma', 'Mark Omernick', 'Slav Petrov', 'Chayut Thanapirom', 'Zora Tung', 'David Weiss']|['cs.CL']
2017-03-28T14:06:20Z|2017-03-15T04:00:27Z|http://arxiv.org/abs/1703.04914v1|http://arxiv.org/pdf/1703.04914v1|Ensemble of Neural Classifiers for Scoring Knowledge Base Triples|ensembl neural classifi score knowledg base tripl|This paper describes our approach for the triple scoring task at WSDM Cup 2017. The task aims to assign a relevance score for each pair of entities and their types in a knowledge base in order to enhance the ranking results in entity retrieval tasks. We propose an approach wherein the outputs of multiple neural network classifiers are combined using a supervised machine learning model. The experimental results show that our proposed method achieves the best performance in one out of three measures, and performs competitively in the other two measures.|paper describ approach tripl score task wsdm cup task aim assign relev score pair entiti type knowledg base order enhanc rank result entiti retriev task propos approach wherein output multipl neural network classifi combin use supervis machin learn model experiment result show propos method achiev best perform one three measur perform competit two measur|['Ikuya Yamada', 'Motoki Sato', 'Hiroyuki Shindo']|['cs.CL', 'cs.IR']
2017-03-28T14:06:20Z|2017-03-15T03:30:13Z|http://arxiv.org/abs/1703.04908v1|http://arxiv.org/pdf/1703.04908v1|Emergence of Grounded Compositional Language in Multi-Agent Populations|emerg ground composit languag multi agent popul|By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis. However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient. In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations. Towards this end, we propose a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined vocabulary and syntax. We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable.|captur statist pattern larg corpora machin learn enabl signific advanc natur languag process includ machin translat question answer sentiment analysi howev agent intellig interact human simpli captur statist pattern insuffici paper investig ground composit languag emerg mean achiev goal multi agent popul toward end propos multi agent learn environ learn method bring emerg basic composit languag languag repres stream abstract discret symbol utter agent time nonetheless coher structur possess defin vocabulari syntax also observ emerg non verbal communic point guid languag communic unavail|['Igor Mordatch', 'Pieter Abbeel']|['cs.AI', 'cs.CL']
2017-03-28T14:06:20Z|2017-03-15T02:26:25Z|http://arxiv.org/abs/1703.04887v1|http://arxiv.org/pdf/1703.04887v1|Improving Neural Machine Translation with Conditional Sequence   Generative Adversarial Nets|improv neural machin translat condit sequenc generat adversari net|This paper proposes a new route for applying the generative adversarial nets (GANs) to NLP tasks (taking the neural machine translation as an instance) and the widespread perspective that GANs can't work well in the NLP area turns out to be unreasonable. In this work, we build a conditional sequence generative adversarial net which comprises of two adversarial sub models, a generative model (generator) which translates the source sentence into the target sentence as the traditional NMT models do and a discriminative model (discriminator) which discriminates the machine-translated target sentence from the human-translated sentence. From the perspective of Turing test, the proposed model is to generate the translation which is indistinguishable from the human-translated one. Experiments show that the proposed model achieves significant improvements than the traditional NMT model. In Chinese-English translation tasks, we obtain up to +2.0 BLEU points improvement. To the best of our knowledge, this is the first time that the quantitative results about the application of GANs in the traditional NLP task is reported. Meanwhile, we present detailed strategies for GAN training. In addition, We find that the discriminator of the proposed model shows great capability in data cleaning.|paper propos new rout appli generat adversari net gan nlp task take neural machin translat instanc widespread perspect gan work well nlp area turn unreason work build condit sequenc generat adversari net compris two adversari sub model generat model generat translat sourc sentenc target sentenc tradit nmt model discrimin model discrimin discrimin machin translat target sentenc human translat sentenc perspect ture test propos model generat translat indistinguish human translat one experi show propos model achiev signific improv tradit nmt model chines english translat task obtain bleu point improv best knowledg first time quantit result applic gan tradit nlp task report meanwhil present detail strategi gan train addit find discrimin propos model show great capabl data clean|['Zhen Yang', 'Wei Chen', 'Feng Wang', 'Bo Xu']|['cs.CL']
2017-03-28T14:06:24Z|2017-03-15T01:54:52Z|http://arxiv.org/abs/1703.04879v1|http://arxiv.org/pdf/1703.04879v1|Sparse Named Entity Classification using Factorization Machines|spars name entiti classif use factor machin|Named entity classification is the task of classifying text-based elements into various categories, including places, names, dates, times, and monetary values. A bottleneck in named entity classification, however, is the data problem of sparseness, because new named entities continually emerge, making it rather difficult to maintain a dictionary for named entity classification. Thus, in this paper, we address the problem of named entity classification using matrix factorization to overcome the problem of feature sparsity. Experimental results show that our proposed model, with fewer features and a smaller size, achieves competitive accuracy to state-of-the-art models.|name entiti classif task classifi text base element various categori includ place name date time monetari valu bottleneck name entiti classif howev data problem spars becaus new name entiti continu emerg make rather difficult maintain dictionari name entiti classif thus paper address problem name entiti classif use matrix factor overcom problem featur sparsiti experiment result show propos model fewer featur smaller size achiev competit accuraci state art model|['Ai Hirata', 'Mamoru Komachi']|['cs.CL']
2017-03-28T14:06:24Z|2017-03-15T00:47:28Z|http://arxiv.org/abs/1703.04854v1|http://arxiv.org/pdf/1703.04854v1|Distributed-Representation Based Hybrid Recommender System with Short   Item Descriptions|distribut represent base hybrid recommend system short item descript|"Collaborative filtering (CF) aims to build a model from users' past behaviors and/or similar decisions made by other users, and use the model to recommend items for users. Despite of the success of previous collaborative filtering approaches, they are all based on the assumption that there are sufficient rating scores available for building high-quality recommendation models. In real world applications, however, it is often difficult to collect sufficient rating scores, especially when new items are introduced into the system, which makes the recommendation task challenging. We find that there are often ""short"" texts describing features of items, based on which we can approximate the similarity of items and make recommendation together with rating scores. In this paper we ""borrow"" the idea of vector representation of words to capture the information of short texts and embed it into a matrix factorization framework. We empirically show that our approach is effective by comparing it with state-of-the-art approaches."|collabor filter cf aim build model user past behavior similar decis made user use model recommend item user despit success previous collabor filter approach base assumpt suffici rate score avail build high qualiti recommend model real world applic howev often difficult collect suffici rate score especi new item introduc system make recommend task challeng find often short text describ featur item base approxim similar item make recommend togeth rate score paper borrow idea vector represent word captur inform short text emb matrix factor framework empir show approach effect compar state art approach|['Junhua He', 'Hankz Hankui Zhuo', 'Jarvan Law']|['cs.IR', 'cs.CL']
2017-03-28T14:06:24Z|2017-03-14T23:25:34Z|http://arxiv.org/abs/1703.04826v1|http://arxiv.org/pdf/1703.04826v1|Encoding Sentences with Graph Convolutional Networks for Semantic Role   Labeling|encod sentenc graph convolut network semant role label|Semantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard natural language processing pipeline, providing information to downstream tasks such as information extraction and question answering. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of multilayer neural networks operating on graphs, suited to modeling syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence encoders, producing latent feature representations of words in a sentence and capturing information relevant to predicting the semantic representations. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and English.|semant role label srl task identifi predic argument structur sentenc typic regard import step standard natur languag process pipelin provid inform downstream task inform extract question answer semant represent close relat syntact one exploit syntact inform model propos version graph convolut network gcns recent class multilay neural network oper graph suit model syntact depend graph gcns syntact depend tree use sentenc encod produc latent featur represent word sentenc captur inform relev predict semant represent observ gcn layer complementari lstm one stack gcn lstm layer obtain substanti improv alreadi state art lstm srl model result best report score standard benchmark conll chines english|['Diego Marcheggiani', 'Ivan Titov']|['cs.CL', 'cs.LG']
2017-03-28T14:06:24Z|2017-03-14T23:09:45Z|http://arxiv.org/abs/1703.04816v1|http://arxiv.org/pdf/1703.04816v1|FastQA: A Simple and Efficient Neural Architecture for Question   Answering|fastqa simpl effici neural architectur question answer|Recent development of large-scale question answering (QA) datasets triggered a substantial amount of research into end-to-end neural architectures for QA. Increasingly complex systems have been conceived without comparison to a simpler neural baseline system that would justify their complexity. In this work, we propose a simple heuristic that guided the development of FastQA, an efficient end-to-end neural model for question answering that is very competitive with existing models. We further demonstrate, that an extended version (FastQAExt) achieves state-of-the-art results on recent benchmark datasets, namely SQuAD, NewsQA and MsMARCO, outperforming most existing models. However, we show that increasing the complexity of FastQA to FastQAExt does not yield any systematic improvements. We argue that the same holds true for most existing systems that are similar to FastQAExt. A manual analysis reveals that our proposed heuristic explains most predictions of our model, which indicates that modeling a simple heuristic is enough to achieve strong performance on extractive QA datasets. The overall strong performance of FastQA puts results of existing, more complex models into perspective.|recent develop larg scale question answer qa dataset trigger substanti amount research end end neural architectur qa increas complex system conceiv without comparison simpler neural baselin system would justifi complex work propos simpl heurist guid develop fastqa effici end end neural model question answer veri competit exist model demonstr extend version fastqaext achiev state art result recent benchmark dataset name squad newsqa msmarco outperform exist model howev show increas complex fastqa fastqaext doe yield ani systemat improv argu hold true exist system similar fastqaext manual analysi reveal propos heurist explain predict model indic model simpl heurist enough achiev strong perform extract qa dataset overal strong perform fastqa put result exist complex model perspect|['Dirk Weissenborn', 'Georg Wiese', 'Laura Seiffe']|['cs.CL', 'cs.AI', 'cs.NE']
2017-03-28T14:06:24Z|2017-03-14T22:28:51Z|http://arxiv.org/abs/1703.04783v1|http://arxiv.org/pdf/1703.04783v1|Multichannel End-to-end Speech Recognition|multichannel end end speech recognit|The field of speech recognition is in the midst of a paradigm shift: end-to-end neural networks are challenging the dominance of hidden Markov models as a core technology. Using an attention mechanism in a recurrent encoder-decoder architecture solves the dynamic time alignment problem, allowing joint end-to-end training of the acoustic and language modeling components. In this paper we extend the end-to-end framework to encompass microphone array signal processing for noise suppression and speech enhancement within the acoustic encoding network. This allows the beamforming components to be optimized jointly within the recognition architecture to improve the end-to-end speech recognition objective. Experiments on the noisy speech benchmarks (CHiME-4 and AMI) show that our multichannel end-to-end system outperformed the attention-based baseline with input from a conventional adaptive beamformer.|field speech recognit midst paradigm shift end end neural network challeng domin hidden markov model core technolog use attent mechan recurr encod decod architectur solv dynam time align problem allow joint end end train acoust languag model compon paper extend end end framework encompass microphon array signal process nois suppress speech enhanc within acoust encod network allow beamform compon optim joint within recognit architectur improv end end speech recognit object experi noisi speech benchmark chime ami show multichannel end end system outperform attent base baselin input convent adapt beamform|['Tsubasa Ochiai', 'Shinji Watanabe', 'Takaaki Hori', 'John R. Hershey']|['cs.SD', 'cs.CL']
2017-03-28T14:06:24Z|2017-03-14T19:14:32Z|http://arxiv.org/abs/1703.04677v1|http://arxiv.org/pdf/1703.04677v1|A computational investigation of sources of variability in sentence   comprehension difficulty in aphasia|comput investig sourc variabl sentenc comprehens difficulti aphasia|We present a computational evaluation of three hypotheses about sources of deficit in sentence comprehension in aphasia: slowed processing, intermittent deficiency, and resource reduction. The ACT-R based Lewis & Vasishth 2005 model is used to implement these three proposals. Slowed processing is implemented as slowed default production-rule firing time; intermittent deficiency as increased random noise in activation of chunks in memory; and resource reduction as reduced goal activation. As data, we considered subject vs. object relatives presented in a self-paced listening modality to 56 individuals with aphasia (IWA) and 46 matched controls. The participants heard the sentences and carried out a picture verification task to decide on an interpretation of the sentence. These response accuracies are used to identify the best parameters (for each participant) that correspond to the three hypotheses mentioned above. We show that controls have more tightly clustered (less variable) parameter values than IWA; specifically, compared to controls, among IWA there are more individuals with low goal activations, high noise, and slow default action times. This suggests that (i) individual patients show differential amounts of deficit along the three dimensions of slowed processing, intermittent deficient, and resource reduction, (ii) overall, there is evidence for all three sources of deficit playing a role, and (iii) IWA have a more variable range of parameter values than controls. In sum, this study contributes a proof of concept of a quantitative implementation of, and evidence for, these three accounts of comprehension deficits in aphasia.|present comput evalu three hypothes sourc deficit sentenc comprehens aphasia slow process intermitt defici resourc reduct act base lewi vasishth model use implement three propos slow process implement slow default product rule fire time intermitt defici increas random nois activ chunk memori resourc reduct reduc goal activ data consid subject vs object relat present self pace listen modal individu aphasia iwa match control particip heard sentenc carri pictur verif task decid interpret sentenc respons accuraci use identifi best paramet particip correspond three hypothes mention abov show control tight cluster less variabl paramet valu iwa specif compar control among iwa individu low goal activ high nois slow default action time suggest individu patient show differenti amount deficit along three dimens slow process intermitt defici resourc reduct ii overal evid three sourc deficit play role iii iwa variabl rang paramet valu control sum studi contribut proof concept quantit implement evid three account comprehens deficit aphasia|['Paul Mätzig', 'Shravan Vasishth', 'Felix Engelmann', 'David Caplan']|['cs.CL', 'cs.AI']
2017-03-28T14:06:24Z|2017-03-21T12:56:11Z|http://arxiv.org/abs/1703.04650v2|http://arxiv.org/pdf/1703.04650v2|Joint Learning of Correlated Sequence Labelling Tasks Using   Bidirectional Recurrent Neural Networks|joint learn correl sequenc label task use bidirect recurr neural network|The stream of words produced by Automatic Speech Recognition (ASR) systems is devoid of any punctuations and formatting. Most natural language processing applications usually expect segmented and well-formatted texts as input, which is not available in ASR output. This paper proposes a novel technique of jointly modelling multiple correlated tasks such as punctuation and capitalization using bidirectional recurrent neural networks, which leads to improved performance for each of these tasks. This method can be extended for joint modelling of any other correlated multiple sequence labelling tasks.|stream word produc automat speech recognit asr system devoid ani punctuat format natur languag process applic usual expect segment well format text input avail asr output paper propos novel techniqu joint model multipl correl task punctuat capit use bidirect recurr neural network lead improv perform task method extend joint model ani correl multipl sequenc label task|['Vardaan Pahuja', 'Anirban Laha', 'Shachar Mirkin', 'Vikas Raykar', 'Lili Kotlerman', 'Guy Lev']|['cs.CL']
2017-03-28T14:06:24Z|2017-03-25T16:17:03Z|http://arxiv.org/abs/1703.04617v2|http://arxiv.org/pdf/1703.04617v2|Exploring Question Understanding and Adaptation in Neural-Network-Based   Question Answering|explor question understand adapt neural network base question answer|The last several years have seen intensive interest in exploring neural-network-based models for machine comprehension (MC) and question answering (QA). In this paper, we approach the problems by closely modelling questions in a neural network framework. We first introduce syntactic information to help encode questions. We then view and model different types of questions and the information shared among them as an adaptation task and proposed adaptation models for them. On the Stanford Question Answering Dataset (SQuAD), we show that these approaches can help attain better results over a competitive baseline.|last sever year seen intens interest explor neural network base model machin comprehens mc question answer qa paper approach problem close model question neural network framework first introduc syntact inform help encod question view model differ type question inform share among adapt task propos adapt model stanford question answer dataset squad show approach help attain better result competit baselin|['Junbei Zhang', 'Xiaodan Zhu', 'Qian Chen', 'Lirong Dai', 'Si Wei', 'Hui Jiang']|['cs.CL']
2017-03-28T14:06:24Z|2017-03-13T17:34:18Z|http://arxiv.org/abs/1703.04498v1|http://arxiv.org/pdf/1703.04498v1|High-Throughput and Language-Agnostic Entity Disambiguation and Linking   on User Generated Data|high throughput languag agnost entiti disambigu link user generat data|The Entity Disambiguation and Linking (EDL) task matches entity mentions in text to a unique Knowledge Base (KB) identifier such as a Wikipedia or Freebase id. It plays a critical role in the construction of a high quality information network, and can be further leveraged for a variety of information retrieval and NLP tasks such as text categorization and document tagging. EDL is a complex and challenging problem due to ambiguity of the mentions and real world text being multi-lingual. Moreover, EDL systems need to have high throughput and should be lightweight in order to scale to large datasets and run on off-the-shelf machines. More importantly, these systems need to be able to extract and disambiguate dense annotations from the data in order to enable an Information Retrieval or Extraction task running on the data to be more efficient and accurate. In order to address all these challenges, we present the Lithium EDL system and algorithm - a high-throughput, lightweight, language-agnostic EDL system that extracts and correctly disambiguates 75% more entities than state-of-the-art EDL systems and is significantly faster than them.|entiti disambigu link edl task match entiti mention text uniqu knowledg base kb identifi wikipedia freebas id play critic role construct high qualiti inform network leverag varieti inform retriev nlp task text categor document tag edl complex challeng problem due ambigu mention real world text multi lingual moreov edl system need high throughput lightweight order scale larg dataset run shelf machin import system need abl extract disambigu dens annot data order enabl inform retriev extract task run data effici accur order address challeng present lithium edl system algorithm high throughput lightweight languag agnost edl system extract correct disambigu entiti state art edl system signific faster|['Preeti Bhargava', 'Nemanja Spasojevic', 'Guoning Hu']|['cs.IR', 'cs.AI', 'cs.CL']
2017-03-28T14:06:24Z|2017-03-13T17:13:51Z|http://arxiv.org/abs/1703.04489v1|http://arxiv.org/pdf/1703.04489v1|Reinforcement Learning for Transition-Based Mention Detection|reinforc learn transit base mention detect|This paper describes an application of reinforcement learning to the mention detection task. We define a novel action-based formulation for the mention detection task, in which a model can flexibly revise past labeling decisions by grouping together tokens and assigning partial mention labels. We devise a method to create mention-level episodes and we train a model by rewarding correctly labeled complete mentions, irrespective of the inner structure created. The model yields results which are on par with a competitive supervised counterpart while being more flexible in terms of achieving targeted behavior through reward modeling and generating internal mention structure, especially on longer mentions.|paper describ applic reinforc learn mention detect task defin novel action base formul mention detect task model flexibl revis past label decis group togeth token assign partial mention label devis method creat mention level episod train model reward correct label complet mention irrespect inner structur creat model yield result par competit supervis counterpart flexibl term achiev target behavior reward model generat intern mention structur especi longer mention|['Georgiana Dinu', 'Wael Hamza', 'Radu Florian']|['cs.CL', 'cs.AI']
2017-03-28T14:06:28Z|2017-03-13T16:50:36Z|http://arxiv.org/abs/1703.04481v1|http://arxiv.org/pdf/1703.04481v1|Geometrical morphology|geometr morpholog|We explore inflectional morphology as an example of the relationship of the discrete and the continuous in linguistics. The grammar requests a form of a lexeme by specifying a set of feature values, which corresponds to a corner M of a hypercube in feature value space. The morphology responds to that request by providing a morpheme, or a set of morphemes, whose vector sum is geometrically closest to the corner M. In short, the chosen morpheme $\mu$ is the morpheme (or set of morphemes) that maximizes the inner product of $\mu$ and M.|explor inflect morpholog exampl relationship discret continu linguist grammar request form lexem specifi set featur valu correspond corner hypercub featur valu space morpholog respond request provid morphem set morphem whose vector sum geometr closest corner short chosen morphem mu morphem set morphem maxim inner product mu|['John Goldsmith', 'Eric Rosen']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-13T16:36:38Z|http://arxiv.org/abs/1703.04474v1|http://arxiv.org/pdf/1703.04474v1|DRAGNN: A Transition-based Framework for Dynamically Connected Neural   Networks|dragnn transit base framework dynam connect neural network|In this work, we present a compact, modular framework for constructing novel recurrent neural architectures. Our basic module is a new generic unit, the Transition Based Recurrent Unit (TBRU). In addition to hidden layer activations, TBRUs have discrete state dynamics that allow network connections to be built dynamically as a function of intermediate activations. By connecting multiple TBRUs, we can extend and combine commonly used architectures such as sequence-to-sequence, attention mechanisms, and re-cursive tree-structured models. A TBRU can also serve as both an encoder for downstream tasks and as a decoder for its own task simultaneously, resulting in more accurate multi-task learning. We call our approach Dynamic Recurrent Acyclic Graphical Neural Networks, or DRAGNN. We show that DRAGNN is significantly more accurate and efficient than seq2seq with attention for syntactic dependency parsing and yields more accurate multi-task learning for extractive summarization tasks.|work present compact modular framework construct novel recurr neural architectur basic modul new generic unit transit base recurr unit tbru addit hidden layer activ tbrus discret state dynam allow network connect built dynam function intermedi activ connect multipl tbrus extend combin common use architectur sequenc sequenc attent mechan cursiv tree structur model tbru also serv encod downstream task decod task simultan result accur multi task learn call approach dynam recurr acycl graphic neural network dragnn show dragnn signific accur effici seqseq attent syntact depend pars yield accur multi task learn extract summar task|['Lingpeng Kong', 'Chris Alberti', 'Daniel Andor', 'Ivan Bogatyy', 'David Weiss']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-13T14:34:23Z|http://arxiv.org/abs/1703.04417v1|http://arxiv.org/pdf/1703.04417v1|El Lenguaje Natural como Lenguaje Formal|el lenguaj natur como lenguaj formal|"Formal languages theory is useful for the study of natural language. In particular, it is of interest to study the adequacy of the grammatical formalisms to express syntactic phenomena present in natural language. First, it helps to draw hypothesis about the nature and complexity of the speaker-hearer linguistic competence, a fundamental question in linguistics and other cognitive sciences. Moreover, from an engineering point of view, it allows the knowledge of practical limitations of applications based on those formalisms. In this article I introduce the adequacy problem of grammatical formalisms for natural language, also introducing some formal language theory concepts required for this discussion. Then, I review the formalisms that have been proposed in history, and the arguments that have been given to support or reject their adequacy.   -----   La teor\'ia de lenguajes formales es \'util para el estudio de los lenguajes naturales. En particular, resulta de inter\'es estudiar la adecuaci\'on de los formalismos gramaticales para expresar los fen\'omenos sint\'acticos presentes en el lenguaje natural. Primero, ayuda a trazar hip\'otesis acerca de la naturaleza y complejidad de las competencias ling\""u\'isticas de los hablantes-oyentes del lenguaje, un interrogante fundamental de la ling\""u\'istica y otras ciencias cognitivas. Adem\'as, desde el punto de vista de la ingenier\'ia, permite conocer limitaciones pr\'acticas de las aplicaciones basadas en dichos formalismos. En este art\'iculo hago una introducci\'on al problema de la adecuaci\'on de los formalismos gramaticales para el lenguaje natural, introduciendo tambi\'en algunos conceptos de la teor\'ia de lenguajes formales necesarios para esta discusi\'on. Luego, hago un repaso de los formalismos que han sido propuestos a lo largo de la historia, y de los argumentos que se han dado para sostener o refutar su adecuaci\'on."|formal languag theori use studi natur languag particular interest studi adequaci grammat formal express syntact phenomena present natur languag first help draw hypothesi natur complex speaker hearer linguist compet fundament question linguist cognit scienc moreov engin point view allow knowledg practic limit applic base formal articl introduc adequaci problem grammat formal natur languag also introduc formal languag theori concept requir discuss review formal propos histori argument given support reject adequaci la teor ia de lenguaj formal es util para el estudio de los lenguaj natural en particular resulta de inter es estudiar la adecuaci de los formalismo gramatical para expresar los fen omeno sint actico present en el lenguaj natur primero ayuda trazar hip otesi acerca de la naturaleza complejidad de las competencia ling istica de los hablant oyent del lenguaj un interrogant fundament de la ling istica otra ciencia cognitiva adem desd el punto de vista de la ingeni ia permit conoc limitacion pr actica de las aplicacion basada en dicho formalismo en est art iculo hago una introducci al problema de la adecuaci de los formalismo gramatical para el lenguaj natur introduciendo tambi en alguno concepto de la teor ia de lenguaj formal necesario para esta discusi luego hago un repaso de los formalismo que han sido propuesto lo largo de la historia de los argumento que se han dado para sosten refutar su adecuaci|['Franco M. Luque']|['cs.CL', 'cs.FL']
2017-03-28T14:06:28Z|2017-03-13T12:28:03Z|http://arxiv.org/abs/1703.04357v1|http://arxiv.org/pdf/1703.04357v1|Nematus: a Toolkit for Neural Machine Translation|nematus toolkit neural machin translat|We present Nematus, a toolkit for Neural Machine Translation. The toolkit prioritizes high translation accuracy, usability, and extensibility. Nematus has been used to build top-performing submissions to shared translation tasks at WMT and IWSLT, and has been used to train systems for production environments.|present nematus toolkit neural machin translat toolkit priorit high translat accuraci usabl extens nematus use build top perform submiss share translat task wmt iwslt use train system product environ|['Rico Sennrich', 'Orhan Firat', 'Kyunghyun Cho', 'Alexandra Birch', 'Barry Haddow', 'Julian Hitschler', 'Marcin Junczys-Dowmunt', 'Samuel Läubli', 'Antonio Valerio Miceli Barone', 'Jozef Mokry', 'Maria Nădejde']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-13T11:19:56Z|http://arxiv.org/abs/1703.04336v1|http://arxiv.org/pdf/1703.04336v1|A Visual Representation of Wittgenstein's Tractatus Logico-Philosophicus|visual represent wittgenstein tractatus logico philosophicus|In this paper we present a data visualization method together with its potential usefulness in digital humanities and philosophy of language. We compile a multilingual parallel corpus from different versions of Wittgenstein's Tractatus Logico-Philosophicus, including the original in German and translations into English, Spanish, French, and Russian. Using this corpus, we compute a similarity measure between propositions and render a visual network of relations for different languages.|paper present data visual method togeth potenti use digit human philosophi languag compil multilingu parallel corpus differ version wittgenstein tractatus logico philosophicus includ origin german translat english spanish french russian use corpus comput similar measur proposit render visual network relat differ languag|['Anca Bucur', 'Sergiu Nisioi']|['cs.IR', 'cs.CL']
2017-03-28T14:06:28Z|2017-03-13T11:03:40Z|http://arxiv.org/abs/1703.04330v1|http://arxiv.org/pdf/1703.04330v1|Story Cloze Ending Selection Baselines and Data Examination|stori cloze end select baselin data examin|This paper describes two supervised baseline systems for the Story Cloze Test Shared Task (Mostafazadeh et al., 2016a). We first build a classifier using features based on word embeddings and semantic similarity computation. We further implement a neural LSTM system with different encoding strategies that try to model the relation between the story and the provided endings. Our experiments show that a model using representation features based on average word embedding vectors over the given story words and the candidate ending sentences words, joint with similarity features between the story and candidate ending representations performed better than the neural models. Our best model achieves an accuracy of 72.42, ranking 3rd in the official evaluation.|paper describ two supervis baselin system stori cloze test share task mostafazadeh et al first build classifi use featur base word embed semant similar comput implement neural lstm system differ encod strategi tri model relat stori provid end experi show model use represent featur base averag word embed vector given stori word candid end sentenc word joint similar featur stori candid end represent perform better neural model best model achiev accuraci rank rd offici evalu|['Todor Mihaylov', 'Anette Frank']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-13T04:55:19Z|http://arxiv.org/abs/1703.04247v1|http://arxiv.org/pdf/1703.04247v1|DeepFM: A Factorization-Machine based Neural Network for CTR Prediction|deepfm factor machin base neural network ctr predict|"Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and high-order feature interactions. The proposed model, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide \& Deep model from Google, DeepFM has a shared input to its ""wide"" and ""deep"" parts, with no need of feature engineering besides raw features. Comprehensive experiments are conducted to demonstrate the effectiveness and efficiency of DeepFM over the existing models for CTR prediction, on both benchmark data and commercial data."|learn sophist featur interact behind user behavior critic maxim ctr recommend system despit great progress exist method seem strong bias toward low high order interact requir expertis featur engin paper show possibl deriv end end learn model emphas low high order featur interact propos model deepfm combin power factor machin recommend deep learn featur learn new neural network architectur compar latest wide deep model googl deepfm share input wide deep part need featur engin besid raw featur comprehens experi conduct demonstr effect effici deepfm exist model ctr predict benchmark data commerci data|['Huifeng Guo', 'Ruiming Tang', 'Yunming Ye', 'Zhenguo Li', 'Xiuqiang He']|['cs.IR', 'cs.CL']
2017-03-28T14:06:28Z|2017-03-14T20:26:32Z|http://arxiv.org/abs/1703.04213v2|http://arxiv.org/pdf/1703.04213v2|MetaPAD: Meta Pattern Discovery from Massive Text Corpora|metapad meta pattern discoveri massiv text corpora|Mining textual patterns in news, tweets, papers, and many other kinds of text corpora has been an active theme in text mining and NLP research. Previous studies adopt a dependency parsing-based pattern discovery approach. However, the parsing results lose rich context around entities in the patterns, and the process is costly for a corpus of large scale. In this study, we propose a novel typed textual pattern structure, called meta pattern, which is extended to a frequent, informative, and precise subsequence pattern in certain context. We propose an efficient framework, called MetaPAD, which discovers meta patterns from massive corpora with three techniques: (1) it develops a context-aware segmentation method to carefully determine the boundaries of patterns with a learnt pattern quality assessment function, which avoids costly dependency parsing and generates high-quality patterns; (2) it identifies and groups synonymous meta patterns from multiple facets---their types, contexts, and extractions; and (3) it examines type distributions of entities in the instances extracted by each group of patterns, and looks for appropriate type levels to make discovered patterns precise. Experiments demonstrate that our proposed framework discovers high-quality typed textual patterns efficiently from different genres of massive corpora and facilitates information extraction.|mine textual pattern news tweet paper mani kind text corpora activ theme text mine nlp research previous studi adopt depend pars base pattern discoveri approach howev pars result lose rich context around entiti pattern process cost corpus larg scale studi propos novel type textual pattern structur call meta pattern extend frequent inform precis subsequ pattern certain context propos effici framework call metapad discov meta pattern massiv corpora three techniqu develop context awar segment method care determin boundari pattern learnt pattern qualiti assess function avoid cost depend pars generat high qualiti pattern identifi group synonym meta pattern multipl facet type context extract examin type distribut entiti instanc extract group pattern look appropri type level make discov pattern precis experi demonstr propos framework discov high qualiti type textual pattern effici differ genr massiv corpora facilit inform extract|['Meng Jiang', 'Jingbo Shang', 'Taylor Cassidy', 'Xiang Ren', 'Lance M. Kaplan', 'Timothy P. Hanratty', 'Jiawei Han']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-23T14:00:55Z|http://arxiv.org/abs/1703.04178v2|http://arxiv.org/pdf/1703.04178v2|Why we have switched from building full-fledged taxonomies to simply   detecting hypernymy relations|whi switch build full fledg taxonomi simpli detect hypernymi relat|The study of taxonomies and hypernymy relations has been extensive on the Natural Language Processing (NLP) literature. However, the evaluation of taxonomy learning approaches has been traditionally troublesome, as it mainly relies on ad-hoc experiments which are hardly reproducible and manually expensive. Partly because of this, current research has been lately focusing on the hypernymy detection task. In this paper we reflect on this trend, analyzing issues related to current evaluation procedures. Finally, we propose three potential avenues for future work so that is-a relations and resources based on them play a more important role in downstream NLP applications.|studi taxonomi hypernymi relat extens natur languag process nlp literatur howev evalu taxonomi learn approach tradit troublesom main reli ad hoc experi hard reproduc manual expens part becaus current research late focus hypernymi detect task paper reflect trend analyz issu relat current evalu procedur final propos three potenti avenu futur work relat resourc base play import role downstream nlp applic|['Jose Camacho-Collados']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-12T08:11:29Z|http://arxiv.org/abs/1703.04081v1|http://arxiv.org/pdf/1703.04081v1|Feature overwriting as a finite mixture process: Evidence from   comprehension data|featur overwrit finit mixtur process evid comprehens data|"The ungrammatical sentence ""The key to the cabinets are on the table"" is known to lead to an illusion of grammaticality. As discussed in the meta-analysis by Jaeger et al., 2017, faster reading times are observed at the verb are in the agreement-attraction sentence above compared to the equally ungrammatical sentence ""The key to the cabinet are on the table"". One explanation for this facilitation effect is the feature percolation account: the plural feature on cabinets percolates up to the head noun key, leading to the illusion. An alternative account is in terms of cue-based retrieval (Lewis & Vasishth, 2005), which assumes that the non-subject noun cabinets is misretrieved due to a partial feature-match when a dependency completion process at the auxiliary initiates a memory access for a subject with plural marking. We present evidence for yet another explanation for the observed facilitation. Because the second sentence has two nouns with identical number, it is possible that these are, in some proportion of trials, more difficult to keep distinct, leading to slower reading times at the verb in the first sentence above; this is the feature overwriting account of Nairne, 1990. We show that the feature overwriting proposal can be implemented as a finite mixture process. We reanalysed ten published data-sets, fitting hierarchical Bayesian mixture models to these data assuming a two-mixture distribution. We show that in nine out of the ten studies, a mixture distribution corresponding to feature overwriting furnishes a superior fit over both the feature percolation and the cue-based retrieval accounts."|ungrammat sentenc key cabinet tabl known lead illus grammat discuss meta analysi jaeger et al faster read time observ verb agreement attract sentenc abov compar equal ungrammat sentenc key cabinet tabl one explan facilit effect featur percol account plural featur cabinet percol head noun key lead illus altern account term cue base retriev lewi vasishth assum non subject noun cabinet misretriev due partial featur match depend complet process auxiliari initi memori access subject plural mark present evid yet anoth explan observ facilit becaus second sentenc two noun ident number possibl proport trial difficult keep distinct lead slower read time verb first sentenc abov featur overwrit account nairn show featur overwrit propos implement finit mixtur process reanalys ten publish data set fit hierarch bayesian mixtur model data assum two mixtur distribut show nine ten studi mixtur distribut correspond featur overwrit furnish superior fit featur percol cue base retriev account|['Shravan Vasishth', 'Lena A. Jaeger', 'Bruno Nicenboim']|['stat.ML', 'cs.CL', 'stat.AP']
2017-03-28T14:06:31Z|2017-03-11T18:20:13Z|http://arxiv.org/abs/1703.04009v1|http://arxiv.org/pdf/1703.04009v1|Automated Hate Speech Detection and the Problem of Offensive Language|autom hate speech detect problem offens languag|A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories. We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classifier to distinguish between these different categories. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive. Tweets without explicit hate keywords are also more difficult to classify.|key challeng automat hate speech detect social media separ hate speech instanc offens languag lexic detect method tend low precis becaus classifi messag contain particular term hate speech previous work use supervis learn fail distinguish two categori use crowd sourc hate speech lexicon collect tweet contain hate speech keyword use crowd sourc label sampl tweet three categori contain hate speech onli offens languag neither train multi class classifi distinguish differ categori close analysi predict error show reliabl separ hate speech offens languag differenti difficult find racist homophob tweet like classifi hate speech sexist tweet general classifi offens tweet without explicit hate keyword also difficult classifi|['Thomas Davidson', 'Dana Warmsley', 'Michael Macy', 'Ingmar Weber']|['cs.CL']
2017-03-28T14:06:31Z|2017-03-11T17:14:55Z|http://arxiv.org/abs/1703.04001v1|http://arxiv.org/pdf/1703.04001v1|Language Use Matters: Analysis of the Linguistic Structure of Question   Texts Can Characterize Answerability in Quora|languag use matter analysi linguist structur question text character answer quora|Quora is one of the most popular community Q&A sites of recent times. However, many question posts on this Q&A site often do not get answered. In this paper, we quantify various linguistic activities that discriminates an answered question from an unanswered one. Our central finding is that the way users use language while writing the question text can be a very effective means to characterize answerability. This characterization helps us to predict early if a question remaining unanswered for a specific time period t will eventually be answered or not and achieve an accuracy of 76.26% (t = 1 month) and 68.33% (t = 3 months). Notably, features representing the language use patterns of the users are most discriminative and alone account for an accuracy of 74.18%. We also compare our method with some of the similar works (Dror et al., Yang et al.) achieving a maximum improvement of ~39% in terms of accuracy.|quora one popular communiti site recent time howev mani question post site often get answer paper quantifi various linguist activ discrimin answer question unansw one central find way user use languag write question text veri effect mean character answer character help us predict earli question remain unansw specif time period eventu answer achiev accuraci month month notabl featur repres languag use pattern user discrimin alon account accuraci also compar method similar work dror et al yang et al achiev maximum improv term accuraci|['Suman Kalyan Maity', 'Aman Kharb', 'Animesh Mukherjee']|['cs.CL', 'cs.SI']
2017-03-28T14:06:31Z|2017-03-11T10:05:19Z|http://arxiv.org/abs/1703.03939v1|http://arxiv.org/pdf/1703.03939v1|Ask Me Even More: Dynamic Memory Tensor Networks (Extended Model)|ask even dynam memori tensor network extend model|We examine Memory Networks for the task of question answering (QA), under common real world scenario where training examples are scarce and under weakly supervised scenario, that is only extrinsic labels are available for training. We propose extensions for the Dynamic Memory Network (DMN), specifically within the attention mechanism, we call the resulting Neural Architecture as Dynamic Memory Tensor Network (DMTN). Ultimately, we see that our proposed extensions results in over 80% improvement in the number of task passed against the baselined standard DMN and 20% more task passed compared to state-of-the-art End-to-End Memory Network for Facebook's single task weakly trained 1K bAbi dataset.|examin memori network task question answer qa common real world scenario train exampl scarc weak supervis scenario onli extrins label avail train propos extens dynam memori network dmn specif within attent mechan call result neural architectur dynam memori tensor network dmtn ultim see propos extens result improv number task pass baselin standard dmn task pass compar state art end end memori network facebook singl task weak train babi dataset|['Govardana Sachithanandam Ramachandran', 'Ajay Sohmshetty']|['cs.CL', 'cs.LG', 'cs.NE']
2017-03-28T14:06:31Z|2017-03-11T07:37:37Z|http://arxiv.org/abs/1703.04718v1|http://arxiv.org/pdf/1703.04718v1|Extending Automatic Discourse Segmentation for Texts in Spanish to   Catalan|extend automat discours segment text spanish catalan|At present, automatic discourse analysis is a relevant research topic in the field of NLP. However, discourse is one of the phenomena most difficult to process. Although discourse parsers have been already developed for several languages, this tool does not exist for Catalan. In order to implement this kind of parser, the first step is to develop a discourse segmenter. In this article we present the first discourse segmenter for texts in Catalan. This segmenter is based on Rhetorical Structure Theory (RST) for Spanish, and uses lexical and syntactic information to translate rules valid for Spanish into rules for Catalan. We have evaluated the system by using a gold standard corpus including manually segmented texts and results are promising.|present automat discours analysi relev research topic field nlp howev discours one phenomena difficult process although discours parser alreadi develop sever languag tool doe exist catalan order implement kind parser first step develop discours segment articl present first discours segment text catalan segment base rhetor structur theori rst spanish use lexic syntact inform translat rule valid spanish rule catalan evalu system use gold standard corpus includ manual segment text result promis|['Iria da Cunha', 'Eric SanJuan', 'Juan-Manuel Torres-Moreno', 'Irene Castellón']|['cs.CL']
2017-03-28T14:06:31Z|2017-03-11T07:35:28Z|http://arxiv.org/abs/1703.03923v1|http://arxiv.org/pdf/1703.03923v1|A German Corpus for Text Similarity Detection Tasks|german corpus text similar detect task|Text similarity detection aims at measuring the degree of similarity between a pair of texts. Corpora available for text similarity detection are designed to evaluate the algorithms to assess the paraphrase level among documents. In this paper we present a textual German corpus for similarity detection. The purpose of this corpus is to automatically assess the similarity between a pair of texts and to evaluate different similarity measures, both for whole documents or for individual sentences. Therefore we have calculated several simple measures on our corpus based on a library of similarity functions.|text similar detect aim measur degre similar pair text corpora avail text similar detect design evalu algorithm assess paraphras level among document paper present textual german corpus similar detect purpos corpus automat assess similar pair text evalu differ similar measur whole document individu sentenc therefor calcul sever simpl measur corpus base librari similar function|['Juan-Manuel Torres-Moreno', 'Gerardo Sierra', 'Peter Peinl']|['cs.IR', 'cs.CL']
2017-03-28T14:06:31Z|2017-03-21T20:34:59Z|http://arxiv.org/abs/1703.03906v2|http://arxiv.org/pdf/1703.03906v2|Massive Exploration of Neural Machine Translation Architectures|massiv explor neural machin translat architectur|Neural Machine Translation (NMT) has shown remarkable progress over the past few years with production systems now being deployed to end-users. One major drawback of current architectures is that they are expensive to train, typically requiring days to weeks of GPU time to converge. This makes exhaustive hyperparameter search, as is commonly done with other neural network architectures, prohibitively expensive. In this work, we present the first large-scale analysis of NMT architecture hyperparameters. We report empirical results and variance numbers for several hundred experimental runs, corresponding to over 250,000 GPU hours on the standard WMT English to German translation task. Our experiments lead to novel insights and practical advice for building and extending NMT architectures. As part of this contribution, we release an open-source NMT framework that enables researchers to easily experiment with novel techniques and reproduce state of the art results.|neural machin translat nmt shown remark progress past year product system deploy end user one major drawback current architectur expens train typic requir day week gpu time converg make exhaust hyperparamet search common done neural network architectur prohibit expens work present first larg scale analysi nmt architectur hyperparamet report empir result varianc number sever hundr experiment run correspond gpu hour standard wmt english german translat task experi lead novel insight practic advic build extend nmt architectur part contribut releas open sourc nmt framework enabl research easili experi novel techniqu reproduc state art result|['Denny Britz', 'Anna Goldie', 'Minh-Thang Luong', 'Quoc Le']|['cs.CL']
2017-03-28T14:06:31Z|2017-03-10T20:54:11Z|http://arxiv.org/abs/1703.03842v1|http://arxiv.org/pdf/1703.03842v1|Effects of Limiting Memory Capacity on the Behaviour of Exemplar   Dynamics|effect limit memori capac behaviour exemplar dynam|Exemplar models are a popular class of models used to describe language change. Here we study how limiting the memory capacity of an individual in these models affects the system's behaviour. In particular we demonstrate the effect this change has on the extinction of categories. Previous work in exemplar dynamics has not addressed this question. In order to investigate this, we will inspect a simplified exemplar model. We will prove for the simplified model that all the sound categories but one will always become extinct, whether memory storage is limited or not. However, computer simulations show that changing the number of stored memories alters how fast categories become extinct.|exemplar model popular class model use describ languag chang studi limit memori capac individu model affect system behaviour particular demonstr effect chang extinct categori previous work exemplar dynam address question order investig inspect simplifi exemplar model prove simplifi model sound categori one alway becom extinct whether memori storag limit howev comput simul show chang number store memori alter fast categori becom extinct|['B. Goodman', 'P. F. Tupper']|['cs.CL', '91F20']
2017-03-28T14:06:31Z|2017-03-10T17:27:38Z|http://arxiv.org/abs/1703.03771v1|http://arxiv.org/pdf/1703.03771v1|Coping with Construals in Broad-Coverage Semantic Annotation of   Adpositions|cope construal broad coverag semant annot adposit|We consider the semantics of prepositions, revisiting a broad-coverage annotation scheme used for annotating all 4,250 preposition tokens in a 55,000 word corpus of English. Attempts to apply the scheme to adpositions and case markers in other languages, as well as some problematic cases in English, have led us to reconsider the assumption that a preposition's lexical contribution is equivalent to the role/relation that it mediates. Our proposal is to embrace the potential for construal in adposition use, expressing such phenomena directly at the token level to manage complexity and avoid sense proliferation. We suggest a framework to represent both the scene role and the adposition's lexical function so they can be annotated at scale---supporting automatic, statistical processing of domain-general language---and sketch how this representation would inform a constructional analysis.|consid semant preposit revisit broad coverag annot scheme use annot preposit token word corpus english attempt appli scheme adposit case marker languag well problemat case english led us reconsid assumpt preposit lexic contribut equival role relat mediat propos embrac potenti construal adposit use express phenomena direct token level manag complex avoid sens prolifer suggest framework repres scene role adposit lexic function annot scale support automat statist process domain general languag sketch represent would inform construct analysi|"['Jena D. Hwang', 'Archna Bhatia', 'Na-Rae Han', ""Tim O'Gorman"", 'Vivek Srikumar', 'Nathan Schneider']"|['cs.CL']
2017-03-28T14:06:32Z|2017-03-10T15:27:45Z|http://arxiv.org/abs/1703.03714v1|http://arxiv.org/pdf/1703.03714v1|Applying the Wizard-of-Oz Technique to Multimodal Human-Robot Dialogue|appli wizard oz techniqu multimod human robot dialogu|Our overall program objective is to provide more natural ways for soldiers to interact and communicate with robots, much like how soldiers communicate with other soldiers today. We describe how the Wizard-of-Oz (WOz) method can be applied to multimodal human-robot dialogue in a collaborative exploration task. While the WOz method can help design robot behaviors, traditional approaches place the burden of decisions on a single wizard. In this work, we consider two wizards to stand in for robot navigation and dialogue management software components. The scenario used to elicit data is one in which a human-robot team is tasked with exploring an unknown environment: a human gives verbal instructions from a remote location and the robot follows them, clarifying possible misunderstandings as needed via dialogue. We found the division of labor between wizards to be workable, which holds promise for future software development.|overal program object provid natur way soldier interact communic robot much like soldier communic soldier today describ wizard oz woz method appli multimod human robot dialogu collabor explor task woz method help design robot behavior tradit approach place burden decis singl wizard work consid two wizard stand robot navig dialogu manag softwar compon scenario use elicit data one human robot team task explor unknown environ human give verbal instruct remot locat robot follow clarifi possibl misunderstand need via dialogu found divis labor wizard workabl hold promis futur softwar develop|['Matthew Marge', 'Claire Bonial', 'Brendan Byrne', 'Taylor Cassidy', 'A. William Evans', 'Susan G. Hill', 'Clare Voss']|['cs.CL', 'cs.AI', 'cs.HC', 'cs.RO']
2017-03-28T14:06:32Z|2017-03-10T12:59:52Z|http://arxiv.org/abs/1703.03666v1|http://arxiv.org/pdf/1703.03666v1|Comparison of SMT and RBMT; The Requirement of Hybridization for   Marathi-Hindi MT|comparison smt rbmt requir hybrid marathi hindi mt|We present in this paper our work on comparison between Statistical Machine Translation (SMT) and Rule-based machine translation for translation from Marathi to Hindi. Rule Based systems although robust take lots of time to build. On the other hand statistical machine translation systems are easier to create, maintain and improve upon. We describe the development of a basic Marathi-Hindi SMT system and evaluate its performance. Through a detailed error analysis, we, point out the relative strengths and weaknesses of both systems. Effectively, we shall see that even with a small amount of training corpus a statistical machine translation system has many advantages for high quality domain specific machine translation over that of a rule-based counterpart.|present paper work comparison statist machin translat smt rule base machin translat translat marathi hindi rule base system although robust take lot time build hand statist machin translat system easier creat maintain improv upon describ develop basic marathi hindi smt system evalu perform detail error analysi point relat strength weak system effect shall see even small amount train corpus statist machin translat system mani advantag high qualiti domain specif machin translat rule base counterpart|['Sreelekha. S', 'Pushpak Bhattacharyya']|['cs.CL']
2017-03-28T14:06:36Z|2017-03-10T11:58:48Z|http://arxiv.org/abs/1703.03640v1|http://arxiv.org/pdf/1703.03640v1|A Study of Metrics of Distance and Correlation Between Ranked Lists for   Compositionality Detection|studi metric distanc correl rank list composit detect|Compositionality in language refers to how much the meaning of some phrase can be decomposed into the meaning of its constituents and the way these constituents are combined. Based on the premise that substitution by synonyms is meaning-preserving, compositionality can be approximated as the semantic similarity between a phrase and a version of that phrase where words have been replaced by their synonyms. Different ways of representing such phrases exist (e.g., vectors [1] or language models [2]), and the choice of representation affects the measurement of semantic similarity.   We propose a new compositionality detection method that represents phrases as ranked lists of term weights. Our method approximates the semantic similarity between two ranked list representations using a range of well-known distance and correlation metrics. In contrast to most state-of-the-art approaches in compositionality detection, our method is completely unsupervised. Experiments with a publicly available dataset of 1048 human-annotated phrases shows that, compared to strong supervised baselines, our approach provides superior measurement of compositionality using any of the distance and correlation metrics considered.|composit languag refer much mean phrase decompos mean constitu way constitu combin base premis substitut synonym mean preserv composit approxim semant similar phrase version phrase word replac synonym differ way repres phrase exist vector languag model choic represent affect measur semant similar propos new composit detect method repres phrase rank list term weight method approxim semant similar two rank list represent use rang well known distanc correl metric contrast state art approach composit detect method complet unsupervis experi public avail dataset human annot phrase show compar strong supervis baselin approach provid superior measur composit use ani distanc correl metric consid|['Christina Lioma', 'Niels Dalum Hansen']|['cs.CL']
2017-03-28T14:06:36Z|2017-03-10T10:17:27Z|http://arxiv.org/abs/1703.03609v1|http://arxiv.org/abs/1703.03609v1|NetSpam: a Network-based Spam Detection Framework for Reviews in Online   Social Media|netspam network base spam detect framework review onlin social media|Nowadays, a big part of people rely on available content in social media in their decisions (e.g. reviews and feedback on a topic or product). The possibility that anybody can leave a review provide a golden opportunity for spammers to write spam reviews about products and services for different interests. Identifying these spammers and the spam content is a hot topic of research and although a considerable number of studies have been done recently toward this end, but so far the methodologies put forth still barely detect spam reviews, and none of them show the importance of each extracted feature type. In this study, we propose a novel framework, named NetSpam, which utilizes spam features for modeling review datasets as heterogeneous information networks to map spam detection procedure into a classification problem in such networks. Using the importance of spam features help us to obtain better results in terms of different metrics experimented on real-world review datasets from Yelp and Amazon websites. The results show that NetSpam outperforms the existing methods and among four categories of features; including review-behavioral, user-behavioral, reviewlinguistic, user-linguistic, the first type of features performs better than the other categories.|nowaday big part peopl reli avail content social media decis review feedback topic product possibl anybodi leav review provid golden opportun spammer write spam review product servic differ interest identifi spammer spam content hot topic research although consider number studi done recent toward end far methodolog put forth still bare detect spam review none show import extract featur type studi propos novel framework name netspam util spam featur model review dataset heterogen inform network map spam detect procedur classif problem network use import spam featur help us obtain better result term differ metric experi real world review dataset yelp amazon websit result show netspam outperform exist method among four categori featur includ review behavior user behavior reviewlinguist user linguist first type featur perform better categori|['Saeedreza Shehnepoor', 'Mostafa Salehi', 'Reza Farahbakhsh', 'Noel Crespi']|['cs.SI', 'cs.CL', 'cs.IR', 'physics.soc-ph']
2017-03-28T14:06:36Z|2017-03-09T19:50:00Z|http://arxiv.org/abs/1703.03442v1|http://arxiv.org/pdf/1703.03442v1|The cognitive roots of regularization in language|cognit root regular languag|Regularization occurs when the output a learner produces is less variable than the linguistic data they observed. In an artificial language learning experiment, we show that there exist at least two independent sources of regularization bias in cognition: a domain-general source based on cognitive load and a domain-specific source triggered by linguistic stimuli. Both of these factors modulate how frequency information is encoded and produced, but only the production-side modulations result in regularization (i.e. cause learners to eliminate variation from the observed input). We formalize the definition of regularization as the reduction of entropy and find that entropy measures are better at identifying regularization behavior than frequency-based analyses. We also use a model of cultural transmission to extrapolate from our experimental data in order to predict the amount of regularization which would develop in each experimental condition if the artificial language was transmitted over several generations of learners. Here we find an interaction between cognitive load and linguistic domain, suggesting that the effect of cognitive constraints can become more complex when put into the context of cultural evolution: although learning biases certainly carry information about the course of language evolution, we should not expect a one-to-one correspondence between the micro-level processes that regularize linguistic datasets and the macro-level evolution of linguistic regularity.|regular occur output learner produc less variabl linguist data observ artifici languag learn experi show exist least two independ sourc regular bias cognit domain general sourc base cognit load domain specif sourc trigger linguist stimuli factor modul frequenc inform encod produc onli product side modul result regular caus learner elimin variat observ input formal definit regular reduct entropi find entropi measur better identifi regular behavior frequenc base analys also use model cultur transmiss extrapol experiment data order predict amount regular would develop experiment condit artifici languag transmit sever generat learner find interact cognit load linguist domain suggest effect cognit constraint becom complex put context cultur evolut although learn bias certain carri inform cours languag evolut expect one one correspond micro level process regular linguist dataset macro level evolut linguist regular|['Vanessa Ferdinand', 'Simon Kirby', 'Kenny Smith']|['cs.CL', 'q-bio.NC']
2017-03-28T14:06:36Z|2017-03-09T19:16:14Z|http://arxiv.org/abs/1703.03429v1|http://arxiv.org/pdf/1703.03429v1|What can you do with a rock? Affordance extraction via word embeddings|rock afford extract via word embed|Autonomous agents must often detect affordances: the set of behaviors enabled by a situation. Affordance detection is particularly helpful in domains with large action spaces, allowing the agent to prune its search space by avoiding futile behaviors. This paper presents a method for affordance extraction via word embeddings trained on a Wikipedia corpus. The resulting word vectors are treated as a common knowledge database which can be queried using linear algebra. We apply this method to a reinforcement learning agent in a text-only environment and show that affordance-based action selection improves performance most of the time. Our method increases the computational complexity of each learning step but significantly reduces the total number of steps needed. In addition, the agent's action selections begin to resemble those a human would choose.|autonom agent must often detect afford set behavior enabl situat afford detect particular help domain larg action space allow agent prune search space avoid futil behavior paper present method afford extract via word embed train wikipedia corpus result word vector treat common knowledg databas queri use linear algebra appli method reinforc learn agent text onli environ show afford base action select improv perform time method increas comput complex learn step signific reduc total number step need addit agent action select begin resembl human would choos|['Nancy Fulda', 'Daniel Ricks', 'Ben Murdoch', 'David Wingate']|['cs.AI', 'cs.CL']
2017-03-28T14:06:36Z|2017-03-09T18:37:50Z|http://arxiv.org/abs/1703.03386v1|http://arxiv.org/pdf/1703.03386v1|Loyalty in Online Communities|loyalti onlin communiti|Loyalty is an essential component of multi-community engagement. When users have the choice to engage with a variety of different communities, they often become loyal to just one, focusing on that community at the expense of others. However, it is unclear how loyalty is manifested in user behavior, or whether loyalty is encouraged by certain community characteristics.   In this paper we operationalize loyalty as a user-community relation: users loyal to a community consistently prefer it over all others; loyal communities retain their loyal users over time. By exploring this relation using a large dataset of discussion communities from Reddit, we reveal that loyalty is manifested in remarkably consistent behaviors across a wide spectrum of communities. Loyal users employ language that signals collective identity and engage with more esoteric, less popular content, indicating they may play a curational role in surfacing new material. Loyal communities have denser user-user interaction networks and lower rates of triadic closure, suggesting that community-level loyalty is associated with more cohesive interactions and less fragmentation into subgroups. We exploit these general patterns to predict future rates of loyalty. Our results show that a user's propensity to become loyal is apparent from their first interactions with a community, suggesting that some users are intrinsically loyal from the very beginning.|loyalti essenti compon multi communiti engag user choic engag varieti differ communiti often becom loyal one focus communiti expens howev unclear loyalti manifest user behavior whether loyalti encourag certain communiti characterist paper operation loyalti user communiti relat user loyal communiti consist prefer loyal communiti retain loyal user time explor relat use larg dataset discuss communiti reddit reveal loyalti manifest remark consist behavior across wide spectrum communiti loyal user employ languag signal collect ident engag esoter less popular content indic may play curat role surfac new materi loyal communiti denser user user interact network lower rate triadic closur suggest communiti level loyalti associ cohes interact less fragment subgroup exploit general pattern predict futur rate loyalti result show user propens becom loyal appar first interact communiti suggest user intrins loyal veri begin|['William L. Hamilton', 'Justine Zhang', 'Cristian Danescu-Niculescu-Mizil', 'Dan Jurafsky', 'Jure Leskovec']|['cs.SI', 'cs.CL']
2017-03-28T14:06:36Z|2017-03-10T08:11:22Z|http://arxiv.org/abs/1703.03200v2|http://arxiv.org/pdf/1703.03200v2|Turkish PoS Tagging by Reducing Sparsity with Morpheme Tags in Small   Datasets|turkish pos tag reduc sparsiti morphem tag small dataset|Sparsity is one of the major problems in natural language processing. The problem becomes even more severe in agglutinating languages that are highly prone to be inflected. We deal with sparsity in Turkish by adopting morphological features for part-of-speech tagging. We learn inflectional and derivational morpheme tags in Turkish by using conditional random fields (CRF) and we employ the morpheme tags in part-of-speech (PoS) tagging by using hidden Markov models (HMMs) to mitigate sparsity. Results show that using morpheme tags in PoS tagging helps alleviate the sparsity in emission probabilities. Our model outperforms other hidden Markov model based PoS tagging models for small training datasets in Turkish. We obtain an accuracy of 94.1% in morpheme tagging and 89.2% in PoS tagging on a 5K training dataset.|sparsiti one major problem natur languag process problem becom even sever agglutin languag high prone inflect deal sparsiti turkish adopt morpholog featur part speech tag learn inflect deriv morphem tag turkish use condit random field crf employ morphem tag part speech pos tag use hidden markov model hmms mitig sparsiti result show use morphem tag pos tag help allevi sparsiti emiss probabl model outperform hidden markov model base pos tag model small train dataset turkish obtain accuraci morphem tag pos tag train dataset|['Burcu Can', 'Ahmet Üstün', 'Murathan Kurfalı']|['cs.CL']
2017-03-28T14:06:36Z|2017-03-09T06:20:49Z|http://arxiv.org/abs/1703.03149v1|http://arxiv.org/pdf/1703.03149v1|Detecting Sockpuppets in Deceptive Opinion Spam|detect sockpuppet decept opinion spam|This paper explores the problem of sockpuppet detection in deceptive opinion spam using authorship attribution and verification approaches. Two methods are explored. The first is a feature subsampling scheme that uses the KL-Divergence on stylistic language models of an author to find discriminative features. The second is a transduction scheme, spy induction that leverages the diversity of authors in the unlabeled test set by sending a set of spies (positive samples) from the training set to retrieve hidden samples in the unlabeled test set using nearest and farthest neighbors. Experiments using ground truth sockpuppet data show the effectiveness of the proposed schemes.|paper explor problem sockpuppet detect decept opinion spam use authorship attribut verif approach two method explor first featur subsampl scheme use kl diverg stylist languag model author find discrimin featur second transduct scheme spi induct leverag divers author unlabel test set send set spi posit sampl train set retriev hidden sampl unlabel test set use nearest farthest neighbor experi use ground truth sockpuppet data show effect propos scheme|['Marjan Hosseinia', 'Arjun Mukherjee']|['cs.CL']
2017-03-28T14:06:36Z|2017-03-09T04:42:30Z|http://arxiv.org/abs/1703.03130v1|http://arxiv.org/pdf/1703.03130v1|A Structured Self-attentive Sentence Embedding|structur self attent sentenc embed|This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.|paper propos new model extract interpret sentenc embed introduc self attent instead use vector use matrix repres embed row matrix attend differ part sentenc also propos self attent mechan special regular term model side effect embed come easi way visual specif part sentenc encod embed evalu model differ task author profil sentiment classif textual entail result show model yield signific perform gain compar sentenc embed method task|['Zhouhan Lin', 'Minwei Feng', 'Cicero Nogueira dos Santos', 'Mo Yu', 'Bing Xiang', 'Bowen Zhou', 'Yoshua Bengio']|['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE']
2017-03-28T14:06:36Z|2017-03-09T01:28:00Z|http://arxiv.org/abs/1703.03097v1|http://arxiv.org/abs/1703.03097v1|Information Extraction in Illicit Domains|inform extract illicit domain|Extracting useful entities and attribute values from illicit domains such as human trafficking is a challenging problem with the potential for widespread social impact. Such domains employ atypical language models, have `long tails' and suffer from the problem of concept drift. In this paper, we propose a lightweight, feature-agnostic Information Extraction (IE) paradigm specifically designed for such domains. Our approach uses raw, unlabeled text from an initial corpus, and a few (12-120) seed annotations per domain-specific attribute, to learn robust IE models for unobserved pages and websites. Empirically, we demonstrate that our approach can outperform feature-centric Conditional Random Field baselines by over 18\% F-Measure on five annotated sets of real-world human trafficking datasets in both low-supervision and high-supervision settings. We also show that our approach is demonstrably robust to concept drift, and can be efficiently bootstrapped even in a serial computing environment.|extract use entiti attribut valu illicit domain human traffick challeng problem potenti widespread social impact domain employ atyp languag model long tail suffer problem concept drift paper propos lightweight featur agnost inform extract ie paradigm specif design domain approach use raw unlabel text initi corpus seed annot per domain specif attribut learn robust ie model unobserv page websit empir demonstr approach outperform featur centric condit random field baselin measur five annot set real world human traffick dataset low supervis high supervis set also show approach demonstr robust concept drift effici bootstrap even serial comput environ|['Mayank Kejriwal', 'Pedro Szekely']|['cs.CL', 'cs.AI']
2017-03-28T14:06:36Z|2017-03-09T01:04:07Z|http://arxiv.org/abs/1703.03091v1|http://arxiv.org/pdf/1703.03091v1|Deep Learning applied to NLP|deep learn appli nlp|Convolutional Neural Network (CNNs) are typically associated with Computer Vision. CNNs are responsible for major breakthroughs in Image Classification and are the core of most Computer Vision systems today. More recently CNNs have been applied to problems in Natural Language Processing and gotten some interesting results. In this paper, we will try to explain the basics of CNNs, its different variations and how they have been applied to NLP.|convolut neural network cnns typic associ comput vision cnns respons major breakthrough imag classif core comput vision system today recent cnns appli problem natur languag process gotten interest result paper tri explain basic cnns differ variat appli nlp|['Marc Moreno Lopez', 'Jugal Kalita']|['cs.CL']
