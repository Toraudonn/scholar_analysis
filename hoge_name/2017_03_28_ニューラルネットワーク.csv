,プログラム実行日時,論文更新日時,論文リンク,PDFリンク,元論文タイトル,論文タイトル,元サマリ,サマリ,著者,事前付与ジャンル,ニューラルネットワーク,自然言語処理,マーケティング,画像解析,音声解析,強化学習
0,2017-03-28T14:05:16Z,2017-03-27T16:48:03Z,http://arxiv.org/abs/1703.09179v1,http://arxiv.org/pdf/1703.09179v1,Transfer learning for music classification and regression tasks,transfer learn music classif regress task,"In this paper, we present a transfer learning approach for music classification and regression tasks. We propose to use a pretrained convnet feature, a concatenated feature vector using activations of feature maps of multiple layers in a trained convolutional network. We show that how this convnet feature can serve as a general-purpose music representation. In the experiment, a convnet is trained for music tagging and then transferred for many music-related classification and regression tasks as well as an audio-related classification task. In experiments, the convnet feature outperforms the baseline MFCC feature in all tasks and many reported approaches of aggregating MFCCs and low- and high-level music features.",paper present transfer learn approach music classif regress task propos use pretrain convnet featur concaten featur vector use activ featur map multipl layer train convolut network show convnet featur serv general purpos music represent experi convnet train music tag transfer mani music relat classif regress task well audio relat classif task experi convnet featur outperform baselin mfcc featur task mani report approach aggreg mfccs low high level music featur,"['Keunwoo Choi', 'György Fazekas', 'Mark Sandler', 'Kyunghyun Cho']","['cs.CV', 'cs.AI', 'cs.MM', 'cs.SD']",True,False,False,False,False,False
28,2017-03-28T14:05:24Z,2017-03-21T23:29:47Z,http://arxiv.org/abs/1703.07469v1,http://arxiv.org/pdf/1703.07469v1,RobustFill: Neural Program Learning under Noisy I/O,robustfil neural program learn noisi,"The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation.   Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task. We additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs. Our best synthesis model achieves 92% accuracy on a real-world test set, compared to the 34% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely.",problem automat generat comput program specif studi sinc earli day ai recent two compet approach automat program learn receiv signific attent neural program synthesi neural network condit input output exampl learn generat program neural program induct neural network generat new output direct use latent program represent first time direct compar approach larg scale real world learn task addit contrast rule base program synthesi use hand craft semant guid program generat neural model use modifi attent rnn allow encod variabl size set pair best synthesi model achiev accuraci real world test set compar accuraci previous best neural synthesi approach synthesi model also outperform compar induct model task import demonstr strength approach high depend evalu metric end user applic final show train neural model remain veri robust type nois expect real world data typo high engin rule base system fail entir,"['Jacob Devlin', 'Jonathan Uesato', 'Surya Bhupatiraju', 'Rishabh Singh', 'Abdel-rahman Mohamed', 'Pushmeet Kohli']",['cs.AI'],True,False,False,False,False,False
304,2017-03-28T14:05:58Z,2017-03-26T20:02:44Z,http://arxiv.org/abs/1703.08864v1,http://arxiv.org/pdf/1703.08864v1,Learning Simpler Language Models with the Delta Recurrent Neural Network   Framework,learn simpler languag model delta recurr neural network framework,"Learning useful information across long time lags is a critical and difficult problem for temporal neural models in tasks like language modeling. Existing architectures that address the issue are often complex and costly to train. The Delta Recurrent Neural Network (Delta-RNN) framework is a simple and high-performing design that unifies previously proposed gated neural models. The Delta-RNN models maintain longer-term memory by learning to interpolate between a fast-changing data-driven representation and a slowly changing, implicitly stable state. This requires hardly any more parameters than a classical simple recurrent network. The models outperform popular complex architectures, such as the Long Short Term Memory (LSTM) and the Gated Recurrent Unit (GRU) and achieve state-of-the art performance in language modeling at character and word levels and yield comparable performance at the subword level.",learn use inform across long time lag critic difficult problem tempor neural model task like languag model exist architectur address issu often complex cost train delta recurr neural network delta rnn framework simpl high perform design unifi previous propos gate neural model delta rnn model maintain longer term memori learn interpol fast chang data driven represent slowli chang implicit stabl state requir hard ani paramet classic simpl recurr network model outperform popular complex architectur long short term memori lstm gate recurr unit gru achiev state art perform languag model charact word level yield compar perform subword level,"['Alexander G. Ororbia II', 'Tomas Mikolov', 'David Reitter']",['cs.CL'],True,False,False,False,False,False
320,2017-03-28T14:06:07Z,2017-03-23T15:57:23Z,http://arxiv.org/abs/1703.08120v1,http://arxiv.org/pdf/1703.08120v1,Recurrent and Contextual Models for Visual Question Answering,recurr contextu model visual question answer,"We propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the Visual7W dataset. Motivated by divergent trends in model complexities in the literature, we explore the balance between model expressiveness and simplicity by studying incrementally more complex architectures. We start with LSTM-encoding of input questions and answers; build on this with context generation by LSTM-encodings of neural image and question representations and attention over images; and evaluate the diversity and predictive power of our models and the ensemble thereof. All models are evaluated against a simple baseline inspired by the current state-of-the-art, consisting of involving simple concatenation of bag-of-words and CNN representations for the text and images, respectively. Generally, we observe marked variation in image-reasoning performance between our models not obvious from their overall performance, as well as evidence of dataset bias. Our standalone models achieve accuracies up to $64.6\%$, while the ensemble of all models achieves the best accuracy of $66.67\%$, within $0.5\%$ of the current state-of-the-art for Visual7W.",propos seri recurr contextu neural network model multipl choic visual question answer visualw dataset motiv diverg trend model complex literatur explor balanc model express simplic studi increment complex architectur start lstm encod input question answer build context generat lstm encod neural imag question represent attent imag evalu divers predict power model ensembl thereof model evalu simpl baselin inspir current state art consist involv simpl concaten bag word cnn represent text imag respect general observ mark variat imag reason perform model obvious overal perform well evid dataset bias standalon model achiev accuraci ensembl model achiev best accuraci within current state art visualw,"['Abhijit Sharang', 'Eric Lau']","['cs.CL', 'cs.CV']",True,False,False,False,False,False
329,2017-03-28T14:06:07Z,2017-03-22T15:42:28Z,http://arxiv.org/abs/1703.07713v1,http://arxiv.org/pdf/1703.07713v1,Hierarchical RNN with Static Sentence-Level Attention for Text-Based   Speaker Change Detection,hierarch rnn static sentenc level attent text base speaker chang detect,"Traditional speaker change detection in dialogues is typically based on audio input. In some scenarios, however, researchers can only obtain text, and do not have access to raw audio signals. Moreover, with the increasing need of deep semantic processing, text-based dialogue understanding is attracting more attention in the community. These raise the problem of text-based speaker change detection. In this paper, we formulate the task as a matching problem of utterances before and after a certain decision point; we propose a hierarchical recurrent neural network (RNN) with static sentence-level attention. Our model comprises three main components: a sentence encoder with a long short term memory (LSTM)-based RNN, a context encoder with another LSTM-RNN, and a static sentence-level attention mechanism, which allows rich information interaction. Experimental results show that neural networks consistently achieve better performance than feature-based approaches, and that our attention-based model significantly outperforms non-attention neural networks.",tradit speaker chang detect dialogu typic base audio input scenario howev research onli obtain text access raw audio signal moreov increas need deep semant process text base dialogu understand attract attent communiti rais problem text base speaker chang detect paper formul task match problem utter befor certain decis point propos hierarch recurr neural network rnn static sentenc level attent model compris three main compon sentenc encod long short term memori lstm base rnn context encod anoth lstm rnn static sentenc level attent mechan allow rich inform interact experiment result show neural network consist achiev better perform featur base approach attent base model signific outperform non attent neural network,"['Zhao Meng', 'Lili Mou', 'Zhi Jin']",['cs.CL'],True,False,False,False,False,False
330,2017-03-28T14:06:12Z,2017-03-22T10:08:51Z,http://arxiv.org/abs/1703.07588v1,http://arxiv.org/pdf/1703.07588v1,Gate Activation Signal Analysis for Gated Recurrent Neural Networks and   Its Correlation with Phoneme Boundaries,gate activ signal analysi gate recurr neural network correl phonem boundari,"In this paper we analyze the gate activation signals inside the gated recurrent neural networks, and find the temporal structure of such signals is highly correlated with the phoneme boundaries. This correlation is further verified by a set of experiments for phoneme segmentation, in which better results compared to standard approaches were obtained.",paper analyz gate activ signal insid gate recurr neural network find tempor structur signal high correl phonem boundari correl verifi set experi phonem segment better result compar standard approach obtain,"['Yu-Hsuan Wang', 'Cheng-Tao Chung', 'Hung-yi Lee']","['cs.SD', 'cs.CL', 'cs.LG']",True,False,False,False,False,False
367,2017-03-28T14:06:24Z,2017-03-25T16:17:03Z,http://arxiv.org/abs/1703.04617v2,http://arxiv.org/pdf/1703.04617v2,Exploring Question Understanding and Adaptation in Neural-Network-Based   Question Answering,explor question understand adapt neural network base question answer,"The last several years have seen intensive interest in exploring neural-network-based models for machine comprehension (MC) and question answering (QA). In this paper, we approach the problems by closely modelling questions in a neural network framework. We first introduce syntactic information to help encode questions. We then view and model different types of questions and the information shared among them as an adaptation task and proposed adaptation models for them. On the Stanford Question Answering Dataset (SQuAD), we show that these approaches can help attain better results over a competitive baseline.",last sever year seen intens interest explor neural network base model machin comprehens mc question answer qa paper approach problem close model question neural network framework first introduc syntact inform help encod question view model differ type question inform share among adapt task propos adapt model stanford question answer dataset squad show approach help attain better result competit baselin,"['Junbei Zhang', 'Xiaodan Zhu', 'Qian Chen', 'Lirong Dai', 'Si Wei', 'Hui Jiang']",['cs.CL'],True,False,False,False,False,False
382,2017-03-28T14:06:31Z,2017-03-11T10:05:19Z,http://arxiv.org/abs/1703.03939v1,http://arxiv.org/pdf/1703.03939v1,Ask Me Even More: Dynamic Memory Tensor Networks (Extended Model),ask even dynam memori tensor network extend model,"We examine Memory Networks for the task of question answering (QA), under common real world scenario where training examples are scarce and under weakly supervised scenario, that is only extrinsic labels are available for training. We propose extensions for the Dynamic Memory Network (DMN), specifically within the attention mechanism, we call the resulting Neural Architecture as Dynamic Memory Tensor Network (DMTN). Ultimately, we see that our proposed extensions results in over 80% improvement in the number of task passed against the baselined standard DMN and 20% more task passed compared to state-of-the-art End-to-End Memory Network for Facebook's single task weakly trained 1K bAbi dataset.",examin memori network task question answer qa common real world scenario train exampl scarc weak supervis scenario onli extrins label avail train propos extens dynam memori network dmn specif within attent mechan call result neural architectur dynam memori tensor network dmtn ultim see propos extens result improv number task pass baselin standard dmn task pass compar state art end end memori network facebook singl task weak train babi dataset,"['Govardana Sachithanandam Ramachandran', 'Ajay Sohmshetty']","['cs.CL', 'cs.LG', 'cs.NE']",True,False,False,False,False,False
404,2017-03-28T14:08:43Z,2017-03-27T16:48:03Z,http://arxiv.org/abs/1703.09179v1,http://arxiv.org/pdf/1703.09179v1,Transfer learning for music classification and regression tasks,transfer learn music classif regress task,"In this paper, we present a transfer learning approach for music classification and regression tasks. We propose to use a pretrained convnet feature, a concatenated feature vector using activations of feature maps of multiple layers in a trained convolutional network. We show that how this convnet feature can serve as a general-purpose music representation. In the experiment, a convnet is trained for music tagging and then transferred for many music-related classification and regression tasks as well as an audio-related classification task. In experiments, the convnet feature outperforms the baseline MFCC feature in all tasks and many reported approaches of aggregating MFCCs and low- and high-level music features.",paper present transfer learn approach music classif regress task propos use pretrain convnet featur concaten featur vector use activ featur map multipl layer train convolut network show convnet featur serv general purpos music represent experi convnet train music tag transfer mani music relat classif regress task well audio relat classif task experi convnet featur outperform baselin mfcc featur task mani report approach aggreg mfccs low high level music featur,"['Keunwoo Choi', 'György Fazekas', 'Mark Sandler', 'Kyunghyun Cho']","['cs.CV', 'cs.AI', 'cs.MM', 'cs.SD']",True,False,False,False,False,False
433,2017-03-28T14:08:56Z,2017-03-25T06:18:38Z,http://arxiv.org/abs/1703.08653v1,http://arxiv.org/pdf/1703.08653v1,Bayesian Optimization for Refining Object Proposals,bayesian optim refin object propos,"We develop a general-purpose algorithm using a Bayesian optimization framework for the efficient refinement of object proposals. While recent research has achieved substantial progress for object localization and related objectives in computer vision, current state-of-the-art object localization procedures are nevertheless encumbered by inefficiency and inaccuracy. We present a novel, computationally efficient method for refining inaccurate bounding-box proposals for a target object using Bayesian optimization. Offline, image features from a convolutional neural network are used to train a model to predict the offset distance of an object proposal from a target object. Online, this model is used in a Bayesian active search to improve inaccurate object proposals. In experiments, we compare our approach to a state-of-the-art bounding-box regression method for localization refinement of pedestrian object proposals. Our method exhibits a substantial improvement for the task of localization refinement over this baseline regression method.",develop general purpos algorithm use bayesian optim framework effici refin object propos recent research achiev substanti progress object local relat object comput vision current state art object local procedur nevertheless encumb ineffici inaccuraci present novel comput effici method refin inaccur bound box propos target object use bayesian optim offlin imag featur convolut neural network use train model predict offset distanc object propos target object onlin model use bayesian activ search improv inaccur object propos experi compar approach state art bound box regress method local refin pedestrian object propos method exhibit substanti improv task local refin baselin regress method,"['Anthony D. Rhodes', 'Jordan Witte', 'Melanie Mitchell', 'Bruno Jedynak']",['cs.CV'],True,False,False,True,False,False
450,2017-03-28T14:09:05Z,2017-03-24T05:54:11Z,http://arxiv.org/abs/1703.08289v1,http://arxiv.org/pdf/1703.08289v1,Deep Direct Regression for Multi-Oriented Scene Text Detection,deep direct regress multi orient scene text detect,"In this paper, we first provide a new perspective to divide existing high performance object detection methods into direct and indirect regressions. Direct regression performs boundary regression by predicting the offsets from a given point, while indirect regression predicts the offsets from some bounding box proposals. Then we analyze the drawbacks of the indirect regression, which the recent state-of-the-art detection structures like Faster-RCNN and SSD follows, for multi-oriented scene text detection, and point out the potential superiority of direct regression. To verify this point of view, we propose a deep direct regression based method for multi-oriented scene text detection. Our detection framework is simple and effective with a fully convolutional network and one-step post processing. The fully convolutional network is optimized in an end-to-end way and has bi-task outputs where one is pixel-wise classification between text and non-text, and the other is direct regression to determine the vertex coordinates of quadrilateral text boundaries. The proposed method is particularly beneficial for localizing incidental scene texts. On the ICDAR2015 Incidental Scene Text benchmark, our method achieves the F1-measure of 81%, which is a new state-of-the-art and significantly outperforms previous approaches. On other standard datasets with focused scene texts, our method also reaches the state-of-the-art performance.",paper first provid new perspect divid exist high perform object detect method direct indirect regress direct regress perform boundari regress predict offset given point indirect regress predict offset bound box propos analyz drawback indirect regress recent state art detect structur like faster rcnn ssd follow multi orient scene text detect point potenti superior direct regress verifi point view propos deep direct regress base method multi orient scene text detect detect framework simpl effect fulli convolut network one step post process fulli convolut network optim end end way bi task output one pixel wise classif text non text direct regress determin vertex coordin quadrilater text boundari propos method particular benefici local incident scene text icdar incident scene text benchmark method achiev measur new state art signific outperform previous approach standard dataset focus scene text method also reach state art perform,"['Wenhao He', 'Xu-Yao Zhang', 'Fei Yin', 'Cheng-Lin Liu']",['cs.CV'],True,False,False,True,False,False
452,2017-03-28T14:09:05Z,2017-03-23T22:25:05Z,http://arxiv.org/abs/1703.08245v1,http://arxiv.org/pdf/1703.08245v1,On the Robustness of Convolutional Neural Networks to Internal   Architecture and Weight Perturbations,robust convolut neural network intern architectur weight perturb,"Deep convolutional neural networks are generally regarded as robust function approximators. So far, this intuition is based on perturbations to external stimuli such as the images to be classified. Here we explore the robustness of convolutional neural networks to perturbations to the internal weights and architecture of the network itself. We show that convolutional networks are surprisingly robust to a number of internal perturbations in the higher convolutional layers but the bottom convolutional layers are much more fragile. For instance, Alexnet shows less than a 30% decrease in classification performance when randomly removing over 70% of weight connections in the top convolutional or dense layers but performance is almost at chance with the same perturbation in the first convolutional layer. Finally, we suggest further investigations which could continue to inform the robustness of convolutional networks to internal perturbations.",deep convolut neural network general regard robust function approxim far intuit base perturb extern stimuli imag classifi explor robust convolut neural network perturb intern weight architectur network show convolut network surpris robust number intern perturb higher convolut layer bottom convolut layer much fragil instanc alexnet show less decreas classif perform random remov weight connect top convolut dens layer perform almost chanc perturb first convolut layer final suggest investig could continu inform robust convolut network intern perturb,"['Nicholas Cheney', 'Martin Schrimpf', 'Gabriel Kreiman']","['cs.LG', 'cs.CV']",True,False,False,False,False,False
455,2017-03-28T14:09:05Z,2017-03-24T12:12:37Z,http://arxiv.org/abs/1703.08132v2,http://arxiv.org/pdf/1703.08132v2,Weakly Supervised Action Learning with RNN based Fine-to-coarse Modeling,weak supervis action learn rnn base fine coars model,"We present an approach for weakly supervised learning of human actions. Given a set of videos and an ordered list of the occurring actions, the goal is to infer start and end frames of the related action classes within the video and to train the respective action classifiers without any need for hand labeled frame boundaries. To address this task, we propose a combination of a discriminative representation of subactions, modeled by a recurrent neural network, and a coarse probabilistic model to allow for a temporal alignment and inference over long sequences. While this system alone already generates good results, we show that the performance can be further improved by approximating the number of subactions to the characteristics of the different action classes. To this end, we adapt the number of subaction classes by iterating realignment and reestimation during training. The proposed system is evaluated on two benchmark datasets, the Breakfast and the Hollywood extended dataset, showing a competitive performance on various weak learning tasks such as temporal action segmentation and action alignment.",present approach weak supervis learn human action given set video order list occur action goal infer start end frame relat action class within video train respect action classifi without ani need hand label frame boundari address task propos combin discrimin represent subact model recurr neural network coars probabilist model allow tempor align infer long sequenc system alon alreadi generat good result show perform improv approxim number subact characterist differ action class end adapt number subact class iter realign reestim dure train propos system evalu two benchmark dataset breakfast hollywood extend dataset show competit perform various weak learn task tempor action segment action align,"['Alexander Richard', 'Hilde Kuehne', 'Juergen Gall']",['cs.CV'],True,False,False,False,False,False
456,2017-03-28T14:09:05Z,2017-03-23T15:57:23Z,http://arxiv.org/abs/1703.08120v1,http://arxiv.org/pdf/1703.08120v1,Recurrent and Contextual Models for Visual Question Answering,recurr contextu model visual question answer,"We propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the Visual7W dataset. Motivated by divergent trends in model complexities in the literature, we explore the balance between model expressiveness and simplicity by studying incrementally more complex architectures. We start with LSTM-encoding of input questions and answers; build on this with context generation by LSTM-encodings of neural image and question representations and attention over images; and evaluate the diversity and predictive power of our models and the ensemble thereof. All models are evaluated against a simple baseline inspired by the current state-of-the-art, consisting of involving simple concatenation of bag-of-words and CNN representations for the text and images, respectively. Generally, we observe marked variation in image-reasoning performance between our models not obvious from their overall performance, as well as evidence of dataset bias. Our standalone models achieve accuracies up to $64.6\%$, while the ensemble of all models achieves the best accuracy of $66.67\%$, within $0.5\%$ of the current state-of-the-art for Visual7W.",propos seri recurr contextu neural network model multipl choic visual question answer visualw dataset motiv diverg trend model complex literatur explor balanc model express simplic studi increment complex architectur start lstm encod input question answer build context generat lstm encod neural imag question represent attent imag evalu divers predict power model ensembl thereof model evalu simpl baselin inspir current state art consist involv simpl concaten bag word cnn represent text imag respect general observ mark variat imag reason perform model obvious overal perform well evid dataset bias standalon model achiev accuraci ensembl model achiev best accuraci within current state art visualw,"['Abhijit Sharang', 'Eric Lau']","['cs.CL', 'cs.CV']",True,False,False,False,False,False
467,2017-03-28T14:09:09Z,2017-03-23T09:06:13Z,http://arxiv.org/abs/1703.07971v1,http://arxiv.org/pdf/1703.07971v1,Image-based Localization using Hourglass Networks,imag base local use hourglass network,"In this paper, we propose an encoder-decoder convolutional neural network (CNN) architecture for estimating camera pose (orientation and location) from a single RGB-image. The architecture has a hourglass shape consisting of a chain of convolution and up-convolution layers followed by a regression part. The up-convolution layers are introduced to preserve the fine-grained information of the input image. Following the common practice, we train our model in end-to-end manner utilizing transfer learning from large scale classification data. The experiments demonstrate the performance of the approach on data exhibiting different lighting conditions, reflections, and motion blur. The results indicate a clear improvement over the previous state-of-the-art even when compared to methods that utilize sequence of test frames instead of a single frame.",paper propos encod decod convolut neural network cnn architectur estim camera pose orient locat singl rgb imag architectur hourglass shape consist chain convolut convolut layer follow regress part convolut layer introduc preserv fine grain inform input imag follow common practic train model end end manner util transfer learn larg scale classif data experi demonstr perform approach data exhibit differ light condit reflect motion blur result indic clear improv previous state art even compar method util sequenc test frame instead singl frame,"['Iaroslav Melekhov', 'Juha Ylioinas', 'Juho Kannala', 'Esa Rahtu']",['cs.CV'],True,False,False,True,False,False
487,2017-03-28T14:09:17Z,2017-03-23T13:56:01Z,http://arxiv.org/abs/1703.07523v2,http://arxiv.org/pdf/1703.07523v2,Deeply-Supervised CNN for Prostate Segmentation,deepli supervis cnn prostat segment,"Prostate segmentation from Magnetic Resonance (MR) images plays an important role in image guided interven- tion. However, the lack of clear boundary specifically at the apex and base, and huge variation of shape and texture between the images from different patients make the task very challenging. To overcome these problems, in this paper, we propose a deeply supervised convolutional neural network (CNN) utilizing the convolutional information to accurately segment the prostate from MR images. The proposed model can effectively detect the prostate region with additional deeply supervised layers compared with other approaches. Since some information will be abandoned after convolution, it is necessary to pass the features extracted from early stages to later stages. The experimental results show that significant segmentation accuracy improvement has been achieved by our proposed method compared to other reported approaches.",prostat segment magnet reson mr imag play import role imag guid interven tion howev lack clear boundari specif apex base huge variat shape textur imag differ patient make task veri challeng overcom problem paper propos deepli supervis convolut neural network cnn util convolut inform accur segment prostat mr imag propos model effect detect prostat region addit deepli supervis layer compar approach sinc inform abandon convolut necessari pass featur extract earli stage later stage experiment result show signific segment accuraci improv achiev propos method compar report approach,"['Qikui Zhu', 'Bo Du', 'Baris Turkbey', 'Peter L . Choyke', 'Pingkun Yan']",['cs.CV'],True,False,False,True,False,False
493,2017-03-28T14:09:21Z,2017-03-22T00:22:49Z,http://arxiv.org/abs/1703.07475v1,http://arxiv.org/pdf/1703.07475v1,PKU-MMD: A Large Scale Benchmark for Continuous Multi-Modal Human Action   Understanding,pku mmd larg scale benchmark continu multi modal human action understand,"Despite the fact that many 3D human activity benchmarks being proposed, most existing action datasets focus on the action recognition tasks for the segmented videos. There is a lack of standard large-scale benchmarks, especially for current popular data-hungry deep learning based methods. In this paper, we introduce a new large scale benchmark (PKU-MMD) for continuous multi-modality 3D human action understanding and cover a wide range of complex human activities with well annotated information. PKU-MMD contains 1076 long video sequences in 51 action categories, performed by 66 subjects in three camera views. It contains almost 20,000 action instances and 5.4 million frames in total. Our dataset also provides multi-modality data sources, including RGB, depth, Infrared Radiation and Skeleton. With different modalities, we conduct extensive experiments on our dataset in terms of two scenarios and evaluate different methods by various metrics, including a new proposed evaluation protocol 2D-AP. We believe this large-scale dataset will benefit future researches on action detection for the community.",despit fact mani human activ benchmark propos exist action dataset focus action recognit task segment video lack standard larg scale benchmark especi current popular data hungri deep learn base method paper introduc new larg scale benchmark pku mmd continu multi modal human action understand cover wide rang complex human activ well annot inform pku mmd contain long video sequenc action categori perform subject three camera view contain almost action instanc million frame total dataset also provid multi modal data sourc includ rgb depth infrar radiat skeleton differ modal conduct extens experi dataset term two scenario evalu differ method various metric includ new propos evalu protocol ap believ larg scale dataset benefit futur research action detect communiti,"['Chunhui Liu', 'Yueyu Hu', 'Yanghao Li', 'Sijie Song', 'Jiaying Liu']",['cs.CV'],True,False,False,False,False,False
496,2017-03-28T14:09:21Z,2017-03-21T21:05:21Z,http://arxiv.org/abs/1703.07431v1,http://arxiv.org/pdf/1703.07431v1,IOD-CNN: Integrating Object Detection Networks for Event Recognition,iod cnn integr object detect network event recognit,"Many previous methods have showed the importance of considering semantically relevant objects for performing event recognition, yet none of the methods have exploited the power of deep convolutional neural networks to directly integrate relevant object information into a unified network. We present a novel unified deep CNN architecture which integrates architecturally different, yet semantically-related object detection networks to enhance the performance of the event recognition task. Our architecture allows the sharing of the convolutional layers and a fully connected layer which effectively integrates event recognition, rigid object detection and non-rigid object detection.",mani previous method show import consid semant relev object perform event recognit yet none method exploit power deep convolut neural network direct integr relev object inform unifi network present novel unifi deep cnn architectur integr architectur differ yet semant relat object detect network enhanc perform event recognit task architectur allow share convolut layer fulli connect layer effect integr event recognit rigid object detect non rigid object detect,"['Sungmin Eum', 'Hyungtae Lee', 'Heesung Kwon', 'David Doermann']",['cs.CV'],True,False,False,False,False,False
800,2017-03-28T14:10:52Z,2017-03-27T16:48:03Z,http://arxiv.org/abs/1703.09179v1,http://arxiv.org/pdf/1703.09179v1,Transfer learning for music classification and regression tasks,transfer learn music classif regress task,"In this paper, we present a transfer learning approach for music classification and regression tasks. We propose to use a pretrained convnet feature, a concatenated feature vector using activations of feature maps of multiple layers in a trained convolutional network. We show that how this convnet feature can serve as a general-purpose music representation. In the experiment, a convnet is trained for music tagging and then transferred for many music-related classification and regression tasks as well as an audio-related classification task. In experiments, the convnet feature outperforms the baseline MFCC feature in all tasks and many reported approaches of aggregating MFCCs and low- and high-level music features.",paper present transfer learn approach music classif regress task propos use pretrain convnet featur concaten featur vector use activ featur map multipl layer train convolut network show convnet featur serv general purpos music represent experi convnet train music tag transfer mani music relat classif regress task well audio relat classif task experi convnet featur outperform baselin mfcc featur task mani report approach aggreg mfccs low high level music featur,"['Keunwoo Choi', 'György Fazekas', 'Mark Sandler', 'Kyunghyun Cho']","['cs.CV', 'cs.AI', 'cs.MM', 'cs.SD']",True,False,False,False,False,False
804,2017-03-28T14:10:52Z,2017-03-22T10:08:51Z,http://arxiv.org/abs/1703.07588v1,http://arxiv.org/pdf/1703.07588v1,Gate Activation Signal Analysis for Gated Recurrent Neural Networks and   Its Correlation with Phoneme Boundaries,gate activ signal analysi gate recurr neural network correl phonem boundari,"In this paper we analyze the gate activation signals inside the gated recurrent neural networks, and find the temporal structure of such signals is highly correlated with the phoneme boundaries. This correlation is further verified by a set of experiments for phoneme segmentation, in which better results compared to standard approaches were obtained.",paper analyz gate activ signal insid gate recurr neural network find tempor structur signal high correl phonem boundari correl verifi set experi phonem segment better result compar standard approach obtain,"['Yu-Hsuan Wang', 'Cheng-Tao Chung', 'Hung-yi Lee']","['cs.SD', 'cs.CL', 'cs.LG']",True,False,False,False,False,False
822,2017-03-28T14:11:00Z,2017-03-06T09:57:25Z,http://arxiv.org/abs/1703.01793v1,http://arxiv.org/pdf/1703.01793v1,Multi-Level and Multi-Scale Feature Aggregation Using Pre-trained   Convolutional Neural Networks for Music Auto-tagging,multi level multi scale featur aggreg use pre train convolut neural network music auto tag,"Music auto-tagging is often handled in a similar manner to image classification by regarding the 2D audio spectrogram as image data. However, music auto-tagging is distinguished from image classification in that the tags are highly diverse and have different levels of abstractions. Considering this issue, we propose a convolutional neural networks (CNN)-based architecture that embraces multi-level and multi-scaled features. The architecture is trained in three steps. First, we conduct supervised feature learning to capture local audio features using a set of CNNs with different input sizes. Second, we extract audio features from each layer of the pre-trained convolutional networks separately and aggregate them altogether given a long audio clip. Finally, we put them into fully-connected networks and make final predictions of the tags. Our experiments show that using the combination of multi-level and multi-scale features is highly effective in music auto-tagging and the proposed method outperforms previous state-of-the-arts on the Magnatagatune dataset and the million song dataset. We further show that the proposed architecture is useful in transfer learning.",music auto tag often handl similar manner imag classif regard audio spectrogram imag data howev music auto tag distinguish imag classif tag high divers differ level abstract consid issu propos convolut neural network cnn base architectur embrac multi level multi scale featur architectur train three step first conduct supervis featur learn captur local audio featur use set cnns differ input size second extract audio featur layer pre train convolut network separ aggreg altogeth given long audio clip final put fulli connect network make final predict tag experi show use combin multi level multi scale featur high effect music auto tag propos method outperform previous state art magnatagatun dataset million song dataset show propos architectur use transfer learn,"['Jongpil Lee', 'Juhan Nam']","['cs.NE', 'cs.LG', 'cs.MM', 'cs.SD']",True,False,False,False,False,False
856,2017-03-28T14:11:13Z,2017-02-11T20:04:46Z,http://arxiv.org/abs/1612.07837v2,http://arxiv.org/pdf/1612.07837v2,SampleRNN: An Unconditional End-to-End Neural Audio Generation Model,samplernn uncondit end end neural audio generat model,"In this paper we propose a novel model for unconditional audio generation based on generating one audio sample at a time. We show that our model, which profits from combining memory-less modules, namely autoregressive multilayer perceptrons, and stateful recurrent neural networks in a hierarchical structure is able to capture underlying sources of variations in the temporal sequences over very long time spans, on three datasets of different nature. Human evaluation on the generated samples indicate that our model is preferred over competing models. We also show how each component of the model contributes to the exhibited performance.",paper propos novel model uncondit audio generat base generat one audio sampl time show model profit combin memori less modul name autoregress multilay perceptron state recurr neural network hierarch structur abl captur sourc variat tempor sequenc veri long time span three dataset differ natur human evalu generat sampl indic model prefer compet model also show compon model contribut exhibit perform,"['Soroush Mehri', 'Kundan Kumar', 'Ishaan Gulrajani', 'Rithesh Kumar', 'Shubham Jain', 'Jose Sotelo', 'Aaron Courville', 'Yoshua Bengio']","['cs.SD', 'cs.AI']",True,False,False,False,False,False
867,2017-03-28T14:11:17Z,2016-12-15T14:32:20Z,http://arxiv.org/abs/1612.05082v1,http://arxiv.org/abs/1612.05082v1,A Fully Convolutional Deep Auditory Model for Musical Chord Recognition,fulli convolut deep auditori model music chord recognit,"Chord recognition systems depend on robust feature extraction pipelines. While these pipelines are traditionally hand-crafted, recent advances in end-to-end machine learning have begun to inspire researchers to explore data-driven methods for such tasks. In this paper, we present a chord recognition system that uses a fully convolutional deep auditory model for feature extraction. The extracted features are processed by a Conditional Random Field that decodes the final chord sequence. Both processing stages are trained automatically and do not require expert knowledge for optimising parameters. We show that the learned auditory system extracts musically interpretable features, and that the proposed chord recognition system achieves results on par or better than state-of-the-art algorithms.",chord recognit system depend robust featur extract pipelin pipelin tradit hand craft recent advanc end end machin learn begun inspir research explor data driven method task paper present chord recognit system use fulli convolut deep auditori model featur extract extract featur process condit random field decod final chord sequenc process stage train automat requir expert knowledg optimis paramet show learn auditori system extract music interpret featur propos chord recognit system achiev result par better state art algorithm,"['Filip Korzeniowski', 'Gerhard Widmer']","['cs.LG', 'cs.SD']",True,False,False,False,False,False
870,2017-03-28T14:11:21Z,2016-12-15T14:01:50Z,http://arxiv.org/abs/1612.05065v1,http://arxiv.org/pdf/1612.05065v1,Feature Learning for Chord Recognition: The Deep Chroma Extractor,featur learn chord recognit deep chroma extractor,"We explore frame-level audio feature learning for chord recognition using artificial neural networks. We present the argument that chroma vectors potentially hold enough information to model harmonic content of audio for chord recognition, but that standard chroma extractors compute too noisy features. This leads us to propose a learned chroma feature extractor based on artificial neural networks. It is trained to compute chroma features that encode harmonic information important for chord recognition, while being robust to irrelevant interferences. We achieve this by feeding the network an audio spectrum with context instead of a single frame as input. This way, the network can learn to selectively compensate noise and resolve harmonic ambiguities.   We compare the resulting features to hand-crafted ones by using a simple linear frame-wise classifier for chord recognition on various data sets. The results show that the learned feature extractor produces superior chroma vectors for chord recognition.",explor frame level audio featur learn chord recognit use artifici neural network present argument chroma vector potenti hold enough inform model harmon content audio chord recognit standard chroma extractor comput noisi featur lead us propos learn chroma featur extractor base artifici neural network train comput chroma featur encod harmon inform import chord recognit robust irrelev interfer achiev feed network audio spectrum context instead singl frame input way network learn select compens nois resolv harmon ambigu compar result featur hand craft one use simpl linear frame wise classifi chord recognit various data set result show learn featur extractor produc superior chroma vector chord recognit,"['Filip Korzeniowski', 'Gerhard Widmer']","['cs.SD', 'cs.LG']",True,False,False,False,False,False
879,2017-03-28T14:11:21Z,2016-12-12T17:06:19Z,http://arxiv.org/abs/1612.03789v1,http://arxiv.org/pdf/1612.03789v1,A Unit Selection Methodology for Music Generation Using Deep Neural   Networks,unit select methodolog music generat use deep neural network,"Several methods exist for a computer to generate music based on data including Markov chains, recurrent neural networks, recombinancy, and grammars. We explore the use of unit selection and concatenation as a means of generating music using a procedure based on ranking, where, we consider a unit to be a variable length number of measures of music. We first examine whether a unit selection method, that is restricted to a finite size unit library, can be sufficient for encompassing a wide spectrum of music. We do this by developing a deep autoencoder that encodes a musical input and reconstructs the input by selecting from the library. We then describe a generative model that combines a deep structured semantic model (DSSM) with an LSTM to predict the next unit, where units consist of four, two, and one measures of music. We evaluate the generative model using objective metrics including mean rank and accuracy and with a subjective listening test in which expert musicians are asked to complete a forced-choiced ranking task. We compare our model to a note-level generative baseline that consists of a stacked LSTM trained to predict forward by one note.",sever method exist comput generat music base data includ markov chain recurr neural network recombin grammar explor use unit select concaten mean generat music use procedur base rank consid unit variabl length number measur music first examin whether unit select method restrict finit size unit librari suffici encompass wide spectrum music develop deep autoencod encod music input reconstruct input select librari describ generat model combin deep structur semant model dssm lstm predict next unit unit consist four two one measur music evalu generat model use object metric includ mean rank accuraci subject listen test expert musician ask complet forc choic rank task compar model note level generat baselin consist stack lstm train predict forward one note,"['Mason Bretan', 'Gil Weinberg', 'Larry Heck']","['cs.SD', 'cs.AI', 'cs.LG']",True,False,False,False,False,False
1258,2017-03-28T14:02:06Z,2017-03-21T02:08:05Z,http://arxiv.org/abs/1703.07027v1,http://arxiv.org/pdf/1703.07027v1,Nonparametric Variational Auto-encoders for Hierarchical Representation   Learning,nonparametr variat auto encod hierarch represent learn,"The recently developed variational autoencoders (VAEs) have proved to be an effective confluence of the rich representational power of neural networks with Bayesian methods. However, most work on VAEs use a rather simple prior over the latent variables such as standard normal distribution, thereby restricting its applications to relatively simple phenomena. In this work, we propose hierarchical nonparametric variational autoencoders, which combines tree-structured Bayesian nonparametric priors with VAEs, to enable infinite flexibility of the latent representation space. Both the neural parameters and Bayesian priors are learned jointly using tailored variational inference. The resulting model induces a hierarchical structure of latent semantic concepts underlying the data corpus, and infers accurate representations of data instances. We apply our model in video representation learning. Our method is able to discover highly interpretable activity hierarchies, and obtain improved clustering accuracy and generalization capacity based on the learned rich representations.",recent develop variat autoencod vae prove effect confluenc rich represent power neural network bayesian method howev work vae use rather simpl prior latent variabl standard normal distribut therebi restrict applic relat simpl phenomena work propos hierarch nonparametr variat autoencod combin tree structur bayesian nonparametr prior vae enabl infinit flexibl latent represent space neural paramet bayesian prior learn joint use tailor variat infer result model induc hierarch structur latent semant concept data corpus infer accur represent data instanc appli model video represent learn method abl discov high interpret activ hierarchi obtain improv cluster accuraci general capac base learn rich represent,"['Prasoon Goyal', 'Zhiting Hu', 'Xiaodan Liang', 'Chenyu Wang', 'Eric Xing']","['cs.LG', 'stat.ML']",True,False,False,False,False,False
1268,2017-03-28T14:02:09Z,2017-03-20T14:02:11Z,http://arxiv.org/abs/1703.06749v1,http://arxiv.org/pdf/1703.06749v1,Efficient variational Bayesian neural network ensembles for outlier   detection,effici variat bayesian neural network ensembl outlier detect,In this work we perform outlier detection using ensembles of neural networks obtained by variational approximation of the posterior in a Bayesian neural network setting. The variational parameters are obtained by sampling from the true posterior by gradient descent. We show our outlier detection results are better than those obtained using other efficient ensembling methods.,work perform outlier detect use ensembl neural network obtain variat approxim posterior bayesian neural network set variat paramet obtain sampl true posterior gradient descent show outlier detect result better obtain use effici ensembl method,"['Nick Pawlowski', 'Miguel Jaques', 'Ben Glocker']","['stat.ML', 'cs.LG']",True,False,False,False,False,False
