2017-03-28T14:07:16Z|2017-03-24T16:55:40Z|http://arxiv.org/abs/1703.08504v1|http://arxiv.org/pdf/1703.08504v1|Shingle 2.0: generalising self-consistent and automated domain   discretisation for multi-scale geophysical models|shingl generalis self consist autom domain discretis multi scale geophys model|The approaches taken to describe and develop spatial discretisations of the domains required for geophysical simulation models are commonly ad hoc, model or application specific and under-documented. This is particularly acute for simulation models that are flexible in their use of multi-scale, anisotropic, fully unstructured meshes where a relatively large number of heterogeneous parameters are required to constrain their full description. As a consequence, it can be difficult to reproduce simulations, ensure a provenance in model data handling and initialisation, and a challenge to conduct model intercomparisons rigorously. This paper takes a novel approach to spatial discretisation, considering it much like a numerical simulation model problem of its own. It introduces a generalised, extensible, self-documenting approach to carefully describe, and necessarily fully, the constraints over the heterogeneous parameter space that determine how a domain is spatially discretised. This additionally provides a method to accurately record these constraints, using high-level natural language based abstractions, that enables full accounts of provenance, sharing and distribution. Together with this description, a generalised consistent approach to unstructured mesh generation for geophysical models is developed, that is automated, robust and repeatable, quick-to-draft, rigorously verified and consistent to the source data throughout. This interprets the description above to execute a self-consistent spatial discretisation process, which is automatically validated to expected discrete characteristics and metrics.|approach taken describ develop spatial discretis domain requir geophys simul model common ad hoc model applic specif document particular acut simul model flexibl use multi scale anisotrop fulli unstructur mesh relat larg number heterogen paramet requir constrain full descript consequ difficult reproduc simul ensur proven model data handl initialis challeng conduct model intercomparison rigor paper take novel approach spatial discretis consid much like numer simul model problem introduc generalis extens self document approach care describ necessarili fulli constraint heterogen paramet space determin domain spatial discretis addit provid method accur record constraint use high level natur languag base abstract enabl full account proven share distribut togeth descript generalis consist approach unstructur mesh generat geophys model develop autom robust repeat quick draft rigor verifi consist sourc data throughout interpret descript abov execut self consist spatial discretis process automat valid expect discret characterist metric|['Adam S. Candy', 'Julie D. Pietrzak']|['physics.geo-ph', 'cs.CG', 'physics.ao-ph', 'physics.comp-ph', 'physics.flu-dyn']
2017-03-28T14:07:16Z|2017-03-24T16:27:52Z|http://arxiv.org/abs/1703.08491v1|http://arxiv.org/pdf/1703.08491v1|A consistent approach to unstructured mesh generation for geophysical   models|consist approach unstructur mesh generat geophys model|Geophysical model domains typically contain irregular, complex fractal-like boundaries and physical processes that act over a wide range of scales. Constructing geographically constrained boundary-conforming spatial discretizations of these domains with flexible use of anisotropically, fully unstructured meshes is a challenge. The problem contains a wide range of scales and a relatively large, heterogeneous constraint parameter space. Approaches are commonly ad hoc, model or application specific and insufficiently described. Development of new spatial domains is frequently time-consuming, hard to repeat, error prone and difficult to ensure consistent due to the significant human input required. As a consequence, it is difficult to reproduce simulations, ensure a provenance in model data handling and initialization, and a challenge to conduct model intercomparisons rigorously. Moreover, for flexible unstructured meshes, there is additionally a greater potential for inconsistencies in model initialization and forcing parameters. This paper introduces a consistent approach to unstructured mesh generation for geophysical models, that is automated, quick-to-draft and repeat, and provides a rigorous and robust approach that is consistent to the source data throughout. The approach is enabling further new research in complex multi-scale domains, difficult or not possible to achieve with existing methods. Examples being actively pursued in a range of geophysical modeling efforts are presented alongside the approach, together with the implementation library Shingle and a selection of its verification test cases.|geophys model domain typic contain irregular complex fractal like boundari physic process act wide rang scale construct geograph constrain boundari conform spatial discret domain flexibl use anisotrop fulli unstructur mesh challeng problem contain wide rang scale relat larg heterogen constraint paramet space approach common ad hoc model applic specif insuffici describ develop new spatial domain frequent time consum hard repeat error prone difficult ensur consist due signific human input requir consequ difficult reproduc simul ensur proven model data handl initi challeng conduct model intercomparison rigor moreov flexibl unstructur mesh addit greater potenti inconsist model initi forc paramet paper introduc consist approach unstructur mesh generat geophys model autom quick draft repeat provid rigor robust approach consist sourc data throughout approach enabl new research complex multi scale domain difficult possibl achiev exist method exampl activ pursu rang geophys model effort present alongsid approach togeth implement librari shingl select verif test case|['Adam S. Candy']|['physics.geo-ph', 'cs.CG', 'physics.ao-ph', 'physics.comp-ph', 'physics.flu-dyn']
2017-03-28T14:07:16Z|2017-03-21T18:50:24Z|http://arxiv.org/abs/1703.07387v1|http://arxiv.org/pdf/1703.07387v1|Topological Analysis of Nerves, Reeb Spaces, Mappers, and Multiscale   Mappers|topolog analysi nerv reeb space mapper multiscal mapper|"Data analysis often concerns not only the space where data come from, but also various types of maps attached to data. In recent years, several related structures have been used to study maps on data, including Reeb spaces, mappers and multiscale mappers. The construction of these structures also relies on the so-called \emph{nerve} of a cover of the domain.   In this paper, we aim to analyze the topological information encoded in these structures in order to provide better understanding of these structures and facilitate their practical usage.   More specifically, we show that the one-dimensional homology of the nerve complex $N(\mathcal{U})$ of a path-connected cover $\mathcal{U}$ of a domain $X$ cannot be richer than that of the domain $X$ itself. Intuitively, this result means that no new $H_1$-homology class can be ""created"" under a natural map from $X$ to the nerve complex $N(\mathcal{U})$. Equipping $X$ with a pseudometric $d$, we further refine this result and characterize the classes of $H_1(X)$ that may survive in the nerve complex using the notion of \emph{size} of the covering elements in $\mathcal{U}$. These fundamental results about nerve complexes then lead to an analysis of the $H_1$-homology of Reeb spaces, mappers and multiscale mappers.   The analysis of $H_1$-homology groups unfortunately does not extend to higher dimensions. Nevertheless, by using a map-induced metric, establishing a Gromov-Hausdorff convergence result between mappers and the domain, and interleaving relevant modules, we can still analyze the persistent homology groups of (multiscale) mappers to establish a connection to Reeb spaces."|data analysi often concern onli space data come also various type map attach data recent year sever relat structur use studi map data includ reeb space mapper multiscal mapper construct structur also reli call emph nerv cover domain paper aim analyz topolog inform encod structur order provid better understand structur facilit practic usag specif show one dimension homolog nerv complex mathcal path connect cover mathcal domain cannot richer domain intuit result mean new homolog class creat natur map nerv complex mathcal equip pseudometr refin result character class may surviv nerv complex use notion emph size cover element mathcal fundament result nerv complex lead analysi homolog reeb space mapper multiscal mapper analysi homolog group unfortun doe extend higher dimens nevertheless use map induc metric establish gromov hausdorff converg result mapper domain interleav relev modul still analyz persist homolog group multiscal mapper establish connect reeb space|['Tamal K. Dey', 'Facundo Memoli', 'Yusu Wang']|['cs.CG', 'math.AT']
2017-03-28T14:07:16Z|2017-03-23T15:17:23Z|http://arxiv.org/abs/1703.06983v2|http://arxiv.org/pdf/1703.06983v2|Collapsibility to a subcomplex of a given dimension is NP-complete|collaps subcomplex given dimens np complet|In this paper we extend the works of Tancer and of Malgouyres and Franc\'es, showing that $(d,k)$-collapsibility is NP-complete for $d\geq k+2$ except $(2,0)$. By $(d,k)$-collapsibility we mean the following problem: determine whether a given $d$-dimensional simplicial complex can be collapsed to some $k$-dimensional subcomplex. The question of establishing the complexity status of $(d,k)$-collapsibility was asked by Tancer, who proved NP-completeness of $(d,0)$ and $(d,1)$-collapsibility (for $d\geq 3$). Our extended result, together with the known polynomial-time algorithms for $(2,0)$ and $d=k+1$, answers the question completely.|paper extend work tancer malgouyr franc es show collaps np complet geq except collaps mean follow problem determin whether given dimension simplici complex collaps dimension subcomplex question establish complex status collaps ask tancer prove np complet collaps geq extend result togeth known polynomi time algorithm answer question complet|['Giovanni Paolini']|['cs.CG', 'cs.CC', 'math.GT']
2017-03-28T14:07:16Z|2017-03-19T22:13:17Z|http://arxiv.org/abs/1703.06526v1|http://arxiv.org/pdf/1703.06526v1|On Optimal 2- and 3-Planar Graphs|optim planar graph|"A graph is $k$-planar if it can be drawn in the plane such that no edge is crossed more than $k$ times. While for $k=1$, optimal $1$-planar graphs, i.e., those with $n$ vertices and exactly $4n-8$ edges, have been completely characterized, this has not been the case for $k \geq 2$. For $k=2,3$ and $4$, upper bounds on the edge density have been developed for the case of simple graphs by Pach and T\'oth, Pach et al. and Ackerman, which have been used to improve the well-known ""Crossing Lemma"". Recently, we proved that these bounds also apply to non-simple $2$- and $3$-planar graphs without homotopic parallel edges and self-loops.   In this paper, we completely characterize optimal $2$- and $3$-planar graphs, i.e., those that achieve the aforementioned upper bounds. We prove that they have a remarkably simple regular structure, although they might be non-simple. The new characterization allows us to develop notable insights concerning new inclusion relationships with other graph classes."|graph planar drawn plane edg cross time optim planar graph vertic exact edg complet character case geq upper bound edg densiti develop case simpl graph pach oth pach et al ackerman use improv well known cross lemma recent prove bound also appli non simpl planar graph without homotop parallel edg self loop paper complet character optim planar graph achiev aforement upper bound prove remark simpl regular structur although might non simpl new character allow us develop notabl insight concern new inclus relationship graph class|['Michael A. Bekos', 'Michael Kaufmann', 'Chrysanthi N. Raftopoulou']|['cs.CG', 'cs.DM']
2017-03-28T14:07:16Z|2017-03-19T18:48:06Z|http://arxiv.org/abs/1703.06487v1|http://arxiv.org/pdf/1703.06487v1|Anisotropic triangulations via discrete Riemannian Voronoi diagrams|anisotrop triangul via discret riemannian voronoi diagram|The construction of anisotropic triangulations is desirable for various applications, such as the numerical solving of partial differential equations and the representation of surfaces in graphics. To solve this notoriously difficult problem in a practical way, we introduce the discrete Riemannian Voronoi diagram, a discrete structure that approximates the Riemannian Voronoi diagram. This structure has been implemented and was shown to lead to good triangulations in $\mathbb{R}^2$ and on surfaces embedded in $\mathbb{R}^3$ as detailed in our experimental companion paper.   In this paper, we study theoretical aspects of our structure. Given a finite set of points $\cal P$ in a domain $\Omega$ equipped with a Riemannian metric, we compare the discrete Riemannian Voronoi diagram of $\cal P$ to its Riemannian Voronoi diagram. Both diagrams have dual structures called the discrete Riemannian Delaunay and the Riemannian Delaunay complex. We provide conditions that guarantee that these dual structures are identical. It then follows from previous results that the discrete Riemannian Delaunay complex can be embedded in $\Omega$ under sufficient conditions, leading to an anisotropic triangulation with curved simplices. Furthermore, we show that, under similar conditions, the simplices of this triangulation can be straightened.|construct anisotrop triangul desir various applic numer solv partial differenti equat represent surfac graphic solv notori difficult problem practic way introduc discret riemannian voronoi diagram discret structur approxim riemannian voronoi diagram structur implement shown lead good triangul mathbb surfac embed mathbb detail experiment companion paper paper studi theoret aspect structur given finit set point cal domain omega equip riemannian metric compar discret riemannian voronoi diagram cal riemannian voronoi diagram diagram dual structur call discret riemannian delaunay riemannian delaunay complex provid condit guarante dual structur ident follow previous result discret riemannian delaunay complex embed omega suffici condit lead anisotrop triangul curv simplic furthermor show similar condit simplic triangul straighten|['Jean-Daniel Boissonnat', 'Mael Rouxel-Labbé', 'Mathijs Wintraecken']|['cs.CG']
2017-03-28T14:07:16Z|2017-03-18T15:35:10Z|http://arxiv.org/abs/1703.06307v1|http://arxiv.org/pdf/1703.06307v1|Definition of geometric space around analytic fractal trees using   derivative coordinate funtions|definit geometr space around analyt fractal tree use deriv coordin funtion|The concept of derivative coordinate functions proved useful in the formulation of analytic fractal functions to represent smooth symmetric binary fractal trees [1]. In this paper we introduce a new geometry that defines the fractal space around these fractal trees. We present the canonical and degenerate form of this fractal space and extend the fractal geometrical space to R3 specifically and Rn by a recurrence relation. We also discuss the usage of such fractal geometry.|concept deriv coordin function prove use formul analyt fractal function repres smooth symmetr binari fractal tree paper introduc new geometri defin fractal space around fractal tree present canon degener form fractal space extend fractal geometr space specif rn recurr relat also discuss usag fractal geometri|['Henk Mulder']|['cs.CG']
2017-03-28T14:07:16Z|2017-03-18T14:58:57Z|http://arxiv.org/abs/1703.06305v1|http://arxiv.org/pdf/1703.06305v1|Hardness of almost embedding simplicial complexes in $\mathbb R^d$|hard almost embed simplici complex mathbb|A map $f\colon K\to \mathbb R^d$ of a simplicial complex is an almost embedding if $f(\sigma)\cap f(\tau)=\emptyset$ whenever $\sigma,\tau$ are disjoint simplices of $K$.   Theorem. Fix integers $d,k\ge2$ such that $d=\frac{3k}2+1$.   (a) Assume that $P\ne NP$. Then there exists a finite $k$-dimensional complex $K$ that does not admit an almost embedding in $\mathbb R^d$ but for which there exists an equivariant map $\tilde K\to S^{d-1}$.   (b) The algorithmic problem of recognition almost embeddability of finite $k$-dimensional complexes in $\mathbb R^d$ is NP hard.   The proof is based on the technique from the Matou\v{s}ek-Tancer-Wagner paper (proving an analogous result for embeddings), and on singular versions of the higher-dimensional Borromean rings lemma and a generalized van Kampen--Flores theorem.|map colon mathbb simplici complex almost embed sigma cap tau emptyset whenev sigma tau disjoint simplic theorem fix integ ge frac assum ne np exist finit dimension complex doe admit almost embed mathbb exist equivari map tild algorithm problem recognit almost embedd finit dimension complex mathbb np hard proof base techniqu matou ek tancer wagner paper prove analog result embed singular version higher dimension borromean ring lemma general van kampen flore theorem|['Arkadiy Skopenkov', 'Martin Tancer']|['math.GT', 'cs.CG']
2017-03-28T14:07:16Z|2017-03-17T17:13:58Z|http://arxiv.org/abs/1703.06107v1|http://arxiv.org/pdf/1703.06107v1|Self-approaching paths in simple polygons|self approach path simpl polygon|We study self-approaching paths that are contained in a simple polygon. A self-approaching path is a directed curve connecting two points such that the Euclidean distance between a point moving along the path and any future position does not increase, that is, for all points $a$, $b$, and $c$ that appear in that order along the curve, $ ac  \ge  bc $. We analyze the properties, and present a characterization of shortest self-approaching paths. In particular, we show that a shortest self-approaching path connecting two points inside a polygon can be forced to use a general class of non-algebraic curves. While this makes it difficult to design an exact algorithm, we show how to find a self-approaching path inside a polygon connecting two points under a model of computation which assumes that we can calculate involute curves of high order. Lastly, we provide an algorithm to test if a given simple polygon is self-approaching, that is, if there exists a self-approaching path for any two points inside the polygon.|studi self approach path contain simpl polygon self approach path direct curv connect two point euclidean distanc point move along path ani futur posit doe increas point appear order along curv ac ge bc analyz properti present character shortest self approach path particular show shortest self approach path connect two point insid polygon forc use general class non algebra curv make difficult design exact algorithm show find self approach path insid polygon connect two point model comput assum calcul involut curv high order last provid algorithm test given simpl polygon self approach exist self approach path ani two point insid polygon|['Prosenjit Bose', 'Irina Kostitsyna', 'Stefan Langerman']|['cs.CG']
2017-03-28T14:07:16Z|2017-03-17T01:31:12Z|http://arxiv.org/abs/1703.05863v1|http://arxiv.org/pdf/1703.05863v1|Packing Short Plane Spanning Graphs in Complete Geometric Graphs|pack short plane span graph complet geometr graph|Given a set of points in the plane, we want to establish a connection network between these points that consists of several disjoint layers. Motivated by sensor networks, we want that each layer is spanning and plane, and that no edge is very long (when compared to the minimum length needed to obtain a spanning graph).   We consider two different approaches: first we show an almost optimal centralized approach to extract two graphs. Then we show a constant factor approximation for a distributed model in which each point can compute its adjacencies using only local information. In both cases the obtained layers are plane|given set point plane want establish connect network point consist sever disjoint layer motiv sensor network want layer span plane edg veri long compar minimum length need obtain span graph consid two differ approach first show almost optim central approach extract two graph show constant factor approxim distribut model point comput adjac use onli local inform case obtain layer plane|['Oswin Aichholzer', 'Thomas Hackl', 'Matias Korman', 'Alexander Pilz', 'Günter Rote', 'André van Renssen', 'Marcel Roeloffzen', 'Birgit Vogtenhuber']|['cs.CG']
2017-03-28T14:07:20Z|2017-03-16T10:22:34Z|http://arxiv.org/abs/1703.05549v1|http://arxiv.org/pdf/1703.05549v1|Minimum Perimeter-Sum Partitions in the Plane|minimum perimet sum partit plane|Let $P$ be a set of $n$ points in the plane. We consider the problem of partitioning $P$ into two subsets $P_1$ and $P_2$ such that the sum of the perimeters of $\text{CH}(P_1)$ and $\text{CH}(P_2)$ is minimized, where $\text{CH}(P_i)$ denotes the convex hull of $P_i$. The problem was first studied by Mitchell and Wynters in 1991 who gave an $O(n^2)$ time algorithm. Despite considerable progress on related problems, no subquadratic time algorithm for this problem was found so far. We present an exact algorithm solving the problem in $O(n \log^4 n)$ time and a $(1+\varepsilon)$-approximation algorithm running in $O(n + 1/\varepsilon^2\cdot\log^4(1/\varepsilon))$ time.|let set point plane consid problem partit two subset sum perimet text ch text ch minim text ch denot convex hull problem first studi mitchel wynter gave time algorithm despit consider progress relat problem subquadrat time algorithm problem found far present exact algorithm solv problem log time varepsilon approxim algorithm run varepsilon cdot log varepsilon time|['Mikkel Abrahamsen', 'Mark de Berg', 'Kevin Buchin', 'Mehran Mehr', 'Ali D. Mehrabi']|['cs.CG']
2017-03-28T14:07:20Z|2017-03-19T22:20:57Z|http://arxiv.org/abs/1703.05475v2|http://arxiv.org/pdf/1703.05475v2|A quest to unravel the metric structure behind perturbed networks|quest unravel metric structur behind perturb network|"Graphs and network data are ubiquitous across a wide spectrum of scientific and application domains. Often in practice, an input graph can be considered as an observed snapshot of a (potentially continuous) hidden domain or process. Subsequent analysis, processing, and inferences are then performed on this observed graph. In this paper we advocate the perspective that an observed graph is often a noisy version of some discretized 1-skeleton of a hidden domain, and specifically we will consider the following natural network model: We assume that there is a true graph ${G^*}$ which is a certain proximity graph for points sampled from a hidden domain $\mathcal{X}$; while the observed graph $G$ is an Erd$\""{o}$s-R$\'{e}$nyi type perturbed version of ${G^*}$.   Our network model is related to, and slightly generalizes, the much-celebrated small-world network model originally proposed by Watts and Strogatz. However, the main question we aim to answer is orthogonal to the usual studies of network models (which often focuses on characterizing / predicting behaviors and properties of real-world networks). Specifically, we aim to recover the metric structure of ${G^*}$ (which reflects that of the hidden space $\mathcal{X}$ as we will show) from the observed graph $G$. Our main result is that a simple filtering process based on the \emph{Jaccard index} can recover this metric within a multiplicative factor of $2$ under our network model. Our work makes one step towards the general question of inferring structure of a hidden space from its observed noisy graph representation. In addition, our results also provide a theoretical understanding for Jaccard-Index-based denoising approaches."|graph network data ubiquit across wide spectrum scientif applic domain often practic input graph consid observ snapshot potenti continu hidden domain process subsequ analysi process infer perform observ graph paper advoc perspect observ graph often noisi version discret skeleton hidden domain specif consid follow natur network model assum true graph certain proxim graph point sampl hidden domain mathcal observ graph erd nyi type perturb version network model relat slight general much celebr small world network model origin propos watt strogatz howev main question aim answer orthogon usual studi network model often focus character predict behavior properti real world network specif aim recov metric structur reflect hidden space mathcal show observ graph main result simpl filter process base emph jaccard index recov metric within multipl factor network model work make one step toward general question infer structur hidden space observ noisi graph represent addit result also provid theoret understand jaccard index base denois approach|['Srinivasan Parthasarathy', 'David Sivakoff', 'Minghao Tian', 'Yusu Wang']|['cs.CG', 'F.2.2; G.2.2']
2017-03-28T14:07:20Z|2017-03-15T01:00:44Z|http://arxiv.org/abs/1703.04861v1|http://arxiv.org/pdf/1703.04861v1|Robust Non-Rigid Registration With Reweighted Dual Sparsities|robust non rigid registr reweight dual sparsiti|Non-rigid registration is challenging because it is ill-posed with high degrees of freedom and is thus sensitive to noise and outliers. We propose a robust non-rigid registration method using reweighted sparsities on position and transformation to estimate the deformations between 3-D shapes. We formulate the energy function with dual sparsities on both the data term and the smoothness term, and define the smoothness constraint using local rigidity. The dual-sparsity based non-rigid registration model is enhanced with a reweighting scheme, and solved by transferring the model into some alternating optimized subproblems which have exact solutions and guaranteed convergence. Experimental results on both public datasets and real scanned datasets show that our method outperforms the state-of-the-art methods and is more robust to noise and outliers than conventional non-rigid registration methods.|non rigid registr challeng becaus ill pose high degre freedom thus sensit nois outlier propos robust non rigid registr method use reweight sparsiti posit transform estim deform shape formul energi function dual sparsiti data term smooth term defin smooth constraint use local rigid dual sparsiti base non rigid registr model enhanc reweight scheme solv transfer model altern optim subproblem exact solut guarante converg experiment result public dataset real scan dataset show method outperform state art method robust nois outlier convent non rigid registr method|['Jingyu Yang', 'Kun Li', 'Yu-Kun Lai', 'Daoliang Guo']|['cs.CV', 'cs.CG', 'cs.GR']
2017-03-28T14:07:20Z|2017-03-14T22:19:50Z|http://arxiv.org/abs/1703.04774v1|http://arxiv.org/pdf/1703.04774v1|Self-Assembly of 4-sided Fractals in the Two-handed Tile Assembly Model|self assembl side fractal two hand tile assembl model|In this paper, we consider the strict self-assembly of fractals in one of the most well-studied models of tile based self-assembling systems known as the Two-handed Tile Assembly Model (2HAM). We are particularly interested in a class of fractals called discrete self-similar fractals (a class of fractals that includes the discrete Sierpinski's carpet). We present a 2HAM system that strictly self-assembles the discrete Sierpinski's carpet with scale factor 1. Moreover, the 2HAM system that we give lends itself to being generalized and we describe how this system can be modified to obtain a 2HAM system that strictly self-assembles one of any fractal from an infinite set of fractals which we call 4-sided fractals. The 2HAM systems we give in this paper are the first examples of systems that strictly self-assemble discrete self-similar fractals at scale factor 1 in a purely growth model of self-assembly. Finally, we give an example of a 3-sided fractal (which is not a tree fractal) that cannot be strictly self-assembled by any 2HAM system.|paper consid strict self assembl fractal one well studi model tile base self assembl system known two hand tile assembl model ham particular interest class fractal call discret self similar fractal class fractal includ discret sierpinski carpet present ham system strict self assembl discret sierpinski carpet scale factor moreov ham system give lend general describ system modifi obtain ham system strict self assembl one ani fractal infinit set fractal call side fractal ham system give paper first exampl system strict self assembl discret self similar fractal scale factor pure growth model self assembl final give exampl side fractal tree fractal cannot strict self assembl ani ham system|['Jacob Hendricks', 'Joseph Opseth']|['cs.ET', 'cs.CG']
2017-03-28T14:07:20Z|2017-03-14T22:13:58Z|http://arxiv.org/abs/1703.04758v1|http://arxiv.org/pdf/1703.04758v1|Approximation Schemes for Independent Set and Sparse Subsets of Polygons|approxim scheme independ set spars subset polygon|We present an $(1+\varepsilon)$-approximation algorithm with quasi-polynomial running time for computing the maximum weight independent set of polygons out of a given set of polygons in the plane (specifically, the running time is $n^{O( \mathrm{poly}( \log n, 1/\varepsilon))}$). Contrasting this, the best known polynomial time algorithm for the problem has an approximation ratio of~$n^{\varepsilon}$. Surprisingly, we can extend the algorithm to the problem of computing the maximum weight subset of the given set of polygons whose intersection graph fulfills some sparsity condition. For example, we show that one can approximate the maximum weight subset of polygons, such that the intersection graph of the subset is planar or does not contain a cycle of length $4$ (i.e., $K_{2,2}$). Our algorithm relies on a recursive partitioning scheme, whose backbone is the existence of balanced cuts with small complexity that intersect polygons from the optimal solution of a small total weight.   For the case of large axis-parallel rectangles, we provide a polynomial time $(1+\varepsilon)$-approximation for the maximum weight independent set. Specifically, we consider the problem where each rectangle has one edge whose length is at least a constant fraction of the length of the corresponding edge of the bounding box of all the input elements. This is now the most general case for which a PTAS is known, and it requires a new and involved partitioning scheme, which should be of independent interest.|present varepsilon approxim algorithm quasi polynomi run time comput maximum weight independ set polygon given set polygon plane specif run time mathrm poli log varepsilon contrast best known polynomi time algorithm problem approxim ratio varepsilon surpris extend algorithm problem comput maximum weight subset given set polygon whose intersect graph fulfil sparsiti condit exampl show one approxim maximum weight subset polygon intersect graph subset planar doe contain cycl length algorithm reli recurs partit scheme whose backbon exist balanc cut small complex intersect polygon optim solut small total weight case larg axi parallel rectangl provid polynomi time varepsilon approxim maximum weight independ set specif consid problem rectangl one edg whose length least constant fraction length correspond edg bound box input element general case ptas known requir new involv partit scheme independ interest|['Anna Adamaszek', 'Sariel Har-Peled', 'Andreas Wiese']|['cs.CG']
2017-03-28T14:07:20Z|2017-03-13T16:18:01Z|http://arxiv.org/abs/1703.04466v1|http://arxiv.org/pdf/1703.04466v1|Bicriteria Rectilinear Shortest Paths among Rectilinear Obstacles in the   Plane|bicriteria rectilinear shortest path among rectilinear obstacl plane|Given a rectilinear domain $\mathcal{P}$ of $h$ pairwise-disjoint rectilinear obstacles with a total of $n$ vertices in the plane, we study the problem of computing bicriteria rectilinear shortest paths between two points $s$ and $t$ in $\mathcal{P}$. Three types of bicriteria rectilinear paths are considered: minimum-link shortest paths, shortest minimum-link paths, and minimum-cost paths where the cost of a path is a non-decreasing function of both the number of edges and the length of the path. The one-point and two-point path queries are also considered. Algorithms for these problems have been given previously. Our contributions are threefold. First, we find a critical error in all previous algorithms. Second, we correct the error in a not-so-trivial way. Third, we further improve the algorithms so that they are even faster than the previous (incorrect) algorithms when $h$ is relatively small. For example, for the minimum-link shortest paths, we obtain the following results. Our algorithm computes a minimum-link shortest $s$-$t$ path in $O(n+h\log^{3/2} h)$ time. For the one-point queries, we build a data structure of size $O(n+ h\log h)$ in $O(n+h\log^{3/2} h)$ time for a source point $s$, such that given any query point $t$, a minimum-link shortest $s$-$t$ path can be determined in $O(\log n)$ time. For the two-point queries, with $O(n+h^2\log^2 h)$ time and space preprocessing, a minimum-link shortest $s$-$t$ path can be determined in $O(\log n+\log^2 h)$ time for any two query points $s$ and $t$; alternatively, with $O(n+h^2\cdot \log^{2} h \cdot 4^{\sqrt{\log h}})$ time and $O(n+h^2\cdot \log h \cdot 4^{\sqrt{\log h}})$ space preprocessing, we can answer each two-point query in $O(\log n)$ time.|given rectilinear domain mathcal pairwis disjoint rectilinear obstacl total vertic plane studi problem comput bicriteria rectilinear shortest path two point mathcal three type bicriteria rectilinear path consid minimum link shortest path shortest minimum link path minimum cost path cost path non decreas function number edg length path one point two point path queri also consid algorithm problem given previous contribut threefold first find critic error previous algorithm second correct error trivial way third improv algorithm even faster previous incorrect algorithm relat small exampl minimum link shortest path obtain follow result algorithm comput minimum link shortest path log time one point queri build data structur size log log time sourc point given ani queri point minimum link shortest path determin log time two point queri log time space preprocess minimum link shortest path determin log log time ani two queri point altern cdot log cdot sqrt log time cdot log cdot sqrt log space preprocess answer two point queri log time|['Haitao Wang']|['cs.CG', 'cs.DS']
2017-03-28T14:07:20Z|2017-03-13T11:00:53Z|http://arxiv.org/abs/1703.04329v1|http://arxiv.org/pdf/1703.04329v1|Stabbing segments with rectilinear objects|stab segment rectilinear object|Given a set $S$ of $n$ line segments in the plane, we say that a region $\mathcal{R}\subseteq \mathbb{R}^2$ is a {\em stabber} for $S$ if $\mathcal{R}$ contains exactly one endpoint of each segment of $S$. In this paper we provide optimal or near-optimal algorithms for reporting all combinatorially different stabbers for several shapes of stabbers. Specifically, we consider the case in which the stabber can be described as the intersection of axis-parallel halfplanes (thus the stabbers are halfplanes, strips, quadrants, $3$-sided rectangles, or rectangles). The running times are $O(n)$ (for the halfplane case), $O(n\log n)$ (for strips, quadrants, and 3-sided rectangles), and $O(n^2 \log n)$ (for rectangles).|given set line segment plane say region mathcal subseteq mathbb em stabber mathcal contain exact one endpoint segment paper provid optim near optim algorithm report combinatori differ stabber sever shape stabber specif consid case stabber describ intersect axi parallel halfplan thus stabber halfplan strip quadrant side rectangl rectangl run time halfplan case log strip quadrant side rectangl log rectangl|['Mercè Claverol', 'Delia Garijo', 'Matias Korman', 'Carlos Seara', 'Rodrigo I. Silveira']|['cs.CG']
2017-03-28T14:07:20Z|2017-03-13T08:00:31Z|http://arxiv.org/abs/1703.04283v1|http://arxiv.org/pdf/1703.04283v1|Universal Slope Sets for 1-Bend Planar Drawings|univers slope set bend planar draw|We describe a set of $\Delta -1$ slopes that are universal for 1-bend planar drawings of planar graphs of maximum degree $\Delta \geq 4$; this establishes a new upper bound of $\Delta-1$ on the 1-bend planar slope number. By universal we mean that every planar graph of degree $\Delta$ has a planar drawing with at most one bend per edge and such that the slopes of the segments forming the edges belong to the given set of slopes. This improves over previous results in two ways: Firstly, the best previously known upper bound for the 1-bend planar slope number was $\frac{3}{2} (\Delta -1)$ (the known lower bound being $\frac{3}{4} (\Delta -1)$); secondly, all the known algorithms to construct 1-bend planar drawings with $O(\Delta)$ slopes use a different set of slopes for each graph and can have bad angular resolution, while our algorithm uses a universal set of slopes, which also guarantees that the minimum angle between any two edges incident to a vertex is $\frac{\pi}{(\Delta-1)}$.|describ set delta slope univers bend planar draw planar graph maximum degre delta geq establish new upper bound delta bend planar slope number univers mean everi planar graph degre delta planar draw one bend per edg slope segment form edg belong given set slope improv previous result two way first best previous known upper bound bend planar slope number frac delta known lower bound frac delta second known algorithm construct bend planar draw delta slope use differ set slope graph bad angular resolut algorithm use univers set slope also guarante minimum angl ani two edg incid vertex frac pi delta|['Patrizio Angelini', 'Michael A. Bekos', 'Giuseppe Liotta', 'Fabrizio Montecchiani']|['cs.CG']
2017-03-28T14:07:20Z|2017-03-12T07:21:50Z|http://arxiv.org/abs/1703.04079v1|http://arxiv.org/pdf/1703.04079v1|SurfNet: Generating 3D shape surfaces using deep residual networks|surfnet generat shape surfac use deep residu network|3D shape models are naturally parameterized using vertices and faces, \ie, composed of polygons forming a surface. However, current 3D learning paradigms for predictive and generative tasks using convolutional neural networks focus on a voxelized representation of the object. Lifting convolution operators from the traditional 2D to 3D results in high computational overhead with little additional benefit as most of the geometry information is contained on the surface boundary. Here we study the problem of directly generating the 3D shape surface of rigid and non-rigid shapes using deep convolutional neural networks. We develop a procedure to create consistent `geometry images' representing the shape surface of a category of 3D objects. We then use this consistent representation for category-specific shape surface generation from a parametric representation or an image by developing novel extensions of deep residual networks for the task of geometry image generation. Our experiments indicate that our network learns a meaningful representation of shape surfaces allowing it to interpolate between shape orientations and poses, invent new shape surfaces and reconstruct 3D shape surfaces from previously unseen images.|shape model natur parameter use vertic face ie compos polygon form surfac howev current learn paradigm predict generat task use convolut neural network focus voxel represent object lift convolut oper tradit result high comput overhead littl addit benefit geometri inform contain surfac boundari studi problem direct generat shape surfac rigid non rigid shape use deep convolut neural network develop procedur creat consist geometri imag repres shape surfac categori object use consist represent categori specif shape surfac generat parametr represent imag develop novel extens deep residu network task geometri imag generat experi indic network learn meaning represent shape surfac allow interpol shape orient pose invent new shape surfac reconstruct shape surfac previous unseen imag|['Ayan Sinha', 'Asim Unmesh', 'Qixing Huang', 'Karthik Ramani']|['cs.CV', 'cs.CG']
2017-03-28T14:07:20Z|2017-03-11T23:16:23Z|http://arxiv.org/abs/1703.04040v1|http://arxiv.org/abs/1703.04040v1|Locality-sensitive hashing of curves|local sensit hash curv|We study data structures for storing a set of polygonal curves in ${\rm R}^d$ such that, given a query curve, we can efficiently retrieve similar curves from the set, where similarity is measured using the discrete Fr\'echet distance or the dynamic time warping distance. To this end we devise the first locality-sensitive hashing schemes for these distance measures. A major challenge is posed by the fact that these distance measures internally optimize the alignment between the curves. We give solutions for different types of alignments including constrained and unconstrained versions. For unconstrained alignments, we improve over a result by Indyk from 2002 for short curves. Let $n$ be the number of input curves and let $m$ be the maximum complexity of a curve in the input. In the particular case where $m \leq \frac{\alpha}{4d} \log n$, for some fixed $\alpha>0$, our solutions imply an approximate near-neighbor data structure for the discrete Fr\'echet distance that uses space in $O(n^{1+\alpha}\log n)$ and achieves query time in $O(n^{\alpha}\log^2 n)$ and constant approximation factor. Furthermore, our solutions provide a trade-off between approximation quality and computational performance: for any parameter $k \in [m]$, we can give a data structure that uses space in $O(2^{2k}m^{k-1} n \log n + nm)$, answers queries in $O( 2^{2k} m^{k}\log n)$ time and achieves approximation factor in $O(m/k)$.|studi data structur store set polygon curv rm given queri curv effici retriev similar curv set similar measur use discret fr echet distanc dynam time warp distanc end devis first local sensit hash scheme distanc measur major challeng pose fact distanc measur intern optim align curv give solut differ type align includ constrain unconstrain version unconstrain align improv result indyk short curv let number input curv let maximum complex curv input particular case leq frac alpha log fix alpha solut impli approxim near neighbor data structur discret fr echet distanc use space alpha log achiev queri time alpha log constant approxim factor furthermor solut provid trade approxim qualiti comput perform ani paramet give data structur use space log nm answer queri log time achiev approxim factor|['Anne Driemel', 'Francesco Silvestri']|['cs.CG', 'cs.DS', 'cs.IR', 'F.2.2']
2017-03-28T14:07:25Z|2017-03-10T13:54:29Z|http://arxiv.org/abs/1703.03687v1|http://arxiv.org/pdf/1703.03687v1|Best Laid Plans of Lions and Men|best laid plan lion men|"We answer the following question dating back to J.E. Littlewood (1885 - 1977): Can two lions catch a man in a bounded area with rectifiable lakes? The lions and the man are all assumed to be points moving with at most unit speed. That the lakes are rectifiable means that their boundaries are finitely long. This requirement is to avoid pathological examples where the man survives forever because any path to the lions is infinitely long. We show that the answer to the question is not always ""yes"" by giving an example of a region $R$ in the plane where the man has a strategy to survive forever. $R$ is a polygonal region with holes and the exterior and interior boundaries are pairwise disjoint, simple polygons. Our construction is the first truly two-dimensional example where the man can survive.   Next, we consider the following game played on the entire plane instead of a bounded area: There is any finite number of unit speed lions and one fast man who can run with speed $1+\varepsilon$ for some value $\varepsilon>0$. Can the man always survive? We answer the question in the affirmative for any constant $\varepsilon>0$."|answer follow question date back littlewood two lion catch man bound area rectifi lake lion man assum point move unit speed lake rectifi mean boundari finit long requir avoid patholog exampl man surviv forev becaus ani path lion infinit long show answer question alway yes give exampl region plane man strategi surviv forev polygon region hole exterior interior boundari pairwis disjoint simpl polygon construct first truli two dimension exampl man surviv next consid follow game play entir plane instead bound area ani finit number unit speed lion one fast man run speed varepsilon valu varepsilon man alway surviv answer question affirm ani constant varepsilon|['Mikkel Abrahamsen', 'Jacob Holm', 'Eva Rotenberg', 'Christian Wulff-Nilsen']|['cs.CG', 'cs.GT']
2017-03-28T14:07:25Z|2017-03-10T08:35:24Z|http://arxiv.org/abs/1703.03575v1|http://arxiv.org/pdf/1703.03575v1|Crossing the Logarithmic Barrier for Dynamic Boolean Data Structure   Lower Bounds|cross logarithm barrier dynam boolean data structur lower bound|"This paper proves the first super-logarithmic lower bounds on the cell probe complexity of dynamic boolean (a.k.a. decision) data structure problems, a long-standing milestone in data structure lower bounds.   We introduce a new method for proving dynamic cell probe lower bounds and use it to prove a $\tilde{\Omega}(\log^{1.5} n)$ lower bound on the operational time of a wide range of boolean data structure problems, most notably, on the query time of dynamic range counting over $\mathbb{F}_2$ ([Pat07]). Proving an $\omega(\lg n)$ lower bound for this problem was explicitly posed as one of five important open problems in the late Mihai P\v{a}tra\c{s}cu's obituary [Tho13]. This result also implies the first $\omega(\lg n)$ lower bound for the classical 2D range counting problem, one of the most fundamental data structure problems in computational geometry and spatial databases. We derive similar lower bounds for boolean versions of dynamic polynomial evaluation and 2D rectangle stabbing, and for the (non-boolean) problems of range selection and range median.   Our technical centerpiece is a new way of ""weakly"" simulating dynamic data structures using efficient one-way communication protocols with small advantage over random guessing. This simulation involves a surprising excursion to low-degree (Chebychev) polynomials which may be of independent interest, and offers an entirely new algorithmic angle on the ""cell sampling"" method of Panigrahy et al. [PTW10]."|paper prove first super logarithm lower bound cell probe complex dynam boolean decis data structur problem long stand mileston data structur lower bound introduc new method prove dynam cell probe lower bound use prove tild omega log lower bound oper time wide rang boolean data structur problem notabl queri time dynam rang count mathbb pat prove omega lg lower bound problem explicit pose one five import open problem late mihai tra cu obituari tho result also impli first omega lg lower bound classic rang count problem one fundament data structur problem comput geometri spatial databas deriv similar lower bound boolean version dynam polynomi evalu rectangl stab non boolean problem rang select rang median technic centerpiec new way weak simul dynam data structur use effici one way communic protocol small advantag random guess simul involv surpris excurs low degre chebychev polynomi may independ interest offer entir new algorithm angl cell sampl method panigrahi et al ptw|['Kasper Green Larsen', 'Omri Weinstein', 'Huacheng Yu']|['cs.DS', 'cs.CC', 'cs.CG', 'cs.IT', 'math.IT']
2017-03-28T14:07:25Z|2017-03-08T21:50:06Z|http://arxiv.org/abs/1703.03048v1|http://arxiv.org/pdf/1703.03048v1|Quickest Visibility Queries in Polygonal Domains|quickest visibl queri polygon domain|Let $s$ be a point in a polygonal domain $\mathcal{P}$ of $h-1$ holes and $n$ vertices. We consider a quickest visibility query problem. Given a query point $q$ in $\mathcal{P}$, the goal is to find a shortest path in $\mathcal{P}$ to move from $s$ to see $q$ as quickly as possible. Previously, Arkin et al. (SoCG 2015) built a data structure of size $O(n^22^{\alpha(n)}\log n)$ that can answer each query in $O(K\log^2 n)$ time, where $\alpha(n)$ is the inverse Ackermann function and $K$ is the size of the visibility polygon of $q$ in $\mathcal{P}$ (and $K$ can be $\Theta(n)$ in the worst case). In this paper, we present a new data structure of size $O(n\log h + h^2)$ that can answer each query in $O(h\log h\log n)$ time. Our result improves the previous work when $h$ is relatively small. In particular, if $h$ is a constant, then our result even matches the best result for the simple polygon case (i.e., $h=1$), which is optimal. As a by-product, we also have a new algorithm for a shortest-path-to-segment query problem. Given a query line segment $\tau$ in $\mathcal{P}$, the query seeks a shortest path from $s$ to all points of $\tau$. Previously, Arkin et al. gave a data structure of size $O(n^22^{\alpha(n)}\log n)$ that can answer each query in $O(\log^2 n)$ time, and another data structure of size $O(n^3\log n)$ with $O(\log n)$ query time. We present a data structure of size $O(n)$ with query time $O(h\log \frac{n}{h})$, which also favors small values of $h$ and is optimal when $h=O(1)$.|let point polygon domain mathcal hole vertic consid quickest visibl queri problem given queri point mathcal goal find shortest path mathcal move see quick possibl previous arkin et al socg built data structur size alpha log answer queri log time alpha invers ackermann function size visibl polygon mathcal theta worst case paper present new data structur size log answer queri log log time result improv previous work relat small particular constant result even match best result simpl polygon case optim product also new algorithm shortest path segment queri problem given queri line segment tau mathcal queri seek shortest path point tau previous arkin et al gave data structur size alpha log answer queri log time anoth data structur size log log queri time present data structur size queri time log frac also favor small valu optim|['Haitao Wang']|['cs.CG', 'cs.DS']
2017-03-28T14:07:25Z|2017-03-08T16:32:05Z|http://arxiv.org/abs/1703.02901v1|http://arxiv.org/pdf/1703.02901v1|Local Equivalence and Intrinsic Metrics between Reeb Graphs|local equival intrins metric reeb graph|As graphical summaries for topological spaces and maps, Reeb graphs are common objects in the computer graphics or topological data analysis literature. Defining good metrics between these objects has become an important question for applications, where it matters to quantify the extent by which two given Reeb graphs differ. Recent contributions emphasize this aspect, proposing novel distances such as {\em functional distortion} or {\em interleaving} that are provably more discriminative than the so-called {\em bottleneck distance}, being true metrics whereas the latter is only a pseudo-metric. Their main drawback compared to the bottleneck distance is to be comparatively hard (if at all possible) to evaluate. Here we take the opposite view on the problem and show that the bottleneck distance is in fact good enough {\em locally}, in the sense that it is able to discriminate a Reeb graph from any other Reeb graph in a small enough neighborhood, as efficiently as the other metrics do. This suggests considering the {\em intrinsic metrics} induced by these distances, which turn out to be all {\em globally} equivalent. This novel viewpoint on the study of Reeb graphs has a potential impact on applications, where one may not only be interested in discriminating between data but also in interpolating between them.|graphic summari topolog space map reeb graph common object comput graphic topolog data analysi literatur defin good metric object becom import question applic matter quantifi extent two given reeb graph differ recent contribut emphas aspect propos novel distanc em function distort em interleav provabl discrimin call em bottleneck distanc true metric wherea latter onli pseudo metric main drawback compar bottleneck distanc compar hard possibl evalu take opposit view problem show bottleneck distanc fact good enough em local sens abl discrimin reeb graph ani reeb graph small enough neighborhood effici metric suggest consid em intrins metric induc distanc turn em global equival novel viewpoint studi reeb graph potenti impact applic one may onli interest discrimin data also interpol|['Mathieu Carrière', 'Steve Oudot']|['cs.CG', 'math.AT']
2017-03-28T14:07:25Z|2017-03-08T02:12:35Z|http://arxiv.org/abs/1703.02671v1|http://arxiv.org/pdf/1703.02671v1|Symmetric Assembly Puzzles are Hard, Beyond a Few Pieces|symmetr assembl puzzl hard beyond piec|We study the complexity of symmetric assembly puzzles: given a collection of simple polygons, can we translate, rotate, and possibly flip them so that their interior-disjoint union is line symmetric? On the negative side, we show that the problem is strongly NP-complete even if the pieces are all polyominos. On the positive side, we show that the problem can be solved in polynomial time if the number of pieces is a fixed constant.|studi complex symmetr assembl puzzl given collect simpl polygon translat rotat possibl flip interior disjoint union line symmetr negat side show problem strong np complet even piec polyomino posit side show problem solv polynomi time number piec fix constant|['Erik D. Demaine', 'Matias Korman', 'Jason S. Ku', 'Joseph S. B. Mitchell', 'Yota Otachi', 'André van Renssen', 'Marcel Roeloffzen', 'Ryuhei Uehara', 'Yushi Uno']|['cs.CG']
2017-03-28T14:07:25Z|2017-03-07T23:22:46Z|http://arxiv.org/abs/1703.02637v1|http://arxiv.org/pdf/1703.02637v1|Effective identifiability criteria for tensors and polynomials|effect identifi criteria tensor polynomi|A tensor $T$, in a given tensor space, is said to be $h$-identifiable if it admits a unique decomposition as a sum of $h$ rank one tensors. A criterion for $h$-identifiability is called effective if it is satisfied in a dense, open subset of the set of rank $h$ tensors. In this paper we give effective $h$-identifiability criteria for a large class of tensors. We then improve these criteria for some symmetric tensors. For instance, this allows us to give a complete set of effective identifiability criteria for ternary quintic polynomial. Finally, we implement our identifiability algorithms in Macaulay2.|tensor given tensor space said identifi admit uniqu decomposit sum rank one tensor criterion identifi call effect satisfi dens open subset set rank tensor paper give effect identifi criteria larg class tensor improv criteria symmetr tensor instanc allow us give complet set effect identifi criteria ternari quintic polynomi final implement identifi algorithm macaulay|['Alex Massarenti', 'Massimiliano Mella', 'Giovanni Staglianò']|['math.AG', 'cs.CG', '15A69, 15A72, 11P05 (Primary), 14N05, 15A69 (Secondary)']
2017-03-28T14:07:25Z|2017-03-20T08:48:17Z|http://arxiv.org/abs/1703.02261v2|http://arxiv.org/pdf/1703.02261v2|An annotated bibliography on 1-planarity|annot bibliographi planar|The notion of 1-planarity is among the most natural and most studied generalizations of graph planarity. A graph is 1-planar if it has an embedding where each edge is crossed by at most another edge. The study of 1-planar graphs dates back to more than fifty years ago and, recently, it has driven increasing attention in the areas of graph theory, graph algorithms, graph drawing, and computational geometry. This annotated bibliography aims to provide a guiding reference to researchers who want to have an overview of the large body of literature about 1-planar graphs. It reviews the current literature covering various research streams about 1-planarity, such as characterization and recognition, combinatorial properties, and geometric representations. As an additional contribution, we offer a list of open problems on 1-planar graphs.|notion planar among natur studi general graph planar graph planar embed edg cross anoth edg studi planar graph date back fifti year ago recent driven increas attent area graph theori graph algorithm graph draw comput geometri annot bibliographi aim provid guid refer research want overview larg bodi literatur planar graph review current literatur cover various research stream planar character recognit combinatori properti geometr represent addit contribut offer list open problem planar graph|['Stephen G. Kobourov', 'Giuseppe Liotta', 'Fabrizio Montecchiani']|['cs.CG']
2017-03-28T14:07:25Z|2017-03-06T16:05:05Z|http://arxiv.org/abs/1703.01943v1|http://arxiv.org/pdf/1703.01943v1|Enumeration of $2$-level polytopes|enumer level polytop|A (convex) polytope $P$ is said to be $2$-level if for every direction of hyperplanes which is facet-defining for $P$, the vertices of $P$ can be covered with two hyperplanes of that direction. The study of these polytopes is motivated by questions in combinatorial optimization and communication complexity, among others. In this paper, we present the first algorithm for enumerating all combinatorial types of $2$-level polytopes of a given dimension $d$, and provide complete experimental results for $d \leqslant 7$. Our approach is inductive: for each fixed $(d-1)$-dimensional $2$-level polytope $P_0$, we enumerate all $d$-dimensional $2$-level polytopes $P$ that have $P_0$ as a facet. This relies on the enumeration of the closed sets of a closure operator over a finite ground set. By varying the prescribed facet $P_0$, we obtain all $2$-level polytopes in dimension $d$.|convex polytop said level everi direct hyperplan facet defin vertic cover two hyperplan direct studi polytop motiv question combinatori optim communic complex among paper present first algorithm enumer combinatori type level polytop given dimens provid complet experiment result leqslant approach induct fix dimension level polytop enumer dimension level polytop facet reli enumer close set closur oper finit ground set vari prescrib facet obtain level polytop dimens|['Adam Bohn', 'Yuri Faenza', 'Samuel Fiorini', 'Vissarion Fisikopoulos', 'Marco Macchia', 'Kanstantsin Pashkovich']|['math.CO', 'cs.CG', 'cs.DM', 'math.OC', '05A15, 05C17, 52B12, 52B55, 68W05, 90C22']
2017-03-28T14:07:25Z|2017-03-05T23:29:51Z|http://arxiv.org/abs/1703.01691v1|http://arxiv.org/pdf/1703.01691v1|Drawing Planar Graphs with Few Geometric Primitives|draw planar graph geometr primit|We define the visual complexity of a plane graph drawing to be the number of geometric objects needed to represent all its edges. In particular, one object may represent multiple edges (e.g., one needs only one line segment to draw two collinear edges of the same vertex). Let $n$ denote the number of vertices of a graph. We show that trees can be drawn with $3n/4$ straight-line segments on a polynomial grid, and with $n/2$ straight-line segments on a quasi-polynomial grid. Further, we present an algorithm for drawing planar 3-trees with $(8n-17)/3$ segments on an $O(n)\times O(n^2)$ grid. This algorithm can also be used with a small modification to draw maximal outerplanar graphs with $3n/2$ edges on an $O(n)\times O(n^2)$ grid. We also study the problem of drawing maximal planar graphs with circular arcs and provide an algorithm to draw such graphs using only $(5n - 11)/3$ arcs. This provides a significant improvement over the lower bound of $2n$ for line segments for a nontrivial graph class.|defin visual complex plane graph draw number geometr object need repres edg particular one object may repres multipl edg one need onli one line segment draw two collinear edg vertex let denot number vertic graph show tree drawn straight line segment polynomi grid straight line segment quasi polynomi grid present algorithm draw planar tree segment time grid algorithm also use small modif draw maxim outerplanar graph edg time grid also studi problem draw maxim planar graph circular arc provid algorithm draw graph use onli arc provid signific improv lower bound line segment nontrivi graph class|['Gregor Hültenschmidt', 'Philipp Kindermann', 'Wouter Meulemans', 'André Schulz']|['cs.CG']
2017-03-28T14:07:25Z|2017-03-05T19:10:17Z|http://arxiv.org/abs/1703.01646v1|http://arxiv.org/pdf/1703.01646v1|A PTAS for TSP with Neighborhoods Among Fat Regions in the Plane|ptas tsp neighborhood among fat region plane|"The Euclidean TSP with neighborhoods (TSPN) problem seeks a shortest tour that visits a given collection of $n$ regions ({\em neighborhoods}). We present the first polynomial-time approximation scheme for TSPN for a set of regions given by arbitrary disjoint fat regions in the plane. This improves substantially upon the known approximation algorithms, and is the first PTAS for TSPN on regions of non-comparable sizes. Our result is based on a novel extension of the $m$-guillotine method. The result applies to regions that are ""fat"" in a very weak sense: each region $P_i$ has area $\Omega([diam(P_i)]^2)$, but is otherwise arbitrary."|euclidean tsp neighborhood tspn problem seek shortest tour visit given collect region em neighborhood present first polynomi time approxim scheme tspn set region given arbitrari disjoint fat region plane improv substanti upon known approxim algorithm first ptas tspn region non compar size result base novel extens guillotin method result appli region fat veri weak sens region area omega diam otherwis arbitrari|['Joseph S. B. Mitchell']|['cs.CG']
2017-03-28T14:07:29Z|2017-03-05T18:24:23Z|http://arxiv.org/abs/1703.01640v1|http://arxiv.org/abs/1703.01640v1|Approximation algorithms for TSP with neighborhoods in the plane|approxim algorithm tsp neighborhood plane|In the Euclidean TSP with neighborhoods (TSPN), we are given a collection of n regions (neighborhoods) and we seek a shortest tour that visits each region. As a generalization of the classical Euclidean TSP, TSPN is also NP-hard. In this paper, we present new approximation results for the TSPN, including (1) a constant-factor approximation algorithm for the case of arbitrary connected neighborhoods having comparable diameters; and (2) a PTAS for the important special case of disjoint unit disk neighborhoods (or nearly disjoint, nearly-unit disks). Our methods also yield improved approximation ratios for various special classes of neighborhoods, which have previously been studied. Further, we give a linear-time O(1)-approximation algorithm for the case of neighborhoods that are (infinite) straight lines.|euclidean tsp neighborhood tspn given collect region neighborhood seek shortest tour visit region general classic euclidean tsp tspn also np hard paper present new approxim result tspn includ constant factor approxim algorithm case arbitrari connect neighborhood compar diamet ptas import special case disjoint unit disk neighborhood near disjoint near unit disk method also yield improv approxim ratio various special class neighborhood previous studi give linear time approxim algorithm case neighborhood infinit straight line|['Adrian Dumitrescu', 'Joseph S. B. Mitchell']|['cs.CG', 'cs.DS']
2017-03-28T14:07:29Z|2017-03-05T01:41:08Z|http://arxiv.org/abs/1703.01544v1|http://arxiv.org/pdf/1703.01544v1|L-Graphs and Monotone L-Graphs|graph monoton graph|"In an $\mathsf{L}$-embedding of a graph, each vertex is represented by an $\mathsf{L}$-segment, and two segments intersect each other if and only if the corresponding vertices are adjacent in the graph. If the corner of each $\mathsf{L}$-segment in an $\mathsf{L}$-embedding lies on a straight line, we call it a monotone $\mathsf{L}$-embedding. In this paper we give a full characterization of monotone $\mathsf{L}$-embeddings by introducing a new class of graphs which we call ""non-jumping"" graphs. We show that a graph admits a monotone $\mathsf{L}$-embedding if and only if the graph is a non-jumping graph. Further, we show that outerplanar graphs, convex bipartite graphs, interval graphs, 3-leaf power graphs, and complete graphs are subclasses of non-jumping graphs. Finally, we show that distance-hereditary graphs and $k$-leaf power graphs ($k\le 4$) admit $\mathsf{L}$-embeddings."|mathsf embed graph vertex repres mathsf segment two segment intersect onli correspond vertic adjac graph corner mathsf segment mathsf embed lie straight line call monoton mathsf embed paper give full character monoton mathsf embed introduc new class graph call non jump graph show graph admit monoton mathsf embed onli graph non jump graph show outerplanar graph convex bipartit graph interv graph leaf power graph complet graph subclass non jump graph final show distanc hereditari graph leaf power graph le admit mathsf embed|['Abu Reyan Ahmed', 'Felice De Luca', 'Sabin Devkota', 'Alon Efrat', 'Md Iqbal Hossain', 'Stephen Kobourov', 'Jixian Li', 'Sammi Abida Salma', 'Eric Welch']|['cs.CG']
2017-03-28T14:07:29Z|2017-03-04T10:59:56Z|http://arxiv.org/abs/1703.01439v1|http://arxiv.org/pdf/1703.01439v1|On the set of optimal homeomorphisms for the natural pseudo-distance   associated with the Lie group S^1|set optim homeomorph natur pseudo distanc associ lie group|If $\varphi$ and $\psi$ are two continuous real-valued functions defined on a compact topological space $X$ and $G$ is a subgroup of the group of all homeomorphisms of $X$ onto itself, the natural pseudo-distance $d_G(\varphi,\psi)$ is defined as the infimum of $\mathcal{L}(g)=\ \varphi-\psi \circ g \ _\infty$, as $g$ varies in $G$. In this paper, we make a first step towards extending the study of this concept to the case of Lie groups, by assuming $X=G=S^1$. In particular, we study the set of the optimal homeomorphisms for $d_G$, i.e. the elements $\rho_\alpha$ of $S^1$ such that $\mathcal{L}(\rho_\alpha)$ is equal to $d_G(\varphi,\psi)$. As our main results, we give conditions that a homeomorphism has to meet in order to be optimal, and we prove that the set of the optimal homeomorphisms is finite under suitable conditions.|varphi psi two continu real valu function defin compact topolog space subgroup group homeomorph onto natur pseudo distanc varphi psi defin infimum mathcal varphi psi circ infti vari paper make first step toward extend studi concept case lie group assum particular studi set optim homeomorph element rho alpha mathcal rho alpha equal varphi psi main result give condit homeomorph meet order optim prove set optim homeomorph finit suitabl condit|['Alessandro De Gregorio']|['cs.CG', 'math.AT', 'Primary 57S05, Secondary 55N99']
2017-03-28T14:07:29Z|2017-03-01T02:48:12Z|http://arxiv.org/abs/1703.00112v1|http://arxiv.org/pdf/1703.00112v1|Minimum Enclosing Circle of a Set of Static Points with Dynamic Weight   from One Free Point|minimum enclos circl set static point dynam weight one free point|Given a set $S$ of $n$ static points and a free point $p$ in the Euclidean plane, we study a new variation of the minimum enclosing circle problem, in which a dynamic weight that equals to the reciprocal of the distance from the free point $p$ to the undetermined circle center is included. In this work, we prove the optimal solution of the new problem is unique and lies on the boundary of the farthest-point Voronoi diagram of $S$, once $p$ does not coincide with any vertex of the convex hull of $S$. We propose a tree structure constructed from the boundary of the farthest-point Voronoi diagram and use the hierarchical relationship between edges to locate the optimal solution. The plane could be divide into at most $3n-4$ non-overlapping regions. When $p$ lies in one of the regions, the optimal solution locates at one node or lies on the interior of one edge in the boundary of the farthest-point Voronoi diagram. Moreover, we apply the new variation to calculate the maximum displacement of one point $p$ under the condition that the displacements of points in $S$ are restricted in 2D rigid motion.|given set static point free point euclidean plane studi new variat minimum enclos circl problem dynam weight equal reciproc distanc free point undetermin circl center includ work prove optim solut new problem uniqu lie boundari farthest point voronoi diagram onc doe coincid ani vertex convex hull propos tree structur construct boundari farthest point voronoi diagram use hierarch relationship edg locat optim solut plane could divid non overlap region lie one region optim solut locat one node lie interior one edg boundari farthest point voronoi diagram moreov appli new variat calcul maximum displac one point condit displac point restrict rigid motion|['Lei Qiu', 'Yu Zhang', 'Li Zhang']|['cs.CG']
2017-03-28T14:07:29Z|2017-02-28T09:44:01Z|http://arxiv.org/abs/1702.08716v1|http://arxiv.org/pdf/1702.08716v1|On the Relationship between $k$-Planar and $k$-Quasi Planar Graphs|relationship planar quasi planar graph|A graph is $k$-planar $(k \geq 1)$ if it can be drawn in the plane such that no edge is crossed more than $k$ times. A graph is $k$-quasi planar $(k \geq 2)$ if it can be drawn in the plane with no $k$ pairwise crossing edges. The families of $k$-planar and $k$-quasi planar graphs have been widely studied in the literature, and several bounds have been proven on their edge density. Nonetheless, only trivial results are known about the relationship between these two graph families. In this paper we prove that, for $k \geq 3$, every $k$-planar graph is $(k+1)$-quasi planar.|graph planar geq drawn plane edg cross time graph quasi planar geq drawn plane pairwis cross edg famili planar quasi planar graph wide studi literatur sever bound proven edg densiti nonetheless onli trivial result known relationship two graph famili paper prove geq everi planar graph quasi planar|['Patrizio Angelini', 'Michael A. Bekos', 'Franz J. Brandenburg', 'Giordano Da Lozzo', 'Giuseppe Di Battista', 'Walter Didimo', 'Giuseppe Liotta', 'Fabrizio Montecchiani', 'Ignaz Rutter']|['cs.CG']
2017-03-28T14:07:29Z|2017-02-28T05:47:10Z|http://arxiv.org/abs/1702.08654v1|http://arxiv.org/pdf/1702.08654v1|An Improved Algorithm for General Position Subset Selection|improv algorithm general posit subset select|In the General Position Subset Selection (GPSS) problem, the goal is to find the largest possible subset of a set of points, such that no three of its members are collinear. If $s_{\textrm{GPSS}}$ is the size the optimal solution, $\sqrt{s_{\textrm{GPSS}}}$ is the current best guarantee for the size of the solution obtained using a polynomial time algorithm. In this paper we present an algorithm for GPSS to improve this bound based on the number of collinear pairs of points.|general posit subset select gpss problem goal find largest possibl subset set point three member collinear textrm gpss size optim solut sqrt textrm gpss current best guarante size solut obtain use polynomi time algorithm paper present algorithm gpss improv bound base number collinear pair point|['Ali Gholami Rudi']|['cs.CG', '65D18, 05C69', 'G.2.1; I.3.5; G.2.2']
2017-03-28T14:07:29Z|2017-02-28T02:18:54Z|http://arxiv.org/abs/1702.08607v1|http://arxiv.org/pdf/1702.08607v1|Faster DB-scan and HDB-scan in Low-Dimensional Euclidean Spaces|faster db scan hdb scan low dimension euclidean space|We present a new algorithm for the widely used density-based clustering method DBscan. Our algorithm computes the DBscan-clustering in $O(n\log n)$ time in $\mathbb{R}^2$, irrespective of the scale parameter $\varepsilon$ (and assuming the second parameter MinPts is set to a fixed constant, as is the case in practice). Experiments show that the new algorithm is not only fast in theory, but that a slightly simplified version is competitive in practice and much less sensitive to the choice of $\varepsilon$ than the original DBscan algorithm. We also present an $O(n\log n)$ randomized algorithm for HDBscan in the plane---HDBscan is a hierarchical version of DBscan introduced recently---and we show how to compute an approximate version of HDBscan in near-linear time in any fixed dimension.|present new algorithm wide use densiti base cluster method dbscan algorithm comput dbscan cluster log time mathbb irrespect scale paramet varepsilon assum second paramet minpt set fix constant case practic experi show new algorithm onli fast theori slight simplifi version competit practic much less sensit choic varepsilon origin dbscan algorithm also present log random algorithm hdbscan plane hdbscan hierarch version dbscan introduc recent show comput approxim version hdbscan near linear time ani fix dimens|['Mark de Berg', 'Ade Gunawan', 'Marcel Roeloffzen']|['cs.CG']
2017-03-28T14:07:29Z|2017-02-28T01:14:43Z|http://arxiv.org/abs/1702.08593v1|http://arxiv.org/pdf/1702.08593v1|Mind the Gap: A Study in Global Development through Persistent Homology|mind gap studi global develop persist homolog|"The Gapminder project set out to use statistics to dispel simplistic notions about global development. In the same spirit, we use persistent homology, a technique from computational algebraic topology, to explore the relationship between country development and geography. For each country, two statistics, gross domestic product per capita and average life expectancy, were used to quantify the development. Two analyses were performed. The first considers clusters of the countries based on these two statistics, and the second uncovers cycles in the data when combined with geographic network structure. Our analyses reveal that there is not a clear distinction of ""first"" and ""third"" world countries, and we discovered localized development patterns that are invisible in standard representations."|gapmind project set use statist dispel simplist notion global develop spirit use persist homolog techniqu comput algebra topolog explor relationship countri develop geographi countri two statist gross domest product per capita averag life expect use quantifi develop two analys perform first consid cluster countri base two statist second uncov cycl data combin geograph network structur analys reveal clear distinct first third world countri discov local develop pattern invis standard represent|['Andrew Banman', 'Lori Ziegelmeier']|['math.AT', 'cs.CG']
2017-03-28T14:07:29Z|2017-02-27T22:25:57Z|http://arxiv.org/abs/1703.01350v1|http://arxiv.org/pdf/1703.01350v1|Approximate Convex Hulls|approxim convex hull|We investigate the PPI algorithm as a means for computing ap- proximate convex hull. We explain how the algorithm computes the curvature of points and prove consistency and convergence. We also extend the algorithm to compute approximate convex hulls described in terms of hyperplanes.|investig ppi algorithm mean comput ap proxim convex hull explain algorithm comput curvatur point prove consist converg also extend algorithm comput approxim convex hull describ term hyperplan|['Robert Graham', 'Adam M. Oberman']|['cs.CG', 'math.CO', '05-04']
2017-03-28T14:07:29Z|2017-02-27T17:07:31Z|http://arxiv.org/abs/1702.08380v1|http://arxiv.org/pdf/1702.08380v1|Exploring Increasing-Chord Paths and Trees|explor increas chord path tree|A straight-line drawing $\Gamma$ of a graph $G=(V,E)$ is a drawing of $G$ in the Euclidean plane, where every vertex in $G$ is mapped to a distinct point, and every edge in $G$ is mapped to a straight line segment between their endpoints. A path $P$ in $\Gamma$ is called increasing-chord if for every four points (not necessarily vertices) $a,b,c,d$ on $P$ in this order, the Euclidean distance between $b,c$ is at most the Euclidean distance between $a,d$. A spanning tree $T$ rooted at some vertex $r$ in $\Gamma$ is called increasing-chord if $T$ contains an increasing-chord path from $r$ to every vertex in $T$. In this paper we prove that given a vertex $r$ in a straight-line drawing $\Gamma$, it is NP-complete to determine whether $\Gamma$ contains an increasing-chord spanning tree rooted at $r$. We conjecture that finding an increasing-chord path between a pair of vertices in $\Gamma$, which is an intriguing open problem posed by Alamdari et al., is also NP-complete, and show a (non-polynomial) reduction from the 3-SAT problem.|straight line draw gamma graph draw euclidean plane everi vertex map distinct point everi edg map straight line segment endpoint path gamma call increas chord everi four point necessarili vertic order euclidean distanc euclidean distanc span tree root vertex gamma call increas chord contain increas chord path everi vertex paper prove given vertex straight line draw gamma np complet determin whether gamma contain increas chord span tree root conjectur find increas chord path pair vertic gamma intrigu open problem pose alamdari et al also np complet show non polynomi reduct sat problem|['Yeganeh Bahoo', 'Stephane Durocher', 'Sahar Mehrpour', 'Debajyoti Mondal']|['cs.CG']
2017-03-28T14:07:33Z|2017-02-25T13:55:53Z|http://arxiv.org/abs/1702.07893v1|http://arxiv.org/pdf/1702.07893v1|The Persistent Homotopy Type Distance|persist homotopi type distanc|We introduce the persistent homotopy type distance dHT to compare real valued functions defined on possibly different homotopy equivalent topological spaces. The underlying idea in the definition of dHT is to measure the minimal shift that is necessary to apply to one of the two functions in order that the sublevel sets of the two functions become homotopically equivalent. This distance is interesting in connection with persistent homology. Indeed, our main result states that dHT still provides an upper bound for the bottleneck distance between the persistence diagrams of the intervening functions. Moreover, because homotopy equivalences are weaker than homeomorphisms, this implies a lifting of the standard stability results provided by the L-infty distance and the natural pseudo-distance dNP. From a different standpoint, we prove that dHT extends the L-infty distance and dNP in two ways. First, we show that, appropriately restricting the category of objects to which dHT applies, it can be made to coincide with the other two distances. Finally, we show that dHT has an interpretation in terms of interleavings that naturally places it in the family of distances used in persistence theory.|introduc persist homotopi type distanc dht compar real valu function defin possibl differ homotopi equival topolog space idea definit dht measur minim shift necessari appli one two function order sublevel set two function becom homotop equival distanc interest connect persist homolog inde main result state dht still provid upper bound bottleneck distanc persist diagram interven function moreov becaus homotopi equival weaker homeomorph impli lift standard stabil result provid infti distanc natur pseudo distanc dnp differ standpoint prove dht extend infti distanc dnp two way first show appropri restrict categori object dht appli made coincid two distanc final show dht interpret term interleav natur place famili distanc use persist theori|['Patrizio Frosini', 'Claudia Landi', 'Facundo Memoli']|['cs.CG', 'math.AT']
2017-03-28T14:07:33Z|2017-02-24T14:06:31Z|http://arxiv.org/abs/1702.07589v1|http://arxiv.org/pdf/1702.07589v1|Generalization of Schnyder woods to orientable surfaces and applications|general schnyder wood orient surfac applic|Schnyder woods are particularly elegant combinatorial structures with numerous applications concerning planar triangulations and more generally 3-connected planar maps. We propose a simple generalization of Schnyder woods from the plane to maps on orientable surfaces of any genus with a special emphasis on the toroidal case. We provide a natural partition of the set of Schnyder woods of a given map into distributive lattices depending on the surface homology. In the toroidal case we show the existence of particular Schnyder woods with some global properties that are useful for optimal encoding or graph drawing purpose.|schnyder wood particular eleg combinatori structur numer applic concern planar triangul general connect planar map propos simpl general schnyder wood plane map orient surfac ani genus special emphasi toroid case provid natur partit set schnyder wood given map distribut lattic depend surfac homolog toroid case show exist particular schnyder wood global properti use optim encod graph draw purpos|['Benjamin Lévêque']|['cs.DM', 'cs.CG', 'math.CO']
2017-03-28T14:07:33Z|2017-02-24T12:25:43Z|http://arxiv.org/abs/1702.07555v1|http://arxiv.org/pdf/1702.07555v1|A generalization of crossing families|general cross famili|For a set of points in the plane, a \emph{crossing family} is a set of line segments, each joining two of the points, such that any two line segments cross. We investigate the following generalization of crossing families: a \emph{spoke set} is a set of lines drawn through a point set such that each unbounded region of the induced line arrangement contains at least one point of the point set. We show that every point set has a spoke set of size $\sqrt{\frac{n}{8}}$. We also characterize the matchings obtained by selecting exactly one point in each unbounded region and connecting every such point to the point in the antipodal unbounded region.|set point plane emph cross famili set line segment join two point ani two line segment cross investig follow general cross famili emph spoke set set line drawn point set unbound region induc line arrang contain least one point point set show everi point set spoke set size sqrt frac also character match obtain select exact one point unbound region connect everi point point antipod unbound region|['Patrick Schnider']|['cs.CG']
2017-03-28T14:07:33Z|2017-02-23T21:32:10Z|http://arxiv.org/abs/1702.07399v1|http://arxiv.org/pdf/1702.07399v1|An Optimal Algorithm for Computing the Spherical Depth of Points in the   Plane|optim algorithm comput spheric depth point plane|For a distribution function $F$ on $\mathbb{R}^d$ and a point $q\in \mathbb{R}^d$, the \emph{spherical depth} $\SphD(q;F)$ is defined to be the probability that a point $q$ is contained inside a random closed hyper-ball obtained from a pair of points from $F$. The spherical depth $\SphD(q;S)$ is also defined for an arbitrary data set $S\subseteq \mathbb{R}^d$ and $q\in \mathbb{R}^d$. This definition is based on counting all of the closed hyper-balls, obtained from pairs of points in $S$, that contain $q$. The significant advantage of using the spherical depth in multivariate data analysis is related to its complexity of computation. Unlike most other data depths, the time complexity of the spherical depth grows linearly rather than exponentially in the dimension $d$. The straightforward algorithm for computing the spherical depth in dimension $d$ takes $O(dn^2)$. The main result of this paper is an optimal algorithm that we present for computing the bivariate spherical depth. The algorithm takes $O(n \log n)$ time. By reducing the problem of \textit{Element Uniqueness}, we prove that computing the spherical depth requires $\Omega(n \log n)$ time. Some geometric properties of spherical depth are also investigated in this paper. These properties indicate that \emph{simplicial depth} ($\SD$) (Liu, 1990) is linearly bounded by spherical depth (in particular, $\SphD\geq \frac{2}{3}SD$). To illustrate this relationship between the spherical depth and the simplicial depth, some experimental results are provided. The obtained experimental bound ($\SphD\geq 2\SD$) indicates that, perhaps, a stronger theoretical bound can be achieved.|distribut function mathbb point mathbb emph spheric depth sphd defin probabl point contain insid random close hyper ball obtain pair point spheric depth sphd also defin arbitrari data set subseteq mathbb mathbb definit base count close hyper ball obtain pair point contain signific advantag use spheric depth multivari data analysi relat complex comput unlik data depth time complex spheric depth grow linear rather exponenti dimens straightforward algorithm comput spheric depth dimens take dn main result paper optim algorithm present comput bivari spheric depth algorithm take log time reduc problem textit element uniqu prove comput spheric depth requir omega log time geometr properti spheric depth also investig paper properti indic emph simplici depth sd liu linear bound spheric depth particular sphd geq frac sd illustr relationship spheric depth simplici depth experiment result provid obtain experiment bound sphd geq sd indic perhap stronger theoret bound achiev|['David Bremner', 'Rasoul Shahsavarifar']|['cs.CG']
2017-03-28T14:07:33Z|2017-03-16T14:38:10Z|http://arxiv.org/abs/1702.06829v2|http://arxiv.org/pdf/1702.06829v2|A Simple Convex Layers Algorithm|simpl convex layer algorithm|Given a set of $n$ points $P$ in the plane, the first layer $L_1$ of $P$ is formed by the points that appear on $P$'s convex hull. In general, a point belongs to layer $L_i$, if it lies on the convex hull of the set $P \setminus \bigcup_{j<i}\{L_j\}$. The \emph{convex layers problem} is to compute the convex layers $L_i$. Existing algorithms for this problem either do not achieve the optimal $\mathcal{O}\left(n\log n\right)$ runtime and linear space, or are overly complex and difficult to apply in practice. We propose a new algorithm that is both optimal and simple. The simplicity is achieved by independently computing four sets of monotone convex chains in $\mathcal{O}\left(n\log n\right)$ time and linear space. These are then merged in $\mathcal{O}\left(n\log n\right)$ time.|given set point plane first layer form point appear convex hull general point belong layer lie convex hull set setminus bigcup emph convex layer problem comput convex layer exist algorithm problem either achiev optim mathcal left log right runtim linear space complex difficult appli practic propos new algorithm optim simpl simplic achiev independ comput four set monoton convex chain mathcal left log right time linear space merg mathcal left log right time|['Raimi A. Rufai', 'Dana S. Richards']|['cs.CG', 'cs.DS', '68W99', 'I.3.5']
2017-03-28T14:07:33Z|2017-02-20T20:14:46Z|http://arxiv.org/abs/1702.06163v1|http://arxiv.org/pdf/1702.06163v1|1-Fan-Bundle-Planar Drawings of Graphs|fan bundl planar draw graph|Edge bundling is an important concept, heavily used for graph visualization purposes. To enable the comparison with other established nearly-planarity models in graph drawing, we formulate a new edge-bundling model which is inspired by the recently introduced fan-planar graphs. In particular, we restrict the bundling to the endsegments of the edges. As in 1-planarity, we call our model 1-fan-bundle-planarity, as we allow at most one crossing per bundle.   For the two variants where we allow either one or, more naturally, both endsegments of each edge to be part of bundles, we present edge density results and consider various recognition questions, not only for general graphs, but also for the outer and 2-layer variants. We conclude with a series of challenging questions.|edg bundl import concept heavili use graph visual purpos enabl comparison establish near planar model graph draw formul new edg bundl model inspir recent introduc fan planar graph particular restrict bundl endseg edg planar call model fan bundl planar allow one cross per bundl two variant allow either one natur endseg edg part bundl present edg densiti result consid various recognit question onli general graph also outer layer variant conclud seri challeng question|['Patrizio Angelini', 'Michael A. Bekos', 'Michael Kaufmann', 'Philipp Kindermann', 'Thomas Schneck']|['cs.CG', 'math.CO']
2017-03-28T14:07:33Z|2017-02-20T08:56:40Z|http://arxiv.org/abs/1702.05900v1|http://arxiv.org/pdf/1702.05900v1|$δ$-Greedy $t$-spanner|greedi spanner|We introduce a new geometric spanner, $\delta$-Greedy, whose construction is based on a generalization of the known Path-Greedy and Gap-Greedy spanners. The $\delta$-Greedy spanner combines the most desirable properties of geometric spanners both in theory and in practice. More specifically, it has the same theoretical and practical properties as the Path-Greedy spanner: a natural definition, small degree, linear number of edges, low weight, and strong $(1+\varepsilon)$-spanner for every $\varepsilon>0$. The $\delta$-Greedy algorithm is an improvement over the Path-Greedy algorithm with respect to the number of shortest path queries and hence with respect to its construction time. We show how to construct such a spanner for a set of $n$ points in the plane in $O(n^2 \log n)$ time.   The $\delta$-Greedy spanner has an additional parameter, $\delta$, which indicates how close it is to the Path-Greedy spanner on the account of the number of shortest path queries. For $\delta = t$ the output spanner is identical to the Path-Greedy spanner, while the number of shortest path queries is, in practice, linear.   Finally, we show that for a set of $n$ points placed independently at random in a unit square the expected construction time of the $\delta$-Greedy algorithm is $O(n \log n)$. Our analysis indicates that the $\delta$-Greedy spanner gives the best results among the known spanners of expected $O(n \log n)$ time for random point sets. Moreover, the analysis implies that by setting $\delta = t$, the $\delta$-Greedy algorithm provides a spanner identical to the Path-Greedy spanner in expected $O(n \log n)$ time.|introduc new geometr spanner delta greedi whose construct base general known path greedi gap greedi spanner delta greedi spanner combin desir properti geometr spanner theori practic specif theoret practic properti path greedi spanner natur definit small degre linear number edg low weight strong varepsilon spanner everi varepsilon delta greedi algorithm improv path greedi algorithm respect number shortest path queri henc respect construct time show construct spanner set point plane log time delta greedi spanner addit paramet delta indic close path greedi spanner account number shortest path queri delta output spanner ident path greedi spanner number shortest path queri practic linear final show set point place independ random unit squar expect construct time delta greedi algorithm log analysi indic delta greedi spanner give best result among known spanner expect log time random point set moreov analysi impli set delta delta greedi algorithm provid spanner ident path greedi spanner expect log time|['Gali Bar-On', 'Paz Carmi']|['cs.CG']
2017-03-28T14:07:33Z|2017-02-19T15:48:11Z|http://arxiv.org/abs/1702.05760v1|http://arxiv.org/pdf/1702.05760v1|Hypercube LSH for approximate near neighbors|hypercub lsh approxim near neighbor|A celebrated technique for finding near neighbors for the angular distance involves using a set of \textit{random} hyperplanes to partition the space into hash regions [Charikar, STOC 2002]. Experiments later showed that using a set of \textit{orthogonal} hyperplanes, thereby partitioning the space into the Voronoi regions induced by a hypercube, leads to even better results [Terasawa and Tanaka, WADS 2007]. However, no theoretical explanation for this improvement was ever given, and it remained unclear how the resulting hypercube hash method scales in high dimensions.   In this work, we provide explicit asymptotics for the collision probabilities when using hypercubes to partition the space. For instance, two near-orthogonal vectors are expected to collide with probability $(\frac{1}{\pi})^{d + o(d)}$ in dimension $d$, compared to $(\frac{1}{2})^d$ when using random hyperplanes. Vectors at angle $\frac{\pi}{3}$ collide with probability $(\frac{\sqrt{3}}{\pi})^{d + o(d)}$, compared to $(\frac{2}{3})^d$ for random hyperplanes, and near-parallel vectors collide with similar asymptotic probabilities in both cases.   For $c$-approximate nearest neighbor searching, this translates to a decrease in the exponent $\rho$ of locality-sensitive hashing (LSH) methods of a factor up to $\log_2(\pi) \approx 1.652$ compared to hyperplane LSH. For $c = 2$, we obtain $\rho \approx 0.302 + o(1)$ for hypercube LSH, improving upon the $\rho \approx 0.377$ for hyperplane LSH. We further describe how to use hypercube LSH in practice, and we consider an example application in the area of lattice algorithms.|celebr techniqu find near neighbor angular distanc involv use set textit random hyperplan partit space hash region charikar stoc experi later show use set textit orthogon hyperplan therebi partit space voronoi region induc hypercub lead even better result terasawa tanaka wad howev theoret explan improv ever given remain unclear result hypercub hash method scale high dimens work provid explicit asymptot collis probabl use hypercub partit space instanc two near orthogon vector expect collid probabl frac pi dimens compar frac use random hyperplan vector angl frac pi collid probabl frac sqrt pi compar frac random hyperplan near parallel vector collid similar asymptot probabl case approxim nearest neighbor search translat decreas expon rho local sensit hash lsh method factor log pi approx compar hyperplan lsh obtain rho approx hypercub lsh improv upon rho approx hyperplan lsh describ use hypercub lsh practic consid exampl applic area lattic algorithm|['Thijs Laarhoven']|['cs.DS', 'cs.CC', 'cs.CG', 'cs.CR']
2017-03-28T14:07:33Z|2017-02-18T17:02:58Z|http://arxiv.org/abs/1702.05633v1|http://arxiv.org/pdf/1702.05633v1|Approximation Algorithms for Independence and Domination on B$_1$-VPG   and B$_1$-EPG Graphs|approxim algorithm independ domin vpg epg graph|A graph $G$ is called B$_k$-VPG (resp., B$_k$-EPG), for some constant $k\geq 0$, if it has a string representation on a grid such that each vertex is an orthogonal path with at most $k$ bends and two vertices are adjacent in $G$ if and only if the corresponding strings intersect (resp., the corresponding strings share at least one grid edge). If two adjacent strings of a B$_k$-VPG graph intersect exactly once, then the graph is called a one-string B$_k$-VPG graph.   In this paper, we study the Maximum Independent Set and Minimum Dominating Set problems on B$_1$-VPG and B$_1$-EPG graphs. We first give a simple $O(\log n)$-approximation algorithm for the Maximum Independent Set problem on B$_1$-VPG graphs, improving the previous $O((\log n)^2)$-approximation algorithm of Lahiri et al. (COCOA 2015). Then, we consider the Minimum Dominating Set problem. We give an $O(1)$-approximation algorithm for this problem on one-string B$_1$-VPG graphs, providing the first constant-factor approximation algorithm for this problem. Moreover, we show that the Minimum Dominating Set problem is APX-hard on B$_1$-EPG graphs, ruling out the possibility of a PTAS unless P=NP. Finally, we give constant-factor approximation algorithms for this problem on two non-trivial subclasses of B$_1$-EPG graphs. To our knowledge, these are the first results for the Minimum Dominating Set problem on B$_1$-EPG graphs, partially answering a question posed by Epstein et al. (WADS 2013).|graph call vpg resp epg constant geq string represent grid vertex orthogon path bend two vertic adjac onli correspond string intersect resp correspond string share least one grid edg two adjac string vpg graph intersect exact onc graph call one string vpg graph paper studi maximum independ set minimum domin set problem vpg epg graph first give simpl log approxim algorithm maximum independ set problem vpg graph improv previous log approxim algorithm lahiri et al cocoa consid minimum domin set problem give approxim algorithm problem one string vpg graph provid first constant factor approxim algorithm problem moreov show minimum domin set problem apx hard epg graph rule possibl ptas unless np final give constant factor approxim algorithm problem two non trivial subclass epg graph knowledg first result minimum domin set problem epg graph partial answer question pose epstein et al wad|['Saeed Mehrabi']|['cs.CG']
2017-03-28T14:07:33Z|2017-02-17T16:07:53Z|http://arxiv.org/abs/1702.06188v1|http://arxiv.org/pdf/1702.06188v1|Forest understory trees revealed using sufficiently dense airborne laser   scanning point clouds|forest understori tree reveal use suffici dens airborn laser scan point cloud|Airborne laser scanning (lidar) point clouds can be process to extract tree-level information over large forested landscapes. Existing procedures typically detect more than 90% of overstory trees, yet they barely detect 60% of understory trees because of reduced number of lidar points penetrating the top canopy layer. Although understory trees provide limited financial value, they offer habitat for numerous wildlife species and are important for stand development. Here we model tree identification accuracy according to point cloud density by decomposing lidar point cloud into overstory and multiple understory canopy layers, estimating the fraction of points representing the different layers, and inspecting tree identification accuracy as a function of point density. We show at a density of about 170 pt/m2 understory tree identification accuracy likely plateaus, which we regard as the required point density for reasonable identification of understory trees. Given the advancements of lidar sensor technology, point clouds can feasibly reach the required density to enable effective identification of individual understory trees, ultimately making remote quantification of forest resources more accurate. The layer decomposition methodology can also be adopted for other similar remote sensing or advanced imaging applications such as geological subsurface modelling or biomedical tissue analysis.|airborn laser scan lidar point cloud process extract tree level inform larg forest landscap exist procedur typic detect overstori tree yet bare detect understori tree becaus reduc number lidar point penetr top canopi layer although understori tree provid limit financi valu offer habitat numer wildlif speci import stand develop model tree identif accuraci accord point cloud densiti decompos lidar point cloud overstori multipl understori canopi layer estim fraction point repres differ layer inspect tree identif accuraci function point densiti show densiti pt understori tree identif accuraci like plateaus regard requir point densiti reason identif understori tree given advanc lidar sensor technolog point cloud feasibl reach requir densiti enabl effect identif individu understori tree ultim make remot quantif forest resourc accur layer decomposit methodolog also adopt similar remot sens advanc imag applic geolog subsurfac model biomed tissu analysi|['Hamid Hamraz', 'Marco A. Contreras', 'Jun Zhang']|['cs.CV', 'cs.CG']
2017-03-28T14:07:37Z|2017-02-17T14:34:08Z|http://arxiv.org/abs/1702.05358v1|http://arxiv.org/pdf/1702.05358v1|Computational topology of graphs on surfaces|comput topolog graph surfac|Computational topology is an area that revisits topological problems from an algorithmic point of view, and develops topological tools for improved algorithms. We survey results in computational topology that are concerned with graphs drawn on surfaces. Typical questions include representing surfaces and graphs embedded on them computationally, deciding whether a graph embeds on a surface, solving computational problems related to homotopy, optimizing curves and graphs on surfaces, and solving standard graph algorithm problems more efficiently in the case of surface-embedded graphs.|comput topolog area revisit topolog problem algorithm point view develop topolog tool improv algorithm survey result comput topolog concern graph drawn surfac typic question includ repres surfac graph embed comput decid whether graph emb surfac solv comput problem relat homotopi optim curv graph surfac solv standard graph algorithm problem effici case surfac embed graph|['Éric Colin de Verdière']|['cs.CG', 'cs.DM', 'cs.DS', 'math.AT', 'math.CO', '68U05, 05C10, 57M15, 68R10', 'F.2.2; G.2.2; I.3.5']
2017-03-28T14:07:37Z|2017-02-17T09:19:02Z|http://arxiv.org/abs/1702.05265v1|http://arxiv.org/pdf/1702.05265v1|T-Shape Visibility Representations of 1-Planar Graphs|shape visibl represent planar graph|A shape visibility representation displays a graph so that each vertex is represented by an orthogonal polygon of a particular shape and for each edge there is a horizontal or vertical line of sight between the polygons assigned to its endvertices. Special shapes are rectangles, L, T, E and H-shapes, and caterpillars. A flat rectangle is a horizontal bar of height $\epsilon>0$. A graph is 1-planar if there is a drawing in the plane such that each edge is crossed at most once and is IC-planar if in addition no two crossing edges share a vertex.   We show that every IC-planar graph has a flat rectangle visibility representation and that every 1-planar graph has a T-shape visibility representation. The representations use quadratic area and can be computed in linear time from a given embedding.|shape visibl represent display graph vertex repres orthogon polygon particular shape edg horizont vertic line sight polygon assign endvertic special shape rectangl shape caterpillar flat rectangl horizont bar height epsilon graph planar draw plane edg cross onc ic planar addit two cross edg share vertex show everi ic planar graph flat rectangl visibl represent everi planar graph shape visibl represent represent use quadrat area comput linear time given embed|['Franz J. Brandenburg']|['cs.CG', '68R10', 'G.2.2']
2017-03-28T14:07:37Z|2017-02-15T14:59:10Z|http://arxiv.org/abs/1702.04641v1|http://arxiv.org/pdf/1702.04641v1|Filling missing data in point clouds by merging structured and   unstructured point clouds|fill miss data point cloud merg structur unstructur point cloud|"Point clouds arising from structured data, mainly as a result of CT scans, provides special properties on the distribution of points and the distances between those. Yet often, the amount of data provided can not compare to unstructured point clouds, i.e. data that arises from 3D light scans or laser scans. This article hereby proposes an approach to extend structured data and enhance the quality by inserting selected points from an unstructured point cloud. The resulting point cloud still has a partial structure that is called ""half-structure"". In this way, missing data that can not be optimally recovered through other surface reconstruction methods can be completed."|point cloud aris structur data main result ct scan provid special properti distribut point distanc yet often amount data provid compar unstructur point cloud data aris light scan laser scan articl herebi propos approach extend structur data enhanc qualiti insert select point unstructur point cloud result point cloud still partial structur call half structur way miss data optim recov surfac reconstruct method complet|['Franziska Lippoldt', 'Hartmut Schwandt']|['cs.CG', 'cs.CV', 'cs.DM', '53A05', 'F.2.2; G.2.1; I.3.5']
2017-03-28T14:07:37Z|2017-02-14T15:20:23Z|http://arxiv.org/abs/1702.04259v1|http://arxiv.org/pdf/1702.04259v1|On the metastable Mabillard-Wagner conjecture|metast mabillard wagner conjectur|The purpose of this note is to attract attention to the following conjecture (metastable $r$-fold Whitney trick) by clarifying its status as not having a complete proof, in the sense described in the paper.   Assume that $D=D_1\sqcup\ldots\sqcup D_r$ is disjoint union of $r$ disks of dimension $s$, $f:D\to B^d$ a proper PL map such that $f\partial D_1\cap\ldots\cap f\partial D_r=\emptyset$, $rd\ge (r+1)s+3$ and $d\ge s+3$. If the map $$f^r:\partial(D_1\times\ldots\times D_r)\to (B^d)^r-\{(x,x,\ldots,x)\in(B^d)^r\  \ x\in B^d\}$$ extends to $D_1\times\ldots\times D_r$, then there is a PL map $\overline f:D\to B^d$ such that $$\overline f=f \quad\text{on}\quad D_r\cup\partial D\quad\text{and}\quad \overline fD_1\cap\ldots\cap \overline fD_r=\emptyset.$$|purpos note attract attent follow conjectur metast fold whitney trick clarifi status complet proof sens describ paper assum sqcup ldot sqcup disjoint union disk dimens proper pl map partial cap ldot cap partial emptyset rd ge ge map partial time ldot time ldot extend time ldot time pl map overlin overlin quad text quad cup partial quad text quad overlin fd cap ldot cap overlin fd emptyset|['A. Skopenkov']|['math.GT', 'cs.CG', '57Q35, 57R65, 52B99']
2017-03-28T14:07:37Z|2017-03-19T08:52:47Z|http://arxiv.org/abs/1702.03676v2|http://arxiv.org/pdf/1702.03676v2|Epsilon-approximations and epsilon-nets|epsilon approxim epsilon net|The use of random samples to approximate properties of geometric configurations has been an influential idea for both combinatorial and algorithmic purposes. This chapter considers two related notions---$\epsilon$-approximations and $\epsilon$-nets---that capture the most important quantitative properties that one would expect from a random sample with respect to an underlying geometric configuration.|use random sampl approxim properti geometr configur influenti idea combinatori algorithm purpos chapter consid two relat notion epsilon approxim epsilon net captur import quantit properti one would expect random sampl respect geometr configur|['Nabil H. Mustafa', 'Kasturi R. Varadarajan']|['cs.CG', 'math.CO', 'math.PR']
2017-03-28T14:07:37Z|2017-02-11T01:20:50Z|http://arxiv.org/abs/1702.03364v1|http://arxiv.org/pdf/1702.03364v1|Techniques in Lattice Basis Reduction|techniqu lattic basi reduct|The credit on {\it reduction theory} goes back to the work of Lagrange, Gauss, Hermite, Korkin, Zolotarev, and Minkowski. Modern reduction theory is voluminous and includes the work of A. Lenstra, H. Lenstra and L. Lovasz who created the well known LLL algorithm, and many other researchers such as L. Babai and C. P. Schnorr who created significant new variants of basis reduction algorithms. In this paper, we propose and investigate the efficacy of new optimization techniques to be used along with LLL algorithm. The techniques we have proposed are: i) {\it hill climbing (HC)}, ii) {\it lattice diffusion-sub lattice fusion (LDSF)}, and iii) {\it multistage hybrid LDSF-HC}. The first technique relies on the sensitivity of LLL to permutations of the input basis $B$, and optimization ideas over the symmetric group $S_m$ viewed as a metric space. The second technique relies on partitioning the lattice into sublattices, performing basis reduction in the partition sublattice blocks, fusing the sublattices, and repeating. We also point out places where parallel computation can reduce run-times achieving almost linear speedup. The multistage hybrid technique relies on the lattice diffusion and sublattice fusion and hill climbing algorithms.|credit reduct theori goe back work lagrang gauss hermit korkin zolotarev minkowski modern reduct theori volumin includ work lenstra lenstra lovasz creat well known lll algorithm mani research babai schnorr creat signific new variant basi reduct algorithm paper propos investig efficaci new optim techniqu use along lll algorithm techniqu propos hill climb hc ii lattic diffus sub lattic fusion ldsf iii multistag hybrid ldsf hc first techniqu reli sensit lll permut input basi optim idea symmetr group view metric space second techniqu reli partit lattic sublattic perform basi reduct partit sublattic block fuse sublattic repeat also point place parallel comput reduc run time achiev almost linear speedup multistag hybrid techniqu reli lattic diffus sublattic fusion hill climb algorithm|['Bal K. Khadka', 'Spyros M. Magliveras']|['cs.CG']
2017-03-28T14:07:37Z|2017-02-10T17:54:59Z|http://arxiv.org/abs/1702.03266v1|http://arxiv.org/pdf/1702.03266v1|Two Optimization Problems for Unit Disks|two optim problem unit disk|We present an implementation of a recent algorithm to compute shortest-path trees in unit disk graphs in $O(n\log n)$ worst-case time, where $n$ is the number of disks.   In the minimum-separation problem, we are given $n$ unit disks and two points $s$ and $t$, not contained in any of the disks, and we want to compute the minimum number of disks one needs to retain so that any curve connecting $s$ to $t$ intersects some of the retained disks. We present a new algorithm solving this problem in $O(n^2\log^3 n)$ worst-case time and its implementation.|present implement recent algorithm comput shortest path tree unit disk graph log worst case time number disk minimum separ problem given unit disk two point contain ani disk want comput minimum number disk one need retain ani curv connect intersect retain disk present new algorithm solv problem log worst case time implement|['Sergio Cabello', 'Lazar Milinković']|['cs.CG']
2017-03-28T14:07:37Z|2017-02-10T14:37:00Z|http://arxiv.org/abs/1702.03187v1|http://arxiv.org/pdf/1702.03187v1|On vertices and facets of combinatorial 2-level polytopes|vertic facet combinatori level polytop|2-level polytopes naturally appear in several areas of pure and applied mathematics, including combinatorial optimization, polyhedral combinatorics, communication complexity, and statistics. In this paper, we present a polyhedral study of 2-level polytopes arising in combinatorial settings. For all the known (to the best of our knowledge) such polytopes P, we show that v(P).f(P) is upper bounded by d2^(d+1). Here v(P) (resp. f(P)) is the number of vertices (resp. facets) of P, and d is its dimension. Whether this holds for all 2-level polytopes was asked in [Bohn et al., ESA 2015], where experimental results showed it true up to dimension 6. The key to most of our proofs is an understanding of the combinatorial structures underlying those polytopes. This leads to a number of results that we believe to be of independent interest: a trade-off formula for the number of cliques and stable sets in a graph; a description of the facets of the base polytope of the 2-sum of matroids; a linear-size description of the base polytope of matroids that are 2-level in terms of cuts of an associated tree. We also give a self-contained proof of the characterization of the last class, a result first obtained by Grande and Sanyal.|level polytop natur appear sever area pure appli mathemat includ combinatori optim polyhedr combinator communic complex statist paper present polyhedr studi level polytop aris combinatori set known best knowledg polytop show upper bound resp number vertic resp facet dimens whether hold level polytop ask bohn et al esa experiment result show true dimens key proof understand combinatori structur polytop lead number result believ independ interest trade formula number cliqu stabl set graph descript facet base polytop sum matroid linear size descript base polytop matroid level term cut associ tree also give self contain proof character last class result first obtain grand sanyal|['Manuel Aprile', 'Alfonso Cevallos', 'Yuri Faenza']|['math.CO', 'cs.CG']
2017-03-28T14:07:37Z|2017-02-09T14:04:20Z|http://arxiv.org/abs/1702.02838v1|http://arxiv.org/pdf/1702.02838v1|The DTM-signature for a geometric comparison of metric-measure spaces   from samples|dtm signatur geometr comparison metric measur space sampl|In this paper, we introduce the notion of DTM-signature, a measure on R + that can be associated to any metric-measure space. This signature is based on the distance to a measure (DTM) introduced by Chazal, Cohen-Steiner and M\'erigot. It leads to a pseudo-metric between metric-measure spaces, upper-bounded by the Gromov-Wasserstein distance. Under some geometric assumptions, we derive lower bounds for this pseudo-metric. Given two N-samples, we also build an asymptotic statistical test based on the DTM-signature, to reject the hypothesis of equality of the two underlying metric-measure spaces, up to a measure-preserving isometry. We give strong theoretical justifications for this test and propose an algorithm for its implementation.|paper introduc notion dtm signatur measur associ ani metric measur space signatur base distanc measur dtm introduc chazal cohen steiner erigot lead pseudo metric metric measur space upper bound gromov wasserstein distanc geometr assumpt deriv lower bound pseudo metric given two sampl also build asymptot statist test base dtm signatur reject hypothesi equal two metric measur space measur preserv isometri give strong theoret justif test propos algorithm implement|['Claire Brécheteau']|['cs.CG', 'math.PR', 'math.ST', 'stat.TH']
2017-03-28T14:07:37Z|2017-02-07T01:11:38Z|http://arxiv.org/abs/1702.01836v1|http://arxiv.org/pdf/1702.01836v1|Linear Time Approximation Schemes for Geometric Maximum Coverage|linear time approxim scheme geometr maximum coverag|We study approximation algorithms for the following geometric version of the maximum coverage problem: Let $\mathcal{P}$ be a set of $n$ weighted points in the plane. Let $D$ represent a planar object, such as a rectangle, or a disk. We want to place $m$ copies of $D$ such that the sum of the weights of the points in $\mathcal{P}$ covered by these copies is maximized. For any fixed $\varepsilon>0$, we present efficient approximation schemes that can find a $(1-\varepsilon)$-approximation to the optimal solution. In particular, for $m=1$ and for the special case where $D$ is a rectangle, our algorithm runs in time $O(n\log (\frac{1}{\varepsilon}))$, improving on the previous result. For $m>1$ and the rectangular case, our algorithm runs in $O(\frac{n}{\varepsilon}\log (\frac{1}{\varepsilon})+\frac{m}{\varepsilon}\log m +m(\frac{1}{\varepsilon})^{O(\min(\sqrt{m},\frac{1}{\varepsilon}))})$ time. For a more general class of shapes (including disks, polygons with $O(1)$ edges), our algorithm runs in $O(n(\frac{1}{\varepsilon})^{O(1)}+\frac{m}{\epsilon}\log m + m(\frac{1}{\varepsilon})^{O(\min(m,\frac{1}{\varepsilon^2}))})$ time.|studi approxim algorithm follow geometr version maximum coverag problem let mathcal set weight point plane let repres planar object rectangl disk want place copi sum weight point mathcal cover copi maxim ani fix varepsilon present effici approxim scheme find varepsilon approxim optim solut particular special case rectangl algorithm run time log frac varepsilon improv previous result rectangular case algorithm run frac varepsilon log frac varepsilon frac varepsilon log frac varepsilon min sqrt frac varepsilon time general class shape includ disk polygon edg algorithm run frac varepsilon frac epsilon log frac varepsilon min frac varepsilon time|['Kai Jin', 'Jian Li', 'Haitao Wang', 'Bowei Zhang', 'Ningye Zhang']|['cs.CG', 'F.2.2']
2017-03-28T14:07:41Z|2017-02-06T21:31:57Z|http://arxiv.org/abs/1702.01799v1|http://arxiv.org/pdf/1702.01799v1|Radial Contour Labeling with Straight Leaders|radial contour label straight leader|The usefulness of technical drawings as well as scientific illustrations such as medical drawings of human anatomy essentially depends on the placement of labels that describe all relevant parts of the figure. In order to not spoil or clutter the figure with text, the labels are often placed around the figure and are associated by thin connecting lines to their features, respectively. This labeling technique is known as external label placement.   In this paper we introduce a flexible and general approach for external label placement assuming a contour of the figure prescribing the possible positions of the labels. While much research on external label placement aims for fast labeling procedures for interactive systems, we focus on highest-quality illustrations. Based on interviews with domain experts and a semi-automatic analysis of 202 handmade anatomical drawings, we identify a set of 18 layout quality criteria, naturally not all of equal importance. We design a new geometric label placement algorithm that is based only on the most important criteria. Yet, other criteria can flexibly be included in the algorithm, either as hard constraints not to be violated or as soft constraints whose violation is penalized by a general cost function. We formally prove that our approach yields labelings that satisfy all hard constraints and have minimum overall cost. Introducing several speedup techniques, we further demonstrate how to deploy our approach in practice. In an experimental evaluation on real-world anatomical drawings we show that the resulting labelings are of high quality and can be produced in adequate time.|use technic draw well scientif illustr medic draw human anatomi essenti depend placement label describ relev part figur order spoil clutter figur text label often place around figur associ thin connect line featur respect label techniqu known extern label placement paper introduc flexibl general approach extern label placement assum contour figur prescrib possibl posit label much research extern label placement aim fast label procedur interact system focus highest qualiti illustr base interview domain expert semi automat analysi handmad anatom draw identifi set layout qualiti criteria natur equal import design new geometr label placement algorithm base onli import criteria yet criteria flexibl includ algorithm either hard constraint violat soft constraint whose violat penal general cost function formal prove approach yield label satisfi hard constraint minimum overal cost introduc sever speedup techniqu demonstr deploy approach practic experiment evalu real world anatom draw show result label high qualiti produc adequ time|['Benjamin Niedermann', 'Martin Nöllenburg', 'Ignaz Rutter']|['cs.CG']
2017-03-28T14:07:41Z|2017-02-06T17:38:26Z|http://arxiv.org/abs/1702.01719v1|http://arxiv.org/pdf/1702.01719v1|A 2-Approximation for the Height of Maximal Outerplanar Graph Drawings|approxim height maxim outerplanar graph draw|In this paper, we study planar drawings of maximal outerplanar graphs with the objective of achieving small height. A recent paper gave an algorithm for such drawings that is within a factor of 4 of the optimum height. In this paper, we substantially improve the approximation factor to become 2. The main ingredient is to define a new parameter of outerplanar graphs (the so-called umbrella depth, obtained by recursively splitting the graph into graphs called umbrellas). We argue that the height of any poly-line drawing must be at least the umbrella depth, and then devise an algorithm that achieves height at most twice the umbrella depth.|paper studi planar draw maxim outerplanar graph object achiev small height recent paper gave algorithm draw within factor optimum height paper substanti improv approxim factor becom main ingredi defin new paramet outerplanar graph call umbrella depth obtain recurs split graph graph call umbrella argu height ani poli line draw must least umbrella depth devis algorithm achiev height twice umbrella depth|['Therese Biedl', 'Philippe Demontigny']|['cs.DS', 'cs.CG']
2017-03-28T14:07:41Z|2017-02-06T08:01:16Z|http://arxiv.org/abs/1702.01524v1|http://arxiv.org/pdf/1702.01524v1|Edge N-Level Sparse Visibility Graphs: Fast Optimal Any-Angle   Pathfinding Using Hierarchical Taut Paths|edg level spars visibl graph fast optim ani angl pathfind use hierarch taut path|In the Any-Angle Pathfinding problem, the goal is to find the shortest path between a pair of vertices on a uniform square grid, that is not constrained to any fixed number of possible directions over the grid. Visibility Graphs are a known optimal algorithm for solving the problem with the use of pre-processing. However, Visibility Graphs are known to perform poorly in terms of running time, especially on large, complex maps. In this paper, we introduce two improvements over the Visibility Graph Algorithm to compute optimal paths. Sparse Visibility Graphs (SVGs) are constructed by pruning unnecessary edges from the original Visibility Graph. Edge N-Level Sparse Visibility Graphs (ENLSVGs) is a hierarchical SVG built by iteratively pruning non-taut paths. We also introduce Line-of-Sight Scans, a faster algorithm for building Visibility Graphs over a grid. SVGs run much faster than Visibility Graphs by reducing the average vertex degree. ENLSVGs, a hierarchical algorithm, improves this further, especially on larger maps. On large maps, with the use of pre-processing, these algorithms are orders of magnitude faster than existing algorithms like Visibility Graphs and Theta*.|ani angl pathfind problem goal find shortest path pair vertic uniform squar grid constrain ani fix number possibl direct grid visibl graph known optim algorithm solv problem use pre process howev visibl graph known perform poor term run time especi larg complex map paper introduc two improv visibl graph algorithm comput optim path spars visibl graph svgs construct prune unnecessari edg origin visibl graph edg level spars visibl graph enlsvg hierarch svg built iter prune non taut path also introduc line sight scan faster algorithm build visibl graph grid svgs run much faster visibl graph reduc averag vertex degre enlsvg hierarch algorithm improv especi larger map larg map use pre process algorithm order magnitud faster exist algorithm like visibl graph theta|['Shunhao Oh', 'Hon Wai Leong']|['cs.CG']
2017-03-28T14:07:41Z|2017-02-09T01:46:20Z|http://arxiv.org/abs/1702.01446v2|http://arxiv.org/pdf/1702.01446v2|Efficient Algorithms for k-Regret Minimizing Sets|effici algorithm regret minim set|A regret minimizing set Q is a small size representation of a much larger database P so that user queries executed on Q return answers whose scores are not much worse than those on the full dataset. In particular, a k-regret minimizing set has the property that the regret ratio between the score of the top-1 item in Q and the score of the top-k item in P is minimized, where the score of an item is the inner product of the item's attributes with a user's weight (preference) vector. The problem is challenging because we want to find a single representative set Q whose regret ratio is small with respect to all possible user weight vectors.   We show that k-regret minimization is NP-Complete for all dimensions d >= 3. This settles an open problem from Chester et al. [VLDB 2014], and resolves the complexity status of the problem for all d: the problem is known to have polynomial-time solution for d <= 2. In addition, we propose two new approximation schemes for regret minimization, both with provable guarantees, one based on coresets and another based on hitting sets. We also carry out extensive experimental evaluation, and show that our schemes compute regret-minimizing sets comparable in size to the greedy algorithm proposed in [VLDB 14] but our schemes are significantly faster and scalable to large data sets.|regret minim set small size represent much larger databas user queri execut return answer whose score much wors full dataset particular regret minim set properti regret ratio score top item score top item minim score item inner product item attribut user weight prefer vector problem challeng becaus want find singl repres set whose regret ratio small respect possibl user weight vector show regret minim np complet dimens settl open problem chester et al vldb resolv complex status problem problem known polynomi time solut addit propos two new approxim scheme regret minim provabl guarante one base coreset anoth base hit set also carri extens experiment evalu show scheme comput regret minim set compar size greedi algorithm propos vldb scheme signific faster scalabl larg data set|['Pankaj K. Agarwal', 'Nirman Kumar', 'Stavros Sintos', 'Subhash Suri']|['cs.DS', 'cs.CG', 'cs.DB']
2017-03-28T14:07:41Z|2017-02-04T11:51:50Z|http://arxiv.org/abs/1702.01277v1|http://arxiv.org/pdf/1702.01277v1|Geometric Biplane Graphs II: Graph Augmentation|geometr biplan graph ii graph augment|We study biplane graphs drawn on a finite point set $S$ in the plane in general position. This is the family of geometric graphs whose vertex set is $S$ and which can be decomposed into two plane graphs. We show that every sufficiently large point set admits a 5-connected biplane graph and that there are arbitrarily large point sets that do not admit any 6-connected biplane graph. Furthermore, we show that every plane graph (other than a wheel or a fan) can be augmented into a 4-connected biplane graph. However, there are arbitrarily large plane graphs that cannot be augmented to a 5-connected biplane graph by adding pairwise noncrossing edges.|studi biplan graph drawn finit point set plane general posit famili geometr graph whose vertex set decompos two plane graph show everi suffici larg point set admit connect biplan graph arbitrarili larg point set admit ani connect biplan graph furthermor show everi plane graph wheel fan augment connect biplan graph howev arbitrarili larg plane graph cannot augment connect biplan graph ad pairwis noncross edg|['Alfredo García', 'Ferran Hurtado', 'Matias Korman', 'Inês Matos', 'Maria Saumell', 'Rodrigo I. Silveira', 'Javier Tejel', 'Csaba D. Tóth']|['cs.CG']
2017-03-28T14:07:41Z|2017-02-04T11:51:44Z|http://arxiv.org/abs/1702.01275v1|http://arxiv.org/pdf/1702.01275v1|Geometric Biplane Graphs I: Maximal Graphs|geometr biplan graph maxim graph|We study biplane graphs drawn on a finite planar point set $S$ in general position. This is the family of geometric graphs whose vertex set is $S$ and can be decomposed into two plane graphs. We show that two maximal biplane graphs---in the sense that no edge can be added while staying biplane---may differ in the number of edges, and we provide an efficient algorithm for adding edges to a biplane graph to make it maximal. We also study extremal properties of maximal biplane graphs such as the maximum number of edges and the largest maximum connectivity over $n$-element point sets.|studi biplan graph drawn finit planar point set general posit famili geometr graph whose vertex set decompos two plane graph show two maxim biplan graph sens edg ad stay biplan may differ number edg provid effici algorithm ad edg biplan graph make maxim also studi extrem properti maxim biplan graph maximum number edg largest maximum connect element point set|['Alfredo García', 'Ferran Hurtado', 'Matias Korman', 'Inês Matos', 'Maria Saumell', 'Rodrigo I. Silveira', 'Javier Tejel', 'Csaba D. Tóth']|['cs.CG']
2017-03-28T14:07:41Z|2017-02-02T22:20:25Z|http://arxiv.org/abs/1702.00849v1|http://arxiv.org/pdf/1702.00849v1|On the union complexity of families of axis-parallel rectangles with a   low packing number|union complex famili axi parallel rectangl low pack number|Let R be a family of n axis-parallel rectangles with packing number p-1, meaning that among any p of the rectangles, there are two with a non-empty intersection. We show that the union complexity of R is at most O(n+p^2), and that the (<=k)-level complexity of R is at most O(kn+k^2p^2). Both upper bounds are tight.|let famili axi parallel rectangl pack number mean among ani rectangl two non empti intersect show union complex level complex kn upper bound tight|['Chaya Keller', 'Shakhar Smorodinsky']|['math.CO', 'cs.CG', '52C45, 52C15']
2017-03-28T14:07:41Z|2017-02-01T16:55:41Z|http://arxiv.org/abs/1702.00353v1|http://arxiv.org/pdf/1702.00353v1|The non-cooperative tile assembly model is not intrinsically universal   or capable of bounded Turing machine simulation|non cooper tile assembl model intrins univers capabl bound ture machin simul|The field of algorithmic self-assembly is concerned with the computational and expressive power of nanoscale self-assembling molecular systems. In the well-studied cooperative, or temperature 2, abstract tile assembly model it is known that there is a tile set to simulate any Turing machine and an intrinsically universal tile set that simulates the shapes and dynamics of any instance of the model, up to spatial rescaling. It has been an open question as to whether the seemingly simpler noncooperative, or temperature 1, model is capable of such behaviour. Here we show that this is not the case, by showing that there is no tile set in the noncooperative model that is intrinsically universal, nor one capable of time-bounded Turing machine simulation within a bounded region of the plane.   Although the noncooperative model intuitively seems to lack the complexity and power of the cooperative model it has been exceedingly hard to prove this. One reason is that there have been few tools to analyse the structure of complicated paths in the plane. This paper provides a number of such tools. A second reason is that almost every obvious and small generalisation to the model (e.g. allowing error, 3D, non-square tiles, signals/wires on tiles, tiles that repel each other, parallel synchronous growth) endows it with great computational, and sometimes simulation, power. Our main results show that all of these generalisations provably increase computational and/or simulation power. Our results hold for both deterministic and nondeterministic noncooperative systems. Our first main result stands in stark contrast with the fact that for both the cooperative tile assembly model, and for 3D noncooperative tile assembly, there are respective intrinsically universal tilesets. Our second main result gives a new technique (reduction to simulation) for proving negative results about computation in tile assembly.|field algorithm self assembl concern comput express power nanoscal self assembl molecular system well studi cooper temperatur abstract tile assembl model known tile set simul ani ture machin intrins univers tile set simul shape dynam ani instanc model spatial rescal open question whether seem simpler noncoop temperatur model capabl behaviour show case show tile set noncoop model intrins univers one capabl time bound ture machin simul within bound region plane although noncoop model intuit seem lack complex power cooper model exceed hard prove one reason tool analys structur complic path plane paper provid number tool second reason almost everi obvious small generalis model allow error non squar tile signal wire tile tile repel parallel synchron growth endow great comput sometim simul power main result show generalis provabl increas comput simul power result hold determinist nondeterminist noncoop system first main result stand stark contrast fact cooper tile assembl model noncoop tile assembl respect intrins univers tileset second main result give new techniqu reduct simul prove negat result comput tile assembl|['Pierre-Étienne Meunier', 'Damien Woods']|['cs.CC', 'cs.CG', 'cs.DS']
2017-03-28T14:07:41Z|2017-02-01T06:45:40Z|http://arxiv.org/abs/1702.00146v1|http://arxiv.org/pdf/1702.00146v1|Untangling Planar Curves|untangl planar curv|Any generic closed curve in the plane can be transformed into a simple closed curve by a finite sequence of local transformations called homotopy moves. We prove that simplifying a planar closed curve with $n$ self-crossings requires $\Theta(n^{3/2})$ homotopy moves in the worst case. Our algorithm improves the best previous upper bound $O(n^2)$, which is already implicit in the classical work of Steinitz; the matching lower bound follows from the construction of closed curves with large defect, a topological invariant of generic closed curves introduced by Aicardi and Arnold. Our lower bound also implies that $\Omega(n^{3/2})$ facial electrical transformations are required to reduce any plane graph with treewidth $\Omega(\sqrt{n})$ to a single vertex, matching known upper bounds for rectangular and cylindrical grid graphs. More generally, we prove that transforming one immersion of $k$ circles with at most $n$ self-crossings into another requires $\Theta(n^{3/2} + nk + k^2)$ homotopy moves in the worst case. Finally, we prove that transforming one noncontractible closed curve to another on any orientable surface requires $\Omega(n^2)$ homotopy moves in the worst case; this lower bound is tight if the curve is homotopic to a simple closed curve.|ani generic close curv plane transform simpl close curv finit sequenc local transform call homotopi move prove simplifi planar close curv self cross requir theta homotopi move worst case algorithm improv best previous upper bound alreadi implicit classic work steinitz match lower bound follow construct close curv larg defect topolog invari generic close curv introduc aicardi arnold lower bound also impli omega facial electr transform requir reduc ani plane graph treewidth omega sqrt singl vertex match known upper bound rectangular cylindr grid graph general prove transform one immers circl self cross anoth requir theta nk homotopi move worst case final prove transform one noncontract close curv anoth ani orient surfac requir omega homotopi move worst case lower bound tight curv homotop simpl close curv|['Hsien-Chih Chang', 'Jeff Erickson']|['cs.CG', 'math.GT']
2017-03-28T14:07:41Z|2017-01-29T19:55:27Z|http://arxiv.org/abs/1701.08423v1|http://arxiv.org/pdf/1701.08423v1|One Size Fits All : Effectiveness of Local Search on Structured Data|one size fit effect local search structur data|In this paper, we analyze the performance of a simple and standard Local Search algorithm for clustering on well behaved data. Since the seminal paper by Ostrovsky, Rabani, Schulman and Swamy [FOCS 2006], much progress has been made to characterize real-world instances. We distinguish the three main definitions -- Distribution Stability (Awasthi, Blum, Sheffet, FOCS 2010) -- Spectral Separability (Kumar, Kannan, FOCS 2010) -- Perturbation Resilience (Bilu, Linial, ICS 2010) We show that Local Search performs well on the instances with the aforementioned stability properties. Specifically, for the $k$-means and $k$-median objective, we show that Local Search exactly recovers the optimal clustering if the dataset is $3+\varepsilon$-perturbation resilient, and is a PTAS for distribution stability and spectral separability. This implies the first PTAS for instances satisfying the spectral separability condition. For the distribution stability condition we also go beyond previous work by showing that the clustering output by the algorithm and the optimal clustering are very similar. This is a significant step toward understanding the success of Local Search heuristics in clustering applications and supports the legitimacy of the stability conditions: They characterize some of the structure of real-world instances that make Local Search a popular heuristic.|paper analyz perform simpl standard local search algorithm cluster well behav data sinc semin paper ostrovski rabani schulman swami foc much progress made character real world instanc distinguish three main definit distribut stabil awasthi blum sheffet foc spectral separ kumar kannan foc perturb resili bilu linial ic show local search perform well instanc aforement stabil properti specif mean median object show local search exact recov optim cluster dataset varepsilon perturb resili ptas distribut stabil spectral separ impli first ptas instanc satisfi spectral separ condit distribut stabil condit also go beyond previous work show cluster output algorithm optim cluster veri similar signific step toward understand success local search heurist cluster applic support legitimaci stabil condit character structur real world instanc make local search popular heurist|['Vincent Cohen-Addad', 'Chris Schwiegelshohn']|['cs.DS', 'cs.CG', 'cs.LG']
2017-03-28T14:07:47Z|2017-01-19T18:01:10Z|http://arxiv.org/abs/1701.05532v1|http://arxiv.org/pdf/1701.05532v1|Tighter Bounds for the Discrepancy of Boxes and Polytopes|tighter bound discrep box polytop|Combinatorial discrepancy is a complexity measure of a collection of sets which quantifies how well the sets in the collection can be simultaneously balanced. More precisely, we are given an n-point set $P$, and a collection $\mathcal{F} = \{F_1, ..., F_m\}$ of subsets of $P$, and our goal is color $P$ with two colors, red and blue, so that the largest absolute difference between the number of red elements and the number of blue elements (i.e. the discrepancy) in any $F_i$ is minimized. Combinatorial discrepancy has many applications in mathematics and computer science, including constructions of uniformly distributed point sets, and lower bounds for data structures and private data analysis algorithms.   We investigate the combinatorial discrepancy of geometrically defined set systems, in which $P$ is an n-point set in $d$-dimensional space, and $\mathcal{F}$ is the collection of subsets of $P$ induced by dilations and translations of a fixed convex polytope $B$. Such set systems include sets induced by axis-aligned boxes, whose discrepancy is the subject of the well known Tusnady problem. We prove new discrepancy upper bounds for such set systems by extending the approach based on factorization norms previously used by the author and Matousek. We improve the best known upper bound for the Tusnady problem by a logarithmic factor, using a result of Banaszczyk on signed series of vectors. We extend this improvement to any arbitrary convex polytope B by using a decomposition due to Matousek.|combinatori discrep complex measur collect set quantifi well set collect simultan balanc precis given point set collect mathcal subset goal color two color red blue largest absolut differ number red element number blue element discrep ani minim combinatori discrep mani applic mathemat comput scienc includ construct uniform distribut point set lower bound data structur privat data analysi algorithm investig combinatori discrep geometr defin set system point set dimension space mathcal collect subset induc dilat translat fix convex polytop set system includ set induc axi align box whose discrep subject well known tusnadi problem prove new discrep upper bound set system extend approach base factor norm previous use author matousek improv best known upper bound tusnadi problem logarithm factor use result banaszczyk sign seri vector extend improv ani arbitrari convex polytop use decomposit due matousek|['Aleksandar Nikolov']|['math.CO', 'cs.CG']
2017-03-28T14:07:47Z|2017-01-19T16:24:27Z|http://arxiv.org/abs/1701.05500v1|http://arxiv.org/pdf/1701.05500v1|The number of realizations of a Laman graph|number realize laman graph|Laman graphs model planar frameworks that are rigid for a general choice of distances between the vertices. There are finitely many ways, up to isometries, to realize a Laman graph in the plane. Such realizations can be seen as solutions of systems of quadratic equations prescribing the distances between pairs of points. Using ideas from algebraic and tropical geometry, we provide a recursion formula for the number of complex solutions of such systems.|laman graph model planar framework rigid general choic distanc vertic finit mani way isometri realiz laman graph plane realize seen solut system quadrat equat prescrib distanc pair point use idea algebra tropic geometri provid recurs formula number complex solut system|['Jose Capco', 'Matteo Gallet', 'Georg Grasegger', 'Christoph Koutschan', 'Niels Lubbes', 'Josef Schicho']|['math.AG', 'cs.CG', 'cs.SC', 'math.CO', '14T05, 14N99, 52C25, 05C99']
2017-03-28T14:07:47Z|2017-01-19T15:33:50Z|http://arxiv.org/abs/1701.05475v1|http://arxiv.org/pdf/1701.05475v1|Irrational Guards are Sometimes Needed|irrat guard sometim need|In this paper we study the art gallery problem, which is one of the fundamental problems in computational geometry. The objective is to place a minimum number of guards inside a simple polygon such that the guards together can see the whole polygon. We say that a guard at position $x$ sees a point $y$ if the line segment $xy$ is fully contained in the polygon.   Despite an extensive study of the art gallery problem, it remained an open question whether there are polygons given by integer coordinates that require guard positions with irrational coordinates in any optimal solution. We give a positive answer to this question by constructing a monotone polygon with integer coordinates that can be guarded by three guards only when we allow to place the guards at points with irrational coordinates. Otherwise, four guards are needed. By extending this example, we show that for every $n$, there is polygon which can be guarded by $3n$ guards with irrational coordinates but need $4n$ guards if the coordinates have to be rational. Subsequently, we show that there are rectilinear polygons given by integer coordinates that require guards with irrational coordinates in any optimal solution.|paper studi art galleri problem one fundament problem comput geometri object place minimum number guard insid simpl polygon guard togeth see whole polygon say guard posit see point line segment xy fulli contain polygon despit extens studi art galleri problem remain open question whether polygon given integ coordin requir guard posit irrat coordin ani optim solut give posit answer question construct monoton polygon integ coordin guard three guard onli allow place guard point irrat coordin otherwis four guard need extend exampl show everi polygon guard guard irrat coordin need guard coordin ration subsequ show rectilinear polygon given integ coordin requir guard irrat coordin ani optim solut|['Mikkel Abrahamsen', 'Anna Adamaszek', 'Tillmann Miltzow']|['cs.CG', 'cs.DM', 'math.CO']
2017-03-28T14:07:47Z|2017-01-19T03:57:28Z|http://arxiv.org/abs/1701.05290v1|http://arxiv.org/pdf/1701.05290v1|Range-efficient consistent sampling and locality-sensitive hashing for   polygons|rang effici consist sampl local sensit hash polygon|Locality-sensitive hashing (LSH) is a fundamental technique for similarity search and similarity estimation in high-dimensional spaces. The basic idea is that similar objects should produce hash collisions with probability significantly larger than objects with low similarity. We consider LSH for objects that can be represented as point sets in either one or two dimensions. To make the point sets finite size we consider the subset of points on a grid. Directly applying LSH (e.g. min-wise hashing) to these point sets would require time proportional to the number of points. We seek to achieve time that is much lower than direct approaches.   Technically, we introduce new primitives for range-efficient consistent sampling (of independent interest), and show how to turn such samples into LSH values. Another application of our technique is a data structure for quickly estimating the size of the intersection or union of a set of preprocessed polygons. Curiously, our consistent sampling method uses transformation to a geometric problem.|local sensit hash lsh fundament techniqu similar search similar estim high dimension space basic idea similar object produc hash collis probabl signific larger object low similar consid lsh object repres point set either one two dimens make point set finit size consid subset point grid direct appli lsh min wise hash point set would requir time proport number point seek achiev time much lower direct approach technic introduc new primit rang effici consist sampl independ interest show turn sampl lsh valu anoth applic techniqu data structur quick estim size intersect union set preprocess polygon curious consist sampl method use transform geometr problem|['Joachim Gudmundsson', 'Rasmus Pagh']|['cs.CG', '68U05', 'F.2.2']
2017-03-28T14:07:47Z|2017-01-19T03:20:51Z|http://arxiv.org/abs/1701.05286v1|http://arxiv.org/pdf/1701.05286v1|Algorithms For Longest Chains In Pseudo- Transitive Graphs|algorithm longest chain pseudo transit graph|A directed acyclic graph G = (V, E) is pseudo-transitive with respect to a given subset of edges E1, if for any edge ab in E1 and any edge bc in E, we have ac in E. We give algorithms for computing longest chains and demonstrate geometric applications that unify and improves some important past results. (For specific applications see the introduction.)|direct acycl graph pseudo transit respect given subset edg ani edg ab ani edg bc ac give algorithm comput longest chain demonstr geometr applic unifi improv import past result specif applic see introduct|['Farhad Shahrokhi']|['cs.CG', 'math.CO']
2017-03-28T14:07:47Z|2017-01-18T16:46:08Z|http://arxiv.org/abs/1701.05141v1|http://arxiv.org/pdf/1701.05141v1|The Explicit Corridor Map: A Medial Axis-Based Navigation Mesh for   Multi-Layered Environments|explicit corridor map medial axi base navig mesh multi layer environ|Path planning for walking characters in complicated virtual environments is a fundamental task in simulations and games. In this paper, we present an improved definition of the Explicit Corridor Map (ECM), a navigation mesh that allows efficient path planning and crowd simulation for disk-shaped characters of any radius. The ECM is a medial axis (MA) annotated with nearest-obstacle information. For a planar environment with $n$ obstacle vertices, the ECM has size $O(n)$ and can be computed in $O(n \log n)$ time.   We also introduce multi-layered environments (MLEs), in which multiple planar layers are connected by line segment connections. Typical real-world examples are multi-storey buildings, train stations, and sports stadiums. We define the MA and the ECM for multi-layered environments, based on projected distances on the ground plane. For an MLE with $n$ obstacle points and $k$ connections, the MA has size $O(n)$. We present an improved algorithm that constructs the MA and ECM in $O(n \log n \log k)$ time.   Our implementations show that the ECM can be computed efficiently for large 2D and multi-layered environments, and that it can be used to compute paths within milliseconds. This enables simulations of large virtual crowds of heterogeneous characters in real-time.|path plan walk charact complic virtual environ fundament task simul game paper present improv definit explicit corridor map ecm navig mesh allow effici path plan crowd simul disk shape charact ani radius ecm medial axi annot nearest obstacl inform planar environ obstacl vertic ecm size comput log time also introduc multi layer environ mles multipl planar layer connect line segment connect typic real world exampl multi storey build train station sport stadium defin ecm multi layer environ base project distanc ground plane mle obstacl point connect size present improv algorithm construct ecm log log time implement show ecm comput effici larg multi layer environ use comput path within millisecond enabl simul larg virtual crowd heterogen charact real time|['Wouter van Toll', 'Atlas F. Cook IV', 'Marc J. van Kreveld', 'Roland Geraerts']|['cs.CG', 'cs.DS']
2017-03-28T14:07:47Z|2017-01-13T15:08:46Z|http://arxiv.org/abs/1701.03693v1|http://arxiv.org/pdf/1701.03693v1|Multivariate Analysis for Computing Maxima in High Dimensions|multivari analysi comput maxima high dimens|We study the problem of computing the \textsc{Maxima} of a set of $n$ $d$-dimensional points. For dimensions 2 and 3, there are algorithms to solve the problem with order-oblivious instance-optimal running time. However, in higher dimensions there is still room for improvements. We present an algorithm sensitive to the structural entropy of the input set, which improves the running time, for large classes of instances, on the best solution for \textsc{Maxima} to date for $d \ge 4$.|studi problem comput textsc maxima set dimension point dimens algorithm solv problem order oblivi instanc optim run time howev higher dimens still room improv present algorithm sensit structur entropi input set improv run time larg class instanc best solut textsc maxima date ge|['Jérémy Barbay', 'Javiel Rojas']|['cs.CG', 'cs.DS', 'F.2.2']
2017-03-28T14:07:47Z|2017-01-12T16:01:50Z|http://arxiv.org/abs/1701.03388v1|http://arxiv.org/pdf/1701.03388v1|Dynamic and Kinetic Conflict-Free Coloring of Intervals with Respect to   Points|dynam kinet conflict free color interv respect point|We introduce the dynamic conflict-free coloring problem for a set $S$ of intervals in $\mathbb{R}^1$ with respect to points, where the goal is to maintain a conflict-free coloring for $S$ under insertions and deletions. We investigate trade-offs between the number of colors used and the number of intervals that are recolored upon insertion or deletion of an interval. Our results include:   - a lower bound on the number of recolorings as a function of the number of colors, which implies that with $O(1)$ recolorings per update the worst-case number of colors is $\Omega(\log n/\log\log n)$, and that any strategy using $O(1/\varepsilon)$ colors needs $\Omega(\varepsilon n^{\varepsilon})$ recolorings;   - a coloring strategy that uses $O(\log n)$ colors at the cost of $O(\log n)$ recolorings, and another strategy that uses $O(1/\varepsilon)$ colors at the cost of $O(n^{\varepsilon}/\varepsilon)$ recolorings;   - stronger upper and lower bounds for special cases.   We also consider the kinetic setting where the intervals move continuously (but there are no insertions or deletions); here we show how to maintain a coloring with only four colors at the cost of three recolorings per event and show this is tight.|introduc dynam conflict free color problem set interv mathbb respect point goal maintain conflict free color insert delet investig trade number color use number interv recolor upon insert delet interv result includ lower bound number recolor function number color impli recolor per updat worst case number color omega log log log ani strategi use varepsilon color need omega varepsilon varepsilon recolor color strategi use log color cost log recolor anoth strategi use varepsilon color cost varepsilon varepsilon recolor stronger upper lower bound special case also consid kinet set interv move continu insert delet show maintain color onli four color cost three recolor per event show tight|['Mark de Berg', 'Tim Leijsen', 'André van Renssen', 'Marcel Roeloffzen', 'Aleksandar Markovic', 'Gerhard Woeginger']|['cs.CG']
2017-03-28T14:07:47Z|2017-01-12T04:51:15Z|http://arxiv.org/abs/1701.03230v1|http://arxiv.org/pdf/1701.03230v1|Surface Reconstruction with Data-driven Exemplar Priors|surfac reconstruct data driven exemplar prior|In this paper, we propose a framework to reconstruct 3D models from raw scanned points by learning the prior knowledge of a specific class of objects. Unlike previous work that heuristically specifies particular regularities and defines parametric models, our shape priors are learned directly from existing 3D models under a framework based on affinity propagation. Given a database of 3D models within the same class of objects, we build a comprehensive library of 3D local shape priors. We then formulate the problem to select as-few-as-possible priors from the library, referred to as exemplar priors. These priors are sufficient to represent the 3D shapes of the whole class of objects from where they are generated. By manipulating these priors, we are able to reconstruct geometrically faithful models with the same class of objects from raw point clouds. Our framework can be easily generalized to reconstruct various categories of 3D objects that have more geometrically or topologically complex structures. Comprehensive experiments exhibit the power of our exemplar priors for gracefully solving several problems in 3D shape reconstruction such as preserving sharp features, recovering fine details and so on.|paper propos framework reconstruct model raw scan point learn prior knowledg specif class object unlik previous work heurist specifi particular regular defin parametr model shape prior learn direct exist model framework base affin propag given databas model within class object build comprehens librari local shape prior formul problem select possibl prior librari refer exemplar prior prior suffici repres shape whole class object generat manipul prior abl reconstruct geometr faith model class object raw point cloud framework easili general reconstruct various categori object geometr topolog complex structur comprehens experi exhibit power exemplar prior grace solv sever problem shape reconstruct preserv sharp featur recov fine detail|['Oussama Remil', 'Qian Xie', 'Xingyu Xie', 'Kai Xu', 'Jun Wang']|['cs.CG', 'cs.GR']
2017-03-28T14:07:47Z|2017-01-11T04:04:43Z|http://arxiv.org/abs/1701.02843v1|http://arxiv.org/pdf/1701.02843v1|Solve Partial Differential Equations on Manifold From Incomplete   Inter-Point Distance|solv partial differenti equat manifold incomplet inter point distanc|Solutions of partial differential equations (PDEs) on manifolds have provided important applications in different fields in science and engineering. Existing methods are majorly based on discretization of manifolds as implicit functions, triangle meshes, or point clouds, where the manifold structure is approximated by either zero level set of an implicit function or a set of points. In many applications, manifolds might be only provided as an inter-point distance matrix with possible missing values. This paper discusses a framework to discretize PDEs on manifolds represented as incomplete distance information. Without conducting a time-consuming global coordinates reconstruction, we propose a more efficient strategy by discretizing differential operators only based on point-wisely local reconstruction. Our local reconstruction model is based on the recent advances of low-rank matrix completion theory, where only a very small random portion of distance information is required. This method enables us to conduct analyses of incomplete distance data using solutions of special designed PDEs such as the Laplace-Beltrami (LB) eigen-system. As an application, we demonstrate a new way of manifold reconstruction from an incomplete distance by stitching patches using the spectrum of the LB operator. Intensive numerical experiments demonstrate the effectiveness of the proposed methods.|solut partial differenti equat pdes manifold provid import applic differ field scienc engin exist method major base discret manifold implicit function triangl mesh point cloud manifold structur approxim either zero level set implicit function set point mani applic manifold might onli provid inter point distanc matrix possibl miss valu paper discuss framework discret pdes manifold repres incomplet distanc inform without conduct time consum global coordin reconstruct propos effici strategi discret differenti oper onli base point wise local reconstruct local reconstruct model base recent advanc low rank matrix complet theori onli veri small random portion distanc inform requir method enabl us conduct analys incomplet distanc data use solut special design pdes laplac beltrami lb eigen system applic demonstr new way manifold reconstruct incomplet distanc stitch patch use spectrum lb oper intens numer experi demonstr effect propos method|['Rongjie Lai', 'Jia Li']|['math.NA', 'cs.CG', '65D18, 65D25, 65N25']
2017-03-28T14:07:51Z|2017-01-09T16:17:10Z|http://arxiv.org/abs/1701.02229v1|http://arxiv.org/pdf/1701.02229v1|Searching edges in the overlap of two plane graphs|search edg overlap two plane graph|Consider a pair of plane straight-line graphs, whose edges are colored red and blue, respectively, and let n be the total complexity of both graphs. We present a O(n log n)-time O(n)-space technique to preprocess such pair of graphs, that enables efficient searches among the red-blue intersections along edges of one of the graphs. Our technique has a number of applications to geometric problems. This includes: (1) a solution to the batched red-blue search problem [Dehne et al. 2006] in O(n log n) queries to the oracle; (2) an algorithm to compute the maximum vertical distance between a pair of 3D polyhedral terrains one of which is convex in O(n log n) time, where n is the total complexity of both terrains; (3) an algorithm to construct the Hausdorff Voronoi diagram of a family of point clusters in the plane in O((n+m) log^3 n) time and O(n+m) space, where n is the total number of points in all clusters and m is the number of crossings between all clusters; (4) an algorithm to construct the farthest-color Voronoi diagram of the corners of n axis-aligned rectangles in O(n log^2 n) time; (5) an algorithm to solve the stabbing circle problem for n parallel line segments in the plane in optimal O(n log n) time. All these results are new or improve on the best known algorithms.|consid pair plane straight line graph whose edg color red blue respect let total complex graph present log time space techniqu preprocess pair graph enabl effici search among red blue intersect along edg one graph techniqu number applic geometr problem includ solut batch red blue search problem dehn et al log queri oracl algorithm comput maximum vertic distanc pair polyhedr terrain one convex log time total complex terrain algorithm construct hausdorff voronoi diagram famili point cluster plane log time space total number point cluster number cross cluster algorithm construct farthest color voronoi diagram corner axi align rectangl log time algorithm solv stab circl problem parallel line segment plane optim log time result new improv best known algorithm|['John Iacono', 'Elena Khramtcova', 'Stefan Langerman']|['cs.CG']
2017-03-28T14:07:51Z|2017-01-09T15:18:28Z|http://arxiv.org/abs/1701.02208v1|http://arxiv.org/pdf/1701.02208v1|Barcodes of Towers and a Streaming Algorithm for Persistent Homology|barcod tower stream algorithm persist homolog|A tower is a sequence of simplicial complexes connected by simplicial maps. We show how to compute a filtration, a sequence of nested simplicial complexes, with the same persistent barcode as the tower. Our approach is based on the coning strategy by Dey et al. (SoCG 2014). We show that a variant of this approach yields a filtration that is asymptotically only marginally larger than the tower and can be efficiently computed by a streaming algorithm, both in theory and in practice. Furthermore, we show that our approach can be combined with a streaming algorithm to compute the barcode of the tower via matrix reduction. The space complexity of the algorithm does not depend on the length of the tower, but the maximal size of any subcomplex within the tower.|tower sequenc simplici complex connect simplici map show comput filtrat sequenc nest simplici complex persist barcod tower approach base cone strategi dey et al socg show variant approach yield filtrat asymptot onli margin larger tower effici comput stream algorithm theori practic furthermor show approach combin stream algorithm comput barcod tower via matrix reduct space complex algorithm doe depend length tower maxim size ani subcomplex within tower|['Michael Kerber', 'Hannah Schreiber']|['math.AT', 'cs.CG']
2017-03-28T14:07:51Z|2017-02-22T20:40:08Z|http://arxiv.org/abs/1701.02200v2|http://arxiv.org/pdf/1701.02200v2|Bounding a global red-blue proportion using local conditions|bound global red blue proport use local condit|"We study the following local-to-global phenomenon: Let $B$ and $R$ be two finite sets of (blue and red) points in the Euclidean plane $\mathbb{R}^2$. Suppose that in each ""neighborhood"" of a red point, the number of blue points is at least as large as the number of red points. We show that in this case the total number of blue points is at least one fifth of the total number of red points. We also show that this bound is optimal and we generalize the result to arbitrary dimension and arbitrary norm using results from Minkowski arrangements."|studi follow local global phenomenon let two finit set blue red point euclidean plane mathbb suppos neighborhood red point number blue point least larg number red point show case total number blue point least one fifth total number red point also show bound optim general result arbitrari dimens arbitrari norm use result minkowski arrang|['Márton Naszódi', 'Leonardo Martínez Sandoval', 'Shakhar Smorodinsky']|['cs.CG']
2017-03-28T14:07:51Z|2017-01-05T12:00:37Z|http://arxiv.org/abs/1701.06430v1|http://arxiv.org/pdf/1701.06430v1|An Upper Bound of the Minimal Dispersion via Delta Covers|upper bound minim dispers via delta cover|For a point set of $n$ elements in the $d$-dimensional unit cube and a class of test sets we are interested in the largest volume of a test set which does not contain any point. For all natural numbers $n$, $d$ and under the assumption of a $delta$-cover with cardinality $\vert \Gamma_\delta \vert$ we prove that there is a point set, such that the largest volume of such a test set without any point is bounded by $\frac{\log \vert \Gamma_\delta \vert}{n} + \delta$. For axis-parallel boxes on the unit cube this leads to a volume of at most $\frac{4d}{n}\log(\frac{9n}{d})$ and on the torus to $\frac{4d}{n}\log (2n)$.|point set element dimension unit cube class test set interest largest volum test set doe contain ani point natur number assumpt delta cover cardin vert gamma delta vert prove point set largest volum test set without ani point bound frac log vert gamma delta vert delta axi parallel box unit cube lead volum frac log frac torus frac log|['Daniel Rudolf']|['cs.CG', 'math.NA', '52B55, 68Q25']
2017-03-28T14:07:51Z|2017-01-04T07:44:19Z|http://arxiv.org/abs/1701.00921v1|http://arxiv.org/pdf/1701.00921v1|Towards Faithful Graph Visualizations|toward faith graph visual|Readability criteria have been addressed as a measurement of the quality of graph visualizations. In this paper, we argue that readability criteria are necessary but not sufficient. We propose a new kind of criteria, namely faithfulness, to evaluate the quality of graph layouts. We introduce a general model for quantify faithfulness, and contrast it with the well established readability criteria. We show examples of common visualization techniques, such as multidimensional scaling, edge bundling and several other visualization metaphors for the study of faithfulness.|readabl criteria address measur qualiti graph visual paper argu readabl criteria necessari suffici propos new kind criteria name faith evalu qualiti graph layout introduc general model quantifi faith contrast well establish readabl criteria show exampl common visual techniqu multidimension scale edg bundl sever visual metaphor studi faith|['Quan Hoang Nguyen', 'Peter Eades', 'Seok-Hee Hong']|['cs.CG']
2017-03-28T14:07:51Z|2017-01-03T12:41:18Z|http://arxiv.org/abs/1701.00679v1|http://arxiv.org/pdf/1701.00679v1|Removing Depth-Order Cycles Among Triangles: An Efficient Algorithm   Generating Triangular Fragments|remov depth order cycl among triangl effici algorithm generat triangular fragment|We present an algorithm that cuts any collection of n disjoint triangles in R^3 into O(n^{7/4} polylog n) triangular fragments such that all cycles in the depth-order relation are eliminated. The running time of our algorithm is O(n^{3.69}). We also prove a refined bound, which depends on the number, K, of intersections between the projections of the triangle edges onto the xy-plane. More precisely, we show that O(n^{1+\eps} + n^{1/4} K^{3/4} polylog n) fragments suffice to eliminate all cycles. This result extends to xy-monotone surface patches bounded by a constant number of bounded-degree algebraic arcs in general position.|present algorithm cut ani collect disjoint triangl polylog triangular fragment cycl depth order relat elimin run time algorithm also prove refin bound depend number intersect project triangl edg onto xy plane precis show ep polylog fragment suffic elimin cycl result extend xy monoton surfac patch bound constant number bound degre algebra arc general posit|['Mark de Berg']|['cs.CG', 'F.2.2']
2017-03-28T14:07:51Z|2017-01-02T16:45:18Z|http://arxiv.org/abs/1701.00441v1|http://arxiv.org/pdf/1701.00441v1|Collecting a Swarm in a Grid Environment Using Shared, Global Inputs|collect swarm grid environ use share global input|This paper investigates efficient techniques to collect and concentrate an under-actuated particle swarm despite obstacles. Concentrating a swarm of particles is of critical importance in health-care for targeted drug delivery, where micro-scale particles must be steered to a goal location. Individual particles must be small in order to navigate through micro-vasculature, but decreasing size brings new challenges. Individual particles are too small to contain on-board power or computation and are instead controlled by a global input, such as an applied fluidic flow or electric field.   To make progress, this paper considers a swarm of robots initialized in a grid world in which each position is either free-space or obstacle. This paper provides algorithms that collect all the robots to one position and compares these algorithms on the basis of efficiency and implementation time.|paper investig effici techniqu collect concentr actuat particl swarm despit obstacl concentr swarm particl critic import health care target drug deliveri micro scale particl must steer goal locat individu particl must small order navig micro vasculatur decreas size bring new challeng individu particl small contain board power comput instead control global input appli fluidic flow electr field make progress paper consid swarm robot initi grid world posit either free space obstacl paper provid algorithm collect robot one posit compar algorithm basi effici implement time|['Arun V. Mahadev', 'Dominik Krupke', 'Jan-Marc Reinhardt', 'Sándor P. Fekete', 'Aaron T. Becker']|['cs.RO', 'cs.CG', 'I.2.11; F.2.2']
2017-03-28T14:07:51Z|2017-01-01T04:49:47Z|http://arxiv.org/abs/1701.00198v1|http://arxiv.org/abs/1701.00198v1|A robust approach for tree segmentation in deciduous forests using   small-footprint airborne LiDAR data|robust approach tree segment decidu forest use small footprint airborn lidar data|This paper presents a non-parametric approach for segmenting trees from airborne LiDAR data in deciduous forests. Based on the LiDAR point cloud, the approach collects crown information such as steepness and height on-the-fly to delineate crown boundaries, and most importantly, does not require a priori assumptions of crown shape and size. The approach segments trees iteratively starting from the tallest within a given area to the smallest until all trees have been segmented. To evaluate its performance, the approach was applied to the University of Kentucky Robinson Forest, a deciduous closed-canopy forest with complex terrain and vegetation conditions. The approach identified 94% of dominant and co-dominant trees with a false detection rate of 13%. About 62% of intermediate, overtopped, and dead trees were also detected with a false detection rate of 15%. The overall segmentation accuracy was 77%. Correlations of the segmentation scores of the proposed approach with local terrain and stand metrics was not significant, which is likely an indication of the robustness of the approach as results are not sensitive to the differences in terrain and stand structures.|paper present non parametr approach segment tree airborn lidar data decidu forest base lidar point cloud approach collect crown inform steep height fli delin crown boundari import doe requir priori assumpt crown shape size approach segment tree iter start tallest within given area smallest tree segment evalu perform approach appli univers kentucki robinson forest decidu close canopi forest complex terrain veget condit approach identifi domin co domin tree fals detect rate intermedi overtop dead tree also detect fals detect rate overal segment accuraci correl segment score propos approach local terrain stand metric signific like indic robust approach result sensit differ terrain stand structur|['Hamid Hamraz', 'Marco A. Contreras', 'Jun Zhang']|['cs.CV', 'cs.CE', 'cs.CG']
2017-03-28T14:07:51Z|2016-12-31T21:53:09Z|http://arxiv.org/abs/1701.00169v1|http://arxiv.org/pdf/1701.00169v1|Tree segmentation in multi-story stands within small-footprint airborne   LiDAR data|tree segment multi stori stand within small footprint airborn lidar data|Airborne LiDAR point cloud of a forest contains three dimensional data, from which vertical stand structure (including information about under-story trees) can be derived. This paper presents a segmentation approach for multi-story stands that strips the point cloud to its canopy layers, identifies individual tree segments within each layer using a DSM-based tree identification method as a building block, and combines the segments of immediate layers in order to fix potential over-segmentation of tree crowns across the layers. We introduce local layering that analyzes the vertical distributions of LiDAR points within their local neighborhoods in order to locally determine the height thresholds for layering the canopy. Unlike the previous work that stripped stiff layers within constrained areas, the local layering method strips flexible (in thickness and elevation) and narrower canopy layers within unconstrained areas. Statistical analyses showed that layering in general strongly improves identifying (specifically under-story) trees for the cost of moderately increasing over-segmentation rate of the identified trees. Combining tree segments across the immediate layers did not seem to improve tree identification accuracy remarkably, suggesting that layers separated canopy layers rather precisely.|airborn lidar point cloud forest contain three dimension data vertic stand structur includ inform stori tree deriv paper present segment approach multi stori stand strip point cloud canopi layer identifi individu tree segment within layer use dsm base tree identif method build block combin segment immedi layer order fix potenti segment tree crown across layer introduc local layer analyz vertic distribut lidar point within local neighborhood order local determin height threshold layer canopi unlik previous work strip stiff layer within constrain area local layer method strip flexibl thick elev narrow canopi layer within unconstrain area statist analys show layer general strong improv identifi specif stori tree cost moder increas segment rate identifi tree combin tree segment across immedi layer seem improv tree identif accuraci remark suggest layer separ canopi layer rather precis|['Hamid Hamraz', 'Marco A. Contreras', 'Jun Zhang']|['cs.CV', 'cs.CE', 'cs.CG']
2017-03-28T14:07:51Z|2016-12-31T17:05:53Z|http://arxiv.org/abs/1701.00146v1|http://arxiv.org/pdf/1701.00146v1|Even $1 \times n$ Edge-Matching and Jigsaw Puzzles are Really Hard|even time edg match jigsaw puzzl realli hard|We prove the computational intractability of rotating and placing $n$ square tiles into a $1 \times n$ array such that adjacent tiles are compatible--either equal edge colors, as in edge-matching puzzles, or matching tab/pocket shapes, as in jigsaw puzzles. Beyond basic NP-hardness, we prove that it is NP-hard even to approximately maximize the number of placed tiles (allowing blanks), while satisfying the compatibility constraint between nonblank tiles, within a factor of 0.9999999851. (On the other hand, there is an easy $1 \over 2$-approximation.) This is the first (correct) proof of inapproximability for edge-matching and jigsaw puzzles. Along the way, we prove NP-hardness of distinguishing, for a directed graph on $n$ nodes, between having a Hamiltonian path (length $n-1$) and having at most $0.999999284 (n-1)$ edges that form a vertex-disjoint union of paths. We use this gap hardness and gap-preserving reductions to establish similar gap hardness for $1 \times n$ jigsaw and edge-matching puzzles.|prove comput intract rotat place squar tile time array adjac tile compat either equal edg color edg match puzzl match tab pocket shape jigsaw puzzl beyond basic np hard prove np hard even approxim maxim number place tile allow blank satisfi compat constraint nonblank tile within factor hand easi approxim first correct proof inapproxim edg match jigsaw puzzl along way prove np hard distinguish direct graph node hamiltonian path length edg form vertex disjoint union path use gap hard gap preserv reduct establish similar gap hard time jigsaw edg match puzzl|['Jeffrey Bosboom', 'Erik D. Demaine', 'Martin L. Demaine', 'Adam Hesterberg', 'Pasin Manurangsi', 'Anak Yodpinyanee']|['cs.CC', 'cs.CG']
2017-03-28T14:07:55Z|2016-12-30T09:33:07Z|http://arxiv.org/abs/1612.09434v1|http://arxiv.org/pdf/1612.09434v1|Data driven estimation of Laplace-Beltrami operator|data driven estim laplac beltrami oper|Approximations of Laplace-Beltrami operators on manifolds through graph Lapla-cians have become popular tools in data analysis and machine learning. These discretized operators usually depend on bandwidth parameters whose tuning remains a theoretical and practical problem. In this paper, we address this problem for the unnormalized graph Laplacian by establishing an oracle inequality that opens the door to a well-founded data-driven procedure for the bandwidth selection. Our approach relies on recent results by Lacour and Massart [LM15] on the so-called Lepski's method.|approxim laplac beltrami oper manifold graph lapla cian becom popular tool data analysi machin learn discret oper usual depend bandwidth paramet whose tune remain theoret practic problem paper address problem unnorm graph laplacian establish oracl inequ open door well found data driven procedur bandwidth select approach reli recent result lacour massart lm call lepski method|['Frédéric Chazal', 'Ilaria Giulini', 'Bertrand Michel']|['cs.CG', 'cs.LG', 'math.ST', 'stat.TH']
2017-03-28T14:07:55Z|2017-01-02T14:15:21Z|http://arxiv.org/abs/1612.09277v2|http://arxiv.org/pdf/1612.09277v2|On Planar Greedy Drawings of 3-Connected Planar Graphs|planar greedi draw connect planar graph|"A graph drawing is $\textit{greedy}$ if, for every ordered pair of vertices $(x,y)$, there is a path from $x$ to $y$ such that the Euclidean distance to $y$ decreases monotonically at every vertex of the path. Greedy drawings support a simple geometric routing scheme, in which any node that has to send a packet to a destination ""greedily"" forwards the packet to any neighbor that is closer to the destination than itself, according to the Euclidean distance in the drawing. In a greedy drawing such a neighbor always exists and hence this routing scheme is guaranteed to succeed.   In 2004 Papadimitriou and Ratajczak stated two conjectures related to greedy drawings. The $\textit{greedy embedding conjecture}$ states that every $3$-connected planar graph admits a greedy drawing. The $\textit{convex greedy embedding conjecture}$ asserts that every $3$-connected planar graph admits a planar greedy drawing in which the faces are delimited by convex polygons. In 2008 the greedy embedding conjecture was settled in the positive by Leighton and Moitra.   In this paper we prove that every $3$-connected planar graph admits a $\textit{planar}$ greedy drawing. Apart from being a strengthening of Leighton and Moitra's result, this theorem constitutes a natural intermediate step towards a proof of the convex greedy embedding conjecture."|graph draw textit greedi everi order pair vertic path euclidean distanc decreas monoton everi vertex path greedi draw support simpl geometr rout scheme ani node send packet destin greedili forward packet ani neighbor closer destin accord euclidean distanc draw greedi draw neighbor alway exist henc rout scheme guarante succeed papadimitriou ratajczak state two conjectur relat greedi draw textit greedi embed conjectur state everi connect planar graph admit greedi draw textit convex greedi embed conjectur assert everi connect planar graph admit planar greedi draw face delimit convex polygon greedi embed conjectur settl posit leighton moitra paper prove everi connect planar graph admit textit planar greedi draw apart strengthen leighton moitra result theorem constitut natur intermedi step toward proof convex greedi embed conjectur|"['Giordano Da Lozzo', ""Anthony D'Angelo"", 'Fabrizio Frati']"|['cs.CG']
2017-03-28T14:07:55Z|2016-12-24T09:00:37Z|http://arxiv.org/abs/1612.08153v1|http://arxiv.org/pdf/1612.08153v1|EgoReID: Cross-view Self-Identification and Human Re-identification in   Egocentric and Surveillance Videos|egoreid cross view self identif human identif egocentr surveil video|Human identification remains to be one of the challenging tasks in computer vision community due to drastic changes in visual features across different viewpoints, lighting conditions, occlusion, etc. Most of the literature has been focused on exploring human re-identification across viewpoints that are not too drastically different in nature. Cameras usually capture oblique or side views of humans, leaving room for a lot of geometric and visual reasoning. Given the recent popularity of egocentric and top-view vision, re-identification across these two drastically different views can now be explored. Having an egocentric and a top view video, our goal is to identify the cameraman in the content of the top-view video, and also re-identify the people visible in the egocentric video, by matching them to the identities present in the top-view video. We propose a CRF-based method to address the two problems. Our experimental results demonstrates the efficiency of the proposed approach over a variety of video recorded from two views.|human identif remain one challeng task comput vision communiti due drastic chang visual featur across differ viewpoint light condit occlus etc literatur focus explor human identif across viewpoint drastic differ natur camera usual captur obliqu side view human leav room lot geometr visual reason given recent popular egocentr top view vision identif across two drastic differ view explor egocentr top view video goal identifi cameraman content top view video also identifi peopl visibl egocentr video match ident present top view video propos crf base method address two problem experiment result demonstr effici propos approach varieti video record two view|['Shervin Ardeshir', 'Sandesh Sharma', 'Ali Broji']|['cs.CV', 'cs.CG']
2017-03-28T14:07:55Z|2016-12-22T00:55:29Z|http://arxiv.org/abs/1612.07405v1|http://arxiv.org/pdf/1612.07405v1|Practical linear-space Approximate Near Neighbors in high dimension|practic linear space approxim near neighbor high dimens|The $c$-approximate Near Neighbor problem in high dimensional spaces has been mainly addressed by Locality Sensitive Hashing (LSH), which offers polynomial dependence on the dimension, query time sublinear in the size of the dataset, and subquadratic space requirement. For practical applications, linear space is typically imperative. Most previous work in the linear space regime focuses on the case that $c$ exceeds $1$ by a constant term. In a recently accepted paper, optimal bounds have been achieved for any $c>1$ \cite{ALRW17}.   Towards practicality, we present a new and simple data structure using linear space and sublinear query time for any $c>1$ including $c\to 1^+$. Given an LSH family of functions for some metric space, we randomly project points to the Hamming cube of dimension $\log n$, where $n$ is the number of input points. The projected space contains strings which serve as keys for buckets containing the input points. The query algorithm simply projects the query point, then examines points which are assigned to the same or nearby vertices on the Hamming cube. We analyze in detail the query time for some standard LSH families.   To illustrate our claim of practicality, we offer an open-source implementation in {\tt C++}, and report on several experiments in dimension up to 1000 and $n$ up to $10^6$. Our algorithm is one to two orders of magnitude faster than brute force search. Experiments confirm the sublinear dependence on $n$ and the linear dependence on the dimension. We have compared against state-of-the-art LSH-based library {\tt FALCONN}: our search is somewhat slower, but memory usage and preprocessing time are significantly smaller.|approxim near neighbor problem high dimension space main address local sensit hash lsh offer polynomi depend dimens queri time sublinear size dataset subquadrat space requir practic applic linear space typic imper previous work linear space regim focus case exceed constant term recent accept paper optim bound achiev ani cite alrw toward practic present new simpl data structur use linear space sublinear queri time ani includ given lsh famili function metric space random project point ham cube dimens log number input point project space contain string serv key bucket contain input point queri algorithm simpli project queri point examin point assign nearbi vertic ham cube analyz detail queri time standard lsh famili illustr claim practic offer open sourc implement tt report sever experi dimens algorithm one two order magnitud faster brute forc search experi confirm sublinear depend linear depend dimens compar state art lsh base librari tt falconn search somewhat slower memori usag preprocess time signific smaller|['Georgia Avarikioti', 'Ioannis Z. Emiris', 'Ioannis Psarros', 'Georgios Samaras']|['cs.CG']
2017-03-28T14:07:55Z|2016-12-21T18:58:17Z|http://arxiv.org/abs/1612.07276v1|http://arxiv.org/pdf/1612.07276v1|Splitting $B_2$-VPG graphs into outer-string and co-comparability graphs|split vpg graph outer string co compar graph|In this paper, we show that any $B_2$-VPG graph (i.e., an intersection graph of orthogonal curves with at most 2 bends) can be decomposed into $O(\log n)$ outerstring graphs or $O(\log^3 n)$ permutation graphs. This leads to better approximation algorithms for hereditary graph problems, such as independent set, clique and clique cover, on $B_2$-VPG graphs.|paper show ani vpg graph intersect graph orthogon curv bend decompos log outerstr graph log permut graph lead better approxim algorithm hereditari graph problem independ set cliqu cliqu cover vpg graph|['Martin Derka', 'Therese Biedl']|['cs.CG', 'cs.DS']
2017-03-28T14:07:55Z|2017-02-27T10:00:30Z|http://arxiv.org/abs/1701.00541v2|http://arxiv.org/pdf/1701.00541v2|Packing Unequal Circles into a Square Container by Partitioning Narrow   Action Spaces and Circle Items|pack unequ circl squar contain partit narrow action space circl item|We address the NP-hard problem of finding a non-overlapping dense packing pattern for n Unequal Circle items in a two-dimensional Square Container (PUC-SC) such that the size of the container is minimized. Based on our previous work on an Action Space based Global Optimization (ASGO) that approximates each circle item as a square item to efficiently find the large unoccupied spaces, we propose an optimization algorithm based on the Partitioned Action Space and Partitioned Circle Items (PAS-PCI). The PAS is to partition the narrow action space on the long side to find two equal action spaces to fully utilize the unoccupied spaces. The PCI is to partition the circle items into four groups based on size for the basin hopping strategy. Experiments on two sets of benchmark instances show the effectiveness of the proposed method. In comparison with our previous algorithm ASGO on the 68 tested instances that ASGO published, PAS-PCI not only gains smaller containers in 64 instances and matches the other 4 but also runs faster in most instances. In comparison with the best record of the Packomania website on a total of 98 instances, PAS-PCI finds smaller containers on 82 and matches the other 16. Note that we updated 19 records for (47-48, 51-54, 57, 61-72) that had been kept unchanged since 2013.|address np hard problem find non overlap dens pack pattern unequ circl item two dimension squar contain puc sc size contain minim base previous work action space base global optim asgo approxim circl item squar item effici find larg unoccupi space propos optim algorithm base partit action space partit circl item pas pci pas partit narrow action space long side find two equal action space fulli util unoccupi space pci partit circl item four group base size basin hop strategi experi two set benchmark instanc show effect propos method comparison previous algorithm asgo test instanc asgo publish pas pci onli gain smaller contain instanc match also run faster instanc comparison best record packomania websit total instanc pas pci find smaller contain match note updat record kept unchang sinc|['Kun He', 'Mohammed Dosh', 'Shenghao Zou']|['cs.CG', 'cs.DS', '52C26']
2017-03-28T14:07:55Z|2017-01-03T14:51:30Z|http://arxiv.org/abs/1612.06954v2|http://arxiv.org/pdf/1612.06954v2|Colored stochastic dominance problems|color stochast domin problem|In this paper, we study the dominance relation under a stochastic setting. Let $\mathcal{S}$ be a set of $n$ colored stochastic points in $\mathbb{R}^d$, each of which is associated with an existence probability. We investigate the problem of computing the probability that a realization of $\mathcal{S}$ contains inter-color dominances, which we call the \textit{colored stochastic dominance} (CSD) problem. We propose the first algorithm to solve the CSD problem for $d=2$ in $O(n^2 \log^2 n)$ time. On the other hand, we prove that, for $d \geq 3$, even the CSD problem with a restricted color pattern is #P-hard. In addition, even if the existence probabilities are restricted to be $\frac{1}{2}$, the problem remains #P-hard for $d \geq 7$. A simple FPRAS is then provided to approximate the desired probability in any dimension. We also study a variant of the CSD problem in which the dominance relation is considered with respect to not only the standard basis but any orthogonal basis of $\mathbb{R}^d$. Specifically, this variant, which we call the {\em free-basis colored stochastic dominance} (FBCSD) problem, considers the probability that a realization of $\mathcal{S}$ contains inter-color dominances with respect to any orthogonal basis of $\mathbb{R}^d$. We show that the CSD problem is polynomial-time reducible to the FBCSD problem in the same dimension, which proves the #P-hardness of the latter for $d \geq 3$. Conversely, we reduce the FBCSD problem in $\mathbb{R}^2$ to the CSD problem in $\mathbb{R}^2$, by which an $O(n^4 \log^2 n)$ time algorithm for the former is obtained.|paper studi domin relat stochast set let mathcal set color stochast point mathbb associ exist probabl investig problem comput probabl realize mathcal contain inter color domin call textit color stochast domin csd problem propos first algorithm solv csd problem log time hand prove geq even csd problem restrict color pattern hard addit even exist probabl restrict frac problem remain hard geq simpl fpras provid approxim desir probabl ani dimens also studi variant csd problem domin relat consid respect onli standard basi ani orthogon basi mathbb specif variant call em free basi color stochast domin fbcsd problem consid probabl realize mathcal contain inter color domin respect ani orthogon basi mathbb show csd problem polynomi time reduc fbcsd problem dimens prove hard latter geq convers reduc fbcsd problem mathbb csd problem mathbb log time algorithm former obtain|['Jie Xue', 'Yuan Li']|['cs.CG', 'F.2.2']
2017-03-28T14:07:55Z|2017-03-09T14:09:06Z|http://arxiv.org/abs/1612.05101v2|http://arxiv.org/pdf/1612.05101v2|Open problem on risk-aware planning in the plane|open problem risk awar plan plane|"We consider the problem of planning a collision-free path of a robot in the presence of risk zones. The robot is allowed to travel in these zones but is penalized in a super-linear fashion for consecutive accumulative time spent there. We recently suggested a natural cost function that balances path length and risk-exposure time. When no risk zones exists, our problem resorts to computing minimal-length paths which is known to be computationally hard in the number of dimensions. It is well known that in two-dimensions computing minimal-length paths can be done efficiently. Thus, a natural question we pose is ""Is our problem computationally hard or not?"" If the problem is hard, we wish to find an approximation algorithm to compute a near-optimal path. If not, then a polynomial-time algorithm should be found."|consid problem plan collis free path robot presenc risk zone robot allow travel zone penal super linear fashion consecut accumul time spent recent suggest natur cost function balanc path length risk exposur time risk zone exist problem resort comput minim length path known comput hard number dimens well known two dimens comput minim length path done effici thus natur question pose problem comput hard problem hard wish find approxim algorithm comput near optim path polynomi time algorithm found|['Oren Salzman', 'Siddhartha Srinivasa']|['cs.CG']
2017-03-28T14:07:55Z|2016-12-15T00:17:43Z|http://arxiv.org/abs/1612.04890v1|http://arxiv.org/pdf/1612.04890v1|Stochastic closest-pair problem and most-likely nearest-neighbor search   in tree spaces|stochast closest pair problem like nearest neighbor search tree space|Let $T$ be a tree space (or tree network) represented by a weighted tree with $t$ vertices, and $S$ be a set of $n$ stochastic points in $T$, each of which has a fixed location with an independent existence probability. We investigate two fundamental problems under such a stochastic setting, the closest-pair problem and the nearest-neighbor search. For the former, we study the computation of the $\ell$-threshold probability and the expectation of the closest-pair distance of a realization of $S$. We propose the first algorithm to compute the $\ell$-threshold probability in $O(t+n\log n+ \min\{tn,n^2\})$ time for any given threshold $\ell$, which immediately results in an $O(t+\min\{tn^3,n^4\})$-time algorithm for computing the expected closest-pair distance. Based on this, we further show that one can compute a $(1+\varepsilon)$-approximation for the expected closest-pair distance in $O(t+\varepsilon^{-1}\min\{tn^2,n^3\})$ time, by arguing that the expected closest-pair distance can be approximated via $O(\varepsilon^{-1}n)$ threshold probability queries. For the latter, we study the $k$ most-likely nearest-neighbor search ($k$-LNN) via a notion called $k$ most-likely Voronoi Diagram ($k$-LVD). We show that the size of the $k$-LVD $\varPsi_T^S$ of $S$ on $T$ is bounded by $O(kn)$ if the existence probabilities of the points in $S$ are constant-far from 0. Furthermore, we establish an $O(kn)$ average-case upper bound for the size of $\varPsi_T^S$, by regarding the existence probabilities as i.i.d. random variables drawn from some fixed distribution. Our results imply the existence of an LVD data structure which answers $k$-LNN queries in $O(\log n+k)$ time using average-case $O(t+k^2n)$ space, and worst-case $O(t+kn^2)$ space if the existence probabilities are constant-far from 0. Finally, we also give an $O(t+ n^2\log n+n^2k)$-time algorithm to construct the LVD data structure.|let tree space tree network repres weight tree vertic set stochast point fix locat independ exist probabl investig two fundament problem stochast set closest pair problem nearest neighbor search former studi comput ell threshold probabl expect closest pair distanc realize propos first algorithm comput ell threshold probabl log min tn time ani given threshold ell immedi result min tn time algorithm comput expect closest pair distanc base show one comput varepsilon approxim expect closest pair distanc varepsilon min tn time argu expect closest pair distanc approxim via varepsilon threshold probabl queri latter studi like nearest neighbor search lnn via notion call like voronoi diagram lvd show size lvd varpsi bound kn exist probabl point constant far furthermor establish kn averag case upper bound size varpsi regard exist probabl random variabl drawn fix distribut result impli exist lvd data structur answer lnn queri log time use averag case space worst case kn space exist probabl constant far final also give log time algorithm construct lvd data structur|['Jie Xue', 'Yuan Li']|['cs.CG', 'F.2.2']
2017-03-28T14:07:55Z|2016-12-14T19:33:00Z|http://arxiv.org/abs/1612.04780v1|http://arxiv.org/pdf/1612.04780v1|Minimum Weight Connectivity Augmentation for Planar Straight-Line Graphs|minimum weight connect augment planar straight line graph|We consider edge insertion and deletion operations that increase the connectivity of a given planar straight-line graph (PSLG), while minimizing the total edge length of the output. We show that every connected PSLG $G=(V,E)$ in general position can be augmented to a 2-connected PSLG $(V,E\cup E^+)$ by adding new edges of total Euclidean length $\ E^+\ \leq 2\ E\ $, and this bound is the best possible. An optimal edge set $E^+$ can be computed in $O( V ^4)$ time; however the problem becomes NP-hard when $G$ is disconnected. Further, there is a sequence of edge insertions and deletions that transforms a connected PSLG $G=(V,E)$ into a planar straight-line cycle $G'=(V,E')$ such that $\ E'\ \leq 2\ {\rm MST}(V)\ $, and the graph remains connected with edge length below $\ E\ +\ {\rm MST}(V)\ $ at all stages. These bounds are the best possible.|consid edg insert delet oper increas connect given planar straight line graph pslg minim total edg length output show everi connect pslg general posit augment connect pslg cup ad new edg total euclidean length leq bound best possibl optim edg set comput time howev problem becom np hard disconnect sequenc edg insert delet transform connect pslg planar straight line cycl leq rm mst graph remain connect edg length rm mst stage bound best possibl|['Hugo A. Akitaya', 'Rajasekhar Inkulu', 'Torrie L. Nichols', 'Diane L. Souvaine', 'Csaba D. Tóth', 'Charles R. Winston']|['cs.CG', '05C40, 05C85, 68R10', 'I.3.5']
2017-04-07T11:28:39Z|2017-04-06T02:02:25Z|http://arxiv.org/abs/1704.01687v1|http://arxiv.org/pdf/1704.01687v1|Computational determination of the largest lattice polytope diameter|comput determin largest lattic polytop diamet|A lattice (d, k)-polytope is the convex hull of a set of points in dimension d whose coordinates are integers between 0 and k. Let {\delta}(d, k) be the largest diameter over all lattice (d, k)-polytopes. We develop a computational framework to determine {\delta}(d, k) for small instances. We show that {\delta}(3, 4) = 7 and {\delta}(3, 5) = 9; that is, we verify for (d, k) = (3, 4) and (3, 5) the conjecture whereby {\delta}(d, k) is at most (k + 1)d/2 and is achieved, up to translation, by a Minkowski sum of lattice vectors.|lattic polytop convex hull set point dimens whose coordin integ let delta largest diamet lattic polytop develop comput framework determin delta small instanc show delta delta verifi conjectur wherebi delta achiev translat minkowski sum lattic vector|['Nathan Chadder', 'Antoine Deza']|['cs.CG', '52C, 90C']
2017-04-07T11:28:39Z|2017-04-03T16:51:44Z|http://arxiv.org/abs/1704.00683v1|http://arxiv.org/abs/1704.00683v1|Big Holes in Big Data: A Monte Carlo Algorithm for Detecting Large   Hyper-rectangles in High Dimensional Data|big hole big data mont carlo algorithm detect larg hyper rectangl high dimension data|We present the first algorithm for finding holes in high dimensional data that runs in polynomial time with respect to the number of dimensions. Previous algorithms are exponential. Finding large empty rectangles or boxes in a set of points in 2D and 3D space has been well studied. Efficient algorithms exist to identify the empty regions in these low-dimensional spaces. Unfortunately such efficiency is lacking in higher dimensions where the problem has been shown to be NP-complete when the dimensions are included in the input. Applications for algorithms that find large empty spaces include big data analysis, recommender systems, automated knowledge discovery, and query optimization. Our Monte Carlo-based algorithm discovers interesting maximal empty hyper-rectangles in cases where dimensionality and input size would otherwise make analysis impractical. The run-time is polynomial in the size of the input and the number of dimensions. We apply the algorithm on a 39-dimensional data set for protein structures and discover interesting properties that we think could not be inferred otherwise.|present first algorithm find hole high dimension data run polynomi time respect number dimens previous algorithm exponenti find larg empti rectangl box set point space well studi effici algorithm exist identifi empti region low dimension space unfortun effici lack higher dimens problem shown np complet dimens includ input applic algorithm find larg empti space includ big data analysi recommend system autom knowledg discoveri queri optim mont carlo base algorithm discov interest maxim empti hyper rectangl case dimension input size would otherwis make analysi impract run time polynomi size input number dimens appli algorithm dimension data set protein structur discov interest properti think could infer otherwis|['Joseph Lemley', 'Filip Jagodzinski', 'Razvan Andonie']|['cs.CG', 'physics.data-an']
2017-04-07T11:28:39Z|2017-04-03T13:15:59Z|http://arxiv.org/abs/1704.00565v1|http://arxiv.org/pdf/1704.00565v1|Dynamic Planar Embeddings of Dynamic Graphs|dynam planar embed dynam graph|We present an algorithm to support the dynamic embedding in the plane of a dynamic graph. An edge can be inserted across a face between two vertices on the face boundary (we call such a vertex pair linkable), and edges can be deleted. The planar embedding can also be changed locally by flipping components that are connected to the rest of the graph by at most two vertices.   Given vertices $u,v$, linkable$(u,v)$ decides whether $u$ and $v$ are linkable in the current embedding, and if so, returns a list of suggestions for the placement of $(u,v)$ in the embedding. For non-linkable vertices $u,v$, we define a new query, one-flip-linkable$(u,v)$ providing a suggestion for a flip that will make them linkable if one exists. We support all updates and queries in O(log$^2 n$) time. Our time bounds match those of Italiano et al. for a static (flipless) embedding of a dynamic graph.   Our new algorithm is simpler, exploiting that the complement of a spanning tree of a connected plane graph is a spanning tree of the dual graph. The primal and dual trees are interpreted as having the same Euler tour, and a main idea of the new algorithm is an elegant interaction between top trees over the two trees via their common Euler tour.|present algorithm support dynam embed plane dynam graph edg insert across face two vertic face boundari call vertex pair linkabl edg delet planar embed also chang local flip compon connect rest graph two vertic given vertic linkabl decid whether linkabl current embed return list suggest placement embed non linkabl vertic defin new queri one flip linkabl provid suggest flip make linkabl one exist support updat queri log time time bound match italiano et al static flipless embed dynam graph new algorithm simpler exploit complement span tree connect plane graph span tree dual graph primal dual tree interpret euler tour main idea new algorithm eleg interact top tree two tree via common euler tour|['Jacob Holm', 'Eva Rotenberg']|['cs.DS', 'cs.CG']
2017-04-07T11:28:39Z|2017-04-02T14:01:53Z|http://arxiv.org/abs/1704.00300v1|http://arxiv.org/pdf/1704.00300v1|On van Kampen-Flores, Conway-Gordon-Sachs and Radon theorems|van kampen flore conway gordon sach radon theorem|We exhibit relations between van Kampen-Flores, Conway-Gordon-Sachs and Radon theorems, by presenting direct proofs of some implications between them. The key idea is an interesting relation between the van Kampen and the Conway-Gordon-Sachs numbers for restrictions of a map of $(d+2)$-simplex to $\mathbb R^d$ to the $(d+1)$-face and to the $[d/2]$-skeleton.|exhibit relat van kampen flore conway gordon sach radon theorem present direct proof implic key idea interest relat van kampen conway gordon sach number restrict map simplex mathbb face skeleton|['A. Skopenkov']|['math.GT', 'cs.CG', 'math.AT', '52A35, 55S91, 57Q35']
2017-04-07T11:28:39Z|2017-04-01T21:00:43Z|http://arxiv.org/abs/1704.00229v1|http://arxiv.org/pdf/1704.00229v1|Dense point sets with many halving lines|dens point set mani halv line|We construct a dense point set of $n$ points in the plane with $ne^{\Omega\left({\sqrt{\log n}}\right)}$ halving lines. This improves the bound $O(n\log n)$ of Edelsbrunner, Valtr and Welzl from 1997. We also observe that the upper bound on the maximum number of halving lines of dense point set can be improved to $O(n^{7/6})$.   Our construction can be generalized to higher dimensions, for any $d$ we construct a dense point set of $n$ points in $\mathbb{R}^d$ with $n^{d-1}e^{\Omega\left({\sqrt{\log n}}\right)}$ halving hyperplanes. Our lower bounds are asymptotically the same as the best known lower bounds for general point sets.|construct dens point set point plane ne omega left sqrt log right halv line improv bound log edelsbrunn valtr welzl also observ upper bound maximum number halv line dens point set improv construct general higher dimens ani construct dens point set point mathbb omega left sqrt log right halv hyperplan lower bound asymptot best known lower bound general point set|['István Kovács', 'Géza Tóth']|['math.CO', 'cs.CG']
2017-04-07T11:28:39Z|2017-04-01T09:05:32Z|http://arxiv.org/abs/1704.00143v1|http://arxiv.org/pdf/1704.00143v1|Eliminating higher-multiplicity intersections in the metastable   dimension range|elimin higher multipl intersect metast dimens rang|The $r$-fold analogues of Whitney trick were `in the air' since 1960s. However, only in this century they were stated, proved and applied to obtain interesting results, most notably by Mabillard and Wagner. Here we prove and apply a version of the $r$-fold Whitney trick when general position $r$-tuple intersections have positive dimension.   Theorem. Assume that $D=D_1\sqcup\ldots\sqcup D_r$ is disjoint union of $k$-dimensional disks, $rd\ge (r+1)k+3$, and $f:D\to B^d$ a proper PL (smooth) map such that $f\partial D_1\cap\ldots\cap f\partial D_r=\emptyset$. If the map $$f^r:\partial(D_1\times\ldots\times D_r)\to (B^d)^r-\{(x,x,\ldots,x)\in(B^d)^r\  \ x\in B^d\}$$ extends to $D_1\times\ldots\times D_r$, then there is a proper PL (smooth) map $\overline f:D\to B^d$ such that $\overline f=f$ on $\partial D$ and $\overline fD_1\cap\ldots\cap \overline fD_r=\emptyset$.|fold analogu whitney trick air sinc howev onli centuri state prove appli obtain interest result notabl mabillard wagner prove appli version fold whitney trick general posit tupl intersect posit dimens theorem assum sqcup ldot sqcup disjoint union dimension disk rd ge proper pl smooth map partial cap ldot cap partial emptyset map partial time ldot time ldot extend time ldot time proper pl smooth map overlin overlin partial overlin fd cap ldot cap overlin fd emptyset|['Arkadiy Skopenkov']|['math.GT', 'cs.CG', '57Q35, 57R40, 55S91, 52A35, 57R12, 57R25, 57R65, 57R42']
2017-04-07T11:28:39Z|2017-04-01T08:45:58Z|http://arxiv.org/abs/1704.00142v1|http://arxiv.org/pdf/1704.00142v1|Arrangements of cellular complexes|arrang cellular complex|In this paper we introduce a novel algorithm to combine two or more cellular complexes, providing a minimal fragmentation of the cells of the resulting complex. This algorithm has several important applications, including Boolean operations over big geometric data, like the detailed geometric modeling of buildings, and the smooth combination of 3D meshes. The algorithm operates over the LAR representation of argument complexes, based on sparse matrices, so being well-suited for implementation on last generation accelerators and GPGPU applications.|paper introduc novel algorithm combin two cellular complex provid minim fragment cell result complex algorithm sever import applic includ boolean oper big geometr data like detail geometr model build smooth combin mesh algorithm oper lar represent argument complex base spars matric well suit implement last generat acceler gpgpu applic|['Alberto Paoluzzi', 'Vadim Shapiro', 'Antonio DiCarlo']|['cs.CG']
2017-04-07T11:28:39Z|2017-03-31T16:40:16Z|http://arxiv.org/abs/1703.10976v1|http://arxiv.org/pdf/1703.10976v1|Approximate Minimum Diameter|approxim minimum diamet|We study the minimum diameter problem for a set of inexact points. By inexact, we mean that the precise location of the points is not known. Instead, the location of each point is restricted to a contineus region ($\impre$ model) or a finite set of points ($\indec$ model). Given a set of inexact points in one of $\impre$ or $\indec$ models, we wish to provide a lower-bound on the diameter of the real points.   In the first part of the paper, we focus on $\indec$ model. We present an $O(2^{\frac{1}{\epsilon^d}} \cdot \epsilon^{-2d} \cdot n^3 )$ time approximation algorithm of factor $(1+\epsilon)$ for finding minimum diameter of a set of points in $d$ dimensions. This improves the previously proposed algorithms for this problem substantially.   Next, we consider the problem in $\impre$ model. In $d$-dimensional space, we propose a polynomial time $\sqrt{d}$-approximation algorithm. In addition, for $d=2$, we define the notion of $\alpha$-separability and use our algorithm for $\indec$ model to obtain $(1+\epsilon)$-approximation algorithm for a set of $\alpha$-separable regions in time $O(2^{\frac{1}{\epsilon^2}}\allowbreak . \frac{n^3}{\epsilon^{10} .\sin(\alpha/2)^3} )$.|studi minimum diamet problem set inexact point inexact mean precis locat point known instead locat point restrict contineus region impr model finit set point indec model given set inexact point one impr indec model wish provid lower bound diamet real point first part paper focus indec model present frac epsilon cdot epsilon cdot time approxim algorithm factor epsilon find minimum diamet set point dimens improv previous propos algorithm problem substanti next consid problem impr model dimension space propos polynomi time sqrt approxim algorithm addit defin notion alpha separ use algorithm indec model obtain epsilon approxim algorithm set alpha separ region time frac epsilon allowbreak frac epsilon sin alpha|['Mohammad Ghodsi', 'Hamid Homapour', 'Masoud Seddighin']|['cs.CG']
2017-04-07T11:28:39Z|2017-03-31T11:54:29Z|http://arxiv.org/abs/1703.10868v1|http://arxiv.org/abs/1703.10868v1|Near-Optimal $\varepsilon$-Kernel Construction and Related Problems|near optim varepsilon kernel construct relat problem|The computation of (i) $\varepsilon$-kernels, (ii) approximate diameter, and (iii) approximate bichromatic closest pair are fundamental problems in geometric approximation. In this paper, we describe new algorithms that offer significant improvements to their running times. In each case the input is a set of $n$ points in $R^d$ for a constant dimension $d \geq 3$ and an approximation parameter $\varepsilon > 0$. We reduce the respective running times (i) from $O((n + 1/\varepsilon^{d-2})\log(1/\varepsilon))$ to $O(n \log(1/\varepsilon) + 1/\varepsilon^{(d-1)/2+\alpha})$, (ii) from $O((n + 1/\varepsilon^{d-2})\log(1/\varepsilon))$ to $O(n \log(1/\varepsilon) + 1/\varepsilon^{(d-1)/2+\alpha})$, and (iii) from $O(n / \varepsilon^{d/3})$ to $O(n / \varepsilon^{d/4+\alpha}),$ for an arbitrarily small constant $\alpha > 0$. Result (i) is nearly optimal since the size of the output $\varepsilon$-kernel is $\Theta(1/\varepsilon^{(d-1)/2})$ in the worst case.   These results are all based on an efficient decomposition of a convex body using a hierarchy of Macbeath regions, and contrast to previous solutions that decompose space using quadtrees and grids. By further application of these techniques, we also show that it is possible to obtain near-optimal preprocessing time for the most efficient data structures to approximately answer queries for (iv) nearest-neighbor searching, (v) directional width, and (vi) polytope membership.|comput varepsilon kernel ii approxim diamet iii approxim bichromat closest pair fundament problem geometr approxim paper describ new algorithm offer signific improv run time case input set point constant dimens geq approxim paramet varepsilon reduc respect run time varepsilon log varepsilon log varepsilon varepsilon alpha ii varepsilon log varepsilon log varepsilon varepsilon alpha iii varepsilon varepsilon alpha arbitrarili small constant alpha result near optim sinc size output varepsilon kernel theta varepsilon worst case result base effici decomposit convex bodi use hierarchi macbeath region contrast previous solut decompos space use quadtre grid applic techniqu also show possibl obtain near optim preprocess time effici data structur approxim answer queri iv nearest neighbor search direct width vi polytop membership|['Sunil Arya', 'Guilherme D. da Fonseca', 'David M. Mount']|['cs.CG', 'F.2.2']
2017-04-07T11:28:39Z|2017-03-28T12:16:50Z|http://arxiv.org/abs/1703.09533v1|http://arxiv.org/pdf/1703.09533v1|Routing in Polygons with Holes|rout polygon hole|Sending a message through an unknown network is a difficult problem. In this paper, we consider the case in which, during a preprocessing phase, we assign a label and a routing table to each node. The routing strategy must then decide where to send the package using only the label of the target node and the routing table of the node the message is currently at.   In this paper, we present the first routing scheme for the particular case in which the network is defined by the visibility graph of a polygon with $n$ vertices and $h$ holes. For any $\varepsilon > 0$ the routing scheme provides stretch at most $1+\varepsilon$. The labels have $O(\log n)$ bits and the corresponding routing tables are of size $O(\varepsilon^{-1}(h+1)\log n)$. The preprocessing time is $O(n^2\log n+(h+1)n^2+\varepsilon^{-1}(h+1)n)$ and can be improved to $O(n^2+\varepsilon^{-1}n)$ for simple polygons.|send messag unknown network difficult problem paper consid case dure preprocess phase assign label rout tabl node rout strategi must decid send packag use onli label target node rout tabl node messag current paper present first rout scheme particular case network defin visibl graph polygon vertic hole ani varepsilon rout scheme provid stretch varepsilon label log bit correspond rout tabl size varepsilon log preprocess time log varepsilon improv varepsilon simpl polygon|['Matias Korman', 'Wolfgang Mulzer', 'André van Renssen', 'Marcel Roeloffzen', 'Paul Seiferth', 'Yannik Stein', 'Birgit Vogtenhuber', 'Max Willert']|['cs.CG', 'cs.DS']
2017-04-07T11:28:43Z|2017-03-24T16:55:40Z|http://arxiv.org/abs/1703.08504v1|http://arxiv.org/pdf/1703.08504v1|Shingle 2.0: generalising self-consistent and automated domain   discretisation for multi-scale geophysical models|shingl generalis self consist autom domain discretis multi scale geophys model|The approaches taken to describe and develop spatial discretisations of the domains required for geophysical simulation models are commonly ad hoc, model or application specific and under-documented. This is particularly acute for simulation models that are flexible in their use of multi-scale, anisotropic, fully unstructured meshes where a relatively large number of heterogeneous parameters are required to constrain their full description. As a consequence, it can be difficult to reproduce simulations, ensure a provenance in model data handling and initialisation, and a challenge to conduct model intercomparisons rigorously. This paper takes a novel approach to spatial discretisation, considering it much like a numerical simulation model problem of its own. It introduces a generalised, extensible, self-documenting approach to carefully describe, and necessarily fully, the constraints over the heterogeneous parameter space that determine how a domain is spatially discretised. This additionally provides a method to accurately record these constraints, using high-level natural language based abstractions, that enables full accounts of provenance, sharing and distribution. Together with this description, a generalised consistent approach to unstructured mesh generation for geophysical models is developed, that is automated, robust and repeatable, quick-to-draft, rigorously verified and consistent to the source data throughout. This interprets the description above to execute a self-consistent spatial discretisation process, which is automatically validated to expected discrete characteristics and metrics.|approach taken describ develop spatial discretis domain requir geophys simul model common ad hoc model applic specif document particular acut simul model flexibl use multi scale anisotrop fulli unstructur mesh relat larg number heterogen paramet requir constrain full descript consequ difficult reproduc simul ensur proven model data handl initialis challeng conduct model intercomparison rigor paper take novel approach spatial discretis consid much like numer simul model problem introduc generalis extens self document approach care describ necessarili fulli constraint heterogen paramet space determin domain spatial discretis addit provid method accur record constraint use high level natur languag base abstract enabl full account proven share distribut togeth descript generalis consist approach unstructur mesh generat geophys model develop autom robust repeat quick draft rigor verifi consist sourc data throughout interpret descript abov execut self consist spatial discretis process automat valid expect discret characterist metric|['Adam S. Candy', 'Julie D. Pietrzak']|['physics.geo-ph', 'cs.CG', 'physics.ao-ph', 'physics.comp-ph', 'physics.flu-dyn']
2017-04-07T11:28:43Z|2017-03-24T16:27:52Z|http://arxiv.org/abs/1703.08491v1|http://arxiv.org/pdf/1703.08491v1|A consistent approach to unstructured mesh generation for geophysical   models|consist approach unstructur mesh generat geophys model|Geophysical model domains typically contain irregular, complex fractal-like boundaries and physical processes that act over a wide range of scales. Constructing geographically constrained boundary-conforming spatial discretizations of these domains with flexible use of anisotropically, fully unstructured meshes is a challenge. The problem contains a wide range of scales and a relatively large, heterogeneous constraint parameter space. Approaches are commonly ad hoc, model or application specific and insufficiently described. Development of new spatial domains is frequently time-consuming, hard to repeat, error prone and difficult to ensure consistent due to the significant human input required. As a consequence, it is difficult to reproduce simulations, ensure a provenance in model data handling and initialization, and a challenge to conduct model intercomparisons rigorously. Moreover, for flexible unstructured meshes, there is additionally a greater potential for inconsistencies in model initialization and forcing parameters. This paper introduces a consistent approach to unstructured mesh generation for geophysical models, that is automated, quick-to-draft and repeat, and provides a rigorous and robust approach that is consistent to the source data throughout. The approach is enabling further new research in complex multi-scale domains, difficult or not possible to achieve with existing methods. Examples being actively pursued in a range of geophysical modeling efforts are presented alongside the approach, together with the implementation library Shingle and a selection of its verification test cases.|geophys model domain typic contain irregular complex fractal like boundari physic process act wide rang scale construct geograph constrain boundari conform spatial discret domain flexibl use anisotrop fulli unstructur mesh challeng problem contain wide rang scale relat larg heterogen constraint paramet space approach common ad hoc model applic specif insuffici describ develop new spatial domain frequent time consum hard repeat error prone difficult ensur consist due signific human input requir consequ difficult reproduc simul ensur proven model data handl initi challeng conduct model intercomparison rigor moreov flexibl unstructur mesh addit greater potenti inconsist model initi forc paramet paper introduc consist approach unstructur mesh generat geophys model autom quick draft repeat provid rigor robust approach consist sourc data throughout approach enabl new research complex multi scale domain difficult possibl achiev exist method exampl activ pursu rang geophys model effort present alongsid approach togeth implement librari shingl select verif test case|['Adam S. Candy']|['physics.geo-ph', 'cs.CG', 'physics.ao-ph', 'physics.comp-ph', 'physics.flu-dyn']
2017-04-07T11:28:43Z|2017-03-21T18:50:24Z|http://arxiv.org/abs/1703.07387v1|http://arxiv.org/pdf/1703.07387v1|Topological Analysis of Nerves, Reeb Spaces, Mappers, and Multiscale   Mappers|topolog analysi nerv reeb space mapper multiscal mapper|"Data analysis often concerns not only the space where data come from, but also various types of maps attached to data. In recent years, several related structures have been used to study maps on data, including Reeb spaces, mappers and multiscale mappers. The construction of these structures also relies on the so-called \emph{nerve} of a cover of the domain.   In this paper, we aim to analyze the topological information encoded in these structures in order to provide better understanding of these structures and facilitate their practical usage.   More specifically, we show that the one-dimensional homology of the nerve complex $N(\mathcal{U})$ of a path-connected cover $\mathcal{U}$ of a domain $X$ cannot be richer than that of the domain $X$ itself. Intuitively, this result means that no new $H_1$-homology class can be ""created"" under a natural map from $X$ to the nerve complex $N(\mathcal{U})$. Equipping $X$ with a pseudometric $d$, we further refine this result and characterize the classes of $H_1(X)$ that may survive in the nerve complex using the notion of \emph{size} of the covering elements in $\mathcal{U}$. These fundamental results about nerve complexes then lead to an analysis of the $H_1$-homology of Reeb spaces, mappers and multiscale mappers.   The analysis of $H_1$-homology groups unfortunately does not extend to higher dimensions. Nevertheless, by using a map-induced metric, establishing a Gromov-Hausdorff convergence result between mappers and the domain, and interleaving relevant modules, we can still analyze the persistent homology groups of (multiscale) mappers to establish a connection to Reeb spaces."|data analysi often concern onli space data come also various type map attach data recent year sever relat structur use studi map data includ reeb space mapper multiscal mapper construct structur also reli call emph nerv cover domain paper aim analyz topolog inform encod structur order provid better understand structur facilit practic usag specif show one dimension homolog nerv complex mathcal path connect cover mathcal domain cannot richer domain intuit result mean new homolog class creat natur map nerv complex mathcal equip pseudometr refin result character class may surviv nerv complex use notion emph size cover element mathcal fundament result nerv complex lead analysi homolog reeb space mapper multiscal mapper analysi homolog group unfortun doe extend higher dimens nevertheless use map induc metric establish gromov hausdorff converg result mapper domain interleav relev modul still analyz persist homolog group multiscal mapper establish connect reeb space|['Tamal K. Dey', 'Facundo Memoli', 'Yusu Wang']|['cs.CG', 'math.AT']
2017-04-07T11:28:43Z|2017-03-23T15:17:23Z|http://arxiv.org/abs/1703.06983v2|http://arxiv.org/pdf/1703.06983v2|Collapsibility to a subcomplex of a given dimension is NP-complete|collaps subcomplex given dimens np complet|In this paper we extend the works of Tancer and of Malgouyres and Franc\'es, showing that $(d,k)$-collapsibility is NP-complete for $d\geq k+2$ except $(2,0)$. By $(d,k)$-collapsibility we mean the following problem: determine whether a given $d$-dimensional simplicial complex can be collapsed to some $k$-dimensional subcomplex. The question of establishing the complexity status of $(d,k)$-collapsibility was asked by Tancer, who proved NP-completeness of $(d,0)$ and $(d,1)$-collapsibility (for $d\geq 3$). Our extended result, together with the known polynomial-time algorithms for $(2,0)$ and $d=k+1$, answers the question completely.|paper extend work tancer malgouyr franc es show collaps np complet geq except collaps mean follow problem determin whether given dimension simplici complex collaps dimension subcomplex question establish complex status collaps ask tancer prove np complet collaps geq extend result togeth known polynomi time algorithm answer question complet|['Giovanni Paolini']|['cs.CG', 'cs.CC', 'math.GT']
2017-04-07T11:28:43Z|2017-03-19T22:13:17Z|http://arxiv.org/abs/1703.06526v1|http://arxiv.org/pdf/1703.06526v1|On Optimal 2- and 3-Planar Graphs|optim planar graph|"A graph is $k$-planar if it can be drawn in the plane such that no edge is crossed more than $k$ times. While for $k=1$, optimal $1$-planar graphs, i.e., those with $n$ vertices and exactly $4n-8$ edges, have been completely characterized, this has not been the case for $k \geq 2$. For $k=2,3$ and $4$, upper bounds on the edge density have been developed for the case of simple graphs by Pach and T\'oth, Pach et al. and Ackerman, which have been used to improve the well-known ""Crossing Lemma"". Recently, we proved that these bounds also apply to non-simple $2$- and $3$-planar graphs without homotopic parallel edges and self-loops.   In this paper, we completely characterize optimal $2$- and $3$-planar graphs, i.e., those that achieve the aforementioned upper bounds. We prove that they have a remarkably simple regular structure, although they might be non-simple. The new characterization allows us to develop notable insights concerning new inclusion relationships with other graph classes."|graph planar drawn plane edg cross time optim planar graph vertic exact edg complet character case geq upper bound edg densiti develop case simpl graph pach oth pach et al ackerman use improv well known cross lemma recent prove bound also appli non simpl planar graph without homotop parallel edg self loop paper complet character optim planar graph achiev aforement upper bound prove remark simpl regular structur although might non simpl new character allow us develop notabl insight concern new inclus relationship graph class|['Michael A. Bekos', 'Michael Kaufmann', 'Chrysanthi N. Raftopoulou']|['cs.CG', 'cs.DM']
2017-04-07T11:28:43Z|2017-03-19T18:48:06Z|http://arxiv.org/abs/1703.06487v1|http://arxiv.org/pdf/1703.06487v1|Anisotropic triangulations via discrete Riemannian Voronoi diagrams|anisotrop triangul via discret riemannian voronoi diagram|The construction of anisotropic triangulations is desirable for various applications, such as the numerical solving of partial differential equations and the representation of surfaces in graphics. To solve this notoriously difficult problem in a practical way, we introduce the discrete Riemannian Voronoi diagram, a discrete structure that approximates the Riemannian Voronoi diagram. This structure has been implemented and was shown to lead to good triangulations in $\mathbb{R}^2$ and on surfaces embedded in $\mathbb{R}^3$ as detailed in our experimental companion paper.   In this paper, we study theoretical aspects of our structure. Given a finite set of points $\cal P$ in a domain $\Omega$ equipped with a Riemannian metric, we compare the discrete Riemannian Voronoi diagram of $\cal P$ to its Riemannian Voronoi diagram. Both diagrams have dual structures called the discrete Riemannian Delaunay and the Riemannian Delaunay complex. We provide conditions that guarantee that these dual structures are identical. It then follows from previous results that the discrete Riemannian Delaunay complex can be embedded in $\Omega$ under sufficient conditions, leading to an anisotropic triangulation with curved simplices. Furthermore, we show that, under similar conditions, the simplices of this triangulation can be straightened.|construct anisotrop triangul desir various applic numer solv partial differenti equat represent surfac graphic solv notori difficult problem practic way introduc discret riemannian voronoi diagram discret structur approxim riemannian voronoi diagram structur implement shown lead good triangul mathbb surfac embed mathbb detail experiment companion paper paper studi theoret aspect structur given finit set point cal domain omega equip riemannian metric compar discret riemannian voronoi diagram cal riemannian voronoi diagram diagram dual structur call discret riemannian delaunay riemannian delaunay complex provid condit guarante dual structur ident follow previous result discret riemannian delaunay complex embed omega suffici condit lead anisotrop triangul curv simplic furthermor show similar condit simplic triangul straighten|['Jean-Daniel Boissonnat', 'Mael Rouxel-Labbé', 'Mathijs Wintraecken']|['cs.CG']
2017-04-07T11:28:43Z|2017-03-18T15:35:10Z|http://arxiv.org/abs/1703.06307v1|http://arxiv.org/pdf/1703.06307v1|Definition of geometric space around analytic fractal trees using   derivative coordinate funtions|definit geometr space around analyt fractal tree use deriv coordin funtion|The concept of derivative coordinate functions proved useful in the formulation of analytic fractal functions to represent smooth symmetric binary fractal trees [1]. In this paper we introduce a new geometry that defines the fractal space around these fractal trees. We present the canonical and degenerate form of this fractal space and extend the fractal geometrical space to R3 specifically and Rn by a recurrence relation. We also discuss the usage of such fractal geometry.|concept deriv coordin function prove use formul analyt fractal function repres smooth symmetr binari fractal tree paper introduc new geometri defin fractal space around fractal tree present canon degener form fractal space extend fractal geometr space specif rn recurr relat also discuss usag fractal geometri|['Henk Mulder']|['cs.CG']
2017-04-07T11:28:43Z|2017-03-18T14:58:57Z|http://arxiv.org/abs/1703.06305v1|http://arxiv.org/pdf/1703.06305v1|Hardness of almost embedding simplicial complexes in $\mathbb R^d$|hard almost embed simplici complex mathbb|A map $f\colon K\to \mathbb R^d$ of a simplicial complex is an almost embedding if $f(\sigma)\cap f(\tau)=\emptyset$ whenever $\sigma,\tau$ are disjoint simplices of $K$.   Theorem. Fix integers $d,k\ge2$ such that $d=\frac{3k}2+1$.   (a) Assume that $P\ne NP$. Then there exists a finite $k$-dimensional complex $K$ that does not admit an almost embedding in $\mathbb R^d$ but for which there exists an equivariant map $\tilde K\to S^{d-1}$.   (b) The algorithmic problem of recognition almost embeddability of finite $k$-dimensional complexes in $\mathbb R^d$ is NP hard.   The proof is based on the technique from the Matou\v{s}ek-Tancer-Wagner paper (proving an analogous result for embeddings), and on singular versions of the higher-dimensional Borromean rings lemma and a generalized van Kampen--Flores theorem.|map colon mathbb simplici complex almost embed sigma cap tau emptyset whenev sigma tau disjoint simplic theorem fix integ ge frac assum ne np exist finit dimension complex doe admit almost embed mathbb exist equivari map tild algorithm problem recognit almost embedd finit dimension complex mathbb np hard proof base techniqu matou ek tancer wagner paper prove analog result embed singular version higher dimension borromean ring lemma general van kampen flore theorem|['Arkadiy Skopenkov', 'Martin Tancer']|['math.GT', 'cs.CG']
2017-04-07T11:28:43Z|2017-03-17T17:13:58Z|http://arxiv.org/abs/1703.06107v1|http://arxiv.org/pdf/1703.06107v1|Self-approaching paths in simple polygons|self approach path simpl polygon|We study self-approaching paths that are contained in a simple polygon. A self-approaching path is a directed curve connecting two points such that the Euclidean distance between a point moving along the path and any future position does not increase, that is, for all points $a$, $b$, and $c$ that appear in that order along the curve, $ ac  \ge  bc $. We analyze the properties, and present a characterization of shortest self-approaching paths. In particular, we show that a shortest self-approaching path connecting two points inside a polygon can be forced to use a general class of non-algebraic curves. While this makes it difficult to design an exact algorithm, we show how to find a self-approaching path inside a polygon connecting two points under a model of computation which assumes that we can calculate involute curves of high order. Lastly, we provide an algorithm to test if a given simple polygon is self-approaching, that is, if there exists a self-approaching path for any two points inside the polygon.|studi self approach path contain simpl polygon self approach path direct curv connect two point euclidean distanc point move along path ani futur posit doe increas point appear order along curv ac ge bc analyz properti present character shortest self approach path particular show shortest self approach path connect two point insid polygon forc use general class non algebra curv make difficult design exact algorithm show find self approach path insid polygon connect two point model comput assum calcul involut curv high order last provid algorithm test given simpl polygon self approach exist self approach path ani two point insid polygon|['Prosenjit Bose', 'Irina Kostitsyna', 'Stefan Langerman']|['cs.CG']
2017-04-07T11:28:43Z|2017-03-17T01:31:12Z|http://arxiv.org/abs/1703.05863v1|http://arxiv.org/pdf/1703.05863v1|Packing Short Plane Spanning Graphs in Complete Geometric Graphs|pack short plane span graph complet geometr graph|Given a set of points in the plane, we want to establish a connection network between these points that consists of several disjoint layers. Motivated by sensor networks, we want that each layer is spanning and plane, and that no edge is very long (when compared to the minimum length needed to obtain a spanning graph).   We consider two different approaches: first we show an almost optimal centralized approach to extract two graphs. Then we show a constant factor approximation for a distributed model in which each point can compute its adjacencies using only local information. In both cases the obtained layers are plane|given set point plane want establish connect network point consist sever disjoint layer motiv sensor network want layer span plane edg veri long compar minimum length need obtain span graph consid two differ approach first show almost optim central approach extract two graph show constant factor approxim distribut model point comput adjac use onli local inform case obtain layer plane|['Oswin Aichholzer', 'Thomas Hackl', 'Matias Korman', 'Alexander Pilz', 'Günter Rote', 'André van Renssen', 'Marcel Roeloffzen', 'Birgit Vogtenhuber']|['cs.CG']
2017-04-07T11:28:47Z|2017-03-16T10:22:34Z|http://arxiv.org/abs/1703.05549v1|http://arxiv.org/pdf/1703.05549v1|Minimum Perimeter-Sum Partitions in the Plane|minimum perimet sum partit plane|Let $P$ be a set of $n$ points in the plane. We consider the problem of partitioning $P$ into two subsets $P_1$ and $P_2$ such that the sum of the perimeters of $\text{CH}(P_1)$ and $\text{CH}(P_2)$ is minimized, where $\text{CH}(P_i)$ denotes the convex hull of $P_i$. The problem was first studied by Mitchell and Wynters in 1991 who gave an $O(n^2)$ time algorithm. Despite considerable progress on related problems, no subquadratic time algorithm for this problem was found so far. We present an exact algorithm solving the problem in $O(n \log^4 n)$ time and a $(1+\varepsilon)$-approximation algorithm running in $O(n + 1/\varepsilon^2\cdot\log^4(1/\varepsilon))$ time.|let set point plane consid problem partit two subset sum perimet text ch text ch minim text ch denot convex hull problem first studi mitchel wynter gave time algorithm despit consider progress relat problem subquadrat time algorithm problem found far present exact algorithm solv problem log time varepsilon approxim algorithm run varepsilon cdot log varepsilon time|['Mikkel Abrahamsen', 'Mark de Berg', 'Kevin Buchin', 'Mehran Mehr', 'Ali D. Mehrabi']|['cs.CG']
2017-04-07T11:28:47Z|2017-03-19T22:20:57Z|http://arxiv.org/abs/1703.05475v2|http://arxiv.org/pdf/1703.05475v2|A quest to unravel the metric structure behind perturbed networks|quest unravel metric structur behind perturb network|"Graphs and network data are ubiquitous across a wide spectrum of scientific and application domains. Often in practice, an input graph can be considered as an observed snapshot of a (potentially continuous) hidden domain or process. Subsequent analysis, processing, and inferences are then performed on this observed graph. In this paper we advocate the perspective that an observed graph is often a noisy version of some discretized 1-skeleton of a hidden domain, and specifically we will consider the following natural network model: We assume that there is a true graph ${G^*}$ which is a certain proximity graph for points sampled from a hidden domain $\mathcal{X}$; while the observed graph $G$ is an Erd$\""{o}$s-R$\'{e}$nyi type perturbed version of ${G^*}$.   Our network model is related to, and slightly generalizes, the much-celebrated small-world network model originally proposed by Watts and Strogatz. However, the main question we aim to answer is orthogonal to the usual studies of network models (which often focuses on characterizing / predicting behaviors and properties of real-world networks). Specifically, we aim to recover the metric structure of ${G^*}$ (which reflects that of the hidden space $\mathcal{X}$ as we will show) from the observed graph $G$. Our main result is that a simple filtering process based on the \emph{Jaccard index} can recover this metric within a multiplicative factor of $2$ under our network model. Our work makes one step towards the general question of inferring structure of a hidden space from its observed noisy graph representation. In addition, our results also provide a theoretical understanding for Jaccard-Index-based denoising approaches."|graph network data ubiquit across wide spectrum scientif applic domain often practic input graph consid observ snapshot potenti continu hidden domain process subsequ analysi process infer perform observ graph paper advoc perspect observ graph often noisi version discret skeleton hidden domain specif consid follow natur network model assum true graph certain proxim graph point sampl hidden domain mathcal observ graph erd nyi type perturb version network model relat slight general much celebr small world network model origin propos watt strogatz howev main question aim answer orthogon usual studi network model often focus character predict behavior properti real world network specif aim recov metric structur reflect hidden space mathcal show observ graph main result simpl filter process base emph jaccard index recov metric within multipl factor network model work make one step toward general question infer structur hidden space observ noisi graph represent addit result also provid theoret understand jaccard index base denois approach|['Srinivasan Parthasarathy', 'David Sivakoff', 'Minghao Tian', 'Yusu Wang']|['cs.CG', 'F.2.2; G.2.2']
2017-04-07T11:28:47Z|2017-03-15T01:00:44Z|http://arxiv.org/abs/1703.04861v1|http://arxiv.org/pdf/1703.04861v1|Robust Non-Rigid Registration With Reweighted Dual Sparsities|robust non rigid registr reweight dual sparsiti|Non-rigid registration is challenging because it is ill-posed with high degrees of freedom and is thus sensitive to noise and outliers. We propose a robust non-rigid registration method using reweighted sparsities on position and transformation to estimate the deformations between 3-D shapes. We formulate the energy function with dual sparsities on both the data term and the smoothness term, and define the smoothness constraint using local rigidity. The dual-sparsity based non-rigid registration model is enhanced with a reweighting scheme, and solved by transferring the model into some alternating optimized subproblems which have exact solutions and guaranteed convergence. Experimental results on both public datasets and real scanned datasets show that our method outperforms the state-of-the-art methods and is more robust to noise and outliers than conventional non-rigid registration methods.|non rigid registr challeng becaus ill pose high degre freedom thus sensit nois outlier propos robust non rigid registr method use reweight sparsiti posit transform estim deform shape formul energi function dual sparsiti data term smooth term defin smooth constraint use local rigid dual sparsiti base non rigid registr model enhanc reweight scheme solv transfer model altern optim subproblem exact solut guarante converg experiment result public dataset real scan dataset show method outperform state art method robust nois outlier convent non rigid registr method|['Jingyu Yang', 'Kun Li', 'Yu-Kun Lai', 'Daoliang Guo']|['cs.CV', 'cs.CG', 'cs.GR']
2017-04-07T11:28:47Z|2017-03-14T22:19:50Z|http://arxiv.org/abs/1703.04774v1|http://arxiv.org/pdf/1703.04774v1|Self-Assembly of 4-sided Fractals in the Two-handed Tile Assembly Model|self assembl side fractal two hand tile assembl model|In this paper, we consider the strict self-assembly of fractals in one of the most well-studied models of tile based self-assembling systems known as the Two-handed Tile Assembly Model (2HAM). We are particularly interested in a class of fractals called discrete self-similar fractals (a class of fractals that includes the discrete Sierpinski's carpet). We present a 2HAM system that strictly self-assembles the discrete Sierpinski's carpet with scale factor 1. Moreover, the 2HAM system that we give lends itself to being generalized and we describe how this system can be modified to obtain a 2HAM system that strictly self-assembles one of any fractal from an infinite set of fractals which we call 4-sided fractals. The 2HAM systems we give in this paper are the first examples of systems that strictly self-assemble discrete self-similar fractals at scale factor 1 in a purely growth model of self-assembly. Finally, we give an example of a 3-sided fractal (which is not a tree fractal) that cannot be strictly self-assembled by any 2HAM system.|paper consid strict self assembl fractal one well studi model tile base self assembl system known two hand tile assembl model ham particular interest class fractal call discret self similar fractal class fractal includ discret sierpinski carpet present ham system strict self assembl discret sierpinski carpet scale factor moreov ham system give lend general describ system modifi obtain ham system strict self assembl one ani fractal infinit set fractal call side fractal ham system give paper first exampl system strict self assembl discret self similar fractal scale factor pure growth model self assembl final give exampl side fractal tree fractal cannot strict self assembl ani ham system|['Jacob Hendricks', 'Joseph Opseth']|['cs.ET', 'cs.CG']
2017-04-07T11:28:47Z|2017-03-14T22:13:58Z|http://arxiv.org/abs/1703.04758v1|http://arxiv.org/pdf/1703.04758v1|Approximation Schemes for Independent Set and Sparse Subsets of Polygons|approxim scheme independ set spars subset polygon|We present an $(1+\varepsilon)$-approximation algorithm with quasi-polynomial running time for computing the maximum weight independent set of polygons out of a given set of polygons in the plane (specifically, the running time is $n^{O( \mathrm{poly}( \log n, 1/\varepsilon))}$). Contrasting this, the best known polynomial time algorithm for the problem has an approximation ratio of~$n^{\varepsilon}$. Surprisingly, we can extend the algorithm to the problem of computing the maximum weight subset of the given set of polygons whose intersection graph fulfills some sparsity condition. For example, we show that one can approximate the maximum weight subset of polygons, such that the intersection graph of the subset is planar or does not contain a cycle of length $4$ (i.e., $K_{2,2}$). Our algorithm relies on a recursive partitioning scheme, whose backbone is the existence of balanced cuts with small complexity that intersect polygons from the optimal solution of a small total weight.   For the case of large axis-parallel rectangles, we provide a polynomial time $(1+\varepsilon)$-approximation for the maximum weight independent set. Specifically, we consider the problem where each rectangle has one edge whose length is at least a constant fraction of the length of the corresponding edge of the bounding box of all the input elements. This is now the most general case for which a PTAS is known, and it requires a new and involved partitioning scheme, which should be of independent interest.|present varepsilon approxim algorithm quasi polynomi run time comput maximum weight independ set polygon given set polygon plane specif run time mathrm poli log varepsilon contrast best known polynomi time algorithm problem approxim ratio varepsilon surpris extend algorithm problem comput maximum weight subset given set polygon whose intersect graph fulfil sparsiti condit exampl show one approxim maximum weight subset polygon intersect graph subset planar doe contain cycl length algorithm reli recurs partit scheme whose backbon exist balanc cut small complex intersect polygon optim solut small total weight case larg axi parallel rectangl provid polynomi time varepsilon approxim maximum weight independ set specif consid problem rectangl one edg whose length least constant fraction length correspond edg bound box input element general case ptas known requir new involv partit scheme independ interest|['Anna Adamaszek', 'Sariel Har-Peled', 'Andreas Wiese']|['cs.CG']
2017-04-07T11:28:47Z|2017-03-13T16:18:01Z|http://arxiv.org/abs/1703.04466v1|http://arxiv.org/pdf/1703.04466v1|Bicriteria Rectilinear Shortest Paths among Rectilinear Obstacles in the   Plane|bicriteria rectilinear shortest path among rectilinear obstacl plane|Given a rectilinear domain $\mathcal{P}$ of $h$ pairwise-disjoint rectilinear obstacles with a total of $n$ vertices in the plane, we study the problem of computing bicriteria rectilinear shortest paths between two points $s$ and $t$ in $\mathcal{P}$. Three types of bicriteria rectilinear paths are considered: minimum-link shortest paths, shortest minimum-link paths, and minimum-cost paths where the cost of a path is a non-decreasing function of both the number of edges and the length of the path. The one-point and two-point path queries are also considered. Algorithms for these problems have been given previously. Our contributions are threefold. First, we find a critical error in all previous algorithms. Second, we correct the error in a not-so-trivial way. Third, we further improve the algorithms so that they are even faster than the previous (incorrect) algorithms when $h$ is relatively small. For example, for the minimum-link shortest paths, we obtain the following results. Our algorithm computes a minimum-link shortest $s$-$t$ path in $O(n+h\log^{3/2} h)$ time. For the one-point queries, we build a data structure of size $O(n+ h\log h)$ in $O(n+h\log^{3/2} h)$ time for a source point $s$, such that given any query point $t$, a minimum-link shortest $s$-$t$ path can be determined in $O(\log n)$ time. For the two-point queries, with $O(n+h^2\log^2 h)$ time and space preprocessing, a minimum-link shortest $s$-$t$ path can be determined in $O(\log n+\log^2 h)$ time for any two query points $s$ and $t$; alternatively, with $O(n+h^2\cdot \log^{2} h \cdot 4^{\sqrt{\log h}})$ time and $O(n+h^2\cdot \log h \cdot 4^{\sqrt{\log h}})$ space preprocessing, we can answer each two-point query in $O(\log n)$ time.|given rectilinear domain mathcal pairwis disjoint rectilinear obstacl total vertic plane studi problem comput bicriteria rectilinear shortest path two point mathcal three type bicriteria rectilinear path consid minimum link shortest path shortest minimum link path minimum cost path cost path non decreas function number edg length path one point two point path queri also consid algorithm problem given previous contribut threefold first find critic error previous algorithm second correct error trivial way third improv algorithm even faster previous incorrect algorithm relat small exampl minimum link shortest path obtain follow result algorithm comput minimum link shortest path log time one point queri build data structur size log log time sourc point given ani queri point minimum link shortest path determin log time two point queri log time space preprocess minimum link shortest path determin log log time ani two queri point altern cdot log cdot sqrt log time cdot log cdot sqrt log space preprocess answer two point queri log time|['Haitao Wang']|['cs.CG', 'cs.DS']
2017-04-07T11:28:47Z|2017-03-13T11:00:53Z|http://arxiv.org/abs/1703.04329v1|http://arxiv.org/pdf/1703.04329v1|Stabbing segments with rectilinear objects|stab segment rectilinear object|Given a set $S$ of $n$ line segments in the plane, we say that a region $\mathcal{R}\subseteq \mathbb{R}^2$ is a {\em stabber} for $S$ if $\mathcal{R}$ contains exactly one endpoint of each segment of $S$. In this paper we provide optimal or near-optimal algorithms for reporting all combinatorially different stabbers for several shapes of stabbers. Specifically, we consider the case in which the stabber can be described as the intersection of axis-parallel halfplanes (thus the stabbers are halfplanes, strips, quadrants, $3$-sided rectangles, or rectangles). The running times are $O(n)$ (for the halfplane case), $O(n\log n)$ (for strips, quadrants, and 3-sided rectangles), and $O(n^2 \log n)$ (for rectangles).|given set line segment plane say region mathcal subseteq mathbb em stabber mathcal contain exact one endpoint segment paper provid optim near optim algorithm report combinatori differ stabber sever shape stabber specif consid case stabber describ intersect axi parallel halfplan thus stabber halfplan strip quadrant side rectangl rectangl run time halfplan case log strip quadrant side rectangl log rectangl|['Mercè Claverol', 'Delia Garijo', 'Matias Korman', 'Carlos Seara', 'Rodrigo I. Silveira']|['cs.CG']
2017-04-07T11:28:47Z|2017-03-13T08:00:31Z|http://arxiv.org/abs/1703.04283v1|http://arxiv.org/pdf/1703.04283v1|Universal Slope Sets for 1-Bend Planar Drawings|univers slope set bend planar draw|We describe a set of $\Delta -1$ slopes that are universal for 1-bend planar drawings of planar graphs of maximum degree $\Delta \geq 4$; this establishes a new upper bound of $\Delta-1$ on the 1-bend planar slope number. By universal we mean that every planar graph of degree $\Delta$ has a planar drawing with at most one bend per edge and such that the slopes of the segments forming the edges belong to the given set of slopes. This improves over previous results in two ways: Firstly, the best previously known upper bound for the 1-bend planar slope number was $\frac{3}{2} (\Delta -1)$ (the known lower bound being $\frac{3}{4} (\Delta -1)$); secondly, all the known algorithms to construct 1-bend planar drawings with $O(\Delta)$ slopes use a different set of slopes for each graph and can have bad angular resolution, while our algorithm uses a universal set of slopes, which also guarantees that the minimum angle between any two edges incident to a vertex is $\frac{\pi}{(\Delta-1)}$.|describ set delta slope univers bend planar draw planar graph maximum degre delta geq establish new upper bound delta bend planar slope number univers mean everi planar graph degre delta planar draw one bend per edg slope segment form edg belong given set slope improv previous result two way first best previous known upper bound bend planar slope number frac delta known lower bound frac delta second known algorithm construct bend planar draw delta slope use differ set slope graph bad angular resolut algorithm use univers set slope also guarante minimum angl ani two edg incid vertex frac pi delta|['Patrizio Angelini', 'Michael A. Bekos', 'Giuseppe Liotta', 'Fabrizio Montecchiani']|['cs.CG']
2017-04-07T11:28:47Z|2017-03-12T07:21:50Z|http://arxiv.org/abs/1703.04079v1|http://arxiv.org/pdf/1703.04079v1|SurfNet: Generating 3D shape surfaces using deep residual networks|surfnet generat shape surfac use deep residu network|3D shape models are naturally parameterized using vertices and faces, \ie, composed of polygons forming a surface. However, current 3D learning paradigms for predictive and generative tasks using convolutional neural networks focus on a voxelized representation of the object. Lifting convolution operators from the traditional 2D to 3D results in high computational overhead with little additional benefit as most of the geometry information is contained on the surface boundary. Here we study the problem of directly generating the 3D shape surface of rigid and non-rigid shapes using deep convolutional neural networks. We develop a procedure to create consistent `geometry images' representing the shape surface of a category of 3D objects. We then use this consistent representation for category-specific shape surface generation from a parametric representation or an image by developing novel extensions of deep residual networks for the task of geometry image generation. Our experiments indicate that our network learns a meaningful representation of shape surfaces allowing it to interpolate between shape orientations and poses, invent new shape surfaces and reconstruct 3D shape surfaces from previously unseen images.|shape model natur parameter use vertic face ie compos polygon form surfac howev current learn paradigm predict generat task use convolut neural network focus voxel represent object lift convolut oper tradit result high comput overhead littl addit benefit geometri inform contain surfac boundari studi problem direct generat shape surfac rigid non rigid shape use deep convolut neural network develop procedur creat consist geometri imag repres shape surfac categori object use consist represent categori specif shape surfac generat parametr represent imag develop novel extens deep residu network task geometri imag generat experi indic network learn meaning represent shape surfac allow interpol shape orient pose invent new shape surfac reconstruct shape surfac previous unseen imag|['Ayan Sinha', 'Asim Unmesh', 'Qixing Huang', 'Karthik Ramani']|['cs.CV', 'cs.CG']
2017-04-07T11:28:47Z|2017-03-11T23:16:23Z|http://arxiv.org/abs/1703.04040v1|http://arxiv.org/abs/1703.04040v1|Locality-sensitive hashing of curves|local sensit hash curv|We study data structures for storing a set of polygonal curves in ${\rm R}^d$ such that, given a query curve, we can efficiently retrieve similar curves from the set, where similarity is measured using the discrete Fr\'echet distance or the dynamic time warping distance. To this end we devise the first locality-sensitive hashing schemes for these distance measures. A major challenge is posed by the fact that these distance measures internally optimize the alignment between the curves. We give solutions for different types of alignments including constrained and unconstrained versions. For unconstrained alignments, we improve over a result by Indyk from 2002 for short curves. Let $n$ be the number of input curves and let $m$ be the maximum complexity of a curve in the input. In the particular case where $m \leq \frac{\alpha}{4d} \log n$, for some fixed $\alpha>0$, our solutions imply an approximate near-neighbor data structure for the discrete Fr\'echet distance that uses space in $O(n^{1+\alpha}\log n)$ and achieves query time in $O(n^{\alpha}\log^2 n)$ and constant approximation factor. Furthermore, our solutions provide a trade-off between approximation quality and computational performance: for any parameter $k \in [m]$, we can give a data structure that uses space in $O(2^{2k}m^{k-1} n \log n + nm)$, answers queries in $O( 2^{2k} m^{k}\log n)$ time and achieves approximation factor in $O(m/k)$.|studi data structur store set polygon curv rm given queri curv effici retriev similar curv set similar measur use discret fr echet distanc dynam time warp distanc end devis first local sensit hash scheme distanc measur major challeng pose fact distanc measur intern optim align curv give solut differ type align includ constrain unconstrain version unconstrain align improv result indyk short curv let number input curv let maximum complex curv input particular case leq frac alpha log fix alpha solut impli approxim near neighbor data structur discret fr echet distanc use space alpha log achiev queri time alpha log constant approxim factor furthermor solut provid trade approxim qualiti comput perform ani paramet give data structur use space log nm answer queri log time achiev approxim factor|['Anne Driemel', 'Francesco Silvestri']|['cs.CG', 'cs.DS', 'cs.IR', 'F.2.2']
2017-04-07T11:28:51Z|2017-03-10T13:54:29Z|http://arxiv.org/abs/1703.03687v1|http://arxiv.org/pdf/1703.03687v1|Best Laid Plans of Lions and Men|best laid plan lion men|"We answer the following question dating back to J.E. Littlewood (1885 - 1977): Can two lions catch a man in a bounded area with rectifiable lakes? The lions and the man are all assumed to be points moving with at most unit speed. That the lakes are rectifiable means that their boundaries are finitely long. This requirement is to avoid pathological examples where the man survives forever because any path to the lions is infinitely long. We show that the answer to the question is not always ""yes"" by giving an example of a region $R$ in the plane where the man has a strategy to survive forever. $R$ is a polygonal region with holes and the exterior and interior boundaries are pairwise disjoint, simple polygons. Our construction is the first truly two-dimensional example where the man can survive.   Next, we consider the following game played on the entire plane instead of a bounded area: There is any finite number of unit speed lions and one fast man who can run with speed $1+\varepsilon$ for some value $\varepsilon>0$. Can the man always survive? We answer the question in the affirmative for any constant $\varepsilon>0$."|answer follow question date back littlewood two lion catch man bound area rectifi lake lion man assum point move unit speed lake rectifi mean boundari finit long requir avoid patholog exampl man surviv forev becaus ani path lion infinit long show answer question alway yes give exampl region plane man strategi surviv forev polygon region hole exterior interior boundari pairwis disjoint simpl polygon construct first truli two dimension exampl man surviv next consid follow game play entir plane instead bound area ani finit number unit speed lion one fast man run speed varepsilon valu varepsilon man alway surviv answer question affirm ani constant varepsilon|['Mikkel Abrahamsen', 'Jacob Holm', 'Eva Rotenberg', 'Christian Wulff-Nilsen']|['cs.CG', 'cs.GT']
2017-04-07T11:28:51Z|2017-03-10T08:35:24Z|http://arxiv.org/abs/1703.03575v1|http://arxiv.org/pdf/1703.03575v1|Crossing the Logarithmic Barrier for Dynamic Boolean Data Structure   Lower Bounds|cross logarithm barrier dynam boolean data structur lower bound|"This paper proves the first super-logarithmic lower bounds on the cell probe complexity of dynamic boolean (a.k.a. decision) data structure problems, a long-standing milestone in data structure lower bounds.   We introduce a new method for proving dynamic cell probe lower bounds and use it to prove a $\tilde{\Omega}(\log^{1.5} n)$ lower bound on the operational time of a wide range of boolean data structure problems, most notably, on the query time of dynamic range counting over $\mathbb{F}_2$ ([Pat07]). Proving an $\omega(\lg n)$ lower bound for this problem was explicitly posed as one of five important open problems in the late Mihai P\v{a}tra\c{s}cu's obituary [Tho13]. This result also implies the first $\omega(\lg n)$ lower bound for the classical 2D range counting problem, one of the most fundamental data structure problems in computational geometry and spatial databases. We derive similar lower bounds for boolean versions of dynamic polynomial evaluation and 2D rectangle stabbing, and for the (non-boolean) problems of range selection and range median.   Our technical centerpiece is a new way of ""weakly"" simulating dynamic data structures using efficient one-way communication protocols with small advantage over random guessing. This simulation involves a surprising excursion to low-degree (Chebychev) polynomials which may be of independent interest, and offers an entirely new algorithmic angle on the ""cell sampling"" method of Panigrahy et al. [PTW10]."|paper prove first super logarithm lower bound cell probe complex dynam boolean decis data structur problem long stand mileston data structur lower bound introduc new method prove dynam cell probe lower bound use prove tild omega log lower bound oper time wide rang boolean data structur problem notabl queri time dynam rang count mathbb pat prove omega lg lower bound problem explicit pose one five import open problem late mihai tra cu obituari tho result also impli first omega lg lower bound classic rang count problem one fundament data structur problem comput geometri spatial databas deriv similar lower bound boolean version dynam polynomi evalu rectangl stab non boolean problem rang select rang median technic centerpiec new way weak simul dynam data structur use effici one way communic protocol small advantag random guess simul involv surpris excurs low degre chebychev polynomi may independ interest offer entir new algorithm angl cell sampl method panigrahi et al ptw|['Kasper Green Larsen', 'Omri Weinstein', 'Huacheng Yu']|['cs.DS', 'cs.CC', 'cs.CG', 'cs.IT', 'math.IT']
2017-04-07T11:28:51Z|2017-03-08T21:50:06Z|http://arxiv.org/abs/1703.03048v1|http://arxiv.org/pdf/1703.03048v1|Quickest Visibility Queries in Polygonal Domains|quickest visibl queri polygon domain|Let $s$ be a point in a polygonal domain $\mathcal{P}$ of $h-1$ holes and $n$ vertices. We consider a quickest visibility query problem. Given a query point $q$ in $\mathcal{P}$, the goal is to find a shortest path in $\mathcal{P}$ to move from $s$ to see $q$ as quickly as possible. Previously, Arkin et al. (SoCG 2015) built a data structure of size $O(n^22^{\alpha(n)}\log n)$ that can answer each query in $O(K\log^2 n)$ time, where $\alpha(n)$ is the inverse Ackermann function and $K$ is the size of the visibility polygon of $q$ in $\mathcal{P}$ (and $K$ can be $\Theta(n)$ in the worst case). In this paper, we present a new data structure of size $O(n\log h + h^2)$ that can answer each query in $O(h\log h\log n)$ time. Our result improves the previous work when $h$ is relatively small. In particular, if $h$ is a constant, then our result even matches the best result for the simple polygon case (i.e., $h=1$), which is optimal. As a by-product, we also have a new algorithm for a shortest-path-to-segment query problem. Given a query line segment $\tau$ in $\mathcal{P}$, the query seeks a shortest path from $s$ to all points of $\tau$. Previously, Arkin et al. gave a data structure of size $O(n^22^{\alpha(n)}\log n)$ that can answer each query in $O(\log^2 n)$ time, and another data structure of size $O(n^3\log n)$ with $O(\log n)$ query time. We present a data structure of size $O(n)$ with query time $O(h\log \frac{n}{h})$, which also favors small values of $h$ and is optimal when $h=O(1)$.|let point polygon domain mathcal hole vertic consid quickest visibl queri problem given queri point mathcal goal find shortest path mathcal move see quick possibl previous arkin et al socg built data structur size alpha log answer queri log time alpha invers ackermann function size visibl polygon mathcal theta worst case paper present new data structur size log answer queri log log time result improv previous work relat small particular constant result even match best result simpl polygon case optim product also new algorithm shortest path segment queri problem given queri line segment tau mathcal queri seek shortest path point tau previous arkin et al gave data structur size alpha log answer queri log time anoth data structur size log log queri time present data structur size queri time log frac also favor small valu optim|['Haitao Wang']|['cs.CG', 'cs.DS']
2017-04-07T11:28:51Z|2017-03-08T16:32:05Z|http://arxiv.org/abs/1703.02901v1|http://arxiv.org/pdf/1703.02901v1|Local Equivalence and Intrinsic Metrics between Reeb Graphs|local equival intrins metric reeb graph|As graphical summaries for topological spaces and maps, Reeb graphs are common objects in the computer graphics or topological data analysis literature. Defining good metrics between these objects has become an important question for applications, where it matters to quantify the extent by which two given Reeb graphs differ. Recent contributions emphasize this aspect, proposing novel distances such as {\em functional distortion} or {\em interleaving} that are provably more discriminative than the so-called {\em bottleneck distance}, being true metrics whereas the latter is only a pseudo-metric. Their main drawback compared to the bottleneck distance is to be comparatively hard (if at all possible) to evaluate. Here we take the opposite view on the problem and show that the bottleneck distance is in fact good enough {\em locally}, in the sense that it is able to discriminate a Reeb graph from any other Reeb graph in a small enough neighborhood, as efficiently as the other metrics do. This suggests considering the {\em intrinsic metrics} induced by these distances, which turn out to be all {\em globally} equivalent. This novel viewpoint on the study of Reeb graphs has a potential impact on applications, where one may not only be interested in discriminating between data but also in interpolating between them.|graphic summari topolog space map reeb graph common object comput graphic topolog data analysi literatur defin good metric object becom import question applic matter quantifi extent two given reeb graph differ recent contribut emphas aspect propos novel distanc em function distort em interleav provabl discrimin call em bottleneck distanc true metric wherea latter onli pseudo metric main drawback compar bottleneck distanc compar hard possibl evalu take opposit view problem show bottleneck distanc fact good enough em local sens abl discrimin reeb graph ani reeb graph small enough neighborhood effici metric suggest consid em intrins metric induc distanc turn em global equival novel viewpoint studi reeb graph potenti impact applic one may onli interest discrimin data also interpol|['Mathieu Carrière', 'Steve Oudot']|['cs.CG', 'math.AT']
2017-04-07T11:28:51Z|2017-03-08T02:12:35Z|http://arxiv.org/abs/1703.02671v1|http://arxiv.org/pdf/1703.02671v1|Symmetric Assembly Puzzles are Hard, Beyond a Few Pieces|symmetr assembl puzzl hard beyond piec|We study the complexity of symmetric assembly puzzles: given a collection of simple polygons, can we translate, rotate, and possibly flip them so that their interior-disjoint union is line symmetric? On the negative side, we show that the problem is strongly NP-complete even if the pieces are all polyominos. On the positive side, we show that the problem can be solved in polynomial time if the number of pieces is a fixed constant.|studi complex symmetr assembl puzzl given collect simpl polygon translat rotat possibl flip interior disjoint union line symmetr negat side show problem strong np complet even piec polyomino posit side show problem solv polynomi time number piec fix constant|['Erik D. Demaine', 'Matias Korman', 'Jason S. Ku', 'Joseph S. B. Mitchell', 'Yota Otachi', 'André van Renssen', 'Marcel Roeloffzen', 'Ryuhei Uehara', 'Yushi Uno']|['cs.CG']
2017-04-07T11:28:51Z|2017-03-07T23:22:46Z|http://arxiv.org/abs/1703.02637v1|http://arxiv.org/pdf/1703.02637v1|Effective identifiability criteria for tensors and polynomials|effect identifi criteria tensor polynomi|A tensor $T$, in a given tensor space, is said to be $h$-identifiable if it admits a unique decomposition as a sum of $h$ rank one tensors. A criterion for $h$-identifiability is called effective if it is satisfied in a dense, open subset of the set of rank $h$ tensors. In this paper we give effective $h$-identifiability criteria for a large class of tensors. We then improve these criteria for some symmetric tensors. For instance, this allows us to give a complete set of effective identifiability criteria for ternary quintic polynomial. Finally, we implement our identifiability algorithms in Macaulay2.|tensor given tensor space said identifi admit uniqu decomposit sum rank one tensor criterion identifi call effect satisfi dens open subset set rank tensor paper give effect identifi criteria larg class tensor improv criteria symmetr tensor instanc allow us give complet set effect identifi criteria ternari quintic polynomi final implement identifi algorithm macaulay|['Alex Massarenti', 'Massimiliano Mella', 'Giovanni Staglianò']|['math.AG', 'cs.CG', '15A69, 15A72, 11P05 (Primary), 14N05, 15A69 (Secondary)']
2017-04-07T11:28:51Z|2017-03-20T08:48:17Z|http://arxiv.org/abs/1703.02261v2|http://arxiv.org/pdf/1703.02261v2|An annotated bibliography on 1-planarity|annot bibliographi planar|The notion of 1-planarity is among the most natural and most studied generalizations of graph planarity. A graph is 1-planar if it has an embedding where each edge is crossed by at most another edge. The study of 1-planar graphs dates back to more than fifty years ago and, recently, it has driven increasing attention in the areas of graph theory, graph algorithms, graph drawing, and computational geometry. This annotated bibliography aims to provide a guiding reference to researchers who want to have an overview of the large body of literature about 1-planar graphs. It reviews the current literature covering various research streams about 1-planarity, such as characterization and recognition, combinatorial properties, and geometric representations. As an additional contribution, we offer a list of open problems on 1-planar graphs.|notion planar among natur studi general graph planar graph planar embed edg cross anoth edg studi planar graph date back fifti year ago recent driven increas attent area graph theori graph algorithm graph draw comput geometri annot bibliographi aim provid guid refer research want overview larg bodi literatur planar graph review current literatur cover various research stream planar character recognit combinatori properti geometr represent addit contribut offer list open problem planar graph|['Stephen G. Kobourov', 'Giuseppe Liotta', 'Fabrizio Montecchiani']|['cs.CG']
2017-04-07T11:28:51Z|2017-03-31T15:21:44Z|http://arxiv.org/abs/1703.01943v2|http://arxiv.org/pdf/1703.01943v2|Enumeration of $2$-level polytopes|enumer level polytop|A (convex) polytope $P$ is said to be $2$-level if for every direction of hyperplanes which is facet-defining for $P$, the vertices of $P$ can be covered with two hyperplanes of that direction. The study of these polytopes is motivated by questions in combinatorial optimization and communication complexity, among others. In this paper, we present the first algorithm for enumerating all combinatorial types of $2$-level polytopes of a given dimension $d$, and provide complete experimental results for $d \leqslant 7$. Our approach is inductive: for each fixed $(d-1)$-dimensional $2$-level polytope $P_0$, we enumerate all $d$-dimensional $2$-level polytopes $P$ that have $P_0$ as a facet. This relies on the enumeration of the closed sets of a closure operator over a finite ground set. By varying the prescribed facet $P_0$, we obtain all $2$-level polytopes in dimension $d$.|convex polytop said level everi direct hyperplan facet defin vertic cover two hyperplan direct studi polytop motiv question combinatori optim communic complex among paper present first algorithm enumer combinatori type level polytop given dimens provid complet experiment result leqslant approach induct fix dimension level polytop enumer dimension level polytop facet reli enumer close set closur oper finit ground set vari prescrib facet obtain level polytop dimens|['Adam Bohn', 'Yuri Faenza', 'Samuel Fiorini', 'Vissarion Fisikopoulos', 'Marco Macchia', 'Kanstantsin Pashkovich']|['math.CO', 'cs.CG', 'cs.DM', 'math.OC', '05A15, 05C17, 52B12, 52B55, 68W05, 90C22']
2017-04-07T11:28:51Z|2017-03-05T23:29:51Z|http://arxiv.org/abs/1703.01691v1|http://arxiv.org/pdf/1703.01691v1|Drawing Planar Graphs with Few Geometric Primitives|draw planar graph geometr primit|We define the visual complexity of a plane graph drawing to be the number of geometric objects needed to represent all its edges. In particular, one object may represent multiple edges (e.g., one needs only one line segment to draw two collinear edges of the same vertex). Let $n$ denote the number of vertices of a graph. We show that trees can be drawn with $3n/4$ straight-line segments on a polynomial grid, and with $n/2$ straight-line segments on a quasi-polynomial grid. Further, we present an algorithm for drawing planar 3-trees with $(8n-17)/3$ segments on an $O(n)\times O(n^2)$ grid. This algorithm can also be used with a small modification to draw maximal outerplanar graphs with $3n/2$ edges on an $O(n)\times O(n^2)$ grid. We also study the problem of drawing maximal planar graphs with circular arcs and provide an algorithm to draw such graphs using only $(5n - 11)/3$ arcs. This provides a significant improvement over the lower bound of $2n$ for line segments for a nontrivial graph class.|defin visual complex plane graph draw number geometr object need repres edg particular one object may repres multipl edg one need onli one line segment draw two collinear edg vertex let denot number vertic graph show tree drawn straight line segment polynomi grid straight line segment quasi polynomi grid present algorithm draw planar tree segment time grid algorithm also use small modif draw maxim outerplanar graph edg time grid also studi problem draw maxim planar graph circular arc provid algorithm draw graph use onli arc provid signific improv lower bound line segment nontrivi graph class|['Gregor Hültenschmidt', 'Philipp Kindermann', 'Wouter Meulemans', 'André Schulz']|['cs.CG']
2017-04-07T11:28:51Z|2017-03-05T19:10:17Z|http://arxiv.org/abs/1703.01646v1|http://arxiv.org/pdf/1703.01646v1|A PTAS for TSP with Neighborhoods Among Fat Regions in the Plane|ptas tsp neighborhood among fat region plane|"The Euclidean TSP with neighborhoods (TSPN) problem seeks a shortest tour that visits a given collection of $n$ regions ({\em neighborhoods}). We present the first polynomial-time approximation scheme for TSPN for a set of regions given by arbitrary disjoint fat regions in the plane. This improves substantially upon the known approximation algorithms, and is the first PTAS for TSPN on regions of non-comparable sizes. Our result is based on a novel extension of the $m$-guillotine method. The result applies to regions that are ""fat"" in a very weak sense: each region $P_i$ has area $\Omega([diam(P_i)]^2)$, but is otherwise arbitrary."|euclidean tsp neighborhood tspn problem seek shortest tour visit given collect region em neighborhood present first polynomi time approxim scheme tspn set region given arbitrari disjoint fat region plane improv substanti upon known approxim algorithm first ptas tspn region non compar size result base novel extens guillotin method result appli region fat veri weak sens region area omega diam otherwis arbitrari|['Joseph S. B. Mitchell']|['cs.CG']
2017-04-07T11:28:55Z|2017-03-05T18:24:23Z|http://arxiv.org/abs/1703.01640v1|http://arxiv.org/abs/1703.01640v1|Approximation algorithms for TSP with neighborhoods in the plane|approxim algorithm tsp neighborhood plane|In the Euclidean TSP with neighborhoods (TSPN), we are given a collection of n regions (neighborhoods) and we seek a shortest tour that visits each region. As a generalization of the classical Euclidean TSP, TSPN is also NP-hard. In this paper, we present new approximation results for the TSPN, including (1) a constant-factor approximation algorithm for the case of arbitrary connected neighborhoods having comparable diameters; and (2) a PTAS for the important special case of disjoint unit disk neighborhoods (or nearly disjoint, nearly-unit disks). Our methods also yield improved approximation ratios for various special classes of neighborhoods, which have previously been studied. Further, we give a linear-time O(1)-approximation algorithm for the case of neighborhoods that are (infinite) straight lines.|euclidean tsp neighborhood tspn given collect region neighborhood seek shortest tour visit region general classic euclidean tsp tspn also np hard paper present new approxim result tspn includ constant factor approxim algorithm case arbitrari connect neighborhood compar diamet ptas import special case disjoint unit disk neighborhood near disjoint near unit disk method also yield improv approxim ratio various special class neighborhood previous studi give linear time approxim algorithm case neighborhood infinit straight line|['Adrian Dumitrescu', 'Joseph S. B. Mitchell']|['cs.CG', 'cs.DS']
2017-04-07T11:28:55Z|2017-03-05T01:41:08Z|http://arxiv.org/abs/1703.01544v1|http://arxiv.org/pdf/1703.01544v1|L-Graphs and Monotone L-Graphs|graph monoton graph|"In an $\mathsf{L}$-embedding of a graph, each vertex is represented by an $\mathsf{L}$-segment, and two segments intersect each other if and only if the corresponding vertices are adjacent in the graph. If the corner of each $\mathsf{L}$-segment in an $\mathsf{L}$-embedding lies on a straight line, we call it a monotone $\mathsf{L}$-embedding. In this paper we give a full characterization of monotone $\mathsf{L}$-embeddings by introducing a new class of graphs which we call ""non-jumping"" graphs. We show that a graph admits a monotone $\mathsf{L}$-embedding if and only if the graph is a non-jumping graph. Further, we show that outerplanar graphs, convex bipartite graphs, interval graphs, 3-leaf power graphs, and complete graphs are subclasses of non-jumping graphs. Finally, we show that distance-hereditary graphs and $k$-leaf power graphs ($k\le 4$) admit $\mathsf{L}$-embeddings."|mathsf embed graph vertex repres mathsf segment two segment intersect onli correspond vertic adjac graph corner mathsf segment mathsf embed lie straight line call monoton mathsf embed paper give full character monoton mathsf embed introduc new class graph call non jump graph show graph admit monoton mathsf embed onli graph non jump graph show outerplanar graph convex bipartit graph interv graph leaf power graph complet graph subclass non jump graph final show distanc hereditari graph leaf power graph le admit mathsf embed|['Abu Reyan Ahmed', 'Felice De Luca', 'Sabin Devkota', 'Alon Efrat', 'Md Iqbal Hossain', 'Stephen Kobourov', 'Jixian Li', 'Sammi Abida Salma', 'Eric Welch']|['cs.CG']
2017-04-07T11:28:55Z|2017-03-04T10:59:56Z|http://arxiv.org/abs/1703.01439v1|http://arxiv.org/pdf/1703.01439v1|On the set of optimal homeomorphisms for the natural pseudo-distance   associated with the Lie group S^1|set optim homeomorph natur pseudo distanc associ lie group|If $\varphi$ and $\psi$ are two continuous real-valued functions defined on a compact topological space $X$ and $G$ is a subgroup of the group of all homeomorphisms of $X$ onto itself, the natural pseudo-distance $d_G(\varphi,\psi)$ is defined as the infimum of $\mathcal{L}(g)=\ \varphi-\psi \circ g \ _\infty$, as $g$ varies in $G$. In this paper, we make a first step towards extending the study of this concept to the case of Lie groups, by assuming $X=G=S^1$. In particular, we study the set of the optimal homeomorphisms for $d_G$, i.e. the elements $\rho_\alpha$ of $S^1$ such that $\mathcal{L}(\rho_\alpha)$ is equal to $d_G(\varphi,\psi)$. As our main results, we give conditions that a homeomorphism has to meet in order to be optimal, and we prove that the set of the optimal homeomorphisms is finite under suitable conditions.|varphi psi two continu real valu function defin compact topolog space subgroup group homeomorph onto natur pseudo distanc varphi psi defin infimum mathcal varphi psi circ infti vari paper make first step toward extend studi concept case lie group assum particular studi set optim homeomorph element rho alpha mathcal rho alpha equal varphi psi main result give condit homeomorph meet order optim prove set optim homeomorph finit suitabl condit|['Alessandro De Gregorio']|['cs.CG', 'math.AT', 'Primary 57S05, Secondary 55N99']
2017-04-07T11:28:55Z|2017-03-01T02:48:12Z|http://arxiv.org/abs/1703.00112v1|http://arxiv.org/pdf/1703.00112v1|Minimum Enclosing Circle of a Set of Static Points with Dynamic Weight   from One Free Point|minimum enclos circl set static point dynam weight one free point|Given a set $S$ of $n$ static points and a free point $p$ in the Euclidean plane, we study a new variation of the minimum enclosing circle problem, in which a dynamic weight that equals to the reciprocal of the distance from the free point $p$ to the undetermined circle center is included. In this work, we prove the optimal solution of the new problem is unique and lies on the boundary of the farthest-point Voronoi diagram of $S$, once $p$ does not coincide with any vertex of the convex hull of $S$. We propose a tree structure constructed from the boundary of the farthest-point Voronoi diagram and use the hierarchical relationship between edges to locate the optimal solution. The plane could be divide into at most $3n-4$ non-overlapping regions. When $p$ lies in one of the regions, the optimal solution locates at one node or lies on the interior of one edge in the boundary of the farthest-point Voronoi diagram. Moreover, we apply the new variation to calculate the maximum displacement of one point $p$ under the condition that the displacements of points in $S$ are restricted in 2D rigid motion.|given set static point free point euclidean plane studi new variat minimum enclos circl problem dynam weight equal reciproc distanc free point undetermin circl center includ work prove optim solut new problem uniqu lie boundari farthest point voronoi diagram onc doe coincid ani vertex convex hull propos tree structur construct boundari farthest point voronoi diagram use hierarch relationship edg locat optim solut plane could divid non overlap region lie one region optim solut locat one node lie interior one edg boundari farthest point voronoi diagram moreov appli new variat calcul maximum displac one point condit displac point restrict rigid motion|['Lei Qiu', 'Yu Zhang', 'Li Zhang']|['cs.CG']
2017-04-07T11:28:55Z|2017-02-28T09:44:01Z|http://arxiv.org/abs/1702.08716v1|http://arxiv.org/pdf/1702.08716v1|On the Relationship between $k$-Planar and $k$-Quasi Planar Graphs|relationship planar quasi planar graph|A graph is $k$-planar $(k \geq 1)$ if it can be drawn in the plane such that no edge is crossed more than $k$ times. A graph is $k$-quasi planar $(k \geq 2)$ if it can be drawn in the plane with no $k$ pairwise crossing edges. The families of $k$-planar and $k$-quasi planar graphs have been widely studied in the literature, and several bounds have been proven on their edge density. Nonetheless, only trivial results are known about the relationship between these two graph families. In this paper we prove that, for $k \geq 3$, every $k$-planar graph is $(k+1)$-quasi planar.|graph planar geq drawn plane edg cross time graph quasi planar geq drawn plane pairwis cross edg famili planar quasi planar graph wide studi literatur sever bound proven edg densiti nonetheless onli trivial result known relationship two graph famili paper prove geq everi planar graph quasi planar|['Patrizio Angelini', 'Michael A. Bekos', 'Franz J. Brandenburg', 'Giordano Da Lozzo', 'Giuseppe Di Battista', 'Walter Didimo', 'Giuseppe Liotta', 'Fabrizio Montecchiani', 'Ignaz Rutter']|['cs.CG']
2017-04-07T11:28:55Z|2017-03-05T02:18:12Z|http://arxiv.org/abs/1702.08662v3|http://arxiv.org/pdf/1702.08662v3|The computational complexity of integer programming with alternations|comput complex integ program altern|We prove that integer programming with three quantifier alternations is $NP$-complete, even for a fixed number of variables. This complements earlier results by Lenstra and Kannan, which together say that integer programming with at most two quantifier alternations can be done in polynomial time for a fixed number of variables. As a byproduct of the proof, we show that for two polytopes $P,Q \subset \mathbb{R}^4$ , counting the projection of integer points in $Q \backslash P$ is $\#P$-complete. This contrasts the 2003 result by Barvinok and Woods, which allows counting in polynomial time the projection of integer points in $P$ and $Q$ separately.|prove integ program three quantifi altern np complet even fix number variabl complement earlier result lenstra kannan togeth say integ program two quantifi altern done polynomi time fix number variabl byproduct proof show two polytop subset mathbb count project integ point backslash complet contrast result barvinok wood allow count polynomi time project integ point separ|['Danny Nguyen', 'Igor Pak']|['math.CO', 'cs.CC', 'cs.CG', 'cs.DM']
2017-04-07T11:28:55Z|2017-02-28T05:47:10Z|http://arxiv.org/abs/1702.08654v1|http://arxiv.org/pdf/1702.08654v1|An Improved Algorithm for General Position Subset Selection|improv algorithm general posit subset select|In the General Position Subset Selection (GPSS) problem, the goal is to find the largest possible subset of a set of points, such that no three of its members are collinear. If $s_{\textrm{GPSS}}$ is the size the optimal solution, $\sqrt{s_{\textrm{GPSS}}}$ is the current best guarantee for the size of the solution obtained using a polynomial time algorithm. In this paper we present an algorithm for GPSS to improve this bound based on the number of collinear pairs of points.|general posit subset select gpss problem goal find largest possibl subset set point three member collinear textrm gpss size optim solut sqrt textrm gpss current best guarante size solut obtain use polynomi time algorithm paper present algorithm gpss improv bound base number collinear pair point|['Ali Gholami Rudi']|['cs.CG', '65D18, 05C69', 'G.2.1; I.3.5; G.2.2']
2017-04-07T11:28:55Z|2017-02-28T02:18:54Z|http://arxiv.org/abs/1702.08607v1|http://arxiv.org/pdf/1702.08607v1|Faster DB-scan and HDB-scan in Low-Dimensional Euclidean Spaces|faster db scan hdb scan low dimension euclidean space|We present a new algorithm for the widely used density-based clustering method DBscan. Our algorithm computes the DBscan-clustering in $O(n\log n)$ time in $\mathbb{R}^2$, irrespective of the scale parameter $\varepsilon$ (and assuming the second parameter MinPts is set to a fixed constant, as is the case in practice). Experiments show that the new algorithm is not only fast in theory, but that a slightly simplified version is competitive in practice and much less sensitive to the choice of $\varepsilon$ than the original DBscan algorithm. We also present an $O(n\log n)$ randomized algorithm for HDBscan in the plane---HDBscan is a hierarchical version of DBscan introduced recently---and we show how to compute an approximate version of HDBscan in near-linear time in any fixed dimension.|present new algorithm wide use densiti base cluster method dbscan algorithm comput dbscan cluster log time mathbb irrespect scale paramet varepsilon assum second paramet minpt set fix constant case practic experi show new algorithm onli fast theori slight simplifi version competit practic much less sensit choic varepsilon origin dbscan algorithm also present log random algorithm hdbscan plane hdbscan hierarch version dbscan introduc recent show comput approxim version hdbscan near linear time ani fix dimens|['Mark de Berg', 'Ade Gunawan', 'Marcel Roeloffzen']|['cs.CG']
2017-04-07T11:28:55Z|2017-02-28T01:14:43Z|http://arxiv.org/abs/1702.08593v1|http://arxiv.org/pdf/1702.08593v1|Mind the Gap: A Study in Global Development through Persistent Homology|mind gap studi global develop persist homolog|"The Gapminder project set out to use statistics to dispel simplistic notions about global development. In the same spirit, we use persistent homology, a technique from computational algebraic topology, to explore the relationship between country development and geography. For each country, two statistics, gross domestic product per capita and average life expectancy, were used to quantify the development. Two analyses were performed. The first considers clusters of the countries based on these two statistics, and the second uncovers cycles in the data when combined with geographic network structure. Our analyses reveal that there is not a clear distinction of ""first"" and ""third"" world countries, and we discovered localized development patterns that are invisible in standard representations."|gapmind project set use statist dispel simplist notion global develop spirit use persist homolog techniqu comput algebra topolog explor relationship countri develop geographi countri two statist gross domest product per capita averag life expect use quantifi develop two analys perform first consid cluster countri base two statist second uncov cycl data combin geograph network structur analys reveal clear distinct first third world countri discov local develop pattern invis standard represent|['Andrew Banman', 'Lori Ziegelmeier']|['math.AT', 'cs.CG']
2017-04-07T11:28:55Z|2017-02-27T22:25:57Z|http://arxiv.org/abs/1703.01350v1|http://arxiv.org/pdf/1703.01350v1|Approximate Convex Hulls|approxim convex hull|We investigate the PPI algorithm as a means for computing ap- proximate convex hull. We explain how the algorithm computes the curvature of points and prove consistency and convergence. We also extend the algorithm to compute approximate convex hulls described in terms of hyperplanes.|investig ppi algorithm mean comput ap proxim convex hull explain algorithm comput curvatur point prove consist converg also extend algorithm comput approxim convex hull describ term hyperplan|['Robert Graham', 'Adam M. Oberman']|['cs.CG', 'math.CO', '05-04']
2017-04-07T11:29:01Z|2017-02-27T17:07:31Z|http://arxiv.org/abs/1702.08380v1|http://arxiv.org/pdf/1702.08380v1|Exploring Increasing-Chord Paths and Trees|explor increas chord path tree|A straight-line drawing $\Gamma$ of a graph $G=(V,E)$ is a drawing of $G$ in the Euclidean plane, where every vertex in $G$ is mapped to a distinct point, and every edge in $G$ is mapped to a straight line segment between their endpoints. A path $P$ in $\Gamma$ is called increasing-chord if for every four points (not necessarily vertices) $a,b,c,d$ on $P$ in this order, the Euclidean distance between $b,c$ is at most the Euclidean distance between $a,d$. A spanning tree $T$ rooted at some vertex $r$ in $\Gamma$ is called increasing-chord if $T$ contains an increasing-chord path from $r$ to every vertex in $T$. In this paper we prove that given a vertex $r$ in a straight-line drawing $\Gamma$, it is NP-complete to determine whether $\Gamma$ contains an increasing-chord spanning tree rooted at $r$. We conjecture that finding an increasing-chord path between a pair of vertices in $\Gamma$, which is an intriguing open problem posed by Alamdari et al., is also NP-complete, and show a (non-polynomial) reduction from the 3-SAT problem.|straight line draw gamma graph draw euclidean plane everi vertex map distinct point everi edg map straight line segment endpoint path gamma call increas chord everi four point necessarili vertic order euclidean distanc euclidean distanc span tree root vertex gamma call increas chord contain increas chord path everi vertex paper prove given vertex straight line draw gamma np complet determin whether gamma contain increas chord span tree root conjectur find increas chord path pair vertic gamma intrigu open problem pose alamdari et al also np complet show non polynomi reduct sat problem|['Yeganeh Bahoo', 'Stephane Durocher', 'Sahar Mehrpour', 'Debajyoti Mondal']|['cs.CG']
2017-04-07T11:29:01Z|2017-02-25T13:55:53Z|http://arxiv.org/abs/1702.07893v1|http://arxiv.org/pdf/1702.07893v1|The Persistent Homotopy Type Distance|persist homotopi type distanc|We introduce the persistent homotopy type distance dHT to compare real valued functions defined on possibly different homotopy equivalent topological spaces. The underlying idea in the definition of dHT is to measure the minimal shift that is necessary to apply to one of the two functions in order that the sublevel sets of the two functions become homotopically equivalent. This distance is interesting in connection with persistent homology. Indeed, our main result states that dHT still provides an upper bound for the bottleneck distance between the persistence diagrams of the intervening functions. Moreover, because homotopy equivalences are weaker than homeomorphisms, this implies a lifting of the standard stability results provided by the L-infty distance and the natural pseudo-distance dNP. From a different standpoint, we prove that dHT extends the L-infty distance and dNP in two ways. First, we show that, appropriately restricting the category of objects to which dHT applies, it can be made to coincide with the other two distances. Finally, we show that dHT has an interpretation in terms of interleavings that naturally places it in the family of distances used in persistence theory.|introduc persist homotopi type distanc dht compar real valu function defin possibl differ homotopi equival topolog space idea definit dht measur minim shift necessari appli one two function order sublevel set two function becom homotop equival distanc interest connect persist homolog inde main result state dht still provid upper bound bottleneck distanc persist diagram interven function moreov becaus homotopi equival weaker homeomorph impli lift standard stabil result provid infti distanc natur pseudo distanc dnp differ standpoint prove dht extend infti distanc dnp two way first show appropri restrict categori object dht appli made coincid two distanc final show dht interpret term interleav natur place famili distanc use persist theori|['Patrizio Frosini', 'Claudia Landi', 'Facundo Memoli']|['cs.CG', 'math.AT']
2017-04-07T11:29:01Z|2017-02-24T14:06:31Z|http://arxiv.org/abs/1702.07589v1|http://arxiv.org/pdf/1702.07589v1|Generalization of Schnyder woods to orientable surfaces and applications|general schnyder wood orient surfac applic|Schnyder woods are particularly elegant combinatorial structures with numerous applications concerning planar triangulations and more generally 3-connected planar maps. We propose a simple generalization of Schnyder woods from the plane to maps on orientable surfaces of any genus with a special emphasis on the toroidal case. We provide a natural partition of the set of Schnyder woods of a given map into distributive lattices depending on the surface homology. In the toroidal case we show the existence of particular Schnyder woods with some global properties that are useful for optimal encoding or graph drawing purpose.|schnyder wood particular eleg combinatori structur numer applic concern planar triangul general connect planar map propos simpl general schnyder wood plane map orient surfac ani genus special emphasi toroid case provid natur partit set schnyder wood given map distribut lattic depend surfac homolog toroid case show exist particular schnyder wood global properti use optim encod graph draw purpos|['Benjamin Lévêque']|['cs.DM', 'cs.CG', 'math.CO']
2017-04-07T11:29:01Z|2017-02-24T12:25:43Z|http://arxiv.org/abs/1702.07555v1|http://arxiv.org/pdf/1702.07555v1|A generalization of crossing families|general cross famili|For a set of points in the plane, a \emph{crossing family} is a set of line segments, each joining two of the points, such that any two line segments cross. We investigate the following generalization of crossing families: a \emph{spoke set} is a set of lines drawn through a point set such that each unbounded region of the induced line arrangement contains at least one point of the point set. We show that every point set has a spoke set of size $\sqrt{\frac{n}{8}}$. We also characterize the matchings obtained by selecting exactly one point in each unbounded region and connecting every such point to the point in the antipodal unbounded region.|set point plane emph cross famili set line segment join two point ani two line segment cross investig follow general cross famili emph spoke set set line drawn point set unbound region induc line arrang contain least one point point set show everi point set spoke set size sqrt frac also character match obtain select exact one point unbound region connect everi point point antipod unbound region|['Patrick Schnider']|['cs.CG']
2017-04-07T11:29:01Z|2017-02-23T21:32:10Z|http://arxiv.org/abs/1702.07399v1|http://arxiv.org/pdf/1702.07399v1|An Optimal Algorithm for Computing the Spherical Depth of Points in the   Plane|optim algorithm comput spheric depth point plane|For a distribution function $F$ on $\mathbb{R}^d$ and a point $q\in \mathbb{R}^d$, the \emph{spherical depth} $\SphD(q;F)$ is defined to be the probability that a point $q$ is contained inside a random closed hyper-ball obtained from a pair of points from $F$. The spherical depth $\SphD(q;S)$ is also defined for an arbitrary data set $S\subseteq \mathbb{R}^d$ and $q\in \mathbb{R}^d$. This definition is based on counting all of the closed hyper-balls, obtained from pairs of points in $S$, that contain $q$. The significant advantage of using the spherical depth in multivariate data analysis is related to its complexity of computation. Unlike most other data depths, the time complexity of the spherical depth grows linearly rather than exponentially in the dimension $d$. The straightforward algorithm for computing the spherical depth in dimension $d$ takes $O(dn^2)$. The main result of this paper is an optimal algorithm that we present for computing the bivariate spherical depth. The algorithm takes $O(n \log n)$ time. By reducing the problem of \textit{Element Uniqueness}, we prove that computing the spherical depth requires $\Omega(n \log n)$ time. Some geometric properties of spherical depth are also investigated in this paper. These properties indicate that \emph{simplicial depth} ($\SD$) (Liu, 1990) is linearly bounded by spherical depth (in particular, $\SphD\geq \frac{2}{3}SD$). To illustrate this relationship between the spherical depth and the simplicial depth, some experimental results are provided. The obtained experimental bound ($\SphD\geq 2\SD$) indicates that, perhaps, a stronger theoretical bound can be achieved.|distribut function mathbb point mathbb emph spheric depth sphd defin probabl point contain insid random close hyper ball obtain pair point spheric depth sphd also defin arbitrari data set subseteq mathbb mathbb definit base count close hyper ball obtain pair point contain signific advantag use spheric depth multivari data analysi relat complex comput unlik data depth time complex spheric depth grow linear rather exponenti dimens straightforward algorithm comput spheric depth dimens take dn main result paper optim algorithm present comput bivari spheric depth algorithm take log time reduc problem textit element uniqu prove comput spheric depth requir omega log time geometr properti spheric depth also investig paper properti indic emph simplici depth sd liu linear bound spheric depth particular sphd geq frac sd illustr relationship spheric depth simplici depth experiment result provid obtain experiment bound sphd geq sd indic perhap stronger theoret bound achiev|['David Bremner', 'Rasoul Shahsavarifar']|['cs.CG']
2017-04-07T11:29:01Z|2017-03-16T14:38:10Z|http://arxiv.org/abs/1702.06829v2|http://arxiv.org/pdf/1702.06829v2|A Simple Convex Layers Algorithm|simpl convex layer algorithm|Given a set of $n$ points $P$ in the plane, the first layer $L_1$ of $P$ is formed by the points that appear on $P$'s convex hull. In general, a point belongs to layer $L_i$, if it lies on the convex hull of the set $P \setminus \bigcup_{j<i}\{L_j\}$. The \emph{convex layers problem} is to compute the convex layers $L_i$. Existing algorithms for this problem either do not achieve the optimal $\mathcal{O}\left(n\log n\right)$ runtime and linear space, or are overly complex and difficult to apply in practice. We propose a new algorithm that is both optimal and simple. The simplicity is achieved by independently computing four sets of monotone convex chains in $\mathcal{O}\left(n\log n\right)$ time and linear space. These are then merged in $\mathcal{O}\left(n\log n\right)$ time.|given set point plane first layer form point appear convex hull general point belong layer lie convex hull set setminus bigcup emph convex layer problem comput convex layer exist algorithm problem either achiev optim mathcal left log right runtim linear space complex difficult appli practic propos new algorithm optim simpl simplic achiev independ comput four set monoton convex chain mathcal left log right time linear space merg mathcal left log right time|['Raimi A. Rufai', 'Dana S. Richards']|['cs.CG', 'cs.DS', '68W99', 'I.3.5']
2017-04-07T11:29:01Z|2017-02-20T20:14:46Z|http://arxiv.org/abs/1702.06163v1|http://arxiv.org/pdf/1702.06163v1|1-Fan-Bundle-Planar Drawings of Graphs|fan bundl planar draw graph|Edge bundling is an important concept, heavily used for graph visualization purposes. To enable the comparison with other established nearly-planarity models in graph drawing, we formulate a new edge-bundling model which is inspired by the recently introduced fan-planar graphs. In particular, we restrict the bundling to the endsegments of the edges. As in 1-planarity, we call our model 1-fan-bundle-planarity, as we allow at most one crossing per bundle.   For the two variants where we allow either one or, more naturally, both endsegments of each edge to be part of bundles, we present edge density results and consider various recognition questions, not only for general graphs, but also for the outer and 2-layer variants. We conclude with a series of challenging questions.|edg bundl import concept heavili use graph visual purpos enabl comparison establish near planar model graph draw formul new edg bundl model inspir recent introduc fan planar graph particular restrict bundl endseg edg planar call model fan bundl planar allow one cross per bundl two variant allow either one natur endseg edg part bundl present edg densiti result consid various recognit question onli general graph also outer layer variant conclud seri challeng question|['Patrizio Angelini', 'Michael A. Bekos', 'Michael Kaufmann', 'Philipp Kindermann', 'Thomas Schneck']|['cs.CG', 'math.CO']
2017-04-07T11:29:01Z|2017-02-20T08:56:40Z|http://arxiv.org/abs/1702.05900v1|http://arxiv.org/pdf/1702.05900v1|$δ$-Greedy $t$-spanner|greedi spanner|We introduce a new geometric spanner, $\delta$-Greedy, whose construction is based on a generalization of the known Path-Greedy and Gap-Greedy spanners. The $\delta$-Greedy spanner combines the most desirable properties of geometric spanners both in theory and in practice. More specifically, it has the same theoretical and practical properties as the Path-Greedy spanner: a natural definition, small degree, linear number of edges, low weight, and strong $(1+\varepsilon)$-spanner for every $\varepsilon>0$. The $\delta$-Greedy algorithm is an improvement over the Path-Greedy algorithm with respect to the number of shortest path queries and hence with respect to its construction time. We show how to construct such a spanner for a set of $n$ points in the plane in $O(n^2 \log n)$ time.   The $\delta$-Greedy spanner has an additional parameter, $\delta$, which indicates how close it is to the Path-Greedy spanner on the account of the number of shortest path queries. For $\delta = t$ the output spanner is identical to the Path-Greedy spanner, while the number of shortest path queries is, in practice, linear.   Finally, we show that for a set of $n$ points placed independently at random in a unit square the expected construction time of the $\delta$-Greedy algorithm is $O(n \log n)$. Our analysis indicates that the $\delta$-Greedy spanner gives the best results among the known spanners of expected $O(n \log n)$ time for random point sets. Moreover, the analysis implies that by setting $\delta = t$, the $\delta$-Greedy algorithm provides a spanner identical to the Path-Greedy spanner in expected $O(n \log n)$ time.|introduc new geometr spanner delta greedi whose construct base general known path greedi gap greedi spanner delta greedi spanner combin desir properti geometr spanner theori practic specif theoret practic properti path greedi spanner natur definit small degre linear number edg low weight strong varepsilon spanner everi varepsilon delta greedi algorithm improv path greedi algorithm respect number shortest path queri henc respect construct time show construct spanner set point plane log time delta greedi spanner addit paramet delta indic close path greedi spanner account number shortest path queri delta output spanner ident path greedi spanner number shortest path queri practic linear final show set point place independ random unit squar expect construct time delta greedi algorithm log analysi indic delta greedi spanner give best result among known spanner expect log time random point set moreov analysi impli set delta delta greedi algorithm provid spanner ident path greedi spanner expect log time|['Gali Bar-On', 'Paz Carmi']|['cs.CG']
2017-04-07T11:29:01Z|2017-02-19T15:48:11Z|http://arxiv.org/abs/1702.05760v1|http://arxiv.org/pdf/1702.05760v1|Hypercube LSH for approximate near neighbors|hypercub lsh approxim near neighbor|A celebrated technique for finding near neighbors for the angular distance involves using a set of \textit{random} hyperplanes to partition the space into hash regions [Charikar, STOC 2002]. Experiments later showed that using a set of \textit{orthogonal} hyperplanes, thereby partitioning the space into the Voronoi regions induced by a hypercube, leads to even better results [Terasawa and Tanaka, WADS 2007]. However, no theoretical explanation for this improvement was ever given, and it remained unclear how the resulting hypercube hash method scales in high dimensions.   In this work, we provide explicit asymptotics for the collision probabilities when using hypercubes to partition the space. For instance, two near-orthogonal vectors are expected to collide with probability $(\frac{1}{\pi})^{d + o(d)}$ in dimension $d$, compared to $(\frac{1}{2})^d$ when using random hyperplanes. Vectors at angle $\frac{\pi}{3}$ collide with probability $(\frac{\sqrt{3}}{\pi})^{d + o(d)}$, compared to $(\frac{2}{3})^d$ for random hyperplanes, and near-parallel vectors collide with similar asymptotic probabilities in both cases.   For $c$-approximate nearest neighbor searching, this translates to a decrease in the exponent $\rho$ of locality-sensitive hashing (LSH) methods of a factor up to $\log_2(\pi) \approx 1.652$ compared to hyperplane LSH. For $c = 2$, we obtain $\rho \approx 0.302 + o(1)$ for hypercube LSH, improving upon the $\rho \approx 0.377$ for hyperplane LSH. We further describe how to use hypercube LSH in practice, and we consider an example application in the area of lattice algorithms.|celebr techniqu find near neighbor angular distanc involv use set textit random hyperplan partit space hash region charikar stoc experi later show use set textit orthogon hyperplan therebi partit space voronoi region induc hypercub lead even better result terasawa tanaka wad howev theoret explan improv ever given remain unclear result hypercub hash method scale high dimens work provid explicit asymptot collis probabl use hypercub partit space instanc two near orthogon vector expect collid probabl frac pi dimens compar frac use random hyperplan vector angl frac pi collid probabl frac sqrt pi compar frac random hyperplan near parallel vector collid similar asymptot probabl case approxim nearest neighbor search translat decreas expon rho local sensit hash lsh method factor log pi approx compar hyperplan lsh obtain rho approx hypercub lsh improv upon rho approx hyperplan lsh describ use hypercub lsh practic consid exampl applic area lattic algorithm|['Thijs Laarhoven']|['cs.DS', 'cs.CC', 'cs.CG', 'cs.CR']
2017-04-07T11:29:01Z|2017-02-18T17:02:58Z|http://arxiv.org/abs/1702.05633v1|http://arxiv.org/pdf/1702.05633v1|Approximation Algorithms for Independence and Domination on B$_1$-VPG   and B$_1$-EPG Graphs|approxim algorithm independ domin vpg epg graph|A graph $G$ is called B$_k$-VPG (resp., B$_k$-EPG), for some constant $k\geq 0$, if it has a string representation on a grid such that each vertex is an orthogonal path with at most $k$ bends and two vertices are adjacent in $G$ if and only if the corresponding strings intersect (resp., the corresponding strings share at least one grid edge). If two adjacent strings of a B$_k$-VPG graph intersect exactly once, then the graph is called a one-string B$_k$-VPG graph.   In this paper, we study the Maximum Independent Set and Minimum Dominating Set problems on B$_1$-VPG and B$_1$-EPG graphs. We first give a simple $O(\log n)$-approximation algorithm for the Maximum Independent Set problem on B$_1$-VPG graphs, improving the previous $O((\log n)^2)$-approximation algorithm of Lahiri et al. (COCOA 2015). Then, we consider the Minimum Dominating Set problem. We give an $O(1)$-approximation algorithm for this problem on one-string B$_1$-VPG graphs, providing the first constant-factor approximation algorithm for this problem. Moreover, we show that the Minimum Dominating Set problem is APX-hard on B$_1$-EPG graphs, ruling out the possibility of a PTAS unless P=NP. Finally, we give constant-factor approximation algorithms for this problem on two non-trivial subclasses of B$_1$-EPG graphs. To our knowledge, these are the first results for the Minimum Dominating Set problem on B$_1$-EPG graphs, partially answering a question posed by Epstein et al. (WADS 2013).|graph call vpg resp epg constant geq string represent grid vertex orthogon path bend two vertic adjac onli correspond string intersect resp correspond string share least one grid edg two adjac string vpg graph intersect exact onc graph call one string vpg graph paper studi maximum independ set minimum domin set problem vpg epg graph first give simpl log approxim algorithm maximum independ set problem vpg graph improv previous log approxim algorithm lahiri et al cocoa consid minimum domin set problem give approxim algorithm problem one string vpg graph provid first constant factor approxim algorithm problem moreov show minimum domin set problem apx hard epg graph rule possibl ptas unless np final give constant factor approxim algorithm problem two non trivial subclass epg graph knowledg first result minimum domin set problem epg graph partial answer question pose epstein et al wad|['Saeed Mehrabi']|['cs.CG']
2017-04-07T11:29:04Z|2017-02-17T16:07:53Z|http://arxiv.org/abs/1702.06188v1|http://arxiv.org/pdf/1702.06188v1|Forest understory trees revealed using sufficiently dense airborne laser   scanning point clouds|forest understori tree reveal use suffici dens airborn laser scan point cloud|Airborne laser scanning (lidar) point clouds can be process to extract tree-level information over large forested landscapes. Existing procedures typically detect more than 90% of overstory trees, yet they barely detect 60% of understory trees because of reduced number of lidar points penetrating the top canopy layer. Although understory trees provide limited financial value, they offer habitat for numerous wildlife species and are important for stand development. Here we model tree identification accuracy according to point cloud density by decomposing lidar point cloud into overstory and multiple understory canopy layers, estimating the fraction of points representing the different layers, and inspecting tree identification accuracy as a function of point density. We show at a density of about 170 pt/m2 understory tree identification accuracy likely plateaus, which we regard as the required point density for reasonable identification of understory trees. Given the advancements of lidar sensor technology, point clouds can feasibly reach the required density to enable effective identification of individual understory trees, ultimately making remote quantification of forest resources more accurate. The layer decomposition methodology can also be adopted for other similar remote sensing or advanced imaging applications such as geological subsurface modelling or biomedical tissue analysis.|airborn laser scan lidar point cloud process extract tree level inform larg forest landscap exist procedur typic detect overstori tree yet bare detect understori tree becaus reduc number lidar point penetr top canopi layer although understori tree provid limit financi valu offer habitat numer wildlif speci import stand develop model tree identif accuraci accord point cloud densiti decompos lidar point cloud overstori multipl understori canopi layer estim fraction point repres differ layer inspect tree identif accuraci function point densiti show densiti pt understori tree identif accuraci like plateaus regard requir point densiti reason identif understori tree given advanc lidar sensor technolog point cloud feasibl reach requir densiti enabl effect identif individu understori tree ultim make remot quantif forest resourc accur layer decomposit methodolog also adopt similar remot sens advanc imag applic geolog subsurfac model biomed tissu analysi|['Hamid Hamraz', 'Marco A. Contreras', 'Jun Zhang']|['cs.CV', 'cs.CG']
2017-04-07T11:29:04Z|2017-02-17T14:34:08Z|http://arxiv.org/abs/1702.05358v1|http://arxiv.org/pdf/1702.05358v1|Computational topology of graphs on surfaces|comput topolog graph surfac|Computational topology is an area that revisits topological problems from an algorithmic point of view, and develops topological tools for improved algorithms. We survey results in computational topology that are concerned with graphs drawn on surfaces. Typical questions include representing surfaces and graphs embedded on them computationally, deciding whether a graph embeds on a surface, solving computational problems related to homotopy, optimizing curves and graphs on surfaces, and solving standard graph algorithm problems more efficiently in the case of surface-embedded graphs.|comput topolog area revisit topolog problem algorithm point view develop topolog tool improv algorithm survey result comput topolog concern graph drawn surfac typic question includ repres surfac graph embed comput decid whether graph emb surfac solv comput problem relat homotopi optim curv graph surfac solv standard graph algorithm problem effici case surfac embed graph|['Éric Colin de Verdière']|['cs.CG', 'cs.DM', 'cs.DS', 'math.AT', 'math.CO', '68U05, 05C10, 57M15, 68R10', 'F.2.2; G.2.2; I.3.5']
2017-04-07T11:29:04Z|2017-02-17T09:19:02Z|http://arxiv.org/abs/1702.05265v1|http://arxiv.org/pdf/1702.05265v1|T-Shape Visibility Representations of 1-Planar Graphs|shape visibl represent planar graph|A shape visibility representation displays a graph so that each vertex is represented by an orthogonal polygon of a particular shape and for each edge there is a horizontal or vertical line of sight between the polygons assigned to its endvertices. Special shapes are rectangles, L, T, E and H-shapes, and caterpillars. A flat rectangle is a horizontal bar of height $\epsilon>0$. A graph is 1-planar if there is a drawing in the plane such that each edge is crossed at most once and is IC-planar if in addition no two crossing edges share a vertex.   We show that every IC-planar graph has a flat rectangle visibility representation and that every 1-planar graph has a T-shape visibility representation. The representations use quadratic area and can be computed in linear time from a given embedding.|shape visibl represent display graph vertex repres orthogon polygon particular shape edg horizont vertic line sight polygon assign endvertic special shape rectangl shape caterpillar flat rectangl horizont bar height epsilon graph planar draw plane edg cross onc ic planar addit two cross edg share vertex show everi ic planar graph flat rectangl visibl represent everi planar graph shape visibl represent represent use quadrat area comput linear time given embed|['Franz J. Brandenburg']|['cs.CG', '68R10', 'G.2.2']
2017-04-07T11:29:04Z|2017-02-15T14:59:10Z|http://arxiv.org/abs/1702.04641v1|http://arxiv.org/pdf/1702.04641v1|Filling missing data in point clouds by merging structured and   unstructured point clouds|fill miss data point cloud merg structur unstructur point cloud|"Point clouds arising from structured data, mainly as a result of CT scans, provides special properties on the distribution of points and the distances between those. Yet often, the amount of data provided can not compare to unstructured point clouds, i.e. data that arises from 3D light scans or laser scans. This article hereby proposes an approach to extend structured data and enhance the quality by inserting selected points from an unstructured point cloud. The resulting point cloud still has a partial structure that is called ""half-structure"". In this way, missing data that can not be optimally recovered through other surface reconstruction methods can be completed."|point cloud aris structur data main result ct scan provid special properti distribut point distanc yet often amount data provid compar unstructur point cloud data aris light scan laser scan articl herebi propos approach extend structur data enhanc qualiti insert select point unstructur point cloud result point cloud still partial structur call half structur way miss data optim recov surfac reconstruct method complet|['Franziska Lippoldt', 'Hartmut Schwandt']|['cs.CG', 'cs.CV', 'cs.DM', '53A05', 'F.2.2; G.2.1; I.3.5']
2017-04-07T11:29:04Z|2017-02-14T15:20:23Z|http://arxiv.org/abs/1702.04259v1|http://arxiv.org/pdf/1702.04259v1|On the metastable Mabillard-Wagner conjecture|metast mabillard wagner conjectur|The purpose of this note is to attract attention to the following conjecture (metastable $r$-fold Whitney trick) by clarifying its status as not having a complete proof, in the sense described in the paper.   Assume that $D=D_1\sqcup\ldots\sqcup D_r$ is disjoint union of $r$ disks of dimension $s$, $f:D\to B^d$ a proper PL map such that $f\partial D_1\cap\ldots\cap f\partial D_r=\emptyset$, $rd\ge (r+1)s+3$ and $d\ge s+3$. If the map $$f^r:\partial(D_1\times\ldots\times D_r)\to (B^d)^r-\{(x,x,\ldots,x)\in(B^d)^r\  \ x\in B^d\}$$ extends to $D_1\times\ldots\times D_r$, then there is a PL map $\overline f:D\to B^d$ such that $$\overline f=f \quad\text{on}\quad D_r\cup\partial D\quad\text{and}\quad \overline fD_1\cap\ldots\cap \overline fD_r=\emptyset.$$|purpos note attract attent follow conjectur metast fold whitney trick clarifi status complet proof sens describ paper assum sqcup ldot sqcup disjoint union disk dimens proper pl map partial cap ldot cap partial emptyset rd ge ge map partial time ldot time ldot extend time ldot time pl map overlin overlin quad text quad cup partial quad text quad overlin fd cap ldot cap overlin fd emptyset|['A. Skopenkov']|['math.GT', 'cs.CG', '57Q35, 57R65, 52B99']
2017-04-07T11:29:04Z|2017-03-19T08:52:47Z|http://arxiv.org/abs/1702.03676v2|http://arxiv.org/pdf/1702.03676v2|Epsilon-approximations and epsilon-nets|epsilon approxim epsilon net|The use of random samples to approximate properties of geometric configurations has been an influential idea for both combinatorial and algorithmic purposes. This chapter considers two related notions---$\epsilon$-approximations and $\epsilon$-nets---that capture the most important quantitative properties that one would expect from a random sample with respect to an underlying geometric configuration.|use random sampl approxim properti geometr configur influenti idea combinatori algorithm purpos chapter consid two relat notion epsilon approxim epsilon net captur import quantit properti one would expect random sampl respect geometr configur|['Nabil H. Mustafa', 'Kasturi R. Varadarajan']|['cs.CG', 'math.CO', 'math.PR']
2017-04-07T11:29:04Z|2017-02-11T01:20:50Z|http://arxiv.org/abs/1702.03364v1|http://arxiv.org/pdf/1702.03364v1|Techniques in Lattice Basis Reduction|techniqu lattic basi reduct|The credit on {\it reduction theory} goes back to the work of Lagrange, Gauss, Hermite, Korkin, Zolotarev, and Minkowski. Modern reduction theory is voluminous and includes the work of A. Lenstra, H. Lenstra and L. Lovasz who created the well known LLL algorithm, and many other researchers such as L. Babai and C. P. Schnorr who created significant new variants of basis reduction algorithms. In this paper, we propose and investigate the efficacy of new optimization techniques to be used along with LLL algorithm. The techniques we have proposed are: i) {\it hill climbing (HC)}, ii) {\it lattice diffusion-sub lattice fusion (LDSF)}, and iii) {\it multistage hybrid LDSF-HC}. The first technique relies on the sensitivity of LLL to permutations of the input basis $B$, and optimization ideas over the symmetric group $S_m$ viewed as a metric space. The second technique relies on partitioning the lattice into sublattices, performing basis reduction in the partition sublattice blocks, fusing the sublattices, and repeating. We also point out places where parallel computation can reduce run-times achieving almost linear speedup. The multistage hybrid technique relies on the lattice diffusion and sublattice fusion and hill climbing algorithms.|credit reduct theori goe back work lagrang gauss hermit korkin zolotarev minkowski modern reduct theori volumin includ work lenstra lenstra lovasz creat well known lll algorithm mani research babai schnorr creat signific new variant basi reduct algorithm paper propos investig efficaci new optim techniqu use along lll algorithm techniqu propos hill climb hc ii lattic diffus sub lattic fusion ldsf iii multistag hybrid ldsf hc first techniqu reli sensit lll permut input basi optim idea symmetr group view metric space second techniqu reli partit lattic sublattic perform basi reduct partit sublattic block fuse sublattic repeat also point place parallel comput reduc run time achiev almost linear speedup multistag hybrid techniqu reli lattic diffus sublattic fusion hill climb algorithm|['Bal K. Khadka', 'Spyros M. Magliveras']|['cs.CG']
2017-04-07T11:29:04Z|2017-02-10T17:54:59Z|http://arxiv.org/abs/1702.03266v1|http://arxiv.org/pdf/1702.03266v1|Two Optimization Problems for Unit Disks|two optim problem unit disk|We present an implementation of a recent algorithm to compute shortest-path trees in unit disk graphs in $O(n\log n)$ worst-case time, where $n$ is the number of disks.   In the minimum-separation problem, we are given $n$ unit disks and two points $s$ and $t$, not contained in any of the disks, and we want to compute the minimum number of disks one needs to retain so that any curve connecting $s$ to $t$ intersects some of the retained disks. We present a new algorithm solving this problem in $O(n^2\log^3 n)$ worst-case time and its implementation.|present implement recent algorithm comput shortest path tree unit disk graph log worst case time number disk minimum separ problem given unit disk two point contain ani disk want comput minimum number disk one need retain ani curv connect intersect retain disk present new algorithm solv problem log worst case time implement|['Sergio Cabello', 'Lazar Milinković']|['cs.CG']
2017-04-07T11:29:04Z|2017-02-10T14:37:00Z|http://arxiv.org/abs/1702.03187v1|http://arxiv.org/pdf/1702.03187v1|On vertices and facets of combinatorial 2-level polytopes|vertic facet combinatori level polytop|2-level polytopes naturally appear in several areas of pure and applied mathematics, including combinatorial optimization, polyhedral combinatorics, communication complexity, and statistics. In this paper, we present a polyhedral study of 2-level polytopes arising in combinatorial settings. For all the known (to the best of our knowledge) such polytopes P, we show that v(P).f(P) is upper bounded by d2^(d+1). Here v(P) (resp. f(P)) is the number of vertices (resp. facets) of P, and d is its dimension. Whether this holds for all 2-level polytopes was asked in [Bohn et al., ESA 2015], where experimental results showed it true up to dimension 6. The key to most of our proofs is an understanding of the combinatorial structures underlying those polytopes. This leads to a number of results that we believe to be of independent interest: a trade-off formula for the number of cliques and stable sets in a graph; a description of the facets of the base polytope of the 2-sum of matroids; a linear-size description of the base polytope of matroids that are 2-level in terms of cuts of an associated tree. We also give a self-contained proof of the characterization of the last class, a result first obtained by Grande and Sanyal.|level polytop natur appear sever area pure appli mathemat includ combinatori optim polyhedr combinator communic complex statist paper present polyhedr studi level polytop aris combinatori set known best knowledg polytop show upper bound resp number vertic resp facet dimens whether hold level polytop ask bohn et al esa experiment result show true dimens key proof understand combinatori structur polytop lead number result believ independ interest trade formula number cliqu stabl set graph descript facet base polytop sum matroid linear size descript base polytop matroid level term cut associ tree also give self contain proof character last class result first obtain grand sanyal|['Manuel Aprile', 'Alfonso Cevallos', 'Yuri Faenza']|['math.CO', 'cs.CG']
2017-04-07T11:29:04Z|2017-02-09T14:04:20Z|http://arxiv.org/abs/1702.02838v1|http://arxiv.org/pdf/1702.02838v1|The DTM-signature for a geometric comparison of metric-measure spaces   from samples|dtm signatur geometr comparison metric measur space sampl|In this paper, we introduce the notion of DTM-signature, a measure on R + that can be associated to any metric-measure space. This signature is based on the distance to a measure (DTM) introduced by Chazal, Cohen-Steiner and M\'erigot. It leads to a pseudo-metric between metric-measure spaces, upper-bounded by the Gromov-Wasserstein distance. Under some geometric assumptions, we derive lower bounds for this pseudo-metric. Given two N-samples, we also build an asymptotic statistical test based on the DTM-signature, to reject the hypothesis of equality of the two underlying metric-measure spaces, up to a measure-preserving isometry. We give strong theoretical justifications for this test and propose an algorithm for its implementation.|paper introduc notion dtm signatur measur associ ani metric measur space signatur base distanc measur dtm introduc chazal cohen steiner erigot lead pseudo metric metric measur space upper bound gromov wasserstein distanc geometr assumpt deriv lower bound pseudo metric given two sampl also build asymptot statist test base dtm signatur reject hypothesi equal two metric measur space measur preserv isometri give strong theoret justif test propos algorithm implement|['Claire Brécheteau']|['cs.CG', 'math.PR', 'math.ST', 'stat.TH']
2017-04-07T11:29:09Z|2017-02-07T01:11:38Z|http://arxiv.org/abs/1702.01836v1|http://arxiv.org/pdf/1702.01836v1|Linear Time Approximation Schemes for Geometric Maximum Coverage|linear time approxim scheme geometr maximum coverag|We study approximation algorithms for the following geometric version of the maximum coverage problem: Let $\mathcal{P}$ be a set of $n$ weighted points in the plane. Let $D$ represent a planar object, such as a rectangle, or a disk. We want to place $m$ copies of $D$ such that the sum of the weights of the points in $\mathcal{P}$ covered by these copies is maximized. For any fixed $\varepsilon>0$, we present efficient approximation schemes that can find a $(1-\varepsilon)$-approximation to the optimal solution. In particular, for $m=1$ and for the special case where $D$ is a rectangle, our algorithm runs in time $O(n\log (\frac{1}{\varepsilon}))$, improving on the previous result. For $m>1$ and the rectangular case, our algorithm runs in $O(\frac{n}{\varepsilon}\log (\frac{1}{\varepsilon})+\frac{m}{\varepsilon}\log m +m(\frac{1}{\varepsilon})^{O(\min(\sqrt{m},\frac{1}{\varepsilon}))})$ time. For a more general class of shapes (including disks, polygons with $O(1)$ edges), our algorithm runs in $O(n(\frac{1}{\varepsilon})^{O(1)}+\frac{m}{\epsilon}\log m + m(\frac{1}{\varepsilon})^{O(\min(m,\frac{1}{\varepsilon^2}))})$ time.|studi approxim algorithm follow geometr version maximum coverag problem let mathcal set weight point plane let repres planar object rectangl disk want place copi sum weight point mathcal cover copi maxim ani fix varepsilon present effici approxim scheme find varepsilon approxim optim solut particular special case rectangl algorithm run time log frac varepsilon improv previous result rectangular case algorithm run frac varepsilon log frac varepsilon frac varepsilon log frac varepsilon min sqrt frac varepsilon time general class shape includ disk polygon edg algorithm run frac varepsilon frac epsilon log frac varepsilon min frac varepsilon time|['Kai Jin', 'Jian Li', 'Haitao Wang', 'Bowei Zhang', 'Ningye Zhang']|['cs.CG', 'F.2.2']
2017-04-07T11:29:09Z|2017-02-06T21:31:57Z|http://arxiv.org/abs/1702.01799v1|http://arxiv.org/pdf/1702.01799v1|Radial Contour Labeling with Straight Leaders|radial contour label straight leader|The usefulness of technical drawings as well as scientific illustrations such as medical drawings of human anatomy essentially depends on the placement of labels that describe all relevant parts of the figure. In order to not spoil or clutter the figure with text, the labels are often placed around the figure and are associated by thin connecting lines to their features, respectively. This labeling technique is known as external label placement.   In this paper we introduce a flexible and general approach for external label placement assuming a contour of the figure prescribing the possible positions of the labels. While much research on external label placement aims for fast labeling procedures for interactive systems, we focus on highest-quality illustrations. Based on interviews with domain experts and a semi-automatic analysis of 202 handmade anatomical drawings, we identify a set of 18 layout quality criteria, naturally not all of equal importance. We design a new geometric label placement algorithm that is based only on the most important criteria. Yet, other criteria can flexibly be included in the algorithm, either as hard constraints not to be violated or as soft constraints whose violation is penalized by a general cost function. We formally prove that our approach yields labelings that satisfy all hard constraints and have minimum overall cost. Introducing several speedup techniques, we further demonstrate how to deploy our approach in practice. In an experimental evaluation on real-world anatomical drawings we show that the resulting labelings are of high quality and can be produced in adequate time.|use technic draw well scientif illustr medic draw human anatomi essenti depend placement label describ relev part figur order spoil clutter figur text label often place around figur associ thin connect line featur respect label techniqu known extern label placement paper introduc flexibl general approach extern label placement assum contour figur prescrib possibl posit label much research extern label placement aim fast label procedur interact system focus highest qualiti illustr base interview domain expert semi automat analysi handmad anatom draw identifi set layout qualiti criteria natur equal import design new geometr label placement algorithm base onli import criteria yet criteria flexibl includ algorithm either hard constraint violat soft constraint whose violat penal general cost function formal prove approach yield label satisfi hard constraint minimum overal cost introduc sever speedup techniqu demonstr deploy approach practic experiment evalu real world anatom draw show result label high qualiti produc adequ time|['Benjamin Niedermann', 'Martin Nöllenburg', 'Ignaz Rutter']|['cs.CG']
2017-04-07T11:29:09Z|2017-02-06T17:38:26Z|http://arxiv.org/abs/1702.01719v1|http://arxiv.org/pdf/1702.01719v1|A 2-Approximation for the Height of Maximal Outerplanar Graph Drawings|approxim height maxim outerplanar graph draw|In this paper, we study planar drawings of maximal outerplanar graphs with the objective of achieving small height. A recent paper gave an algorithm for such drawings that is within a factor of 4 of the optimum height. In this paper, we substantially improve the approximation factor to become 2. The main ingredient is to define a new parameter of outerplanar graphs (the so-called umbrella depth, obtained by recursively splitting the graph into graphs called umbrellas). We argue that the height of any poly-line drawing must be at least the umbrella depth, and then devise an algorithm that achieves height at most twice the umbrella depth.|paper studi planar draw maxim outerplanar graph object achiev small height recent paper gave algorithm draw within factor optimum height paper substanti improv approxim factor becom main ingredi defin new paramet outerplanar graph call umbrella depth obtain recurs split graph graph call umbrella argu height ani poli line draw must least umbrella depth devis algorithm achiev height twice umbrella depth|['Therese Biedl', 'Philippe Demontigny']|['cs.DS', 'cs.CG']
2017-04-07T11:29:09Z|2017-02-06T08:01:16Z|http://arxiv.org/abs/1702.01524v1|http://arxiv.org/pdf/1702.01524v1|Edge N-Level Sparse Visibility Graphs: Fast Optimal Any-Angle   Pathfinding Using Hierarchical Taut Paths|edg level spars visibl graph fast optim ani angl pathfind use hierarch taut path|In the Any-Angle Pathfinding problem, the goal is to find the shortest path between a pair of vertices on a uniform square grid, that is not constrained to any fixed number of possible directions over the grid. Visibility Graphs are a known optimal algorithm for solving the problem with the use of pre-processing. However, Visibility Graphs are known to perform poorly in terms of running time, especially on large, complex maps. In this paper, we introduce two improvements over the Visibility Graph Algorithm to compute optimal paths. Sparse Visibility Graphs (SVGs) are constructed by pruning unnecessary edges from the original Visibility Graph. Edge N-Level Sparse Visibility Graphs (ENLSVGs) is a hierarchical SVG built by iteratively pruning non-taut paths. We also introduce Line-of-Sight Scans, a faster algorithm for building Visibility Graphs over a grid. SVGs run much faster than Visibility Graphs by reducing the average vertex degree. ENLSVGs, a hierarchical algorithm, improves this further, especially on larger maps. On large maps, with the use of pre-processing, these algorithms are orders of magnitude faster than existing algorithms like Visibility Graphs and Theta*.|ani angl pathfind problem goal find shortest path pair vertic uniform squar grid constrain ani fix number possibl direct grid visibl graph known optim algorithm solv problem use pre process howev visibl graph known perform poor term run time especi larg complex map paper introduc two improv visibl graph algorithm comput optim path spars visibl graph svgs construct prune unnecessari edg origin visibl graph edg level spars visibl graph enlsvg hierarch svg built iter prune non taut path also introduc line sight scan faster algorithm build visibl graph grid svgs run much faster visibl graph reduc averag vertex degre enlsvg hierarch algorithm improv especi larger map larg map use pre process algorithm order magnitud faster exist algorithm like visibl graph theta|['Shunhao Oh', 'Hon Wai Leong']|['cs.CG']
2017-04-07T11:29:09Z|2017-02-09T01:46:20Z|http://arxiv.org/abs/1702.01446v2|http://arxiv.org/pdf/1702.01446v2|Efficient Algorithms for k-Regret Minimizing Sets|effici algorithm regret minim set|A regret minimizing set Q is a small size representation of a much larger database P so that user queries executed on Q return answers whose scores are not much worse than those on the full dataset. In particular, a k-regret minimizing set has the property that the regret ratio between the score of the top-1 item in Q and the score of the top-k item in P is minimized, where the score of an item is the inner product of the item's attributes with a user's weight (preference) vector. The problem is challenging because we want to find a single representative set Q whose regret ratio is small with respect to all possible user weight vectors.   We show that k-regret minimization is NP-Complete for all dimensions d >= 3. This settles an open problem from Chester et al. [VLDB 2014], and resolves the complexity status of the problem for all d: the problem is known to have polynomial-time solution for d <= 2. In addition, we propose two new approximation schemes for regret minimization, both with provable guarantees, one based on coresets and another based on hitting sets. We also carry out extensive experimental evaluation, and show that our schemes compute regret-minimizing sets comparable in size to the greedy algorithm proposed in [VLDB 14] but our schemes are significantly faster and scalable to large data sets.|regret minim set small size represent much larger databas user queri execut return answer whose score much wors full dataset particular regret minim set properti regret ratio score top item score top item minim score item inner product item attribut user weight prefer vector problem challeng becaus want find singl repres set whose regret ratio small respect possibl user weight vector show regret minim np complet dimens settl open problem chester et al vldb resolv complex status problem problem known polynomi time solut addit propos two new approxim scheme regret minim provabl guarante one base coreset anoth base hit set also carri extens experiment evalu show scheme comput regret minim set compar size greedi algorithm propos vldb scheme signific faster scalabl larg data set|['Pankaj K. Agarwal', 'Nirman Kumar', 'Stavros Sintos', 'Subhash Suri']|['cs.DS', 'cs.CG', 'cs.DB']
2017-04-07T11:29:09Z|2017-02-04T11:51:50Z|http://arxiv.org/abs/1702.01277v1|http://arxiv.org/pdf/1702.01277v1|Geometric Biplane Graphs II: Graph Augmentation|geometr biplan graph ii graph augment|We study biplane graphs drawn on a finite point set $S$ in the plane in general position. This is the family of geometric graphs whose vertex set is $S$ and which can be decomposed into two plane graphs. We show that every sufficiently large point set admits a 5-connected biplane graph and that there are arbitrarily large point sets that do not admit any 6-connected biplane graph. Furthermore, we show that every plane graph (other than a wheel or a fan) can be augmented into a 4-connected biplane graph. However, there are arbitrarily large plane graphs that cannot be augmented to a 5-connected biplane graph by adding pairwise noncrossing edges.|studi biplan graph drawn finit point set plane general posit famili geometr graph whose vertex set decompos two plane graph show everi suffici larg point set admit connect biplan graph arbitrarili larg point set admit ani connect biplan graph furthermor show everi plane graph wheel fan augment connect biplan graph howev arbitrarili larg plane graph cannot augment connect biplan graph ad pairwis noncross edg|['Alfredo García', 'Ferran Hurtado', 'Matias Korman', 'Inês Matos', 'Maria Saumell', 'Rodrigo I. Silveira', 'Javier Tejel', 'Csaba D. Tóth']|['cs.CG']
2017-04-07T11:29:09Z|2017-02-04T11:51:44Z|http://arxiv.org/abs/1702.01275v1|http://arxiv.org/pdf/1702.01275v1|Geometric Biplane Graphs I: Maximal Graphs|geometr biplan graph maxim graph|We study biplane graphs drawn on a finite planar point set $S$ in general position. This is the family of geometric graphs whose vertex set is $S$ and can be decomposed into two plane graphs. We show that two maximal biplane graphs---in the sense that no edge can be added while staying biplane---may differ in the number of edges, and we provide an efficient algorithm for adding edges to a biplane graph to make it maximal. We also study extremal properties of maximal biplane graphs such as the maximum number of edges and the largest maximum connectivity over $n$-element point sets.|studi biplan graph drawn finit planar point set general posit famili geometr graph whose vertex set decompos two plane graph show two maxim biplan graph sens edg ad stay biplan may differ number edg provid effici algorithm ad edg biplan graph make maxim also studi extrem properti maxim biplan graph maximum number edg largest maximum connect element point set|['Alfredo García', 'Ferran Hurtado', 'Matias Korman', 'Inês Matos', 'Maria Saumell', 'Rodrigo I. Silveira', 'Javier Tejel', 'Csaba D. Tóth']|['cs.CG']
2017-04-07T11:29:09Z|2017-02-02T22:20:25Z|http://arxiv.org/abs/1702.00849v1|http://arxiv.org/pdf/1702.00849v1|On the union complexity of families of axis-parallel rectangles with a   low packing number|union complex famili axi parallel rectangl low pack number|Let R be a family of n axis-parallel rectangles with packing number p-1, meaning that among any p of the rectangles, there are two with a non-empty intersection. We show that the union complexity of R is at most O(n+p^2), and that the (<=k)-level complexity of R is at most O(kn+k^2p^2). Both upper bounds are tight.|let famili axi parallel rectangl pack number mean among ani rectangl two non empti intersect show union complex level complex kn upper bound tight|['Chaya Keller', 'Shakhar Smorodinsky']|['math.CO', 'cs.CG', '52C45, 52C15']
2017-04-07T11:29:09Z|2017-02-01T16:55:41Z|http://arxiv.org/abs/1702.00353v1|http://arxiv.org/pdf/1702.00353v1|The non-cooperative tile assembly model is not intrinsically universal   or capable of bounded Turing machine simulation|non cooper tile assembl model intrins univers capabl bound ture machin simul|The field of algorithmic self-assembly is concerned with the computational and expressive power of nanoscale self-assembling molecular systems. In the well-studied cooperative, or temperature 2, abstract tile assembly model it is known that there is a tile set to simulate any Turing machine and an intrinsically universal tile set that simulates the shapes and dynamics of any instance of the model, up to spatial rescaling. It has been an open question as to whether the seemingly simpler noncooperative, or temperature 1, model is capable of such behaviour. Here we show that this is not the case, by showing that there is no tile set in the noncooperative model that is intrinsically universal, nor one capable of time-bounded Turing machine simulation within a bounded region of the plane.   Although the noncooperative model intuitively seems to lack the complexity and power of the cooperative model it has been exceedingly hard to prove this. One reason is that there have been few tools to analyse the structure of complicated paths in the plane. This paper provides a number of such tools. A second reason is that almost every obvious and small generalisation to the model (e.g. allowing error, 3D, non-square tiles, signals/wires on tiles, tiles that repel each other, parallel synchronous growth) endows it with great computational, and sometimes simulation, power. Our main results show that all of these generalisations provably increase computational and/or simulation power. Our results hold for both deterministic and nondeterministic noncooperative systems. Our first main result stands in stark contrast with the fact that for both the cooperative tile assembly model, and for 3D noncooperative tile assembly, there are respective intrinsically universal tilesets. Our second main result gives a new technique (reduction to simulation) for proving negative results about computation in tile assembly.|field algorithm self assembl concern comput express power nanoscal self assembl molecular system well studi cooper temperatur abstract tile assembl model known tile set simul ani ture machin intrins univers tile set simul shape dynam ani instanc model spatial rescal open question whether seem simpler noncoop temperatur model capabl behaviour show case show tile set noncoop model intrins univers one capabl time bound ture machin simul within bound region plane although noncoop model intuit seem lack complex power cooper model exceed hard prove one reason tool analys structur complic path plane paper provid number tool second reason almost everi obvious small generalis model allow error non squar tile signal wire tile tile repel parallel synchron growth endow great comput sometim simul power main result show generalis provabl increas comput simul power result hold determinist nondeterminist noncoop system first main result stand stark contrast fact cooper tile assembl model noncoop tile assembl respect intrins univers tileset second main result give new techniqu reduct simul prove negat result comput tile assembl|['Pierre-Étienne Meunier', 'Damien Woods']|['cs.CC', 'cs.CG', 'cs.DS']
2017-04-07T11:29:09Z|2017-02-01T06:45:40Z|http://arxiv.org/abs/1702.00146v1|http://arxiv.org/pdf/1702.00146v1|Untangling Planar Curves|untangl planar curv|Any generic closed curve in the plane can be transformed into a simple closed curve by a finite sequence of local transformations called homotopy moves. We prove that simplifying a planar closed curve with $n$ self-crossings requires $\Theta(n^{3/2})$ homotopy moves in the worst case. Our algorithm improves the best previous upper bound $O(n^2)$, which is already implicit in the classical work of Steinitz; the matching lower bound follows from the construction of closed curves with large defect, a topological invariant of generic closed curves introduced by Aicardi and Arnold. Our lower bound also implies that $\Omega(n^{3/2})$ facial electrical transformations are required to reduce any plane graph with treewidth $\Omega(\sqrt{n})$ to a single vertex, matching known upper bounds for rectangular and cylindrical grid graphs. More generally, we prove that transforming one immersion of $k$ circles with at most $n$ self-crossings into another requires $\Theta(n^{3/2} + nk + k^2)$ homotopy moves in the worst case. Finally, we prove that transforming one noncontractible closed curve to another on any orientable surface requires $\Omega(n^2)$ homotopy moves in the worst case; this lower bound is tight if the curve is homotopic to a simple closed curve.|ani generic close curv plane transform simpl close curv finit sequenc local transform call homotopi move prove simplifi planar close curv self cross requir theta homotopi move worst case algorithm improv best previous upper bound alreadi implicit classic work steinitz match lower bound follow construct close curv larg defect topolog invari generic close curv introduc aicardi arnold lower bound also impli omega facial electr transform requir reduc ani plane graph treewidth omega sqrt singl vertex match known upper bound rectangular cylindr grid graph general prove transform one immers circl self cross anoth requir theta nk homotopi move worst case final prove transform one noncontract close curv anoth ani orient surfac requir omega homotopi move worst case lower bound tight curv homotop simpl close curv|['Hsien-Chih Chang', 'Jeff Erickson']|['cs.CG', 'math.GT']
2017-04-07T11:29:14Z|2017-01-29T19:55:27Z|http://arxiv.org/abs/1701.08423v1|http://arxiv.org/pdf/1701.08423v1|One Size Fits All : Effectiveness of Local Search on Structured Data|one size fit effect local search structur data|In this paper, we analyze the performance of a simple and standard Local Search algorithm for clustering on well behaved data. Since the seminal paper by Ostrovsky, Rabani, Schulman and Swamy [FOCS 2006], much progress has been made to characterize real-world instances. We distinguish the three main definitions -- Distribution Stability (Awasthi, Blum, Sheffet, FOCS 2010) -- Spectral Separability (Kumar, Kannan, FOCS 2010) -- Perturbation Resilience (Bilu, Linial, ICS 2010) We show that Local Search performs well on the instances with the aforementioned stability properties. Specifically, for the $k$-means and $k$-median objective, we show that Local Search exactly recovers the optimal clustering if the dataset is $3+\varepsilon$-perturbation resilient, and is a PTAS for distribution stability and spectral separability. This implies the first PTAS for instances satisfying the spectral separability condition. For the distribution stability condition we also go beyond previous work by showing that the clustering output by the algorithm and the optimal clustering are very similar. This is a significant step toward understanding the success of Local Search heuristics in clustering applications and supports the legitimacy of the stability conditions: They characterize some of the structure of real-world instances that make Local Search a popular heuristic.|paper analyz perform simpl standard local search algorithm cluster well behav data sinc semin paper ostrovski rabani schulman swami foc much progress made character real world instanc distinguish three main definit distribut stabil awasthi blum sheffet foc spectral separ kumar kannan foc perturb resili bilu linial ic show local search perform well instanc aforement stabil properti specif mean median object show local search exact recov optim cluster dataset varepsilon perturb resili ptas distribut stabil spectral separ impli first ptas instanc satisfi spectral separ condit distribut stabil condit also go beyond previous work show cluster output algorithm optim cluster veri similar signific step toward understand success local search heurist cluster applic support legitimaci stabil condit character structur real world instanc make local search popular heurist|['Vincent Cohen-Addad', 'Chris Schwiegelshohn']|['cs.DS', 'cs.CG', 'cs.LG']
2017-04-07T11:29:14Z|2017-01-19T18:01:10Z|http://arxiv.org/abs/1701.05532v1|http://arxiv.org/pdf/1701.05532v1|Tighter Bounds for the Discrepancy of Boxes and Polytopes|tighter bound discrep box polytop|Combinatorial discrepancy is a complexity measure of a collection of sets which quantifies how well the sets in the collection can be simultaneously balanced. More precisely, we are given an n-point set $P$, and a collection $\mathcal{F} = \{F_1, ..., F_m\}$ of subsets of $P$, and our goal is color $P$ with two colors, red and blue, so that the largest absolute difference between the number of red elements and the number of blue elements (i.e. the discrepancy) in any $F_i$ is minimized. Combinatorial discrepancy has many applications in mathematics and computer science, including constructions of uniformly distributed point sets, and lower bounds for data structures and private data analysis algorithms.   We investigate the combinatorial discrepancy of geometrically defined set systems, in which $P$ is an n-point set in $d$-dimensional space, and $\mathcal{F}$ is the collection of subsets of $P$ induced by dilations and translations of a fixed convex polytope $B$. Such set systems include sets induced by axis-aligned boxes, whose discrepancy is the subject of the well known Tusnady problem. We prove new discrepancy upper bounds for such set systems by extending the approach based on factorization norms previously used by the author and Matousek. We improve the best known upper bound for the Tusnady problem by a logarithmic factor, using a result of Banaszczyk on signed series of vectors. We extend this improvement to any arbitrary convex polytope B by using a decomposition due to Matousek.|combinatori discrep complex measur collect set quantifi well set collect simultan balanc precis given point set collect mathcal subset goal color two color red blue largest absolut differ number red element number blue element discrep ani minim combinatori discrep mani applic mathemat comput scienc includ construct uniform distribut point set lower bound data structur privat data analysi algorithm investig combinatori discrep geometr defin set system point set dimension space mathcal collect subset induc dilat translat fix convex polytop set system includ set induc axi align box whose discrep subject well known tusnadi problem prove new discrep upper bound set system extend approach base factor norm previous use author matousek improv best known upper bound tusnadi problem logarithm factor use result banaszczyk sign seri vector extend improv ani arbitrari convex polytop use decomposit due matousek|['Aleksandar Nikolov']|['math.CO', 'cs.CG']
2017-04-07T11:29:14Z|2017-01-19T16:24:27Z|http://arxiv.org/abs/1701.05500v1|http://arxiv.org/pdf/1701.05500v1|The number of realizations of a Laman graph|number realize laman graph|Laman graphs model planar frameworks that are rigid for a general choice of distances between the vertices. There are finitely many ways, up to isometries, to realize a Laman graph in the plane. Such realizations can be seen as solutions of systems of quadratic equations prescribing the distances between pairs of points. Using ideas from algebraic and tropical geometry, we provide a recursion formula for the number of complex solutions of such systems.|laman graph model planar framework rigid general choic distanc vertic finit mani way isometri realiz laman graph plane realize seen solut system quadrat equat prescrib distanc pair point use idea algebra tropic geometri provid recurs formula number complex solut system|['Jose Capco', 'Matteo Gallet', 'Georg Grasegger', 'Christoph Koutschan', 'Niels Lubbes', 'Josef Schicho']|['math.AG', 'cs.CG', 'cs.SC', 'math.CO', '14T05, 14N99, 52C25, 05C99']
2017-04-07T11:29:14Z|2017-01-19T15:33:50Z|http://arxiv.org/abs/1701.05475v1|http://arxiv.org/pdf/1701.05475v1|Irrational Guards are Sometimes Needed|irrat guard sometim need|In this paper we study the art gallery problem, which is one of the fundamental problems in computational geometry. The objective is to place a minimum number of guards inside a simple polygon such that the guards together can see the whole polygon. We say that a guard at position $x$ sees a point $y$ if the line segment $xy$ is fully contained in the polygon.   Despite an extensive study of the art gallery problem, it remained an open question whether there are polygons given by integer coordinates that require guard positions with irrational coordinates in any optimal solution. We give a positive answer to this question by constructing a monotone polygon with integer coordinates that can be guarded by three guards only when we allow to place the guards at points with irrational coordinates. Otherwise, four guards are needed. By extending this example, we show that for every $n$, there is polygon which can be guarded by $3n$ guards with irrational coordinates but need $4n$ guards if the coordinates have to be rational. Subsequently, we show that there are rectilinear polygons given by integer coordinates that require guards with irrational coordinates in any optimal solution.|paper studi art galleri problem one fundament problem comput geometri object place minimum number guard insid simpl polygon guard togeth see whole polygon say guard posit see point line segment xy fulli contain polygon despit extens studi art galleri problem remain open question whether polygon given integ coordin requir guard posit irrat coordin ani optim solut give posit answer question construct monoton polygon integ coordin guard three guard onli allow place guard point irrat coordin otherwis four guard need extend exampl show everi polygon guard guard irrat coordin need guard coordin ration subsequ show rectilinear polygon given integ coordin requir guard irrat coordin ani optim solut|['Mikkel Abrahamsen', 'Anna Adamaszek', 'Tillmann Miltzow']|['cs.CG', 'cs.DM', 'math.CO']
2017-04-07T11:29:14Z|2017-01-19T03:57:28Z|http://arxiv.org/abs/1701.05290v1|http://arxiv.org/pdf/1701.05290v1|Range-efficient consistent sampling and locality-sensitive hashing for   polygons|rang effici consist sampl local sensit hash polygon|Locality-sensitive hashing (LSH) is a fundamental technique for similarity search and similarity estimation in high-dimensional spaces. The basic idea is that similar objects should produce hash collisions with probability significantly larger than objects with low similarity. We consider LSH for objects that can be represented as point sets in either one or two dimensions. To make the point sets finite size we consider the subset of points on a grid. Directly applying LSH (e.g. min-wise hashing) to these point sets would require time proportional to the number of points. We seek to achieve time that is much lower than direct approaches.   Technically, we introduce new primitives for range-efficient consistent sampling (of independent interest), and show how to turn such samples into LSH values. Another application of our technique is a data structure for quickly estimating the size of the intersection or union of a set of preprocessed polygons. Curiously, our consistent sampling method uses transformation to a geometric problem.|local sensit hash lsh fundament techniqu similar search similar estim high dimension space basic idea similar object produc hash collis probabl signific larger object low similar consid lsh object repres point set either one two dimens make point set finit size consid subset point grid direct appli lsh min wise hash point set would requir time proport number point seek achiev time much lower direct approach technic introduc new primit rang effici consist sampl independ interest show turn sampl lsh valu anoth applic techniqu data structur quick estim size intersect union set preprocess polygon curious consist sampl method use transform geometr problem|['Joachim Gudmundsson', 'Rasmus Pagh']|['cs.CG', '68U05', 'F.2.2']
2017-04-07T11:29:14Z|2017-01-19T03:20:51Z|http://arxiv.org/abs/1701.05286v1|http://arxiv.org/pdf/1701.05286v1|Algorithms For Longest Chains In Pseudo- Transitive Graphs|algorithm longest chain pseudo transit graph|A directed acyclic graph G = (V, E) is pseudo-transitive with respect to a given subset of edges E1, if for any edge ab in E1 and any edge bc in E, we have ac in E. We give algorithms for computing longest chains and demonstrate geometric applications that unify and improves some important past results. (For specific applications see the introduction.)|direct acycl graph pseudo transit respect given subset edg ani edg ab ani edg bc ac give algorithm comput longest chain demonstr geometr applic unifi improv import past result specif applic see introduct|['Farhad Shahrokhi']|['cs.CG', 'math.CO']
2017-04-07T11:29:14Z|2017-01-18T16:46:08Z|http://arxiv.org/abs/1701.05141v1|http://arxiv.org/pdf/1701.05141v1|The Explicit Corridor Map: A Medial Axis-Based Navigation Mesh for   Multi-Layered Environments|explicit corridor map medial axi base navig mesh multi layer environ|Path planning for walking characters in complicated virtual environments is a fundamental task in simulations and games. In this paper, we present an improved definition of the Explicit Corridor Map (ECM), a navigation mesh that allows efficient path planning and crowd simulation for disk-shaped characters of any radius. The ECM is a medial axis (MA) annotated with nearest-obstacle information. For a planar environment with $n$ obstacle vertices, the ECM has size $O(n)$ and can be computed in $O(n \log n)$ time.   We also introduce multi-layered environments (MLEs), in which multiple planar layers are connected by line segment connections. Typical real-world examples are multi-storey buildings, train stations, and sports stadiums. We define the MA and the ECM for multi-layered environments, based on projected distances on the ground plane. For an MLE with $n$ obstacle points and $k$ connections, the MA has size $O(n)$. We present an improved algorithm that constructs the MA and ECM in $O(n \log n \log k)$ time.   Our implementations show that the ECM can be computed efficiently for large 2D and multi-layered environments, and that it can be used to compute paths within milliseconds. This enables simulations of large virtual crowds of heterogeneous characters in real-time.|path plan walk charact complic virtual environ fundament task simul game paper present improv definit explicit corridor map ecm navig mesh allow effici path plan crowd simul disk shape charact ani radius ecm medial axi annot nearest obstacl inform planar environ obstacl vertic ecm size comput log time also introduc multi layer environ mles multipl planar layer connect line segment connect typic real world exampl multi storey build train station sport stadium defin ecm multi layer environ base project distanc ground plane mle obstacl point connect size present improv algorithm construct ecm log log time implement show ecm comput effici larg multi layer environ use comput path within millisecond enabl simul larg virtual crowd heterogen charact real time|['Wouter van Toll', 'Atlas F. Cook IV', 'Marc J. van Kreveld', 'Roland Geraerts']|['cs.CG', 'cs.DS']
2017-04-07T11:29:14Z|2017-01-13T15:08:46Z|http://arxiv.org/abs/1701.03693v1|http://arxiv.org/pdf/1701.03693v1|Multivariate Analysis for Computing Maxima in High Dimensions|multivari analysi comput maxima high dimens|We study the problem of computing the \textsc{Maxima} of a set of $n$ $d$-dimensional points. For dimensions 2 and 3, there are algorithms to solve the problem with order-oblivious instance-optimal running time. However, in higher dimensions there is still room for improvements. We present an algorithm sensitive to the structural entropy of the input set, which improves the running time, for large classes of instances, on the best solution for \textsc{Maxima} to date for $d \ge 4$.|studi problem comput textsc maxima set dimension point dimens algorithm solv problem order oblivi instanc optim run time howev higher dimens still room improv present algorithm sensit structur entropi input set improv run time larg class instanc best solut textsc maxima date ge|['Jérémy Barbay', 'Javiel Rojas']|['cs.CG', 'cs.DS', 'F.2.2']
2017-04-07T11:29:14Z|2017-01-12T16:01:50Z|http://arxiv.org/abs/1701.03388v1|http://arxiv.org/pdf/1701.03388v1|Dynamic and Kinetic Conflict-Free Coloring of Intervals with Respect to   Points|dynam kinet conflict free color interv respect point|We introduce the dynamic conflict-free coloring problem for a set $S$ of intervals in $\mathbb{R}^1$ with respect to points, where the goal is to maintain a conflict-free coloring for $S$ under insertions and deletions. We investigate trade-offs between the number of colors used and the number of intervals that are recolored upon insertion or deletion of an interval. Our results include:   - a lower bound on the number of recolorings as a function of the number of colors, which implies that with $O(1)$ recolorings per update the worst-case number of colors is $\Omega(\log n/\log\log n)$, and that any strategy using $O(1/\varepsilon)$ colors needs $\Omega(\varepsilon n^{\varepsilon})$ recolorings;   - a coloring strategy that uses $O(\log n)$ colors at the cost of $O(\log n)$ recolorings, and another strategy that uses $O(1/\varepsilon)$ colors at the cost of $O(n^{\varepsilon}/\varepsilon)$ recolorings;   - stronger upper and lower bounds for special cases.   We also consider the kinetic setting where the intervals move continuously (but there are no insertions or deletions); here we show how to maintain a coloring with only four colors at the cost of three recolorings per event and show this is tight.|introduc dynam conflict free color problem set interv mathbb respect point goal maintain conflict free color insert delet investig trade number color use number interv recolor upon insert delet interv result includ lower bound number recolor function number color impli recolor per updat worst case number color omega log log log ani strategi use varepsilon color need omega varepsilon varepsilon recolor color strategi use log color cost log recolor anoth strategi use varepsilon color cost varepsilon varepsilon recolor stronger upper lower bound special case also consid kinet set interv move continu insert delet show maintain color onli four color cost three recolor per event show tight|['Mark de Berg', 'Tim Leijsen', 'André van Renssen', 'Marcel Roeloffzen', 'Aleksandar Markovic', 'Gerhard Woeginger']|['cs.CG']
2017-04-07T11:29:15Z|2017-01-12T04:51:15Z|http://arxiv.org/abs/1701.03230v1|http://arxiv.org/pdf/1701.03230v1|Surface Reconstruction with Data-driven Exemplar Priors|surfac reconstruct data driven exemplar prior|In this paper, we propose a framework to reconstruct 3D models from raw scanned points by learning the prior knowledge of a specific class of objects. Unlike previous work that heuristically specifies particular regularities and defines parametric models, our shape priors are learned directly from existing 3D models under a framework based on affinity propagation. Given a database of 3D models within the same class of objects, we build a comprehensive library of 3D local shape priors. We then formulate the problem to select as-few-as-possible priors from the library, referred to as exemplar priors. These priors are sufficient to represent the 3D shapes of the whole class of objects from where they are generated. By manipulating these priors, we are able to reconstruct geometrically faithful models with the same class of objects from raw point clouds. Our framework can be easily generalized to reconstruct various categories of 3D objects that have more geometrically or topologically complex structures. Comprehensive experiments exhibit the power of our exemplar priors for gracefully solving several problems in 3D shape reconstruction such as preserving sharp features, recovering fine details and so on.|paper propos framework reconstruct model raw scan point learn prior knowledg specif class object unlik previous work heurist specifi particular regular defin parametr model shape prior learn direct exist model framework base affin propag given databas model within class object build comprehens librari local shape prior formul problem select possibl prior librari refer exemplar prior prior suffici repres shape whole class object generat manipul prior abl reconstruct geometr faith model class object raw point cloud framework easili general reconstruct various categori object geometr topolog complex structur comprehens experi exhibit power exemplar prior grace solv sever problem shape reconstruct preserv sharp featur recov fine detail|['Oussama Remil', 'Qian Xie', 'Xingyu Xie', 'Kai Xu', 'Jun Wang']|['cs.CG', 'cs.GR']
2017-04-07T11:29:18Z|2017-01-11T04:04:43Z|http://arxiv.org/abs/1701.02843v1|http://arxiv.org/pdf/1701.02843v1|Solve Partial Differential Equations on Manifold From Incomplete   Inter-Point Distance|solv partial differenti equat manifold incomplet inter point distanc|Solutions of partial differential equations (PDEs) on manifolds have provided important applications in different fields in science and engineering. Existing methods are majorly based on discretization of manifolds as implicit functions, triangle meshes, or point clouds, where the manifold structure is approximated by either zero level set of an implicit function or a set of points. In many applications, manifolds might be only provided as an inter-point distance matrix with possible missing values. This paper discusses a framework to discretize PDEs on manifolds represented as incomplete distance information. Without conducting a time-consuming global coordinates reconstruction, we propose a more efficient strategy by discretizing differential operators only based on point-wisely local reconstruction. Our local reconstruction model is based on the recent advances of low-rank matrix completion theory, where only a very small random portion of distance information is required. This method enables us to conduct analyses of incomplete distance data using solutions of special designed PDEs such as the Laplace-Beltrami (LB) eigen-system. As an application, we demonstrate a new way of manifold reconstruction from an incomplete distance by stitching patches using the spectrum of the LB operator. Intensive numerical experiments demonstrate the effectiveness of the proposed methods.|solut partial differenti equat pdes manifold provid import applic differ field scienc engin exist method major base discret manifold implicit function triangl mesh point cloud manifold structur approxim either zero level set implicit function set point mani applic manifold might onli provid inter point distanc matrix possibl miss valu paper discuss framework discret pdes manifold repres incomplet distanc inform without conduct time consum global coordin reconstruct propos effici strategi discret differenti oper onli base point wise local reconstruct local reconstruct model base recent advanc low rank matrix complet theori onli veri small random portion distanc inform requir method enabl us conduct analys incomplet distanc data use solut special design pdes laplac beltrami lb eigen system applic demonstr new way manifold reconstruct incomplet distanc stitch patch use spectrum lb oper intens numer experi demonstr effect propos method|['Rongjie Lai', 'Jia Li']|['math.NA', 'cs.CG', '65D18, 65D25, 65N25']
2017-04-07T11:29:18Z|2017-01-09T16:17:10Z|http://arxiv.org/abs/1701.02229v1|http://arxiv.org/pdf/1701.02229v1|Searching edges in the overlap of two plane graphs|search edg overlap two plane graph|Consider a pair of plane straight-line graphs, whose edges are colored red and blue, respectively, and let n be the total complexity of both graphs. We present a O(n log n)-time O(n)-space technique to preprocess such pair of graphs, that enables efficient searches among the red-blue intersections along edges of one of the graphs. Our technique has a number of applications to geometric problems. This includes: (1) a solution to the batched red-blue search problem [Dehne et al. 2006] in O(n log n) queries to the oracle; (2) an algorithm to compute the maximum vertical distance between a pair of 3D polyhedral terrains one of which is convex in O(n log n) time, where n is the total complexity of both terrains; (3) an algorithm to construct the Hausdorff Voronoi diagram of a family of point clusters in the plane in O((n+m) log^3 n) time and O(n+m) space, where n is the total number of points in all clusters and m is the number of crossings between all clusters; (4) an algorithm to construct the farthest-color Voronoi diagram of the corners of n axis-aligned rectangles in O(n log^2 n) time; (5) an algorithm to solve the stabbing circle problem for n parallel line segments in the plane in optimal O(n log n) time. All these results are new or improve on the best known algorithms.|consid pair plane straight line graph whose edg color red blue respect let total complex graph present log time space techniqu preprocess pair graph enabl effici search among red blue intersect along edg one graph techniqu number applic geometr problem includ solut batch red blue search problem dehn et al log queri oracl algorithm comput maximum vertic distanc pair polyhedr terrain one convex log time total complex terrain algorithm construct hausdorff voronoi diagram famili point cluster plane log time space total number point cluster number cross cluster algorithm construct farthest color voronoi diagram corner axi align rectangl log time algorithm solv stab circl problem parallel line segment plane optim log time result new improv best known algorithm|['John Iacono', 'Elena Khramtcova', 'Stefan Langerman']|['cs.CG']
2017-04-07T11:29:18Z|2017-01-09T15:18:28Z|http://arxiv.org/abs/1701.02208v1|http://arxiv.org/pdf/1701.02208v1|Barcodes of Towers and a Streaming Algorithm for Persistent Homology|barcod tower stream algorithm persist homolog|A tower is a sequence of simplicial complexes connected by simplicial maps. We show how to compute a filtration, a sequence of nested simplicial complexes, with the same persistent barcode as the tower. Our approach is based on the coning strategy by Dey et al. (SoCG 2014). We show that a variant of this approach yields a filtration that is asymptotically only marginally larger than the tower and can be efficiently computed by a streaming algorithm, both in theory and in practice. Furthermore, we show that our approach can be combined with a streaming algorithm to compute the barcode of the tower via matrix reduction. The space complexity of the algorithm does not depend on the length of the tower, but the maximal size of any subcomplex within the tower.|tower sequenc simplici complex connect simplici map show comput filtrat sequenc nest simplici complex persist barcod tower approach base cone strategi dey et al socg show variant approach yield filtrat asymptot onli margin larger tower effici comput stream algorithm theori practic furthermor show approach combin stream algorithm comput barcod tower via matrix reduct space complex algorithm doe depend length tower maxim size ani subcomplex within tower|['Michael Kerber', 'Hannah Schreiber']|['math.AT', 'cs.CG']
2017-04-07T11:29:18Z|2017-02-22T20:40:08Z|http://arxiv.org/abs/1701.02200v2|http://arxiv.org/pdf/1701.02200v2|Bounding a global red-blue proportion using local conditions|bound global red blue proport use local condit|"We study the following local-to-global phenomenon: Let $B$ and $R$ be two finite sets of (blue and red) points in the Euclidean plane $\mathbb{R}^2$. Suppose that in each ""neighborhood"" of a red point, the number of blue points is at least as large as the number of red points. We show that in this case the total number of blue points is at least one fifth of the total number of red points. We also show that this bound is optimal and we generalize the result to arbitrary dimension and arbitrary norm using results from Minkowski arrangements."|studi follow local global phenomenon let two finit set blue red point euclidean plane mathbb suppos neighborhood red point number blue point least larg number red point show case total number blue point least one fifth total number red point also show bound optim general result arbitrari dimens arbitrari norm use result minkowski arrang|['Márton Naszódi', 'Leonardo Martínez Sandoval', 'Shakhar Smorodinsky']|['cs.CG']
2017-04-07T11:29:18Z|2017-01-05T12:00:37Z|http://arxiv.org/abs/1701.06430v1|http://arxiv.org/pdf/1701.06430v1|An Upper Bound of the Minimal Dispersion via Delta Covers|upper bound minim dispers via delta cover|For a point set of $n$ elements in the $d$-dimensional unit cube and a class of test sets we are interested in the largest volume of a test set which does not contain any point. For all natural numbers $n$, $d$ and under the assumption of a $delta$-cover with cardinality $\vert \Gamma_\delta \vert$ we prove that there is a point set, such that the largest volume of such a test set without any point is bounded by $\frac{\log \vert \Gamma_\delta \vert}{n} + \delta$. For axis-parallel boxes on the unit cube this leads to a volume of at most $\frac{4d}{n}\log(\frac{9n}{d})$ and on the torus to $\frac{4d}{n}\log (2n)$.|point set element dimension unit cube class test set interest largest volum test set doe contain ani point natur number assumpt delta cover cardin vert gamma delta vert prove point set largest volum test set without ani point bound frac log vert gamma delta vert delta axi parallel box unit cube lead volum frac log frac torus frac log|['Daniel Rudolf']|['cs.CG', 'math.NA', '52B55, 68Q25']
2017-04-07T11:29:18Z|2017-01-04T07:44:19Z|http://arxiv.org/abs/1701.00921v1|http://arxiv.org/pdf/1701.00921v1|Towards Faithful Graph Visualizations|toward faith graph visual|Readability criteria have been addressed as a measurement of the quality of graph visualizations. In this paper, we argue that readability criteria are necessary but not sufficient. We propose a new kind of criteria, namely faithfulness, to evaluate the quality of graph layouts. We introduce a general model for quantify faithfulness, and contrast it with the well established readability criteria. We show examples of common visualization techniques, such as multidimensional scaling, edge bundling and several other visualization metaphors for the study of faithfulness.|readabl criteria address measur qualiti graph visual paper argu readabl criteria necessari suffici propos new kind criteria name faith evalu qualiti graph layout introduc general model quantifi faith contrast well establish readabl criteria show exampl common visual techniqu multidimension scale edg bundl sever visual metaphor studi faith|['Quan Hoang Nguyen', 'Peter Eades', 'Seok-Hee Hong']|['cs.CG']
2017-04-07T11:29:18Z|2017-04-06T09:09:11Z|http://arxiv.org/abs/1701.00679v2|http://arxiv.org/pdf/1701.00679v2|Removing Depth-Order Cycles Among Triangles: An Efficient Algorithm   Generating Triangular Fragments|remov depth order cycl among triangl effici algorithm generat triangular fragment|More than 25 years ago Chazelle~\emph{et al.} (FOCS 1991) studied the following question: Is it possible to cut any set of $n$ lines in ${\Bbb R}^3$ into a subquadratic number of fragments such that the resulting fragments admit a depth order? They proved an $O(n^{9/4})$ bound for the very special case of bipartite weavings of lines. Since then only little progress was made, until a recent breakthrough by Aronov and Sharir (STOC 2016) who showed that $O(n^{3/2}\mathrm{polylog}\; n)$ fragments suffice for any set of lines. In a follow-up paper Aronov, Miller and Sharir (SODA 2017) proved an $O(n^{3/2+\varepsilon})$ bound for triangles, but their method results in pieces with curved boundaries. Moreover, their method uses polynomial partitions, for which currently no algorithm is known. Thus the most natural version of the problem is still wide open: Can we cut any collection of $n$ disjoint triangles in ${\Bbb R}^3$ into a subquadratic number of triangular fragments that admit a depth order? And if so, can we compute the cuts efficiently?   We answer this question by presenting an algorithm that cuts any set of $n$ disjoint triangles in ${\Bbb R}^3$ into $O(n^{7/4}\mathrm{polylog}\; n)$ triangular fragments that admit a depth order. The running time of our algorithm is $O(n^{3.69})$. We also prove a refined bound that depends on the number, $K$, of intersections between the projections of the triangle edges onto the $xy$-plane: we show that $O(n^{1+\varepsilon} + n^{1/4} K^{3/4}\mathrm{polylog}\; n)$ fragments suffice to obtain a depth order. This result extends to $xy$-monotone surface patches bounded by a constant number of bounded-degree algebraic arcs, constituting the first subquadratic bound for surface patches. As a byproduct of our approach we obtain a faster algorithm to cut a set of lines into $O(n^{3/2}\mathrm{polylog}\; n)$ fragments that admit a depth order.|year ago chazell emph et al foc studi follow question possibl cut ani set line bbb subquadrat number fragment result fragment admit depth order prove bound veri special case bipartit weav line sinc onli littl progress made recent breakthrough aronov sharir stoc show mathrm polylog fragment suffic ani set line follow paper aronov miller sharir soda prove varepsilon bound triangl method result piec curv boundari moreov method use polynomi partit current algorithm known thus natur version problem still wide open cut ani collect disjoint triangl bbb subquadrat number triangular fragment admit depth order comput cut effici answer question present algorithm cut ani set disjoint triangl bbb mathrm polylog triangular fragment admit depth order run time algorithm also prove refin bound depend number intersect project triangl edg onto xy plane show varepsilon mathrm polylog fragment suffic obtain depth order result extend xy monoton surfac patch bound constant number bound degre algebra arc constitut first subquadrat bound surfac patch byproduct approach obtain faster algorithm cut set line mathrm polylog fragment admit depth order|['Mark de Berg']|['cs.CG', 'F.2.2']
2017-04-07T11:29:18Z|2017-01-02T16:45:18Z|http://arxiv.org/abs/1701.00441v1|http://arxiv.org/pdf/1701.00441v1|Collecting a Swarm in a Grid Environment Using Shared, Global Inputs|collect swarm grid environ use share global input|This paper investigates efficient techniques to collect and concentrate an under-actuated particle swarm despite obstacles. Concentrating a swarm of particles is of critical importance in health-care for targeted drug delivery, where micro-scale particles must be steered to a goal location. Individual particles must be small in order to navigate through micro-vasculature, but decreasing size brings new challenges. Individual particles are too small to contain on-board power or computation and are instead controlled by a global input, such as an applied fluidic flow or electric field.   To make progress, this paper considers a swarm of robots initialized in a grid world in which each position is either free-space or obstacle. This paper provides algorithms that collect all the robots to one position and compares these algorithms on the basis of efficiency and implementation time.|paper investig effici techniqu collect concentr actuat particl swarm despit obstacl concentr swarm particl critic import health care target drug deliveri micro scale particl must steer goal locat individu particl must small order navig micro vasculatur decreas size bring new challeng individu particl small contain board power comput instead control global input appli fluidic flow electr field make progress paper consid swarm robot initi grid world posit either free space obstacl paper provid algorithm collect robot one posit compar algorithm basi effici implement time|['Arun V. Mahadev', 'Dominik Krupke', 'Jan-Marc Reinhardt', 'Sándor P. Fekete', 'Aaron T. Becker']|['cs.RO', 'cs.CG', 'I.2.11; F.2.2']
2017-04-07T11:29:18Z|2017-01-01T04:49:47Z|http://arxiv.org/abs/1701.00198v1|http://arxiv.org/abs/1701.00198v1|A robust approach for tree segmentation in deciduous forests using   small-footprint airborne LiDAR data|robust approach tree segment decidu forest use small footprint airborn lidar data|This paper presents a non-parametric approach for segmenting trees from airborne LiDAR data in deciduous forests. Based on the LiDAR point cloud, the approach collects crown information such as steepness and height on-the-fly to delineate crown boundaries, and most importantly, does not require a priori assumptions of crown shape and size. The approach segments trees iteratively starting from the tallest within a given area to the smallest until all trees have been segmented. To evaluate its performance, the approach was applied to the University of Kentucky Robinson Forest, a deciduous closed-canopy forest with complex terrain and vegetation conditions. The approach identified 94% of dominant and co-dominant trees with a false detection rate of 13%. About 62% of intermediate, overtopped, and dead trees were also detected with a false detection rate of 15%. The overall segmentation accuracy was 77%. Correlations of the segmentation scores of the proposed approach with local terrain and stand metrics was not significant, which is likely an indication of the robustness of the approach as results are not sensitive to the differences in terrain and stand structures.|paper present non parametr approach segment tree airborn lidar data decidu forest base lidar point cloud approach collect crown inform steep height fli delin crown boundari import doe requir priori assumpt crown shape size approach segment tree iter start tallest within given area smallest tree segment evalu perform approach appli univers kentucki robinson forest decidu close canopi forest complex terrain veget condit approach identifi domin co domin tree fals detect rate intermedi overtop dead tree also detect fals detect rate overal segment accuraci correl segment score propos approach local terrain stand metric signific like indic robust approach result sensit differ terrain stand structur|['Hamid Hamraz', 'Marco A. Contreras', 'Jun Zhang']|['cs.CV', 'cs.CE', 'cs.CG']
2017-04-07T11:29:18Z|2017-03-31T19:28:07Z|http://arxiv.org/abs/1701.00169v2|http://arxiv.org/pdf/1701.00169v2|Application of small-footprint airborne LiDAR data to segment   under-story trees in deciduous forests|applic small footprint airborn lidar data segment stori tree decidu forest|Airborne LiDAR point cloud representing a forest contains 3D data, from which vertical stand structure can be derived. This paper presents a tree segmentation approach for multi-story stands that iteratively strips canopy layers off the point cloud and segments individual tree crowns within each layer using a digital surface model based tree segmentation method as a building block. We analyze the vertical distributions of LiDAR points within overlapping locales in order to determine the local height thresholds for stripping a canopy layer. Unlike the previous work that stripped stiff layers within constrained areas, the local layering method strips flexible (in thickness and height) canopy layers within unconstrained areas, which can also be utilized as a robust vertical stratification of canopy, independent of the tree segmentation method applied to each layer. Statistical analyses showed that layering strongly improves detecting under-story trees at the cost of moderately increasing over-segmentation rate of the detected under-story trees, while only slightly affecting the segmentation quality of over-story trees. Results obtained from layering the canopy suggest that acquiring denser LiDAR point clouds (becoming affordable due to advancements of the sensor technology and platforms) would allow segmenting under-story trees as accurately as over-story trees.   Keywords: LiDAR remote sensing, multi-layered stand, canopy layering, vertical stratification, individual tree segmentation.|airborn lidar point cloud repres forest contain data vertic stand structur deriv paper present tree segment approach multi stori stand iter strip canopi layer point cloud segment individu tree crown within layer use digit surfac model base tree segment method build block analyz vertic distribut lidar point within overlap local order determin local height threshold strip canopi layer unlik previous work strip stiff layer within constrain area local layer method strip flexibl thick height canopi layer within unconstrain area also util robust vertic stratif canopi independ tree segment method appli layer statist analys show layer strong improv detect stori tree cost moder increas segment rate detect stori tree onli slight affect segment qualiti stori tree result obtain layer canopi suggest acquir denser lidar point cloud becom afford due advanc sensor technolog platform would allow segment stori tree accur stori tree keyword lidar remot sens multi layer stand canopi layer vertic stratif individu tree segment|['Hamid Hamraz', 'Marco A. Contreras', 'Jun Zhang']|['cs.CV', 'cs.CE', 'cs.CG']
