2017-03-28T14:05:58Z|2017-03-27T15:13:49Z|http://arxiv.org/abs/1703.09137v1|http://arxiv.org/pdf/1703.09137v1|Where to put the Image in an Image Caption Generator|put imag imag caption generat|When a neural language model is used for caption generation, the image information can be fed to the neural network either by directly incorporating it in a recurrent neural network -- conditioning the language model by injecting image features -- or in a layer following the recurrent neural network -- conditioning the language model by merging the image features. While merging implies that visual features are bound at the end of the caption generation process, injecting can bind the visual features at a variety stages. In this paper we empirically show that late binding is superior to early binding in terms of different evaluation metrics. This suggests that the different modalities (visual and linguistic) for caption generation should not be jointly encoded by the RNN; rather, the multimodal integration should be delayed to a subsequent stage. Furthermore, this suggests that recurrent neural networks should not be viewed as actually generating text, but only as encoding it for prediction in a subsequent layer.|neural languag model use caption generat imag inform fed neural network either direct incorpor recurr neural network condit languag model inject imag featur layer follow recurr neural network condit languag model merg imag featur merg impli visual featur bound end caption generat process inject bind visual featur varieti stage paper empir show late bind superior earli bind term differ evalu metric suggest differ modal visual linguist caption generat joint encod rnn rather multimod integr delay subsequ stage furthermor suggest recurr neural network view actual generat text onli encod predict subsequ layer|['Marc Tanti', 'Albert Gatt', 'Kenneth P. Camilleri']|['cs.NE', 'cs.CL', 'cs.CV']
2017-03-28T14:05:58Z|2017-03-27T13:11:33Z|http://arxiv.org/abs/1703.09046v1|http://arxiv.org/pdf/1703.09046v1|Bootstrapping a Lexicon for Emotional Arousal in Software Engineering|bootstrap lexicon emot arous softwar engin|Emotional arousal increases activation and performance but may also lead to burnout in software development. We present the first version of a Software Engineering Arousal lexicon (SEA) that is specifically designed to address the problem of emotional arousal in the software developer ecosystem. SEA is built using a bootstrapping approach that combines word embedding model trained on issue-tracking data and manual scoring of items in the lexicon. We show that our lexicon is able to differentiate between issue priorities, which are a source of emotional activation and then act as a proxy for arousal. The best performance is obtained by combining SEA (428 words) with a previously created general purpose lexicon by Warriner et al. (13,915 words) and it achieves Cohen's d effect sizes up to 0.5.|emot arous increas activ perform may also lead burnout softwar develop present first version softwar engin arous lexicon sea specif design address problem emot arous softwar develop ecosystem sea built use bootstrap approach combin word embed model train issu track data manual score item lexicon show lexicon abl differenti issu prioriti sourc emot activ act proxi arous best perform obtain combin sea word previous creat general purpos lexicon warrin et al word achiev cohen effect size|['Mika V. Mäntylä', 'Nicole Novielli', 'Filippo Lanubile', 'Maëlick Claes', 'Miikka Kuutila']|['cs.SE', 'cs.CL']
2017-03-28T14:05:58Z|2017-03-27T11:15:58Z|http://arxiv.org/abs/1703.09013v1|http://arxiv.org/pdf/1703.09013v1|A Sentence Simplification System for Improving Relation Extraction|sentenc simplif system improv relat extract|In this demo paper, we present a text simplification approach that is directed at improving the performance of state-of-the-art Open Relation Extraction (RE) systems. As syntactically complex sentences often pose a challenge for current Open RE approaches, we have developed a simplification framework that performs a pre-processing step by taking a single sentence as input and using a set of syntactic-based transformation rules to create a textual input that is easier to process for subsequently applied Open RE systems.|demo paper present text simplif approach direct improv perform state art open relat extract system syntact complex sentenc often pose challeng current open approach develop simplif framework perform pre process step take singl sentenc input use set syntact base transform rule creat textual input easier process subsequ appli open system|['Christina Niklaus', 'Bernhard Bermeitinger', 'Siegfried Handschuh', 'André Freitas']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-26T23:48:06Z|http://arxiv.org/abs/1703.08885v1|http://arxiv.org/pdf/1703.08885v1|Question Answering from Unstructured Text by Retrieval and Comprehension|question answer unstructur text retriev comprehens|Open domain Question Answering (QA) systems must interact with external knowledge sources, such as web pages, to find relevant information. Information sources like Wikipedia, however, are not well structured and difficult to utilize in comparison with Knowledge Bases (KBs). In this work we present a two-step approach to question answering from unstructured text, consisting of a retrieval step and a comprehension step. For comprehension, we present an RNN based attention model with a novel mixture mechanism for selecting answers from either retrieved articles or a fixed vocabulary. For retrieval we introduce a hand-crafted model and a neural model for ranking relevant articles. We achieve state-of-the-art performance on W IKI M OVIES dataset, reducing the error by 40%. Our experimental results further demonstrate the importance of each of the introduced components.|open domain question answer qa system must interact extern knowledg sourc web page find relev inform inform sourc like wikipedia howev well structur difficult util comparison knowledg base kbs work present two step approach question answer unstructur text consist retriev step comprehens step comprehens present rnn base attent model novel mixtur mechan select answer either retriev articl fix vocabulari retriev introduc hand craft model neural model rank relev articl achiev state art perform iki ovi dataset reduc error experiment result demonstr import introduc compon|['Yusuke Watanabe', 'Bhuwan Dhingra', 'Ruslan Salakhutdinov']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-26T20:02:44Z|http://arxiv.org/abs/1703.08864v1|http://arxiv.org/pdf/1703.08864v1|Learning Simpler Language Models with the Delta Recurrent Neural Network   Framework|learn simpler languag model delta recurr neural network framework|Learning useful information across long time lags is a critical and difficult problem for temporal neural models in tasks like language modeling. Existing architectures that address the issue are often complex and costly to train. The Delta Recurrent Neural Network (Delta-RNN) framework is a simple and high-performing design that unifies previously proposed gated neural models. The Delta-RNN models maintain longer-term memory by learning to interpolate between a fast-changing data-driven representation and a slowly changing, implicitly stable state. This requires hardly any more parameters than a classical simple recurrent network. The models outperform popular complex architectures, such as the Long Short Term Memory (LSTM) and the Gated Recurrent Unit (GRU) and achieve state-of-the art performance in language modeling at character and word levels and yield comparable performance at the subword level.|learn use inform across long time lag critic difficult problem tempor neural model task like languag model exist architectur address issu often complex cost train delta recurr neural network delta rnn framework simpl high perform design unifi previous propos gate neural model delta rnn model maintain longer term memori learn interpol fast chang data driven represent slowli chang implicit stabl state requir hard ani paramet classic simpl recurr network model outperform popular complex architectur long short term memori lstm gate recurr unit gru achiev state art perform languag model charact word level yield compar perform subword level|['Alexander G. Ororbia II', 'Tomas Mikolov', 'David Reitter']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-26T00:30:38Z|http://arxiv.org/abs/1703.08748v1|http://arxiv.org/pdf/1703.08748v1|LEPOR: An Augmented Machine Translation Evaluation Metric|lepor augment machin translat evalu metric|Machine translation (MT) was developed as one of the hottest research topics in the natural language processing (NLP) literature. One important issue in MT is that how to evaluate the MT system reasonably and tell us whether the translation system makes an improvement or not. The traditional manual judgment methods are expensive, time-consuming, unrepeatable, and sometimes with low agreement. On the other hand, the popular automatic MT evaluation methods have some weaknesses. Firstly, they tend to perform well on the language pairs with English as the target language, but weak when English is used as source. Secondly, some methods rely on many additional linguistic features to achieve good performance, which makes the metric unable to replicate and apply to other language pairs easily. Thirdly, some popular metrics utilize incomprehensive factors, which result in low performance on some practical tasks. In this thesis, to address the existing problems, we design novel MT evaluation methods and investigate their performances on different languages. Firstly, we design augmented factors to yield highly accurate evaluation.Secondly, we design a tunable evaluation model where weighting of factors can be optimised according to the characteristics of languages. Thirdly, in the enhanced version of our methods, we design concise linguistic feature using POS to show that our methods can yield even higher performance when using some external linguistic resources. Finally, we introduce the practical performance of our metrics in the ACL-WMT workshop shared tasks, which show that the proposed methods are robust across different languages.|machin translat mt develop one hottest research topic natur languag process nlp literatur one import issu mt evalu mt system reason tell us whether translat system make improv tradit manual judgment method expens time consum unrepeat sometim low agreement hand popular automat mt evalu method weak first tend perform well languag pair english target languag weak english use sourc second method reli mani addit linguist featur achiev good perform make metric unabl replic appli languag pair easili third popular metric util incomprehens factor result low perform practic task thesi address exist problem design novel mt evalu method investig perform differ languag first design augment factor yield high accur evalu second design tunabl evalu model weight factor optimis accord characterist languag third enhanc version method design concis linguist featur use pos show method yield even higher perform use extern linguist resourc final introduc practic perform metric acl wmt workshop share task show propos method robust across differ languag|['Lifeng Han']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-25T15:37:09Z|http://arxiv.org/abs/1703.08705v1|http://arxiv.org/pdf/1703.08705v1|Comparing Rule-Based and Deep Learning Models for Patient Phenotyping|compar rule base deep learn model patient phenotyp|Objective: We investigate whether deep learning techniques for natural language processing (NLP) can be used efficiently for patient phenotyping. Patient phenotyping is a classification task for determining whether a patient has a medical condition, and is a crucial part of secondary analysis of healthcare data. We assess the performance of deep learning algorithms and compare them with classical NLP approaches.   Materials and Methods: We compare convolutional neural networks (CNNs), n-gram models, and approaches based on cTAKES that extract pre-defined medical concepts from clinical notes and use them to predict patient phenotypes. The performance is tested on 10 different phenotyping tasks using 1,610 discharge summaries extracted from the MIMIC-III database.   Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The average F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our model having an F1-score up to 37 points higher than alternative approaches. We additionally assess the interpretability of our model by presenting a method that extracts the most salient phrases for a particular prediction.   Conclusion: We show that NLP methods based on deep learning improve the performance of patient phenotyping. Our CNN-based algorithm automatically learns the phrases associated with each patient phenotype. As such, it reduces the annotation complexity for clinical domain experts, who are normally required to develop task-specific annotation rules and identify relevant phrases. Our method performs well in terms of both performance and interpretability, which indicates that deep learning is an effective approach to patient phenotyping based on clinicians' notes.|object investig whether deep learn techniqu natur languag process nlp use effici patient phenotyp patient phenotyp classif task determin whether patient medic condit crucial part secondari analysi healthcar data assess perform deep learn algorithm compar classic nlp approach materi method compar convolut neural network cnns gram model approach base ctake extract pre defin medic concept clinic note use predict patient phenotyp perform test differ phenotyp task use discharg summari extract mimic iii databas result cnns outperform phenotyp algorithm task averag score model ppv sensit model score point higher altern approach addit assess interpret model present method extract salient phrase particular predict conclus show nlp method base deep learn improv perform patient phenotyp cnn base algorithm automat learn phrase associ patient phenotyp reduc annot complex clinic domain expert normal requir develop task specif annot rule identifi relev phrase method perform well term perform interpret indic deep learn effect approach patient phenotyp base clinician note|['Sebastian Gehrmann', 'Franck Dernoncourt', 'Yeran Li', 'Eric T. Carlson', 'Joy T. Wu', 'Jonathan Welt', 'John Foote Jr.', 'Edward T. Moseley', 'David W. Grant', 'Patrick D. Tyler', 'Leo Anthony Celi']|['cs.CL', 'cs.AI', 'cs.NE', 'stat.ML']
2017-03-28T14:05:58Z|2017-03-25T14:56:27Z|http://arxiv.org/abs/1703.08701v1|http://arxiv.org/pdf/1703.08701v1|Morphological Analysis for the Maltese Language: The Challenges of a   Hybrid System|morpholog analysi maltes languag challeng hybrid system|Maltese is a morphologically rich language with a hybrid morphological system which features both concatenative and non-concatenative processes. This paper analyses the impact of this hybridity on the performance of machine learning techniques for morphological labelling and clustering. In particular, we analyse a dataset of morphologically related word clusters to evaluate the difference in results for concatenative and nonconcatenative clusters. We also describe research carried out in morphological labelling, with a particular focus on the verb category. Two evaluations were carried out, one using an unseen dataset, and another one using a gold standard dataset which was manually labelled. The gold standard dataset was split into concatenative and non-concatenative to analyse the difference in results between the two morphological systems.|maltes morpholog rich languag hybrid morpholog system featur concaten non concaten process paper analys impact hybrid perform machin learn techniqu morpholog label cluster particular analys dataset morpholog relat word cluster evalu differ result concaten nonconcaten cluster also describ research carri morpholog label particular focus verb categori two evalu carri one use unseen dataset anoth one use gold standard dataset manual label gold standard dataset split concaten non concaten analys differ result two morpholog system|['Claudia Borg', 'Albert Gatt']|['cs.CL', 'I.2.7']
2017-03-28T14:05:58Z|2017-03-25T04:25:21Z|http://arxiv.org/abs/1703.08646v1|http://arxiv.org/pdf/1703.08646v1|Simplifying the Bible and Wikipedia Using Statistical Machine   Translation|simplifi bibl wikipedia use statist machin translat|"I started this work with the hope of generating a text synthesizer (like a musical synthesizer) that can imitate certain linguistic styles. Most of the report focuses on text simplification using statistical machine translation (SMT) techniques. I applied MOSES to a parallel corpus of the Bible (King James Version and Easy-to-Read Version) and that of Wikipedia articles (normal and simplified). I report the importance of the three main components of SMT---phrase translation, language model, and recording---by changing their weights and comparing the resulting quality of simplified text in terms of METEOR and BLEU. Toward the end of the report will be presented some examples of text ""synthesized"" into the King James style."|start work hope generat text synthes like music synthes imit certain linguist style report focus text simplif use statist machin translat smt techniqu appli mose parallel corpus bibl king jame version easi read version wikipedia articl normal simplifi report import three main compon smt phrase translat languag model record chang weight compar result qualiti simplifi text term meteor bleu toward end report present exampl text synthes king jame style|['Yohan Jo']|['cs.CL']
2017-03-28T14:05:58Z|2017-03-24T19:45:24Z|http://arxiv.org/abs/1703.08581v1|http://arxiv.org/pdf/1703.08581v1|Sequence-to-Sequence Models Can Directly Transcribe Foreign Speech|sequenc sequenc model direct transcrib foreign speech|We present a recurrent encoder-decoder deep neural network architecture that directly translates speech in one language into text in another. The model does not explicitly transcribe the speech into text in the source language, nor does it require supervision from the ground truth source language transcription during training. We apply a slightly modified sequence-to-sequence with attention architecture that has previously been used for speech recognition and show that it can be repurposed for this more complex task, illustrating the power of attention-based models. A single model trained end-to-end obtains state-of-the-art performance on the Fisher Callhome Spanish-English speech translation task, outperforming a cascade of independently trained sequence-to-sequence speech recognition and machine translation models by 1.8 BLEU points on the Fisher test set. In addition, we find that making use of the training data in both languages by multi-task training sequence-to-sequence speech translation and recognition models with a shared encoder network can improve performance by a further 1.4 BLEU points.|present recurr encod decod deep neural network architectur direct translat speech one languag text anoth model doe explicit transcrib speech text sourc languag doe requir supervis ground truth sourc languag transcript dure train appli slight modifi sequenc sequenc attent architectur previous use speech recognit show repurpos complex task illustr power attent base model singl model train end end obtain state art perform fisher callhom spanish english speech translat task outperform cascad independ train sequenc sequenc speech recognit machin translat model bleu point fisher test set addit find make use train data languag multi task train sequenc sequenc speech translat recognit model share encod network improv perform bleu point|['Ron J. Weiss', 'Jan Chorowski', 'Navdeep Jaitly', 'Yonghui Wu', 'Zhifeng Chen']|['cs.CL', 'cs.LG', 'stat.ML']
2017-03-28T14:06:02Z|2017-03-24T17:55:33Z|http://arxiv.org/abs/1703.08537v1|http://arxiv.org/pdf/1703.08537v1|Crowdsourcing Universal Part-Of-Speech Tags for Code-Switching|crowdsourc univers part speech tag code switch|Code-switching is the phenomenon by which bilingual speakers switch between multiple languages during communication. The importance of developing language technologies for codeswitching data is immense, given the large populations that routinely code-switch. High-quality linguistic annotations are extremely valuable for any NLP task, and performance is often limited by the amount of high-quality labeled data. However, little such data exists for code-switching. In this paper, we describe crowd-sourcing universal part-of-speech tags for the Miami Bangor Corpus of Spanish-English code-switched speech. We split the annotation task into three subtasks: one in which a subset of tokens are labeled automatically, one in which questions are specifically designed to disambiguate a subset of high frequency words, and a more general cascaded approach for the remaining data in which questions are displayed to the worker following a decision tree structure. Each subtask is extended and adapted for a multilingual setting and the universal tagset. The quality of the annotation process is measured using hidden check questions annotated with gold labels. The overall agreement between gold standard labels and the majority vote is between 0.95 and 0.96 for just three labels and the average recall across part-of-speech tags is between 0.87 and 0.99, depending on the task.|code switch phenomenon bilingu speaker switch multipl languag dure communic import develop languag technolog codeswitch data immens given larg popul routin code switch high qualiti linguist annot extrem valuabl ani nlp task perform often limit amount high qualiti label data howev littl data exist code switch paper describ crowd sourc univers part speech tag miami bangor corpus spanish english code switch speech split annot task three subtask one subset token label automat one question specif design disambigu subset high frequenc word general cascad approach remain data question display worker follow decis tree structur subtask extend adapt multilingu set univers tagset qualiti annot process measur use hidden check question annot gold label overal agreement gold standard label major vote three label averag recal across part speech tag depend task|['Victor Soto', 'Julia Hirschberg']|['cs.CL']
2017-03-28T14:06:02Z|2017-03-24T17:13:08Z|http://arxiv.org/abs/1703.08513v1|http://arxiv.org/pdf/1703.08513v1|Interactive Natural Language Acquisition in a Multi-modal Recurrent   Neural Architecture|interact natur languag acquisit multi modal recurr neural architectur|The human brain is one of the most complex dynamic systems that enables us to communicate in natural language. We have a good understanding of some principles underlying natural languages and language processing, some knowledge about socio-cultural conditions framing acquisition, and some insights about where activity is occurring in the brain. However, we were not yet able to understand the behavioural and mechanistic characteristics for natural language and how mechanisms in the brain allow to acquire and process language.   In an effort to bridge the gap between insights from behavioural psychology and neuroscience, the goal of this paper is to contribute a computational understanding of the appropriate characteristics that favour language acquisition, in a brain-inspired neural architecture. Accordingly, we provide concepts and refinements in cognitive modelling regarding principles and mechanisms in the brain - such as the hierarchical abstraction of context - in a plausible recurrent architecture. On this basis, we propose neurocognitively plausible model for embodied language acquisition from real world interaction of a humanoid robot with its environment. The model is capable of learning language production grounded in both, temporal dynamic somatosensation and vision. In particular, the architecture consists of a continuous time recurrent neural network, where parts have different leakage characteristics and thus operate on multiple timescales for every modality and the association of the higher level nodes of all modalities into cell assemblies. Thus, this model features hierarchical concept abstraction in sensation as well as concept decomposition in production, multi-modal integration, and self-organisation of latent representations.|human brain one complex dynam system enabl us communic natur languag good understand principl natur languag languag process knowledg socio cultur condit frame acquisit insight activ occur brain howev yet abl understand behaviour mechanist characterist natur languag mechan brain allow acquir process languag effort bridg gap insight behaviour psycholog neurosci goal paper contribut comput understand appropri characterist favour languag acquisit brain inspir neural architectur accord provid concept refin cognit model regard principl mechan brain hierarch abstract context plausibl recurr architectur basi propos neurocognit plausibl model embodi languag acquisit real world interact humanoid robot environ model capabl learn languag product ground tempor dynam somatosens vision particular architectur consist continu time recurr neural network part differ leakag characterist thus oper multipl timescal everi modal associ higher level node modal cell assembl thus model featur hierarch concept abstract sensat well concept decomposit product multi modal integr self organis latent represent|['Stefan Heinrich', 'Stefan Wermter']|['cs.CL', 'q-bio.NC']
2017-03-28T14:06:02Z|2017-03-24T15:40:19Z|http://arxiv.org/abs/1703.08471v1|http://arxiv.org/pdf/1703.08471v1|Batch-normalized joint training for DNN-based distant speech recognition|batch normal joint train dnn base distant speech recognit|Improving distant speech recognition is a crucial step towards flexible human-machine interfaces. Current technology, however, still exhibits a lack of robustness, especially when adverse acoustic conditions are met. Despite the significant progress made in the last years on both speech enhancement and speech recognition, one potential limitation of state-of-the-art technology lies in composing modules that are not well matched because they are not trained jointly. To address this concern, a promising approach consists in concatenating a speech enhancement and a speech recognition deep neural network and to jointly update their parameters as if they were within a single bigger network. Unfortunately, joint training can be difficult because the output distribution of the speech enhancement system may change substantially during the optimization procedure. The speech recognition module would have to deal with an input distribution that is non-stationary and unnormalized. To mitigate this issue, we propose a joint training approach based on a fully batch-normalized architecture. Experiments, conducted using different datasets, tasks and acoustic conditions, revealed that the proposed framework significantly overtakes other competitive solutions, especially in challenging environments.|improv distant speech recognit crucial step toward flexibl human machin interfac current technolog howev still exhibit lack robust especi advers acoust condit met despit signific progress made last year speech enhanc speech recognit one potenti limit state art technolog lie compos modul well match becaus train joint address concern promis approach consist concaten speech enhanc speech recognit deep neural network joint updat paramet within singl bigger network unfortun joint train difficult becaus output distribut speech enhanc system may chang substanti dure optim procedur speech recognit modul would deal input distribut non stationari unnorm mitig issu propos joint train approach base fulli batch normal architectur experi conduct use differ dataset task acoust condit reveal propos framework signific overtak competit solut especi challeng environ|['Mirco Ravanelli', 'Philemon Brakel', 'Maurizio Omologo', 'Yoshua Bengio']|['cs.CL', 'cs.LG']
2017-03-28T14:06:02Z|2017-03-24T14:49:58Z|http://arxiv.org/abs/1703.08544v1|http://arxiv.org/pdf/1703.08544v1|D.TRUMP: Data-mining Textual Responses to Uncover Misconception Patterns|trump data mine textual respons uncov misconcept pattern|An important, yet largely unstudied, problem in student data analysis is to detect misconceptions from students' responses to open-response questions. Misconception detection enables instructors to deliver more targeted feedback on the misconceptions exhibited by many students in their class, thus improving the quality of instruction. In this paper, we propose D.TRUMP, a new natural language processing-based framework to detect the common misconceptions among students' textual responses to short-answer questions. We propose a probabilistic model for students' textual responses involving misconceptions and experimentally validate it on a real-world student-response dataset. Experimental results show that D.TRUMP excels at classifying whether a response exhibits one or more misconceptions. More importantly, it can also automatically detect the common misconceptions exhibited across responses from multiple students to multiple questions; this property is especially important at large scale, since instructors will no longer need to manually specify all possible misconceptions that students might exhibit.|import yet larg unstudi problem student data analysi detect misconcept student respons open respons question misconcept detect enabl instructor deliv target feedback misconcept exhibit mani student class thus improv qualiti instruct paper propos trump new natur languag process base framework detect common misconcept among student textual respons short answer question propos probabilist model student textual respons involv misconcept experiment valid real world student respons dataset experiment result show trump excel classifi whether respons exhibit one misconcept import also automat detect common misconcept exhibit across respons multipl student multipl question properti especi import larg scale sinc instructor longer need manual specifi possibl misconcept student might exhibit|['Joshua J. Michalenko', 'Andrew S. Lan', 'Richard G. Baraniuk']|['stat.ML', 'cs.CL']
2017-03-28T14:06:02Z|2017-03-24T14:40:31Z|http://arxiv.org/abs/1703.08428v1|http://arxiv.org/abs/1703.08428v1|Calendar.help: Designing a Workflow-Based Scheduling Agent with Humans   in the Loop|calendar help design workflow base schedul agent human loop|Although information workers may complain about meetings, they are an essential part of their work life. Consequently, busy people spend a significant amount of time scheduling meetings. We present Calendar.help, a system that provides fast, efficient scheduling through structured workflows. Users interact with the system via email, delegating their scheduling needs to the system as if it were a human personal assistant. Common scheduling scenarios are broken down using well-defined workflows and completed as a series of microtasks that are automated when possible and executed by a human otherwise. Unusual scenarios fall back to a trained human assistant who executes them as unstructured macrotasks. We describe the iterative approach we used to develop Calendar.help, and share the lessons learned from scheduling thousands of meetings during a year of real-world deployments. Our findings provide insight into how complex information tasks can be broken down into repeatable components that can be executed efficiently to improve productivity.|although inform worker may complain meet essenti part work life consequ busi peopl spend signific amount time schedul meet present calendar help system provid fast effici schedul structur workflow user interact system via email deleg schedul need system human person assist common schedul scenario broken use well defin workflow complet seri microtask autom possibl execut human otherwis unusu scenario fall back train human assist execut unstructur macrotask describ iter approach use develop calendar help share lesson learn schedul thousand meet dure year real world deploy find provid insight complex inform task broken repeat compon execut effici improv product|['Justin Cranshaw', 'Emad Elwany', 'Todd Newman', 'Rafal Kocielnik', 'Bowen Yu', 'Sandeep Soni', 'Jaime Teevan', 'Andrés Monroy-Hernández']|['cs.HC', 'cs.AI', 'cs.CL']
2017-03-28T14:06:02Z|2017-03-24T09:32:23Z|http://arxiv.org/abs/1703.08324v1|http://arxiv.org/pdf/1703.08324v1|Are crossing dependencies really scarce?|cross depend realli scarc|The syntactic structure of a sentence can be modelled as a tree, where vertices correspond to words and edges indicate syntactic dependencies. It has been claimed recurrently that the number of edge crossings in real sentences is small. However, a baseline or null hypothesis has been lacking. Here we quantify the amount of crossings of real sentences and compare it to the predictions of a series of baselines. We conclude that crossings are really scarce in real sentences. Their scarcity is unexpected by the hubiness of the trees. Indeed, real sentences are close to linear trees, where the potential number of crossings is maximized.|syntact structur sentenc model tree vertic correspond word edg indic syntact depend claim recurr number edg cross real sentenc small howev baselin null hypothesi lack quantifi amount cross real sentenc compar predict seri baselin conclud cross realli scarc real sentenc scarciti unexpect hubi tree inde real sentenc close linear tree potenti number cross maxim|['Ramon Ferrer-i-Cancho', 'Carlos Gomez-Rodriguez', 'J. L. Esteban']|['physics.soc-ph', 'cond-mat.stat-mech', 'cs.CL', 'physics.data-an']
2017-03-28T14:06:02Z|2017-03-24T08:46:48Z|http://arxiv.org/abs/1703.08314v1|http://arxiv.org/pdf/1703.08314v1|Interacting Conceptual Spaces I : Grammatical Composition of Concepts|interact conceptu space grammat composit concept|The categorical compositional approach to meaning has been successfully applied in natural language processing, outperforming other models in mainstream empirical language processing tasks. We show how this approach can be generalized to conceptual space models of cognition. In order to do this, first we introduce the category of convex relations as a new setting for categorical compositional semantics, emphasizing the convex structure important to conceptual space applications. We then show how to construct conceptual spaces for various types such as nouns, adjectives and verbs. Finally we show by means of examples how concepts can be systematically combined to establish the meanings of composite phrases from the meanings of their constituent parts. This provides the mathematical underpinnings of a new compositional approach to cognition.|categor composit approach mean success appli natur languag process outperform model mainstream empir languag process task show approach general conceptu space model cognit order first introduc categori convex relat new set categor composit semant emphas convex structur import conceptu space applic show construct conceptu space various type noun adject verb final show mean exampl concept systemat combin establish mean composit phrase mean constitu part provid mathemat underpin new composit approach cognit|['Joe Bolt', 'Bob Coecke', 'Fabrizio Genovese', 'Martha Lewis', 'Dan Marsden', 'Robin Piedeleu']|['cs.LO', 'cs.CL']
2017-03-28T14:06:02Z|2017-03-23T22:20:45Z|http://arxiv.org/abs/1703.08244v1|http://arxiv.org/pdf/1703.08244v1|TokTrack: A Complete Token Provenance and Change Tracking Dataset for   the English Wikipedia|toktrack complet token proven chang track dataset english wikipedia|We present a dataset that contains every instance of all tokens (~ words) ever written in undeleted, non-redirect English Wikipedia articles until October 2016, in total 13,545,349,787 instances. Each token is annotated with (i) the article revision it was originally created in, and (ii) lists with all the revisions in which the token was ever deleted and (potentially) re-added and re-deleted from its article, enabling a complete and straightforward tracking of its history. This data would be exceedingly hard to create by an average potential user as it is (i) very expensive to compute and as (ii) accurately tracking the history of each token in revisioned documents is a non-trivial task. Adapting a state-of-the-art algorithm, we have produced a dataset that allows for a range of analyses and metrics, already popular in research and going beyond, to be generated on complete-Wikipedia scale; ensuring quality and allowing researchers to forego expensive text-comparison computation, which so far has hindered scalable usage. We show how this data enables, on token-level, computation of provenance, measuring survival of content over time, very detailed conflict metrics, and fine-grained interactions of editors like partial reverts, re-additions and other metrics, in the process gaining several novel insights.|present dataset contain everi instanc token word ever written undelet non redirect english wikipedia articl octob total instanc token annot articl revis origin creat ii list revis token ever delet potenti ad delet articl enabl complet straightforward track histori data would exceed hard creat averag potenti user veri expens comput ii accur track histori token revis document non trivial task adapt state art algorithm produc dataset allow rang analys metric alreadi popular research go beyond generat complet wikipedia scale ensur qualiti allow research forego expens text comparison comput far hinder scalabl usag show data enabl token level comput proven measur surviv content time veri detail conflict metric fine grain interact editor like partial revert addit metric process gain sever novel insight|['Fabian Flöck', 'Kenan Erdogan', 'Maribel Acosta']|['cs.CL']
2017-03-28T14:06:02Z|2017-03-23T16:46:00Z|http://arxiv.org/abs/1703.08136v1|http://arxiv.org/pdf/1703.08136v1|Visually grounded learning of keyword prediction from untranscribed   speech|visual ground learn keyword predict untranscrib speech|"During language acquisition, infants have the benefit of visual cues to ground spoken language. Robots similarly have access to audio and visual sensors. Recent work has shown that images and spoken captions can be mapped into a meaningful common space, allowing images to be retrieved using speech and vice versa. In this setting of images paired with untranscribed spoken captions, we consider whether computer vision systems can be used to obtain textual labels for the speech. Concretely, we use an image-to-words multi-label visual classifier to tag images with soft textual labels, and then train a neural network to map from the speech to these soft targets. We show that the resulting speech system is able to predict which words occur in an utterance---acting as a spoken bag-of-words classifier---without seeing any parallel speech and text. We find that the model often confuses semantically related words, e.g. ""man"" and ""person"", making it even more effective as a semantic keyword spotter."|dure languag acquisit infant benefit visual cue ground spoken languag robot similar access audio visual sensor recent work shown imag spoken caption map meaning common space allow imag retriev use speech vice versa set imag pair untranscrib spoken caption consid whether comput vision system use obtain textual label speech concret use imag word multi label visual classifi tag imag soft textual label train neural network map speech soft target show result speech system abl predict word occur utter act spoken bag word classifi without see ani parallel speech text find model often confus semant relat word man person make even effect semant keyword spotter|['Herman Kamper', 'Shane Settle', 'Gregory Shakhnarovich', 'Karen Livescu']|['cs.CL', 'cs.CV']
2017-03-28T14:06:02Z|2017-03-23T16:45:22Z|http://arxiv.org/abs/1703.08135v1|http://arxiv.org/pdf/1703.08135v1|An embedded segmental k-means model for unsupervised segmentation and   clustering of speech|embed segment mean model unsupervis segment cluster speech|Unsupervised segmentation and clustering of unlabelled speech are core problems in zero-resource speech processing. Most competitive approaches lie at methodological extremes: some follow a Bayesian approach, defining probabilistic models with convergence guarantees, while others opt for more efficient heuristic techniques. Here we introduce an approximation to a segmental Bayesian model that falls in between, with a clear objective function but using hard clustering and segmentation rather than full Bayesian inference. Like its Bayesian counterpart, this embedded segmental k-means model (ES-KMeans) represents arbitrary-length word segments as fixed-dimensional acoustic word embeddings. On English and Xitsonga data, ES-KMeans outperforms a leading heuristic method in word segmentation, giving similar scores to the Bayesian model while being five times faster with fewer hyperparameters. However, there is a trade-off in cluster purity, with the Bayesian model's purer clusters yielding about 10% better unsupervised word error rates.|unsupervis segment cluster unlabel speech core problem zero resourc speech process competit approach lie methodolog extrem follow bayesian approach defin probabilist model converg guarante opt effici heurist techniqu introduc approxim segment bayesian model fall clear object function use hard cluster segment rather full bayesian infer like bayesian counterpart embed segment mean model es kmean repres arbitrari length word segment fix dimension acoust word embed english xitsonga data es kmean outperform lead heurist method word segment give similar score bayesian model five time faster fewer hyperparamet howev trade cluster puriti bayesian model purer cluster yield better unsupervis word error rate|['Herman Kamper', 'Karen Livescu', 'Sharon Goldwater']|['cs.CL', 'cs.LG']
2017-03-28T14:06:07Z|2017-03-23T15:57:23Z|http://arxiv.org/abs/1703.08120v1|http://arxiv.org/pdf/1703.08120v1|Recurrent and Contextual Models for Visual Question Answering|recurr contextu model visual question answer|We propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the Visual7W dataset. Motivated by divergent trends in model complexities in the literature, we explore the balance between model expressiveness and simplicity by studying incrementally more complex architectures. We start with LSTM-encoding of input questions and answers; build on this with context generation by LSTM-encodings of neural image and question representations and attention over images; and evaluate the diversity and predictive power of our models and the ensemble thereof. All models are evaluated against a simple baseline inspired by the current state-of-the-art, consisting of involving simple concatenation of bag-of-words and CNN representations for the text and images, respectively. Generally, we observe marked variation in image-reasoning performance between our models not obvious from their overall performance, as well as evidence of dataset bias. Our standalone models achieve accuracies up to $64.6\%$, while the ensemble of all models achieves the best accuracy of $66.67\%$, within $0.5\%$ of the current state-of-the-art for Visual7W.|propos seri recurr contextu neural network model multipl choic visual question answer visualw dataset motiv diverg trend model complex literatur explor balanc model express simplic studi increment complex architectur start lstm encod input question answer build context generat lstm encod neural imag question represent attent imag evalu divers predict power model ensembl thereof model evalu simpl baselin inspir current state art consist involv simpl concaten bag word cnn represent text imag respect general observ mark variat imag reason perform model obvious overal perform well evid dataset bias standalon model achiev accuraci ensembl model achiev best accuraci within current state art visualw|['Abhijit Sharang', 'Eric Lau']|['cs.CL', 'cs.CV']
2017-03-28T14:06:07Z|2017-03-23T15:15:26Z|http://arxiv.org/abs/1703.08098v1|http://arxiv.org/pdf/1703.08098v1|An overview of embedding models of entities and relationships for   knowledge base completion|overview embed model entiti relationship knowledg base complet|Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform knowledge base completion, i.e., predict whether a relationship not in the knowledge base is likely to be true. This article presents an overview of embedding models of entities and relationships for knowledge base completion, with up-to-date experimental results on two standard evaluation tasks of link prediction (i.e. entity prediction) and triple classification.|knowledg base real world fact entiti relationship use resourc varieti natur languag process task howev becaus knowledg base typic incomplet use abl perform knowledg base complet predict whether relationship knowledg base like true articl present overview embed model entiti relationship knowledg base complet date experiment result two standard evalu task link predict entiti predict tripl classif|['Dat Quoc Nguyen']|['cs.CL', 'cs.AI', 'cs.IR']
2017-03-28T14:06:07Z|2017-03-25T00:00:00Z|http://arxiv.org/abs/1703.08088v2|http://arxiv.org/abs/1703.08088v2|Rapid-Rate: A Framework for Semi-supervised Real-time Sentiment Trend   Detection in Unstructured Big Data|rapid rate framework semi supervis real time sentiment trend detect unstructur big data|Commercial establishments like restaurants, service centres and retailers have several sources of customer feedback about products and services, most of which need not be as structured as rated reviews provided by services like Yelp, or Amazon, in terms of sentiment conveyed. For instance, Amazon provides a fine-grained score on a numeric scale for product reviews. Some sources, however, like social media (Twitter, Facebook), mailing lists (Google Groups) and forums (Quora) contain text data that is much more voluminous, but unstructured and unlabelled. It might be in the best interests of a business establishment to assess the general sentiment towards their brand on these platforms as well. This text could be pipelined into a system with a built-in prediction model, with the objective of generating real-time graphs on opinion and sentiment trends. Although such tasks like the one described about have been explored with respect to document classification problems in the past, the implementation described in this paper, by virtue of learning a continuous function rather than a discrete one, offers a lot more depth of insight as compared to document classification approaches. This study aims to explore the validity of such a continuous function predicting model to quantify sentiment about an entity, without the additional overhead of manual labelling, and computational preprocessing & feature extraction. This research project also aims to design and implement a re-usable document regression pipeline as a framework, Rapid-Rate, that can be used to predict document scores in real-time.|commerci establish like restaur servic centr retail sever sourc custom feedback product servic need structur rate review provid servic like yelp amazon term sentiment convey instanc amazon provid fine grain score numer scale product review sourc howev like social media twitter facebook mail list googl group forum quora contain text data much volumin unstructur unlabel might best interest busi establish assess general sentiment toward brand platform well text could pipelin system built predict model object generat real time graph opinion sentiment trend although task like one describ explor respect document classif problem past implement describ paper virtu learn continu function rather discret one offer lot depth insight compar document classif approach studi aim explor valid continu function predict model quantifi sentiment entiti without addit overhead manual label comput preprocess featur extract research project also aim design implement usabl document regress pipelin framework rapid rate use predict document score real time|['Vineet John']|['cs.CL', '68T50']
2017-03-28T14:06:07Z|2017-03-23T14:20:52Z|http://arxiv.org/abs/1703.08084v1|http://arxiv.org/pdf/1703.08084v1|Multimodal Compact Bilinear Pooling for Multimodal Neural Machine   Translation|multimod compact bilinear pool multimod neural machin translat|In state-of-the-art Neural Machine Translation, an attention mechanism is used during decoding to enhance the translation. At every step, the decoder uses this mechanism to focus on different parts of the source sentence to gather the most useful information before outputting its target word. Recently, the effectiveness of the attention mechanism has also been explored for multimodal tasks, where it becomes possible to focus both on sentence parts and image regions. Approaches to pool two modalities usually include element-wise product, sum or concatenation. In this paper, we evaluate the more advanced Multimodal Compact Bilinear pooling method, which takes the outer product of two vectors to combine the attention features for the two modalities. This has been previously investigated for visual question answering. We try out this approach for multimodal image caption translation and show improvements compared to basic combination methods.|state art neural machin translat attent mechan use dure decod enhanc translat everi step decod use mechan focus differ part sourc sentenc gather use inform befor output target word recent effect attent mechan also explor multimod task becom possibl focus sentenc part imag region approach pool two modal usual includ element wise product sum concaten paper evalu advanc multimod compact bilinear pool method take outer product two vector combin attent featur two modal previous investig visual question answer tri approach multimod imag caption translat show improv compar basic combin method|['Jean-Benoit Delbrouck', 'Stephane Dupont']|['cs.CL']
2017-03-28T14:06:07Z|2017-03-23T13:48:45Z|http://arxiv.org/abs/1703.08068v1|http://arxiv.org/pdf/1703.08068v1|Sequential Recurrent Neural Networks for Language Modeling|sequenti recurr neural network languag model|Feedforward Neural Network (FNN)-based language models estimate the probability of the next word based on the history of the last N words, whereas Recurrent Neural Networks (RNN) perform the same task based only on the last word and some context information that cycles in the network. This paper presents a novel approach, which bridges the gap between these two categories of networks. In particular, we propose an architecture which takes advantage of the explicit, sequential enumeration of the word history in FNN structure while enhancing each word representation at the projection layer through recurrent context information that evolves in the network. The context integration is performed using an additional word-dependent weight matrix that is also learned during the training. Extensive experiments conducted on the Penn Treebank (PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a significant reduction of the perplexity when compared to state-of-the-art feedforward as well as recurrent neural network architectures.|feedforward neural network fnn base languag model estim probabl next word base histori last word wherea recurr neural network rnn perform task base onli last word context inform cycl network paper present novel approach bridg gap two categori network particular propos architectur take advantag explicit sequenti enumer word histori fnn structur enhanc word represent project layer recurr context inform evolv network context integr perform use addit word depend weight matrix also learn dure train extens experi conduct penn treebank ptb larg text compress benchmark ltcb corpus show signific reduct perplex compar state art feedforward well recurr neural network architectur|['Youssef Oualil', 'Clayton Greenberg', 'Mittul Singh', 'Dietrich Klakow']|['cs.CL']
2017-03-28T14:06:07Z|2017-03-23T13:00:14Z|http://arxiv.org/abs/1703.08052v1|http://arxiv.org/pdf/1703.08052v1|Dynamic Bernoulli Embeddings for Language Evolution|dynam bernoulli embed languag evolut|Word embeddings are a powerful approach for unsupervised analysis of language. Recently, Rudolph et al. (2016) developed exponential family embeddings, which cast word embeddings in a probabilistic framework. Here, we develop dynamic embeddings, building on exponential family embeddings to capture how the meanings of words change over time. We use dynamic embeddings to analyze three large collections of historical texts: the U.S. Senate speeches from 1858 to 2009, the history of computer science ACM abstracts from 1951 to 2014, and machine learning papers on the Arxiv from 2007 to 2015. We find dynamic embeddings provide better fits than classical embeddings and capture interesting patterns about how language changes.|word embed power approach unsupervis analysi languag recent rudolph et al develop exponenti famili embed cast word embed probabilist framework develop dynam embed build exponenti famili embed captur mean word chang time use dynam embed analyz three larg collect histor text senat speech histori comput scienc acm abstract machin learn paper arxiv find dynam embed provid better fit classic embed captur interest pattern languag chang|['Maja Rudolph', 'David Blei']|['stat.ML', 'cs.CL']
2017-03-28T14:06:07Z|2017-03-23T11:02:47Z|http://arxiv.org/abs/1703.08002v1|http://arxiv.org/pdf/1703.08002v1|A network of deep neural networks for distant speech recognition|network deep neural network distant speech recognit|Despite the remarkable progress recently made in distant speech recognition, state-of-the-art technology still suffers from a lack of robustness, especially when adverse acoustic conditions characterized by non-stationary noises and reverberation are met. A prominent limitation of current systems lies in the lack of matching and communication between the various technologies involved in the distant speech recognition process. The speech enhancement and speech recognition modules are, for instance, often trained independently. Moreover, the speech enhancement normally helps the speech recognizer, but the output of the latter is not commonly used, in turn, to improve the speech enhancement. To address both concerns, we propose a novel architecture based on a network of deep neural networks, where all the components are jointly trained and better cooperate with each other thanks to a full communication scheme between them. Experiments, conducted using different datasets, tasks and acoustic conditions, revealed that the proposed framework can overtake other competitive solutions, including recent joint training approaches.|despit remark progress recent made distant speech recognit state art technolog still suffer lack robust especi advers acoust condit character non stationari nois reverber met promin limit current system lie lack match communic various technolog involv distant speech recognit process speech enhanc speech recognit modul instanc often train independ moreov speech enhanc normal help speech recogn output latter common use turn improv speech enhanc address concern propos novel architectur base network deep neural network compon joint train better cooper thank full communic scheme experi conduct use differ dataset task acoust condit reveal propos framework overtak competit solut includ recent joint train approach|['Mirco Ravanelli', 'Philemon Brakel', 'Maurizio Omologo', 'Yoshua Bengio']|['cs.CL', 'cs.LG']
2017-03-28T14:06:07Z|2017-03-22T18:20:07Z|http://arxiv.org/abs/1703.07805v1|http://arxiv.org/abs/1703.07805v1|Supervised Typing of Big Graphs using Semantic Embeddings|supervis type big graph use semant embed|We propose a supervised algorithm for generating type embeddings in the same semantic vector space as a given set of entity embeddings. The algorithm is agnostic to the derivation of the underlying entity embeddings. It does not require any manual feature engineering, generalizes well to hundreds of types and achieves near-linear scaling on Big Graphs containing many millions of triples and instances by virtue of an incremental execution. We demonstrate the utility of the embeddings on a type recommendation task, outperforming a non-parametric feature-agnostic baseline while achieving 15x speedup and near-constant memory usage on a full partition of DBpedia. Using state-of-the-art visualization, we illustrate the agreement of our extensionally derived DBpedia type embeddings with the manually curated domain ontology. Finally, we use the embeddings to probabilistically cluster about 4 million DBpedia instances into 415 types in the DBpedia ontology.|propos supervis algorithm generat type embed semant vector space given set entiti embed algorithm agnost deriv entiti embed doe requir ani manual featur engin general well hundr type achiev near linear scale big graph contain mani million tripl instanc virtu increment execut demonstr util embed type recommend task outperform non parametr featur agnost baselin achiev speedup near constant memori usag full partit dbpedia use state art visual illustr agreement extension deriv dbpedia type embed manual curat domain ontolog final use embed probabilist cluster million dbpedia instanc type dbpedia ontolog|['Mayank Kejriwal', 'Pedro Szekely']|['cs.CL', 'cs.AI']
2017-03-28T14:06:07Z|2017-03-22T17:17:16Z|http://arxiv.org/abs/1703.07754v1|http://arxiv.org/pdf/1703.07754v1|Direct Acoustics-to-Word Models for English Conversational Speech   Recognition|direct acoust word model english convers speech recognit|Recent work on end-to-end automatic speech recognition (ASR) has shown that the connectionist temporal classification (CTC) loss can be used to convert acoustics to phone or character sequences. Such systems are used with a dictionary and separately-trained Language Model (LM) to produce word sequences. However, they are not truly end-to-end in the sense of mapping acoustics directly to words without an intermediate phone representation. In this paper, we present the first results employing direct acoustics-to-word CTC models on two well-known public benchmark tasks: Switchboard and CallHome. These models do not require an LM or even a decoder at run-time and hence recognize speech with minimal complexity. However, due to the large number of word output units, CTC word models require orders of magnitude more data to train reliably compared to traditional systems. We present some techniques to mitigate this issue. Our CTC word model achieves a word error rate of 13.0%/18.8% on the Hub5-2000 Switchboard/CallHome test sets without any LM or decoder compared with 9.6%/16.0% for phone-based CTC with a 4-gram LM. We also present rescoring results on CTC word model lattices to quantify the performance benefits of a LM, and contrast the performance of word and phone CTC models.|recent work end end automat speech recognit asr shown connectionist tempor classif ctc loss use convert acoust phone charact sequenc system use dictionari separ train languag model lm produc word sequenc howev truli end end sens map acoust direct word without intermedi phone represent paper present first result employ direct acoust word ctc model two well known public benchmark task switchboard callhom model requir lm even decod run time henc recogn speech minim complex howev due larg number word output unit ctc word model requir order magnitud data train reliabl compar tradit system present techniqu mitig issu ctc word model achiev word error rate hub switchboard callhom test set without ani lm decod compar phone base ctc gram lm also present rescor result ctc word model lattic quantifi perform benefit lm contrast perform word phone ctc model|['Kartik Audhkhasi', 'Bhuvana Ramabhadran', 'George Saon', 'Michael Picheny', 'David Nahamoo']|['cs.CL', 'cs.NE', 'stat.ML']
2017-03-28T14:06:07Z|2017-03-22T15:42:28Z|http://arxiv.org/abs/1703.07713v1|http://arxiv.org/pdf/1703.07713v1|Hierarchical RNN with Static Sentence-Level Attention for Text-Based   Speaker Change Detection|hierarch rnn static sentenc level attent text base speaker chang detect|Traditional speaker change detection in dialogues is typically based on audio input. In some scenarios, however, researchers can only obtain text, and do not have access to raw audio signals. Moreover, with the increasing need of deep semantic processing, text-based dialogue understanding is attracting more attention in the community. These raise the problem of text-based speaker change detection. In this paper, we formulate the task as a matching problem of utterances before and after a certain decision point; we propose a hierarchical recurrent neural network (RNN) with static sentence-level attention. Our model comprises three main components: a sentence encoder with a long short term memory (LSTM)-based RNN, a context encoder with another LSTM-RNN, and a static sentence-level attention mechanism, which allows rich information interaction. Experimental results show that neural networks consistently achieve better performance than feature-based approaches, and that our attention-based model significantly outperforms non-attention neural networks.|tradit speaker chang detect dialogu typic base audio input scenario howev research onli obtain text access raw audio signal moreov increas need deep semant process text base dialogu understand attract attent communiti rais problem text base speaker chang detect paper formul task match problem utter befor certain decis point propos hierarch recurr neural network rnn static sentenc level attent model compris three main compon sentenc encod long short term memori lstm base rnn context encod anoth lstm rnn static sentenc level attent mechan allow rich inform interact experiment result show neural network consist achiev better perform featur base approach attent base model signific outperform non attent neural network|['Zhao Meng', 'Lili Mou', 'Zhi Jin']|['cs.CL']
2017-03-28T14:06:12Z|2017-03-22T10:08:51Z|http://arxiv.org/abs/1703.07588v1|http://arxiv.org/pdf/1703.07588v1|Gate Activation Signal Analysis for Gated Recurrent Neural Networks and   Its Correlation with Phoneme Boundaries|gate activ signal analysi gate recurr neural network correl phonem boundari|In this paper we analyze the gate activation signals inside the gated recurrent neural networks, and find the temporal structure of such signals is highly correlated with the phoneme boundaries. This correlation is further verified by a set of experiments for phoneme segmentation, in which better results compared to standard approaches were obtained.|paper analyz gate activ signal insid gate recurr neural network find tempor structur signal high correl phonem boundari correl verifi set experi phonem segment better result compar standard approach obtain|['Yu-Hsuan Wang', 'Cheng-Tao Chung', 'Hung-yi Lee']|['cs.SD', 'cs.CL', 'cs.LG']
2017-03-28T14:06:12Z|2017-03-22T00:37:33Z|http://arxiv.org/abs/1703.07476v1|http://arxiv.org/pdf/1703.07476v1|Topic Identification for Speech without ASR|topic identif speech without asr|Modern topic identification (topic ID) systems for speech use automatic speech recognition (ASR) to produce speech transcripts, and perform supervised classification on such ASR outputs. However, under resource-limited conditions, the manually transcribed speech required to develop standard ASR systems can be severely limited or unavailable. In this paper, we investigate alternative unsupervised solutions to obtaining tokenizations of speech in terms of a vocabulary of automatically discovered word-like or phoneme-like units, without depending on the supervised training of ASR systems. Moreover, using automatic phoneme-like tokenizations, we demonstrate that a convolutional neural network based framework for learning spoken document representations provides competitive performance compared to a standard bag-of-words representation, as evidenced by comprehensive topic ID evaluations on both single-label and multi-label classification tasks.|modern topic identif topic id system speech use automat speech recognit asr produc speech transcript perform supervis classif asr output howev resourc limit condit manual transcrib speech requir develop standard asr system sever limit unavail paper investig altern unsupervis solut obtain token speech term vocabulari automat discov word like phonem like unit without depend supervis train asr system moreov use automat phonem like token demonstr convolut neural network base framework learn spoken document represent provid competit perform compar standard bag word represent evidenc comprehens topic id evalu singl label multi label classif task|['Chunxi Liu', 'Jan Trmal', 'Matthew Wiesner', 'Craig Harman', 'Sanjeev Khudanpur']|['cs.CL']
2017-03-28T14:06:12Z|2017-03-21T21:36:28Z|http://arxiv.org/abs/1703.07438v1|http://arxiv.org/pdf/1703.07438v1|The NLTK FrameNet API: Designing for Discoverability with a Rich   Linguistic Resource|nltk framenet api design discover rich linguist resourc|A new Python API, integrated within the NLTK suite, offers access to the FrameNet 1.7 lexical database. The lexicon (structured in terms of frames) as well as annotated sentences can be processed programatically, or browsed with human-readable displays via the interactive Python prompt.|new python api integr within nltk suit offer access framenet lexic databas lexicon structur term frame well annot sentenc process programat brows human readabl display via interact python prompt|['Nathan Schneider', 'Chuck Wooters']|['cs.CL']
2017-03-28T14:06:12Z|2017-03-21T08:24:50Z|http://arxiv.org/abs/1703.07090v1|http://arxiv.org/pdf/1703.07090v1|Deep LSTM for Large Vocabulary Continuous Speech Recognition|deep lstm larg vocabulari continu speech recognit|Recurrent neural networks (RNNs), especially long short-term memory (LSTM) RNNs, are effective network for sequential task like speech recognition. Deeper LSTM models perform well on large vocabulary continuous speech recognition, because of their impressive learning ability. However, it is more difficult to train a deeper network. We introduce a training framework with layer-wise training and exponential moving average methods for deeper LSTM models. It is a competitive framework that LSTM models of more than 7 layers are successfully trained on Shenma voice search data in Mandarin and they outperform the deep LSTM models trained by conventional approach. Moreover, in order for online streaming speech recognition applications, the shallow model with low real time factor is distilled from the very deep model. The recognition accuracy have little loss in the distillation process. Therefore, the model trained with the proposed training framework reduces relative 14\% character error rate, compared to original model which has the similar real-time capability. Furthermore, the novel transfer learning strategy with segmental Minimum Bayes-Risk is also introduced in the framework. The strategy makes it possible that training with only a small part of dataset could outperform full dataset training from the beginning.|recurr neural network rnns especi long short term memori lstm rnns effect network sequenti task like speech recognit deeper lstm model perform well larg vocabulari continu speech recognit becaus impress learn abil howev difficult train deeper network introduc train framework layer wise train exponenti move averag method deeper lstm model competit framework lstm model layer success train shenma voic search data mandarin outperform deep lstm model train convent approach moreov order onlin stream speech recognit applic shallow model low real time factor distil veri deep model recognit accuraci littl loss distil process therefor model train propos train framework reduc relat charact error rate compar origin model similar real time capabl furthermor novel transfer learn strategi segment minimum bay risk also introduc framework strategi make possibl train onli small part dataset could outperform full dataset train begin|['Xu Tian', 'Jun Zhang', 'Zejun Ma', 'Yi He', 'Juan Wei', 'Peihao Wu', 'Wenchang Situ', 'Shuai Li', 'Yang Zhang']|['cs.CL']
2017-03-28T14:06:12Z|2017-03-21T04:56:14Z|http://arxiv.org/abs/1703.07055v1|http://arxiv.org/pdf/1703.07055v1|Investigation of Language Understanding Impact for Reinforcement   Learning Based Dialogue Systems|investig languag understand impact reinforc learn base dialogu system|Language understanding is a key component in a spoken dialogue system. In this paper, we investigate how the language understanding module influences the dialogue system performance by conducting a series of systematic experiments on a task-oriented neural dialogue system in a reinforcement learning based setting. The empirical study shows that among different types of language understanding errors, slot-level errors can have more impact on the overall performance of a dialogue system compared to intent-level errors. In addition, our experiments demonstrate that the reinforcement learning based dialogue system is able to learn when and what to confirm in order to achieve better performance and greater robustness.|languag understand key compon spoken dialogu system paper investig languag understand modul influenc dialogu system perform conduct seri systemat experi task orient neural dialogu system reinforc learn base set empir studi show among differ type languag understand error slot level error impact overal perform dialogu system compar intent level error addit experi demonstr reinforc learn base dialogu system abl learn confirm order achiev better perform greater robust|['Xiujun Li', 'Yun-Nung Chen', 'Lihong Li', 'Jianfeng Gao', 'Asli Celikyilmaz']|['cs.CL', 'cs.AI', 'cs.LG']
2017-03-28T14:06:12Z|2017-03-20T11:11:38Z|http://arxiv.org/abs/1703.06676v1|http://arxiv.org/pdf/1703.06676v1|I2T2I: Learning Text to Image Synthesis with Textual Data Augmentation|iti learn text imag synthesi textual data augment|Translating information between text and image is a fundamental problem in artificial intelligence that connects natural language processing and computer vision. In the past few years, performance in image caption generation has seen significant improvement through the adoption of recurrent neural networks (RNN). Meanwhile, text-to-image generation begun to generate plausible images using datasets of specific categories like birds and flowers. We've even seen image generation from multi-category datasets such as the Microsoft Common Objects in Context (MSCOCO) through the use of generative adversarial networks (GANs). Synthesizing objects with a complex shape, however, is still challenging. For example, animals and humans have many degrees of freedom, which means that they can take on many complex shapes. We propose a new training method called Image-Text-Image (I2T2I) which integrates text-to-image and image-to-text (image captioning) synthesis to improve the performance of text-to-image synthesis. We demonstrate that %the capability of our method to understand the sentence descriptions, so as to I2T2I can generate better multi-categories images using MSCOCO than the state-of-the-art. We also demonstrate that I2T2I can achieve transfer learning by using a pre-trained image captioning module to generate human images on the MPII Human Pose|translat inform text imag fundament problem artifici intellig connect natur languag process comput vision past year perform imag caption generat seen signific improv adopt recurr neural network rnn meanwhil text imag generat begun generat plausibl imag use dataset specif categori like bird flower even seen imag generat multi categori dataset microsoft common object context mscoco use generat adversari network gan synthes object complex shape howev still challeng exampl anim human mani degre freedom mean take mani complex shape propos new train method call imag text imag iti integr text imag imag text imag caption synthesi improv perform text imag synthesi demonstr capabl method understand sentenc descript iti generat better multi categori imag use mscoco state art also demonstr iti achiev transfer learn use pre train imag caption modul generat human imag mpii human pose|['Hao Dong', 'Jingqing Zhang', 'Douglas McIlwraith', 'Yike Guo']|['cs.CV', 'cs.CL']
2017-03-28T14:06:12Z|2017-03-20T09:28:38Z|http://arxiv.org/abs/1703.06642v1|http://arxiv.org/pdf/1703.06642v1|Towards a Quantum World Wide Web|toward quantum world wide web|We elaborate a quantum model for corpora of written documents, like the pages forming the World Wide Web. To that end, we are guided by how physicists constructed quantum theory for microscopic entities, which unlike classical objects cannot be fully represented in our spatial theater. We suggest that a similar construction needs to be carried out by linguists and computational scientists, to capture the full meaning content of collections of documental entities. More precisely, we show how to associate a quantum-like 'entity of meaning' to a 'language entity formed by printed documents', considering the latter as the collection of traces that are left by the former, in specific results of search actions that we describe as measurements. In other words, we offer a perspective where a collection of documents, like the Web, is described as the space of manifestation of a more complex entity - the QWeb - which is the object of our modeling, drawing its inspiration from previous studies on operational-realistic approaches to quantum physics and quantum modeling of human cognition and decision-making. We emphasize that a consistent QWeb model needs to account for the observed correlations between words appearing in printed documents, e.g., co-occurrences, as the latter would depend on the 'meaning connections' existing between the concepts that are associated with these words. In that respect, we show that both 'context and interference (quantum) effects' are required to explain the probabilities calculated by counting the relative number of documents containing certain words and co-ocurrrences of words.|elabor quantum model corpora written document like page form world wide web end guid physicist construct quantum theori microscop entiti unlik classic object cannot fulli repres spatial theater suggest similar construct need carri linguist comput scientist captur full mean content collect document entiti precis show associ quantum like entiti mean languag entiti form print document consid latter collect trace left former specif result search action describ measur word offer perspect collect document like web describ space manifest complex entiti qweb object model draw inspir previous studi oper realist approach quantum physic quantum model human cognit decis make emphas consist qweb model need account observ correl word appear print document co occurr latter would depend mean connect exist concept associ word respect show context interfer quantum effect requir explain probabl calcul count relat number document contain certain word co ocurrr word|['Diederik Aerts', 'Jonito Aerts Arguelles', 'Lester Beltran', 'Lyneth Beltran', 'Isaac Distrito', 'Massimiliano Sassoli de Bianchi', 'Sandro Sozzo', 'Tomas Veloz']|['cs.AI', 'cs.CL', 'quant-ph']
2017-03-28T14:06:12Z|2017-03-20T08:19:43Z|http://arxiv.org/abs/1703.06630v1|http://arxiv.org/pdf/1703.06630v1|Automatic Text Summarization Approaches to Speed up Topic Model Learning   Process|automat text summar approach speed topic model learn process|The number of documents available into Internet moves each day up. For this reason, processing this amount of information effectively and expressibly becomes a major concern for companies and scientists. Methods that represent a textual document by a topic representation are widely used in Information Retrieval (IR) to process big data such as Wikipedia articles. One of the main difficulty in using topic model on huge data collection is related to the material resources (CPU time and memory) required for model estimate. To deal with this issue, we propose to build topic spaces from summarized documents. In this paper, we present a study of topic space representation in the context of big data. The topic space representation behavior is analyzed on different languages. Experiments show that topic spaces estimated from text summaries are as relevant as those estimated from the complete documents. The real advantage of such an approach is the processing time gain: we showed that the processing time can be drastically reduced using summarized documents (more than 60\% in general). This study finally points out the differences between thematic representations of documents depending on the targeted languages such as English or latin languages.|number document avail internet move day reason process amount inform effect express becom major concern compani scientist method repres textual document topic represent wide use inform retriev ir process big data wikipedia articl one main difficulti use topic model huge data collect relat materi resourc cpu time memori requir model estim deal issu propos build topic space summar document paper present studi topic space represent context big data topic space represent behavior analyz differ languag experi show topic space estim text summari relev estim complet document real advantag approach process time gain show process time drastic reduc use summar document general studi final point differ themat represent document depend target languag english latin languag|['Mohamed Morchid', 'Juan-Manuel Torres-Moreno', 'Richard Dufour', 'Javier Ramírez-Rodríguez', 'Georges Linarès']|['cs.IR', 'cs.CL']
2017-03-28T14:06:12Z|2017-03-21T17:41:23Z|http://arxiv.org/abs/1703.06585v2|http://arxiv.org/pdf/1703.06585v2|Learning Cooperative Visual Dialog Agents with Deep Reinforcement   Learning|learn cooper visual dialog agent deep reinforc learn|We introduce the first goal-driven training for visual question answering and dialog agents. Specifically, we pose a cooperative 'image guessing' game between two agents -- Qbot and Abot -- who communicate in natural language dialog so that Qbot can select an unseen image from a lineup of images. We use deep reinforcement learning (RL) to learn the policies of these agents end-to-end -- from pixels to multi-agent multi-round dialog to game reward.   We demonstrate two experimental results.   First, as a 'sanity check' demonstration of pure RL (from scratch), we show results on a synthetic world, where the agents communicate in ungrounded vocabulary, i.e., symbols with no pre-specified meanings (X, Y, Z). We find that two bots invent their own communication protocol and start using certain symbols to ask/answer about certain visual attributes (shape/color/style). Thus, we demonstrate the emergence of grounded language and communication among 'visual' dialog agents with no human supervision.   Second, we conduct large-scale real-image experiments on the VisDial dataset, where we pretrain with supervised dialog data and show that the RL 'fine-tuned' agents significantly outperform SL agents. Interestingly, the RL Qbot learns to ask questions that Abot is good at, ultimately resulting in more informative dialog and a better team.|introduc first goal driven train visual question answer dialog agent specif pose cooper imag guess game two agent qbot abot communic natur languag dialog qbot select unseen imag lineup imag use deep reinforc learn rl learn polici agent end end pixel multi agent multi round dialog game reward demonstr two experiment result first saniti check demonstr pure rl scratch show result synthet world agent communic unground vocabulari symbol pre specifi mean find two bot invent communic protocol start use certain symbol ask answer certain visual attribut shape color style thus demonstr emerg ground languag communic among visual dialog agent human supervis second conduct larg scale real imag experi visdial dataset pretrain supervis dialog data show rl fine tune agent signific outperform sl agent interest rl qbot learn ask question abot good ultim result inform dialog better team|['Abhishek Das', 'Satwik Kottur', 'José M. F. Moura', 'Stefan Lee', 'Dhruv Batra']|['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']
2017-03-28T14:06:12Z|2017-03-19T23:42:28Z|http://arxiv.org/abs/1703.06541v1|http://arxiv.org/pdf/1703.06541v1|Native Language Identification using Stacked Generalization|nativ languag identif use stack general|Ensemble methods using multiple classifiers have proven to be the most successful approach for the task of Native Language Identification (NLI), achieving the current state of the art. However, a systematic examination of ensemble methods for NLI has yet to be conducted. Additionally, deeper ensemble architectures such as classifier stacking have not been closely evaluated. We present a set of experiments using three ensemble-based models, testing each with multiple configurations and algorithms. This includes a rigorous application of meta-classification models for NLI, achieving state-of-the-art results on three datasets from different languages. We also present the first use of statistical significance testing for comparing NLI systems, showing that our results are significantly better than the previous state of the art. We make available a collection of test set predictions to facilitate future statistical tests.|ensembl method use multipl classifi proven success approach task nativ languag identif nli achiev current state art howev systemat examin ensembl method nli yet conduct addit deeper ensembl architectur classifi stack close evalu present set experi use three ensembl base model test multipl configur algorithm includ rigor applic meta classif model nli achiev state art result three dataset differ languag also present first use statist signific test compar nli system show result signific better previous state art make avail collect test set predict facilit futur statist test|['Shervin Malmasi', 'Mark Dras']|['cs.CL']
2017-03-28T14:06:16Z|2017-03-19T19:56:25Z|http://arxiv.org/abs/1703.06501v1|http://arxiv.org/pdf/1703.06501v1|Métodos de Otimização Combinatória Aplicados ao Problema de   Compressão MultiFrases|todo de otimiza combinat ria aplicado ao problema de compress multifras|The Internet has led to a dramatic increase in the amount of available information. In this context, reading and understanding this flow of information have become costly tasks. In the last years, to assist people to understand textual data, various Natural Language Processing (NLP) applications based on Combinatorial Optimization have been devised. However, for Multi-Sentences Compression (MSC), method which reduces the sentence length without removing core information, the insertion of optimization methods requires further study to improve the performance of MSC. This article describes a method for MSC using Combinatorial Optimization and Graph Theory to generate more informative sentences while maintaining their grammaticality. An experiment led on a corpus of 40 clusters of sentences shows that our system has achieved a very good quality and is better than the state-of-the-art.|internet led dramat increas amount avail inform context read understand flow inform becom cost task last year assist peopl understand textual data various natur languag process nlp applic base combinatori optim devis howev multi sentenc compress msc method reduc sentenc length without remov core inform insert optim method requir studi improv perform msc articl describ method msc use combinatori optim graph theori generat inform sentenc maintain grammat experi led corpus cluster sentenc show system achiev veri good qualiti better state art|['Elvys Linhares Pontes', 'Thiago Gouveia da Silva', 'Andréa Carneiro Linhares', 'Juan-Manuel Torres-Moreno', 'Stéphane Huet']|['cs.CL']
2017-03-28T14:06:16Z|2017-03-19T19:14:55Z|http://arxiv.org/abs/1703.06492v1|http://arxiv.org/pdf/1703.06492v1|VQABQ: Visual Question Answering by Basic Questions|vqabq visual question answer basic question|Taking image and question as the input of our method, it can output the text-based answer of the query question about the given image, so called Visual Question Answering (VQA). There are two main modules in our algorithm. Given a natural language question about an image, the first module takes the question as input and then outputs the basic questions of the main question, given question. The second module takes the main question, image and these basic questions as input and then outputs the text-based answer of the main question. We formulate the basic questions generation problem as a LASSO optimization problem, and also propose a criterion about how to exploit these basic questions to help answer main question. Our method is evaluated on the challenging VQA dataset, and yields the competitive performance compared to state-of-the-art.|take imag question input method output text base answer queri question given imag call visual question answer vqa two main modul algorithm given natur languag question imag first modul take question input output basic question main question given question second modul take main question imag basic question input output text base answer main question formul basic question generat problem lasso optim problem also propos criterion exploit basic question help answer main question method evalu challeng vqa dataset yield competit perform compar state art|['Jia-Hong Huang', 'Modar Alfadly', 'Bernard Ghanem']|['cs.CV', 'cs.CL']
2017-03-28T14:06:16Z|2017-03-18T20:21:44Z|http://arxiv.org/abs/1703.06345v1|http://arxiv.org/pdf/1703.06345v1|Transfer Learning for Sequence Tagging with Hierarchical Recurrent   Networks|transfer learn sequenc tag hierarch recurr network|Recent papers have shown that neural networks obtain state-of-the-art performance on several different sequence tagging tasks. One appealing property of such systems is their generality, as excellent performance can be achieved with a unified architecture and without task-specific feature engineering. However, it is unclear if such systems can be used for tasks without large amounts of training data. In this paper we explore the problem of transfer learning for neural sequence taggers, where a source task with plentiful annotations (e.g., POS tagging on Penn Treebank) is used to improve performance on a target task with fewer available annotations (e.g., POS tagging for microblogs). We examine the effects of transfer learning for deep hierarchical recurrent networks across domains, applications, and languages, and show that significant improvement can often be obtained. These improvements lead to improvements over the current state-of-the-art on several well-studied tasks.|recent paper shown neural network obtain state art perform sever differ sequenc tag task one appeal properti system general excel perform achiev unifi architectur without task specif featur engin howev unclear system use task without larg amount train data paper explor problem transfer learn neural sequenc tagger sourc task plenti annot pos tag penn treebank use improv perform target task fewer avail annot pos tag microblog examin effect transfer learn deep hierarch recurr network across domain applic languag show signific improv often obtain improv lead improv current state art sever well studi task|['Zhilin Yang', 'Ruslan Salakhutdinov', 'William W. Cohen']|['cs.CL', 'cs.LG']
2017-03-28T14:06:16Z|2017-03-17T17:16:02Z|http://arxiv.org/abs/1703.06108v1|http://arxiv.org/abs/1703.06108v1|Global Entity Ranking Across Multiple Languages|global entiti rank across multipl languag|We present work on building a global long-tailed ranking of entities across multiple languages using Wikipedia and Freebase knowledge bases. We identify multiple features and build a model to rank entities using a ground-truth dataset of more than 10 thousand labels. The final system ranks 27 million entities with 75% precision and 48% F1 score. We provide performance evaluation and empirical evidence of the quality of ranking across languages, and open the final ranked lists for future research.|present work build global long tail rank entiti across multipl languag use wikipedia freebas knowledg base identifi multipl featur build model rank entiti use ground truth dataset thousand label final system rank million entiti precis score provid perform evalu empir evid qualiti rank across languag open final rank list futur research|['Prantik Bhattacharyya', 'Nemanja Spasojevic']|['cs.IR', 'cs.CL', 'cs.SI', 'H.3.1']
2017-03-28T14:06:16Z|2017-03-17T07:53:03Z|http://arxiv.org/abs/1703.05916v1|http://arxiv.org/pdf/1703.05916v1|Construction of a Japanese Word Similarity Dataset|construct japanes word similar dataset|An evaluation of distributed word representation is generally conducted using a word similarity task and/or a word analogy task. There are many datasets readily available for these tasks in English. However, evaluating distributed representation in languages that do not have such resources (e.g., Japanese) is difficult. Therefore, as a first step toward evaluating distributed representations in Japanese, we constructed a Japanese word similarity dataset. To the best of our knowledge, our dataset is the first resource that can be used to evaluate distributed representations in Japanese. Moreover, our dataset contains various parts of speech and includes rare words in addition to common words.|evalu distribut word represent general conduct use word similar task word analog task mani dataset readili avail task english howev evalu distribut represent languag resourc japanes difficult therefor first step toward evalu distribut represent japanes construct japanes word similar dataset best knowledg dataset first resourc use evalu distribut represent japanes moreov dataset contain various part speech includ rare word addit common word|['Yuya Sakaizawa', 'Mamoru Komachi']|['cs.CL']
2017-03-28T14:06:16Z|2017-03-20T00:28:07Z|http://arxiv.org/abs/1703.05908v2|http://arxiv.org/pdf/1703.05908v2|Learning Robust Visual-Semantic Embeddings|learn robust visual semant embed|Many of the existing methods for learning joint embedding of images and text use only supervised information from paired images and its textual attributes. Taking advantage of the recent success of unsupervised learning in deep neural networks, we propose an end-to-end learning framework that is able to extract more robust multi-modal representations across domains. The proposed method combines representation learning models (i.e., auto-encoders) together with cross-domain learning criteria (i.e., Maximum Mean Discrepancy loss) to learn joint embeddings for semantic and visual features. A novel technique of unsupervised-data adaptation inference is introduced to construct more comprehensive embeddings for both labeled and unlabeled data. We evaluate our method on Animals with Attributes and Caltech-UCSD Birds 200-2011 dataset with a wide range of applications, including zero and few-shot image recognition and retrieval, from inductive to transductive settings. Empirically, we show that our framework improves over the current state of the art on many of the considered tasks.|mani exist method learn joint embed imag text use onli supervis inform pair imag textual attribut take advantag recent success unsupervis learn deep neural network propos end end learn framework abl extract robust multi modal represent across domain propos method combin represent learn model auto encod togeth cross domain learn criteria maximum mean discrep loss learn joint embed semant visual featur novel techniqu unsupervis data adapt infer introduc construct comprehens embed label unlabel data evalu method anim attribut caltech ucsd bird dataset wide rang applic includ zero shot imag recognit retriev induct transduct set empir show framework improv current state art mani consid task|['Yao-Hung Hubert Tsai', 'Liang-Kang Huang', 'Ruslan Salakhutdinov']|['cs.CV', 'cs.CL', 'cs.LG']
2017-03-28T14:06:16Z|2017-03-17T03:38:48Z|http://arxiv.org/abs/1703.05880v1|http://arxiv.org/pdf/1703.05880v1|Empirical Evaluation of Parallel Training Algorithms on Acoustic   Modeling|empir evalu parallel train algorithm acoust model|Deep learning models (DLMs) are state-of-the-art techniques in speech recognition. However, training good DLMs can be time consuming especially for production-size models and corpora. Although several parallel training algorithms have been proposed to improve training efficiency, there is no clear guidance on which one to choose for the task in hand due to lack of systematic and fair comparison among them. In this paper we aim at filling this gap by comparing four popular parallel training algorithms in speech recognition, namely asynchronous stochastic gradient descent (ASGD), blockwise model-update filtering (BMUF), bulk synchronous parallel (BSP) and elastic averaging stochastic gradient descent (EASGD), on 1000-hour LibriSpeech corpora using feed-forward deep neural networks (DNNs) and convolutional, long short-term memory, DNNs (CLDNNs). Based on our experiments, we recommend using BMUF as the top choice to train acoustic models since it is most stable, scales well with number of GPUs, can achieve reproducible results, and in many cases even outperforms single-GPU SGD. ASGD can be used as a substitute in some cases.|deep learn model dlms state art techniqu speech recognit howev train good dlms time consum especi product size model corpora although sever parallel train algorithm propos improv train effici clear guidanc one choos task hand due lack systemat fair comparison among paper aim fill gap compar four popular parallel train algorithm speech recognit name asynchron stochast gradient descent asgd blockwis model updat filter bmuf bulk synchron parallel bsp elast averag stochast gradient descent easgd hour librispeech corpora use feed forward deep neural network dnns convolut long short term memori dnns cldnns base experi recommend use bmuf top choic train acoust model sinc stabl scale well number gpus achiev reproduc result mani case even outperform singl gpu sgd asgd use substitut case|['Wenpeng Li', 'BinBin Zhang', 'Lei Xie', 'Dong Yu']|['cs.CL', 'cs.LG', 'cs.SD']
2017-03-28T14:06:16Z|2017-03-17T00:02:42Z|http://arxiv.org/abs/1703.05851v1|http://arxiv.org/pdf/1703.05851v1|Temporal Information Extraction for Question Answering Using Syntactic   Dependencies in an LSTM-based Architecture|tempor inform extract question answer use syntact depend lstm base architectur|"In this paper, we propose to use a set of simple, uniform in architecture LSTM-based models to recover different kinds of temporal relations from text. Using the shortest dependency path between entities as input, the same architecture is used to extract intra-sentence, cross-sentence, and document creation time relations. A ""double-checking"" technique reverses entity pairs in classification, boosting the recall of positive cases and reducing misclassifications between opposite classes. An efficient pruning algorithm resolves conflicts globally. Evaluated on QA-TempEval (SemEval2015 Task 5), our proposed technique outperforms state-of-the-art methods by a large margin."|paper propos use set simpl uniform architectur lstm base model recov differ kind tempor relat text use shortest depend path entiti input architectur use extract intra sentenc cross sentenc document creation time relat doubl check techniqu revers entiti pair classif boost recal posit case reduc misclassif opposit class effici prune algorithm resolv conflict global evalu qa tempev semev task propos techniqu outperform state art method larg margin|['Yuanliang Meng', 'Anna Rumshisky', 'Alexey Romanov']|['cs.IR', 'cs.CL']
2017-03-28T14:06:16Z|2017-03-17T04:03:36Z|http://arxiv.org/abs/1703.05706v2|http://arxiv.org/pdf/1703.05706v2|Improving Document Clustering by Eliminating Unnatural Language|improv document cluster elimin unnatur languag|Technical documents contain a fair amount of unnatural language, such as tables, formulas, pseudo-codes, etc. Unnatural language can be an important factor of confusing existing NLP tools. This paper presents an effective method of distinguishing unnatural language from natural language, and evaluates the impact of unnatural language detection on NLP tasks such as document clustering. We view this problem as an information extraction task and build a multiclass classification model identifying unnatural language components into four categories. First, we create a new annotated corpus by collecting slides and papers in various formats, PPT, PDF, and HTML, where unnatural language components are annotated into four categories. We then explore features available from plain text to build a statistical model that can handle any format as long as it is converted into plain text. Our experiments show that removing unnatural language components gives an absolute improvement in document clustering up to 15%. Our corpus and tool are publicly available.|technic document contain fair amount unnatur languag tabl formula pseudo code etc unnatur languag import factor confus exist nlp tool paper present effect method distinguish unnatur languag natur languag evalu impact unnatur languag detect nlp task document cluster view problem inform extract task build multiclass classif model identifi unnatur languag compon four categori first creat new annot corpus collect slide paper various format ppt pdf html unnatur languag compon annot four categori explor featur avail plain text build statist model handl ani format long convert plain text experi show remov unnatur languag compon give absolut improv document cluster corpus tool public avail|['Myungha Jang', 'Jinho D. Choi', 'James Allan']|['cs.IR', 'cs.CL']
2017-03-28T14:06:16Z|2017-03-16T03:15:22Z|http://arxiv.org/abs/1703.05465v1|http://arxiv.org/pdf/1703.05465v1|Neobility at SemEval-2017 Task 1: An Attention-based Sentence Similarity   Model|neobil semev task attent base sentenc similar model|This paper describes a neural-network model which performed competitively (top 6) at the SemEval 2017 cross-lingual Semantic Textual Similarity (STS) task. Our system employs an attention-based recurrent neural network model that optimizes the sentence similarity. In this paper, we describe our participation in the multilingual STS task which measures similarity across English, Spanish, and Arabic.|paper describ neural network model perform competit top semev cross lingual semant textual similar sts task system employ attent base recurr neural network model optim sentenc similar paper describ particip multilingu sts task measur similar across english spanish arab|['Wenli Zhuang', 'Ernie Chang']|['cs.CL']
2017-03-28T14:06:20Z|2017-03-16T01:06:07Z|http://arxiv.org/abs/1703.05320v1|http://arxiv.org/pdf/1703.05320v1|Legal Question Answering using Ranking SVM and Deep Convolutional Neural   Network|legal question answer use rank svm deep convolut neural network|This paper presents a study of employing Ranking SVM and Convolutional Neural Network for two missions: legal information retrieval and question answering in the Competition on Legal Information Extraction/Entailment. For the first task, our proposed model used a triple of features (LSI, Manhattan, Jaccard), and is based on paragraph level instead of article level as in previous studies. In fact, each single-paragraph article corresponds to a particular paragraph in a huge multiple-paragraph article. For the legal question answering task, additional statistical features from information retrieval task integrated into Convolutional Neural Network contribute to higher accuracy.|paper present studi employ rank svm convolut neural network two mission legal inform retriev question answer competit legal inform extract entail first task propos model use tripl featur lsi manhattan jaccard base paragraph level instead articl level previous studi fact singl paragraph articl correspond particular paragraph huge multipl paragraph articl legal question answer task addit statist featur inform retriev task integr convolut neural network contribut higher accuraci|['Phong-Khac Do', 'Huy-Tien Nguyen', 'Chien-Xuan Tran', 'Minh-Tien Nguyen', 'Minh-Le Nguyen']|['cs.CL', 'cs.AI', '14J30 (Primary)', 'H.3; H.3.3; I.2.7']
2017-03-28T14:06:20Z|2017-03-15T23:34:20Z|http://arxiv.org/abs/1703.05423v1|http://arxiv.org/pdf/1703.05423v1|End-to-end optimization of goal-driven and visually grounded dialogue   systems|end end optim goal driven visual ground dialogu system|End-to-end design of dialogue systems has recently become a popular research topic thanks to powerful tools such as encoder-decoder architectures for sequence-to-sequence learning. Yet, most current approaches cast human-machine dialogue management as a supervised learning problem, aiming at predicting the next utterance of a participant given the full history of the dialogue. This vision is too simplistic to render the intrinsic planning problem inherent to dialogue as well as its grounded nature, making the context of a dialogue larger than the sole history. This is why only chit-chat and question answering tasks have been addressed so far using end-to-end architectures. In this paper, we introduce a Deep Reinforcement Learning method to optimize visually grounded task-oriented dialogues, based on the policy gradient algorithm. This approach is tested on a dataset of 120k dialogues collected through Mechanical Turk and provides encouraging results at solving both the problem of generating natural dialogues and the task of discovering a specific object in a complex picture.|end end design dialogu system recent becom popular research topic thank power tool encod decod architectur sequenc sequenc learn yet current approach cast human machin dialogu manag supervis learn problem aim predict next utter particip given full histori dialogu vision simplist render intrins plan problem inher dialogu well ground natur make context dialogu larger sole histori whi onli chit chat question answer task address far use end end architectur paper introduc deep reinforc learn method optim visual ground task orient dialogu base polici gradient algorithm approach test dataset dialogu collect mechan turk provid encourag result solv problem generat natur dialogu task discov specif object complex pictur|['Florian Strub', 'Harm de Vries', 'Jeremie Mary', 'Bilal Piot', 'Aaron Courville', 'Olivier Pietquin']|['cs.CL']
2017-03-28T14:06:20Z|2017-03-15T21:20:44Z|http://arxiv.org/abs/1703.05390v1|http://arxiv.org/pdf/1703.05390v1|Convolutional Recurrent Neural Networks for Small-Footprint Keyword   Spotting|convolut recurr neural network small footprint keyword spot|Keyword spotting (KWS) constitutes a major component of human-technology interfaces. Maximizing the detection accuracy at a low false alarm (FA) rate, while minimizing the footprint size, latency and complexity are the goals for KWS. Towards achieving them, we study Convolutional Recurrent Neural Networks (CRNNs). Inspired by large-scale state-of-the-art speech recognition systems, we combine the strengths of convolutional layers and recurrent layers to exploit local structure and long-range context. We analyze the effect of architecture parameters, and propose training strategies to improve performance. With only ~230k parameters, our CRNN model yields acceptably low latency, and achieves 97.71% accuracy at 0.5 FA/hour for 5 dB signal-to-noise ratio.|keyword spot kws constitut major compon human technolog interfac maxim detect accuraci low fals alarm fa rate minim footprint size latenc complex goal kws toward achiev studi convolut recurr neural network crnns inspir larg scale state art speech recognit system combin strength convolut layer recurr layer exploit local structur long rang context analyz effect architectur paramet propos train strategi improv perform onli paramet crnn model yield accept low latenc achiev accuraci fa hour db signal nois ratio|['Sercan O. Arik', 'Markus Kliegl', 'Rewon Child', 'Joel Hestness', 'Andrew Gibiansky', 'Chris Fougner', 'Ryan Prenger', 'Adam Coates']|['cs.CL', 'cs.AI', 'cs.LG']
2017-03-28T14:06:20Z|2017-03-15T17:01:20Z|http://arxiv.org/abs/1703.05260v1|http://arxiv.org/pdf/1703.05260v1|InScript: Narrative texts annotated with script information|inscript narrat text annot script inform|This paper presents the InScript corpus (Narrative Texts Instantiating Script structure). InScript is a corpus of 1,000 stories centered around 10 different scenarios. Verbs and noun phrases are annotated with event and participant types, respectively. Additionally, the text is annotated with coreference information. The corpus shows rich lexical variation and will serve as a unique resource for the study of the role of script knowledge in natural language processing.|paper present inscript corpus narrat text instanti script structur inscript corpus stori center around differ scenario verb noun phrase annot event particip type respect addit text annot corefer inform corpus show rich lexic variat serv uniqu resourc studi role script knowledg natur languag process|['Ashutosh Modi', 'Tatjana Anikina', 'Simon Ostermann', 'Manfred Pinkal']|['cs.CL', 'cs.AI']
2017-03-28T14:06:20Z|2017-03-16T08:57:29Z|http://arxiv.org/abs/1703.05123v2|http://arxiv.org/pdf/1703.05123v2|Character-based Neural Embeddings for Tweet Clustering|charact base neural embed tweet cluster|In this paper we show how the performance of tweet clustering can be improved by leveraging character-based neural networks. The proposed approach overcomes the limitations related to the vocabulary explosion in the word-based models and allows for the seamless processing of the multilingual content. Our evaluation results and code are available on-line at https://github.com/vendi12/tweet2vec_clustering|paper show perform tweet cluster improv leverag charact base neural network propos approach overcom limit relat vocabulari explos word base model allow seamless process multilingu content evalu result code avail line https github com vendi tweetvec cluster|['Svitlana Vakulenko', 'Lyndon Nixon', 'Mihai Lupu']|['cs.IR', 'cs.CL']
2017-03-28T14:06:20Z|2017-03-15T12:32:34Z|http://arxiv.org/abs/1703.05122v1|http://arxiv.org/pdf/1703.05122v1|Is this word borrowed? An automatic approach to quantify the likeliness   of borrowing in social media|word borrow automat approach quantifi likeli borrow social media|Code-mixing or code-switching are the effortless phenomena of natural switching between two or more languages in a single conversation. Use of a foreign word in a language; however, does not necessarily mean that the speaker is code-switching because often languages borrow lexical items from other languages. If a word is borrowed, it becomes a part of the lexicon of a language; whereas, during code-switching, the speaker is aware that the conversation involves foreign words or phrases. Identifying whether a foreign word used by a bilingual speaker is due to borrowing or code-switching is a fundamental importance to theories of multilingualism, and an essential prerequisite towards the development of language and speech technologies for multilingual communities. In this paper, we present a series of novel computational methods to identify the borrowed likeliness of a word, based on the social media signals. We first propose context based clustering method to sample a set of candidate words from the social media data.Next, we propose three novel and similar metrics based on the usage of these words by the users in different tweets; these metrics were used to score and rank the candidate words indicating their borrowed likeliness. We compare these rankings with a ground truth ranking constructed through a human judgment experiment. The Spearman's rank correlation between the two rankings (nearly 0.62 for all the three metric variants) is more than double the value (0.26) of the most competitive existing baseline reported in the literature. Some other striking observations are, (i) the correlation is higher for the ground truth data elicited from the younger participants (age less than 30) than that from the older participants, and (ii )those participants who use mixed-language for tweeting the least, provide the best signals of borrowing.|code mix code switch effortless phenomena natur switch two languag singl convers use foreign word languag howev doe necessarili mean speaker code switch becaus often languag borrow lexic item languag word borrow becom part lexicon languag wherea dure code switch speaker awar convers involv foreign word phrase identifi whether foreign word use bilingu speaker due borrow code switch fundament import theori multilingu essenti prerequisit toward develop languag speech technolog multilingu communiti paper present seri novel comput method identifi borrow likeli word base social media signal first propos context base cluster method sampl set candid word social media data next propos three novel similar metric base usag word user differ tweet metric use score rank candid word indic borrow likeli compar rank ground truth rank construct human judgment experi spearman rank correl two rank near three metric variant doubl valu competit exist baselin report literatur strike observ correl higher ground truth data elicit younger particip age less older particip ii particip use mix languag tweet least provid best signal borrow|['Jasabanta Patro', 'Bidisha Samanta', 'Saurabh Singh', 'Prithwish Mukherjee', 'Monojit Choudhury', 'Animesh Mukherjee']|['cs.CL']
2017-03-28T14:06:20Z|2017-03-15T04:57:17Z|http://arxiv.org/abs/1703.04929v1|http://arxiv.org/pdf/1703.04929v1|SyntaxNet Models for the CoNLL 2017 Shared Task|syntaxnet model conll share task|"We describe a baseline dependency parsing system for the CoNLL2017 Shared Task. This system, which we call ""ParseySaurus,"" uses the DRAGNN framework [Kong et al, 2017] to combine transition-based recurrent parsing and tagging with character-based word representations. On the v1.3 Universal Dependencies Treebanks, the new system outpeforms the publicly available, state-of-the-art ""Parsey's Cousins"" models by 3.47% absolute Labeled Accuracy Score (LAS) across 52 treebanks."|describ baselin depend pars system conll share task system call parseysaurus use dragnn framework kong et al combin transit base recurr pars tag charact base word represent univers depend treebank new system outpeform public avail state art parsey cousin model absolut label accuraci score las across treebank|['Chris Alberti', 'Daniel Andor', 'Ivan Bogatyy', 'Michael Collins', 'Dan Gillick', 'Lingpeng Kong', 'Terry Koo', 'Ji Ma', 'Mark Omernick', 'Slav Petrov', 'Chayut Thanapirom', 'Zora Tung', 'David Weiss']|['cs.CL']
2017-03-28T14:06:20Z|2017-03-15T04:00:27Z|http://arxiv.org/abs/1703.04914v1|http://arxiv.org/pdf/1703.04914v1|Ensemble of Neural Classifiers for Scoring Knowledge Base Triples|ensembl neural classifi score knowledg base tripl|This paper describes our approach for the triple scoring task at WSDM Cup 2017. The task aims to assign a relevance score for each pair of entities and their types in a knowledge base in order to enhance the ranking results in entity retrieval tasks. We propose an approach wherein the outputs of multiple neural network classifiers are combined using a supervised machine learning model. The experimental results show that our proposed method achieves the best performance in one out of three measures, and performs competitively in the other two measures.|paper describ approach tripl score task wsdm cup task aim assign relev score pair entiti type knowledg base order enhanc rank result entiti retriev task propos approach wherein output multipl neural network classifi combin use supervis machin learn model experiment result show propos method achiev best perform one three measur perform competit two measur|['Ikuya Yamada', 'Motoki Sato', 'Hiroyuki Shindo']|['cs.CL', 'cs.IR']
2017-03-28T14:06:20Z|2017-03-15T03:30:13Z|http://arxiv.org/abs/1703.04908v1|http://arxiv.org/pdf/1703.04908v1|Emergence of Grounded Compositional Language in Multi-Agent Populations|emerg ground composit languag multi agent popul|By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis. However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient. In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations. Towards this end, we propose a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined vocabulary and syntax. We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable.|captur statist pattern larg corpora machin learn enabl signific advanc natur languag process includ machin translat question answer sentiment analysi howev agent intellig interact human simpli captur statist pattern insuffici paper investig ground composit languag emerg mean achiev goal multi agent popul toward end propos multi agent learn environ learn method bring emerg basic composit languag languag repres stream abstract discret symbol utter agent time nonetheless coher structur possess defin vocabulari syntax also observ emerg non verbal communic point guid languag communic unavail|['Igor Mordatch', 'Pieter Abbeel']|['cs.AI', 'cs.CL']
2017-03-28T14:06:20Z|2017-03-15T02:26:25Z|http://arxiv.org/abs/1703.04887v1|http://arxiv.org/pdf/1703.04887v1|Improving Neural Machine Translation with Conditional Sequence   Generative Adversarial Nets|improv neural machin translat condit sequenc generat adversari net|This paper proposes a new route for applying the generative adversarial nets (GANs) to NLP tasks (taking the neural machine translation as an instance) and the widespread perspective that GANs can't work well in the NLP area turns out to be unreasonable. In this work, we build a conditional sequence generative adversarial net which comprises of two adversarial sub models, a generative model (generator) which translates the source sentence into the target sentence as the traditional NMT models do and a discriminative model (discriminator) which discriminates the machine-translated target sentence from the human-translated sentence. From the perspective of Turing test, the proposed model is to generate the translation which is indistinguishable from the human-translated one. Experiments show that the proposed model achieves significant improvements than the traditional NMT model. In Chinese-English translation tasks, we obtain up to +2.0 BLEU points improvement. To the best of our knowledge, this is the first time that the quantitative results about the application of GANs in the traditional NLP task is reported. Meanwhile, we present detailed strategies for GAN training. In addition, We find that the discriminator of the proposed model shows great capability in data cleaning.|paper propos new rout appli generat adversari net gan nlp task take neural machin translat instanc widespread perspect gan work well nlp area turn unreason work build condit sequenc generat adversari net compris two adversari sub model generat model generat translat sourc sentenc target sentenc tradit nmt model discrimin model discrimin discrimin machin translat target sentenc human translat sentenc perspect ture test propos model generat translat indistinguish human translat one experi show propos model achiev signific improv tradit nmt model chines english translat task obtain bleu point improv best knowledg first time quantit result applic gan tradit nlp task report meanwhil present detail strategi gan train addit find discrimin propos model show great capabl data clean|['Zhen Yang', 'Wei Chen', 'Feng Wang', 'Bo Xu']|['cs.CL']
2017-03-28T14:06:24Z|2017-03-15T01:54:52Z|http://arxiv.org/abs/1703.04879v1|http://arxiv.org/pdf/1703.04879v1|Sparse Named Entity Classification using Factorization Machines|spars name entiti classif use factor machin|Named entity classification is the task of classifying text-based elements into various categories, including places, names, dates, times, and monetary values. A bottleneck in named entity classification, however, is the data problem of sparseness, because new named entities continually emerge, making it rather difficult to maintain a dictionary for named entity classification. Thus, in this paper, we address the problem of named entity classification using matrix factorization to overcome the problem of feature sparsity. Experimental results show that our proposed model, with fewer features and a smaller size, achieves competitive accuracy to state-of-the-art models.|name entiti classif task classifi text base element various categori includ place name date time monetari valu bottleneck name entiti classif howev data problem spars becaus new name entiti continu emerg make rather difficult maintain dictionari name entiti classif thus paper address problem name entiti classif use matrix factor overcom problem featur sparsiti experiment result show propos model fewer featur smaller size achiev competit accuraci state art model|['Ai Hirata', 'Mamoru Komachi']|['cs.CL']
2017-03-28T14:06:24Z|2017-03-15T00:47:28Z|http://arxiv.org/abs/1703.04854v1|http://arxiv.org/pdf/1703.04854v1|Distributed-Representation Based Hybrid Recommender System with Short   Item Descriptions|distribut represent base hybrid recommend system short item descript|"Collaborative filtering (CF) aims to build a model from users' past behaviors and/or similar decisions made by other users, and use the model to recommend items for users. Despite of the success of previous collaborative filtering approaches, they are all based on the assumption that there are sufficient rating scores available for building high-quality recommendation models. In real world applications, however, it is often difficult to collect sufficient rating scores, especially when new items are introduced into the system, which makes the recommendation task challenging. We find that there are often ""short"" texts describing features of items, based on which we can approximate the similarity of items and make recommendation together with rating scores. In this paper we ""borrow"" the idea of vector representation of words to capture the information of short texts and embed it into a matrix factorization framework. We empirically show that our approach is effective by comparing it with state-of-the-art approaches."|collabor filter cf aim build model user past behavior similar decis made user use model recommend item user despit success previous collabor filter approach base assumpt suffici rate score avail build high qualiti recommend model real world applic howev often difficult collect suffici rate score especi new item introduc system make recommend task challeng find often short text describ featur item base approxim similar item make recommend togeth rate score paper borrow idea vector represent word captur inform short text emb matrix factor framework empir show approach effect compar state art approach|['Junhua He', 'Hankz Hankui Zhuo', 'Jarvan Law']|['cs.IR', 'cs.CL']
2017-03-28T14:06:24Z|2017-03-14T23:25:34Z|http://arxiv.org/abs/1703.04826v1|http://arxiv.org/pdf/1703.04826v1|Encoding Sentences with Graph Convolutional Networks for Semantic Role   Labeling|encod sentenc graph convolut network semant role label|Semantic role labeling (SRL) is the task of identifying the predicate-argument structure of a sentence. It is typically regarded as an important step in the standard natural language processing pipeline, providing information to downstream tasks such as information extraction and question answering. As the semantic representations are closely related to syntactic ones, we exploit syntactic information in our model. We propose a version of graph convolutional networks (GCNs), a recent class of multilayer neural networks operating on graphs, suited to modeling syntactic dependency graphs. GCNs over syntactic dependency trees are used as sentence encoders, producing latent feature representations of words in a sentence and capturing information relevant to predicting the semantic representations. We observe that GCN layers are complementary to LSTM ones: when we stack both GCN and LSTM layers, we obtain a substantial improvement over an already state-of-the-art LSTM SRL model, resulting in the best reported scores on the standard benchmark (CoNLL-2009) both for Chinese and English.|semant role label srl task identifi predic argument structur sentenc typic regard import step standard natur languag process pipelin provid inform downstream task inform extract question answer semant represent close relat syntact one exploit syntact inform model propos version graph convolut network gcns recent class multilay neural network oper graph suit model syntact depend graph gcns syntact depend tree use sentenc encod produc latent featur represent word sentenc captur inform relev predict semant represent observ gcn layer complementari lstm one stack gcn lstm layer obtain substanti improv alreadi state art lstm srl model result best report score standard benchmark conll chines english|['Diego Marcheggiani', 'Ivan Titov']|['cs.CL', 'cs.LG']
2017-03-28T14:06:24Z|2017-03-14T23:09:45Z|http://arxiv.org/abs/1703.04816v1|http://arxiv.org/pdf/1703.04816v1|FastQA: A Simple and Efficient Neural Architecture for Question   Answering|fastqa simpl effici neural architectur question answer|Recent development of large-scale question answering (QA) datasets triggered a substantial amount of research into end-to-end neural architectures for QA. Increasingly complex systems have been conceived without comparison to a simpler neural baseline system that would justify their complexity. In this work, we propose a simple heuristic that guided the development of FastQA, an efficient end-to-end neural model for question answering that is very competitive with existing models. We further demonstrate, that an extended version (FastQAExt) achieves state-of-the-art results on recent benchmark datasets, namely SQuAD, NewsQA and MsMARCO, outperforming most existing models. However, we show that increasing the complexity of FastQA to FastQAExt does not yield any systematic improvements. We argue that the same holds true for most existing systems that are similar to FastQAExt. A manual analysis reveals that our proposed heuristic explains most predictions of our model, which indicates that modeling a simple heuristic is enough to achieve strong performance on extractive QA datasets. The overall strong performance of FastQA puts results of existing, more complex models into perspective.|recent develop larg scale question answer qa dataset trigger substanti amount research end end neural architectur qa increas complex system conceiv without comparison simpler neural baselin system would justifi complex work propos simpl heurist guid develop fastqa effici end end neural model question answer veri competit exist model demonstr extend version fastqaext achiev state art result recent benchmark dataset name squad newsqa msmarco outperform exist model howev show increas complex fastqa fastqaext doe yield ani systemat improv argu hold true exist system similar fastqaext manual analysi reveal propos heurist explain predict model indic model simpl heurist enough achiev strong perform extract qa dataset overal strong perform fastqa put result exist complex model perspect|['Dirk Weissenborn', 'Georg Wiese', 'Laura Seiffe']|['cs.CL', 'cs.AI', 'cs.NE']
2017-03-28T14:06:24Z|2017-03-14T22:28:51Z|http://arxiv.org/abs/1703.04783v1|http://arxiv.org/pdf/1703.04783v1|Multichannel End-to-end Speech Recognition|multichannel end end speech recognit|The field of speech recognition is in the midst of a paradigm shift: end-to-end neural networks are challenging the dominance of hidden Markov models as a core technology. Using an attention mechanism in a recurrent encoder-decoder architecture solves the dynamic time alignment problem, allowing joint end-to-end training of the acoustic and language modeling components. In this paper we extend the end-to-end framework to encompass microphone array signal processing for noise suppression and speech enhancement within the acoustic encoding network. This allows the beamforming components to be optimized jointly within the recognition architecture to improve the end-to-end speech recognition objective. Experiments on the noisy speech benchmarks (CHiME-4 and AMI) show that our multichannel end-to-end system outperformed the attention-based baseline with input from a conventional adaptive beamformer.|field speech recognit midst paradigm shift end end neural network challeng domin hidden markov model core technolog use attent mechan recurr encod decod architectur solv dynam time align problem allow joint end end train acoust languag model compon paper extend end end framework encompass microphon array signal process nois suppress speech enhanc within acoust encod network allow beamform compon optim joint within recognit architectur improv end end speech recognit object experi noisi speech benchmark chime ami show multichannel end end system outperform attent base baselin input convent adapt beamform|['Tsubasa Ochiai', 'Shinji Watanabe', 'Takaaki Hori', 'John R. Hershey']|['cs.SD', 'cs.CL']
2017-03-28T14:06:24Z|2017-03-14T19:14:32Z|http://arxiv.org/abs/1703.04677v1|http://arxiv.org/pdf/1703.04677v1|A computational investigation of sources of variability in sentence   comprehension difficulty in aphasia|comput investig sourc variabl sentenc comprehens difficulti aphasia|We present a computational evaluation of three hypotheses about sources of deficit in sentence comprehension in aphasia: slowed processing, intermittent deficiency, and resource reduction. The ACT-R based Lewis & Vasishth 2005 model is used to implement these three proposals. Slowed processing is implemented as slowed default production-rule firing time; intermittent deficiency as increased random noise in activation of chunks in memory; and resource reduction as reduced goal activation. As data, we considered subject vs. object relatives presented in a self-paced listening modality to 56 individuals with aphasia (IWA) and 46 matched controls. The participants heard the sentences and carried out a picture verification task to decide on an interpretation of the sentence. These response accuracies are used to identify the best parameters (for each participant) that correspond to the three hypotheses mentioned above. We show that controls have more tightly clustered (less variable) parameter values than IWA; specifically, compared to controls, among IWA there are more individuals with low goal activations, high noise, and slow default action times. This suggests that (i) individual patients show differential amounts of deficit along the three dimensions of slowed processing, intermittent deficient, and resource reduction, (ii) overall, there is evidence for all three sources of deficit playing a role, and (iii) IWA have a more variable range of parameter values than controls. In sum, this study contributes a proof of concept of a quantitative implementation of, and evidence for, these three accounts of comprehension deficits in aphasia.|present comput evalu three hypothes sourc deficit sentenc comprehens aphasia slow process intermitt defici resourc reduct act base lewi vasishth model use implement three propos slow process implement slow default product rule fire time intermitt defici increas random nois activ chunk memori resourc reduct reduc goal activ data consid subject vs object relat present self pace listen modal individu aphasia iwa match control particip heard sentenc carri pictur verif task decid interpret sentenc respons accuraci use identifi best paramet particip correspond three hypothes mention abov show control tight cluster less variabl paramet valu iwa specif compar control among iwa individu low goal activ high nois slow default action time suggest individu patient show differenti amount deficit along three dimens slow process intermitt defici resourc reduct ii overal evid three sourc deficit play role iii iwa variabl rang paramet valu control sum studi contribut proof concept quantit implement evid three account comprehens deficit aphasia|['Paul Mätzig', 'Shravan Vasishth', 'Felix Engelmann', 'David Caplan']|['cs.CL', 'cs.AI']
2017-03-28T14:06:24Z|2017-03-21T12:56:11Z|http://arxiv.org/abs/1703.04650v2|http://arxiv.org/pdf/1703.04650v2|Joint Learning of Correlated Sequence Labelling Tasks Using   Bidirectional Recurrent Neural Networks|joint learn correl sequenc label task use bidirect recurr neural network|The stream of words produced by Automatic Speech Recognition (ASR) systems is devoid of any punctuations and formatting. Most natural language processing applications usually expect segmented and well-formatted texts as input, which is not available in ASR output. This paper proposes a novel technique of jointly modelling multiple correlated tasks such as punctuation and capitalization using bidirectional recurrent neural networks, which leads to improved performance for each of these tasks. This method can be extended for joint modelling of any other correlated multiple sequence labelling tasks.|stream word produc automat speech recognit asr system devoid ani punctuat format natur languag process applic usual expect segment well format text input avail asr output paper propos novel techniqu joint model multipl correl task punctuat capit use bidirect recurr neural network lead improv perform task method extend joint model ani correl multipl sequenc label task|['Vardaan Pahuja', 'Anirban Laha', 'Shachar Mirkin', 'Vikas Raykar', 'Lili Kotlerman', 'Guy Lev']|['cs.CL']
2017-03-28T14:06:24Z|2017-03-25T16:17:03Z|http://arxiv.org/abs/1703.04617v2|http://arxiv.org/pdf/1703.04617v2|Exploring Question Understanding and Adaptation in Neural-Network-Based   Question Answering|explor question understand adapt neural network base question answer|The last several years have seen intensive interest in exploring neural-network-based models for machine comprehension (MC) and question answering (QA). In this paper, we approach the problems by closely modelling questions in a neural network framework. We first introduce syntactic information to help encode questions. We then view and model different types of questions and the information shared among them as an adaptation task and proposed adaptation models for them. On the Stanford Question Answering Dataset (SQuAD), we show that these approaches can help attain better results over a competitive baseline.|last sever year seen intens interest explor neural network base model machin comprehens mc question answer qa paper approach problem close model question neural network framework first introduc syntact inform help encod question view model differ type question inform share among adapt task propos adapt model stanford question answer dataset squad show approach help attain better result competit baselin|['Junbei Zhang', 'Xiaodan Zhu', 'Qian Chen', 'Lirong Dai', 'Si Wei', 'Hui Jiang']|['cs.CL']
2017-03-28T14:06:24Z|2017-03-13T17:34:18Z|http://arxiv.org/abs/1703.04498v1|http://arxiv.org/pdf/1703.04498v1|High-Throughput and Language-Agnostic Entity Disambiguation and Linking   on User Generated Data|high throughput languag agnost entiti disambigu link user generat data|The Entity Disambiguation and Linking (EDL) task matches entity mentions in text to a unique Knowledge Base (KB) identifier such as a Wikipedia or Freebase id. It plays a critical role in the construction of a high quality information network, and can be further leveraged for a variety of information retrieval and NLP tasks such as text categorization and document tagging. EDL is a complex and challenging problem due to ambiguity of the mentions and real world text being multi-lingual. Moreover, EDL systems need to have high throughput and should be lightweight in order to scale to large datasets and run on off-the-shelf machines. More importantly, these systems need to be able to extract and disambiguate dense annotations from the data in order to enable an Information Retrieval or Extraction task running on the data to be more efficient and accurate. In order to address all these challenges, we present the Lithium EDL system and algorithm - a high-throughput, lightweight, language-agnostic EDL system that extracts and correctly disambiguates 75% more entities than state-of-the-art EDL systems and is significantly faster than them.|entiti disambigu link edl task match entiti mention text uniqu knowledg base kb identifi wikipedia freebas id play critic role construct high qualiti inform network leverag varieti inform retriev nlp task text categor document tag edl complex challeng problem due ambigu mention real world text multi lingual moreov edl system need high throughput lightweight order scale larg dataset run shelf machin import system need abl extract disambigu dens annot data order enabl inform retriev extract task run data effici accur order address challeng present lithium edl system algorithm high throughput lightweight languag agnost edl system extract correct disambigu entiti state art edl system signific faster|['Preeti Bhargava', 'Nemanja Spasojevic', 'Guoning Hu']|['cs.IR', 'cs.AI', 'cs.CL']
2017-03-28T14:06:24Z|2017-03-13T17:13:51Z|http://arxiv.org/abs/1703.04489v1|http://arxiv.org/pdf/1703.04489v1|Reinforcement Learning for Transition-Based Mention Detection|reinforc learn transit base mention detect|This paper describes an application of reinforcement learning to the mention detection task. We define a novel action-based formulation for the mention detection task, in which a model can flexibly revise past labeling decisions by grouping together tokens and assigning partial mention labels. We devise a method to create mention-level episodes and we train a model by rewarding correctly labeled complete mentions, irrespective of the inner structure created. The model yields results which are on par with a competitive supervised counterpart while being more flexible in terms of achieving targeted behavior through reward modeling and generating internal mention structure, especially on longer mentions.|paper describ applic reinforc learn mention detect task defin novel action base formul mention detect task model flexibl revis past label decis group togeth token assign partial mention label devis method creat mention level episod train model reward correct label complet mention irrespect inner structur creat model yield result par competit supervis counterpart flexibl term achiev target behavior reward model generat intern mention structur especi longer mention|['Georgiana Dinu', 'Wael Hamza', 'Radu Florian']|['cs.CL', 'cs.AI']
2017-03-28T14:06:28Z|2017-03-13T16:50:36Z|http://arxiv.org/abs/1703.04481v1|http://arxiv.org/pdf/1703.04481v1|Geometrical morphology|geometr morpholog|We explore inflectional morphology as an example of the relationship of the discrete and the continuous in linguistics. The grammar requests a form of a lexeme by specifying a set of feature values, which corresponds to a corner M of a hypercube in feature value space. The morphology responds to that request by providing a morpheme, or a set of morphemes, whose vector sum is geometrically closest to the corner M. In short, the chosen morpheme $\mu$ is the morpheme (or set of morphemes) that maximizes the inner product of $\mu$ and M.|explor inflect morpholog exampl relationship discret continu linguist grammar request form lexem specifi set featur valu correspond corner hypercub featur valu space morpholog respond request provid morphem set morphem whose vector sum geometr closest corner short chosen morphem mu morphem set morphem maxim inner product mu|['John Goldsmith', 'Eric Rosen']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-13T16:36:38Z|http://arxiv.org/abs/1703.04474v1|http://arxiv.org/pdf/1703.04474v1|DRAGNN: A Transition-based Framework for Dynamically Connected Neural   Networks|dragnn transit base framework dynam connect neural network|In this work, we present a compact, modular framework for constructing novel recurrent neural architectures. Our basic module is a new generic unit, the Transition Based Recurrent Unit (TBRU). In addition to hidden layer activations, TBRUs have discrete state dynamics that allow network connections to be built dynamically as a function of intermediate activations. By connecting multiple TBRUs, we can extend and combine commonly used architectures such as sequence-to-sequence, attention mechanisms, and re-cursive tree-structured models. A TBRU can also serve as both an encoder for downstream tasks and as a decoder for its own task simultaneously, resulting in more accurate multi-task learning. We call our approach Dynamic Recurrent Acyclic Graphical Neural Networks, or DRAGNN. We show that DRAGNN is significantly more accurate and efficient than seq2seq with attention for syntactic dependency parsing and yields more accurate multi-task learning for extractive summarization tasks.|work present compact modular framework construct novel recurr neural architectur basic modul new generic unit transit base recurr unit tbru addit hidden layer activ tbrus discret state dynam allow network connect built dynam function intermedi activ connect multipl tbrus extend combin common use architectur sequenc sequenc attent mechan cursiv tree structur model tbru also serv encod downstream task decod task simultan result accur multi task learn call approach dynam recurr acycl graphic neural network dragnn show dragnn signific accur effici seqseq attent syntact depend pars yield accur multi task learn extract summar task|['Lingpeng Kong', 'Chris Alberti', 'Daniel Andor', 'Ivan Bogatyy', 'David Weiss']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-13T14:34:23Z|http://arxiv.org/abs/1703.04417v1|http://arxiv.org/pdf/1703.04417v1|El Lenguaje Natural como Lenguaje Formal|el lenguaj natur como lenguaj formal|"Formal languages theory is useful for the study of natural language. In particular, it is of interest to study the adequacy of the grammatical formalisms to express syntactic phenomena present in natural language. First, it helps to draw hypothesis about the nature and complexity of the speaker-hearer linguistic competence, a fundamental question in linguistics and other cognitive sciences. Moreover, from an engineering point of view, it allows the knowledge of practical limitations of applications based on those formalisms. In this article I introduce the adequacy problem of grammatical formalisms for natural language, also introducing some formal language theory concepts required for this discussion. Then, I review the formalisms that have been proposed in history, and the arguments that have been given to support or reject their adequacy.   -----   La teor\'ia de lenguajes formales es \'util para el estudio de los lenguajes naturales. En particular, resulta de inter\'es estudiar la adecuaci\'on de los formalismos gramaticales para expresar los fen\'omenos sint\'acticos presentes en el lenguaje natural. Primero, ayuda a trazar hip\'otesis acerca de la naturaleza y complejidad de las competencias ling\""u\'isticas de los hablantes-oyentes del lenguaje, un interrogante fundamental de la ling\""u\'istica y otras ciencias cognitivas. Adem\'as, desde el punto de vista de la ingenier\'ia, permite conocer limitaciones pr\'acticas de las aplicaciones basadas en dichos formalismos. En este art\'iculo hago una introducci\'on al problema de la adecuaci\'on de los formalismos gramaticales para el lenguaje natural, introduciendo tambi\'en algunos conceptos de la teor\'ia de lenguajes formales necesarios para esta discusi\'on. Luego, hago un repaso de los formalismos que han sido propuestos a lo largo de la historia, y de los argumentos que se han dado para sostener o refutar su adecuaci\'on."|formal languag theori use studi natur languag particular interest studi adequaci grammat formal express syntact phenomena present natur languag first help draw hypothesi natur complex speaker hearer linguist compet fundament question linguist cognit scienc moreov engin point view allow knowledg practic limit applic base formal articl introduc adequaci problem grammat formal natur languag also introduc formal languag theori concept requir discuss review formal propos histori argument given support reject adequaci la teor ia de lenguaj formal es util para el estudio de los lenguaj natural en particular resulta de inter es estudiar la adecuaci de los formalismo gramatical para expresar los fen omeno sint actico present en el lenguaj natur primero ayuda trazar hip otesi acerca de la naturaleza complejidad de las competencia ling istica de los hablant oyent del lenguaj un interrogant fundament de la ling istica otra ciencia cognitiva adem desd el punto de vista de la ingeni ia permit conoc limitacion pr actica de las aplicacion basada en dicho formalismo en est art iculo hago una introducci al problema de la adecuaci de los formalismo gramatical para el lenguaj natur introduciendo tambi en alguno concepto de la teor ia de lenguaj formal necesario para esta discusi luego hago un repaso de los formalismo que han sido propuesto lo largo de la historia de los argumento que se han dado para sosten refutar su adecuaci|['Franco M. Luque']|['cs.CL', 'cs.FL']
2017-03-28T14:06:28Z|2017-03-13T12:28:03Z|http://arxiv.org/abs/1703.04357v1|http://arxiv.org/pdf/1703.04357v1|Nematus: a Toolkit for Neural Machine Translation|nematus toolkit neural machin translat|We present Nematus, a toolkit for Neural Machine Translation. The toolkit prioritizes high translation accuracy, usability, and extensibility. Nematus has been used to build top-performing submissions to shared translation tasks at WMT and IWSLT, and has been used to train systems for production environments.|present nematus toolkit neural machin translat toolkit priorit high translat accuraci usabl extens nematus use build top perform submiss share translat task wmt iwslt use train system product environ|['Rico Sennrich', 'Orhan Firat', 'Kyunghyun Cho', 'Alexandra Birch', 'Barry Haddow', 'Julian Hitschler', 'Marcin Junczys-Dowmunt', 'Samuel Läubli', 'Antonio Valerio Miceli Barone', 'Jozef Mokry', 'Maria Nădejde']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-13T11:19:56Z|http://arxiv.org/abs/1703.04336v1|http://arxiv.org/pdf/1703.04336v1|A Visual Representation of Wittgenstein's Tractatus Logico-Philosophicus|visual represent wittgenstein tractatus logico philosophicus|In this paper we present a data visualization method together with its potential usefulness in digital humanities and philosophy of language. We compile a multilingual parallel corpus from different versions of Wittgenstein's Tractatus Logico-Philosophicus, including the original in German and translations into English, Spanish, French, and Russian. Using this corpus, we compute a similarity measure between propositions and render a visual network of relations for different languages.|paper present data visual method togeth potenti use digit human philosophi languag compil multilingu parallel corpus differ version wittgenstein tractatus logico philosophicus includ origin german translat english spanish french russian use corpus comput similar measur proposit render visual network relat differ languag|['Anca Bucur', 'Sergiu Nisioi']|['cs.IR', 'cs.CL']
2017-03-28T14:06:28Z|2017-03-13T11:03:40Z|http://arxiv.org/abs/1703.04330v1|http://arxiv.org/pdf/1703.04330v1|Story Cloze Ending Selection Baselines and Data Examination|stori cloze end select baselin data examin|This paper describes two supervised baseline systems for the Story Cloze Test Shared Task (Mostafazadeh et al., 2016a). We first build a classifier using features based on word embeddings and semantic similarity computation. We further implement a neural LSTM system with different encoding strategies that try to model the relation between the story and the provided endings. Our experiments show that a model using representation features based on average word embedding vectors over the given story words and the candidate ending sentences words, joint with similarity features between the story and candidate ending representations performed better than the neural models. Our best model achieves an accuracy of 72.42, ranking 3rd in the official evaluation.|paper describ two supervis baselin system stori cloze test share task mostafazadeh et al first build classifi use featur base word embed semant similar comput implement neural lstm system differ encod strategi tri model relat stori provid end experi show model use represent featur base averag word embed vector given stori word candid end sentenc word joint similar featur stori candid end represent perform better neural model best model achiev accuraci rank rd offici evalu|['Todor Mihaylov', 'Anette Frank']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-13T04:55:19Z|http://arxiv.org/abs/1703.04247v1|http://arxiv.org/pdf/1703.04247v1|DeepFM: A Factorization-Machine based Neural Network for CTR Prediction|deepfm factor machin base neural network ctr predict|"Learning sophisticated feature interactions behind user behaviors is critical in maximizing CTR for recommender systems. Despite great progress, existing methods seem to have a strong bias towards low- or high-order interactions, or require expertise feature engineering. In this paper, we show that it is possible to derive an end-to-end learning model that emphasizes both low- and high-order feature interactions. The proposed model, DeepFM, combines the power of factorization machines for recommendation and deep learning for feature learning in a new neural network architecture. Compared to the latest Wide \& Deep model from Google, DeepFM has a shared input to its ""wide"" and ""deep"" parts, with no need of feature engineering besides raw features. Comprehensive experiments are conducted to demonstrate the effectiveness and efficiency of DeepFM over the existing models for CTR prediction, on both benchmark data and commercial data."|learn sophist featur interact behind user behavior critic maxim ctr recommend system despit great progress exist method seem strong bias toward low high order interact requir expertis featur engin paper show possibl deriv end end learn model emphas low high order featur interact propos model deepfm combin power factor machin recommend deep learn featur learn new neural network architectur compar latest wide deep model googl deepfm share input wide deep part need featur engin besid raw featur comprehens experi conduct demonstr effect effici deepfm exist model ctr predict benchmark data commerci data|['Huifeng Guo', 'Ruiming Tang', 'Yunming Ye', 'Zhenguo Li', 'Xiuqiang He']|['cs.IR', 'cs.CL']
2017-03-28T14:06:28Z|2017-03-14T20:26:32Z|http://arxiv.org/abs/1703.04213v2|http://arxiv.org/pdf/1703.04213v2|MetaPAD: Meta Pattern Discovery from Massive Text Corpora|metapad meta pattern discoveri massiv text corpora|Mining textual patterns in news, tweets, papers, and many other kinds of text corpora has been an active theme in text mining and NLP research. Previous studies adopt a dependency parsing-based pattern discovery approach. However, the parsing results lose rich context around entities in the patterns, and the process is costly for a corpus of large scale. In this study, we propose a novel typed textual pattern structure, called meta pattern, which is extended to a frequent, informative, and precise subsequence pattern in certain context. We propose an efficient framework, called MetaPAD, which discovers meta patterns from massive corpora with three techniques: (1) it develops a context-aware segmentation method to carefully determine the boundaries of patterns with a learnt pattern quality assessment function, which avoids costly dependency parsing and generates high-quality patterns; (2) it identifies and groups synonymous meta patterns from multiple facets---their types, contexts, and extractions; and (3) it examines type distributions of entities in the instances extracted by each group of patterns, and looks for appropriate type levels to make discovered patterns precise. Experiments demonstrate that our proposed framework discovers high-quality typed textual patterns efficiently from different genres of massive corpora and facilitates information extraction.|mine textual pattern news tweet paper mani kind text corpora activ theme text mine nlp research previous studi adopt depend pars base pattern discoveri approach howev pars result lose rich context around entiti pattern process cost corpus larg scale studi propos novel type textual pattern structur call meta pattern extend frequent inform precis subsequ pattern certain context propos effici framework call metapad discov meta pattern massiv corpora three techniqu develop context awar segment method care determin boundari pattern learnt pattern qualiti assess function avoid cost depend pars generat high qualiti pattern identifi group synonym meta pattern multipl facet type context extract examin type distribut entiti instanc extract group pattern look appropri type level make discov pattern precis experi demonstr propos framework discov high qualiti type textual pattern effici differ genr massiv corpora facilit inform extract|['Meng Jiang', 'Jingbo Shang', 'Taylor Cassidy', 'Xiang Ren', 'Lance M. Kaplan', 'Timothy P. Hanratty', 'Jiawei Han']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-23T14:00:55Z|http://arxiv.org/abs/1703.04178v2|http://arxiv.org/pdf/1703.04178v2|Why we have switched from building full-fledged taxonomies to simply   detecting hypernymy relations|whi switch build full fledg taxonomi simpli detect hypernymi relat|The study of taxonomies and hypernymy relations has been extensive on the Natural Language Processing (NLP) literature. However, the evaluation of taxonomy learning approaches has been traditionally troublesome, as it mainly relies on ad-hoc experiments which are hardly reproducible and manually expensive. Partly because of this, current research has been lately focusing on the hypernymy detection task. In this paper we reflect on this trend, analyzing issues related to current evaluation procedures. Finally, we propose three potential avenues for future work so that is-a relations and resources based on them play a more important role in downstream NLP applications.|studi taxonomi hypernymi relat extens natur languag process nlp literatur howev evalu taxonomi learn approach tradit troublesom main reli ad hoc experi hard reproduc manual expens part becaus current research late focus hypernymi detect task paper reflect trend analyz issu relat current evalu procedur final propos three potenti avenu futur work relat resourc base play import role downstream nlp applic|['Jose Camacho-Collados']|['cs.CL']
2017-03-28T14:06:28Z|2017-03-12T08:11:29Z|http://arxiv.org/abs/1703.04081v1|http://arxiv.org/pdf/1703.04081v1|Feature overwriting as a finite mixture process: Evidence from   comprehension data|featur overwrit finit mixtur process evid comprehens data|"The ungrammatical sentence ""The key to the cabinets are on the table"" is known to lead to an illusion of grammaticality. As discussed in the meta-analysis by Jaeger et al., 2017, faster reading times are observed at the verb are in the agreement-attraction sentence above compared to the equally ungrammatical sentence ""The key to the cabinet are on the table"". One explanation for this facilitation effect is the feature percolation account: the plural feature on cabinets percolates up to the head noun key, leading to the illusion. An alternative account is in terms of cue-based retrieval (Lewis & Vasishth, 2005), which assumes that the non-subject noun cabinets is misretrieved due to a partial feature-match when a dependency completion process at the auxiliary initiates a memory access for a subject with plural marking. We present evidence for yet another explanation for the observed facilitation. Because the second sentence has two nouns with identical number, it is possible that these are, in some proportion of trials, more difficult to keep distinct, leading to slower reading times at the verb in the first sentence above; this is the feature overwriting account of Nairne, 1990. We show that the feature overwriting proposal can be implemented as a finite mixture process. We reanalysed ten published data-sets, fitting hierarchical Bayesian mixture models to these data assuming a two-mixture distribution. We show that in nine out of the ten studies, a mixture distribution corresponding to feature overwriting furnishes a superior fit over both the feature percolation and the cue-based retrieval accounts."|ungrammat sentenc key cabinet tabl known lead illus grammat discuss meta analysi jaeger et al faster read time observ verb agreement attract sentenc abov compar equal ungrammat sentenc key cabinet tabl one explan facilit effect featur percol account plural featur cabinet percol head noun key lead illus altern account term cue base retriev lewi vasishth assum non subject noun cabinet misretriev due partial featur match depend complet process auxiliari initi memori access subject plural mark present evid yet anoth explan observ facilit becaus second sentenc two noun ident number possibl proport trial difficult keep distinct lead slower read time verb first sentenc abov featur overwrit account nairn show featur overwrit propos implement finit mixtur process reanalys ten publish data set fit hierarch bayesian mixtur model data assum two mixtur distribut show nine ten studi mixtur distribut correspond featur overwrit furnish superior fit featur percol cue base retriev account|['Shravan Vasishth', 'Lena A. Jaeger', 'Bruno Nicenboim']|['stat.ML', 'cs.CL', 'stat.AP']
2017-03-28T14:06:31Z|2017-03-11T18:20:13Z|http://arxiv.org/abs/1703.04009v1|http://arxiv.org/pdf/1703.04009v1|Automated Hate Speech Detection and the Problem of Offensive Language|autom hate speech detect problem offens languag|A key challenge for automatic hate-speech detection on social media is the separation of hate speech from other instances of offensive language. Lexical detection methods tend to have low precision because they classify all messages containing particular terms as hate speech and previous work using supervised learning has failed to distinguish between the two categories. We used a crowd-sourced hate speech lexicon to collect tweets containing hate speech keywords. We use crowd-sourcing to label a sample of these tweets into three categories: those containing hate speech, only offensive language, and those with neither. We train a multi-class classifier to distinguish between these different categories. Close analysis of the predictions and the errors shows when we can reliably separate hate speech from other offensive language and when this differentiation is more difficult. We find that racist and homophobic tweets are more likely to be classified as hate speech but that sexist tweets are generally classified as offensive. Tweets without explicit hate keywords are also more difficult to classify.|key challeng automat hate speech detect social media separ hate speech instanc offens languag lexic detect method tend low precis becaus classifi messag contain particular term hate speech previous work use supervis learn fail distinguish two categori use crowd sourc hate speech lexicon collect tweet contain hate speech keyword use crowd sourc label sampl tweet three categori contain hate speech onli offens languag neither train multi class classifi distinguish differ categori close analysi predict error show reliabl separ hate speech offens languag differenti difficult find racist homophob tweet like classifi hate speech sexist tweet general classifi offens tweet without explicit hate keyword also difficult classifi|['Thomas Davidson', 'Dana Warmsley', 'Michael Macy', 'Ingmar Weber']|['cs.CL']
2017-03-28T14:06:31Z|2017-03-11T17:14:55Z|http://arxiv.org/abs/1703.04001v1|http://arxiv.org/pdf/1703.04001v1|Language Use Matters: Analysis of the Linguistic Structure of Question   Texts Can Characterize Answerability in Quora|languag use matter analysi linguist structur question text character answer quora|Quora is one of the most popular community Q&A sites of recent times. However, many question posts on this Q&A site often do not get answered. In this paper, we quantify various linguistic activities that discriminates an answered question from an unanswered one. Our central finding is that the way users use language while writing the question text can be a very effective means to characterize answerability. This characterization helps us to predict early if a question remaining unanswered for a specific time period t will eventually be answered or not and achieve an accuracy of 76.26% (t = 1 month) and 68.33% (t = 3 months). Notably, features representing the language use patterns of the users are most discriminative and alone account for an accuracy of 74.18%. We also compare our method with some of the similar works (Dror et al., Yang et al.) achieving a maximum improvement of ~39% in terms of accuracy.|quora one popular communiti site recent time howev mani question post site often get answer paper quantifi various linguist activ discrimin answer question unansw one central find way user use languag write question text veri effect mean character answer character help us predict earli question remain unansw specif time period eventu answer achiev accuraci month month notabl featur repres languag use pattern user discrimin alon account accuraci also compar method similar work dror et al yang et al achiev maximum improv term accuraci|['Suman Kalyan Maity', 'Aman Kharb', 'Animesh Mukherjee']|['cs.CL', 'cs.SI']
2017-03-28T14:06:31Z|2017-03-11T10:05:19Z|http://arxiv.org/abs/1703.03939v1|http://arxiv.org/pdf/1703.03939v1|Ask Me Even More: Dynamic Memory Tensor Networks (Extended Model)|ask even dynam memori tensor network extend model|We examine Memory Networks for the task of question answering (QA), under common real world scenario where training examples are scarce and under weakly supervised scenario, that is only extrinsic labels are available for training. We propose extensions for the Dynamic Memory Network (DMN), specifically within the attention mechanism, we call the resulting Neural Architecture as Dynamic Memory Tensor Network (DMTN). Ultimately, we see that our proposed extensions results in over 80% improvement in the number of task passed against the baselined standard DMN and 20% more task passed compared to state-of-the-art End-to-End Memory Network for Facebook's single task weakly trained 1K bAbi dataset.|examin memori network task question answer qa common real world scenario train exampl scarc weak supervis scenario onli extrins label avail train propos extens dynam memori network dmn specif within attent mechan call result neural architectur dynam memori tensor network dmtn ultim see propos extens result improv number task pass baselin standard dmn task pass compar state art end end memori network facebook singl task weak train babi dataset|['Govardana Sachithanandam Ramachandran', 'Ajay Sohmshetty']|['cs.CL', 'cs.LG', 'cs.NE']
2017-03-28T14:06:31Z|2017-03-11T07:37:37Z|http://arxiv.org/abs/1703.04718v1|http://arxiv.org/pdf/1703.04718v1|Extending Automatic Discourse Segmentation for Texts in Spanish to   Catalan|extend automat discours segment text spanish catalan|At present, automatic discourse analysis is a relevant research topic in the field of NLP. However, discourse is one of the phenomena most difficult to process. Although discourse parsers have been already developed for several languages, this tool does not exist for Catalan. In order to implement this kind of parser, the first step is to develop a discourse segmenter. In this article we present the first discourse segmenter for texts in Catalan. This segmenter is based on Rhetorical Structure Theory (RST) for Spanish, and uses lexical and syntactic information to translate rules valid for Spanish into rules for Catalan. We have evaluated the system by using a gold standard corpus including manually segmented texts and results are promising.|present automat discours analysi relev research topic field nlp howev discours one phenomena difficult process although discours parser alreadi develop sever languag tool doe exist catalan order implement kind parser first step develop discours segment articl present first discours segment text catalan segment base rhetor structur theori rst spanish use lexic syntact inform translat rule valid spanish rule catalan evalu system use gold standard corpus includ manual segment text result promis|['Iria da Cunha', 'Eric SanJuan', 'Juan-Manuel Torres-Moreno', 'Irene Castellón']|['cs.CL']
2017-03-28T14:06:31Z|2017-03-11T07:35:28Z|http://arxiv.org/abs/1703.03923v1|http://arxiv.org/pdf/1703.03923v1|A German Corpus for Text Similarity Detection Tasks|german corpus text similar detect task|Text similarity detection aims at measuring the degree of similarity between a pair of texts. Corpora available for text similarity detection are designed to evaluate the algorithms to assess the paraphrase level among documents. In this paper we present a textual German corpus for similarity detection. The purpose of this corpus is to automatically assess the similarity between a pair of texts and to evaluate different similarity measures, both for whole documents or for individual sentences. Therefore we have calculated several simple measures on our corpus based on a library of similarity functions.|text similar detect aim measur degre similar pair text corpora avail text similar detect design evalu algorithm assess paraphras level among document paper present textual german corpus similar detect purpos corpus automat assess similar pair text evalu differ similar measur whole document individu sentenc therefor calcul sever simpl measur corpus base librari similar function|['Juan-Manuel Torres-Moreno', 'Gerardo Sierra', 'Peter Peinl']|['cs.IR', 'cs.CL']
2017-03-28T14:06:31Z|2017-03-21T20:34:59Z|http://arxiv.org/abs/1703.03906v2|http://arxiv.org/pdf/1703.03906v2|Massive Exploration of Neural Machine Translation Architectures|massiv explor neural machin translat architectur|Neural Machine Translation (NMT) has shown remarkable progress over the past few years with production systems now being deployed to end-users. One major drawback of current architectures is that they are expensive to train, typically requiring days to weeks of GPU time to converge. This makes exhaustive hyperparameter search, as is commonly done with other neural network architectures, prohibitively expensive. In this work, we present the first large-scale analysis of NMT architecture hyperparameters. We report empirical results and variance numbers for several hundred experimental runs, corresponding to over 250,000 GPU hours on the standard WMT English to German translation task. Our experiments lead to novel insights and practical advice for building and extending NMT architectures. As part of this contribution, we release an open-source NMT framework that enables researchers to easily experiment with novel techniques and reproduce state of the art results.|neural machin translat nmt shown remark progress past year product system deploy end user one major drawback current architectur expens train typic requir day week gpu time converg make exhaust hyperparamet search common done neural network architectur prohibit expens work present first larg scale analysi nmt architectur hyperparamet report empir result varianc number sever hundr experiment run correspond gpu hour standard wmt english german translat task experi lead novel insight practic advic build extend nmt architectur part contribut releas open sourc nmt framework enabl research easili experi novel techniqu reproduc state art result|['Denny Britz', 'Anna Goldie', 'Minh-Thang Luong', 'Quoc Le']|['cs.CL']
2017-03-28T14:06:31Z|2017-03-10T20:54:11Z|http://arxiv.org/abs/1703.03842v1|http://arxiv.org/pdf/1703.03842v1|Effects of Limiting Memory Capacity on the Behaviour of Exemplar   Dynamics|effect limit memori capac behaviour exemplar dynam|Exemplar models are a popular class of models used to describe language change. Here we study how limiting the memory capacity of an individual in these models affects the system's behaviour. In particular we demonstrate the effect this change has on the extinction of categories. Previous work in exemplar dynamics has not addressed this question. In order to investigate this, we will inspect a simplified exemplar model. We will prove for the simplified model that all the sound categories but one will always become extinct, whether memory storage is limited or not. However, computer simulations show that changing the number of stored memories alters how fast categories become extinct.|exemplar model popular class model use describ languag chang studi limit memori capac individu model affect system behaviour particular demonstr effect chang extinct categori previous work exemplar dynam address question order investig inspect simplifi exemplar model prove simplifi model sound categori one alway becom extinct whether memori storag limit howev comput simul show chang number store memori alter fast categori becom extinct|['B. Goodman', 'P. F. Tupper']|['cs.CL', '91F20']
2017-03-28T14:06:31Z|2017-03-10T17:27:38Z|http://arxiv.org/abs/1703.03771v1|http://arxiv.org/pdf/1703.03771v1|Coping with Construals in Broad-Coverage Semantic Annotation of   Adpositions|cope construal broad coverag semant annot adposit|We consider the semantics of prepositions, revisiting a broad-coverage annotation scheme used for annotating all 4,250 preposition tokens in a 55,000 word corpus of English. Attempts to apply the scheme to adpositions and case markers in other languages, as well as some problematic cases in English, have led us to reconsider the assumption that a preposition's lexical contribution is equivalent to the role/relation that it mediates. Our proposal is to embrace the potential for construal in adposition use, expressing such phenomena directly at the token level to manage complexity and avoid sense proliferation. We suggest a framework to represent both the scene role and the adposition's lexical function so they can be annotated at scale---supporting automatic, statistical processing of domain-general language---and sketch how this representation would inform a constructional analysis.|consid semant preposit revisit broad coverag annot scheme use annot preposit token word corpus english attempt appli scheme adposit case marker languag well problemat case english led us reconsid assumpt preposit lexic contribut equival role relat mediat propos embrac potenti construal adposit use express phenomena direct token level manag complex avoid sens prolifer suggest framework repres scene role adposit lexic function annot scale support automat statist process domain general languag sketch represent would inform construct analysi|"['Jena D. Hwang', 'Archna Bhatia', 'Na-Rae Han', ""Tim O'Gorman"", 'Vivek Srikumar', 'Nathan Schneider']"|['cs.CL']
2017-03-28T14:06:32Z|2017-03-10T15:27:45Z|http://arxiv.org/abs/1703.03714v1|http://arxiv.org/pdf/1703.03714v1|Applying the Wizard-of-Oz Technique to Multimodal Human-Robot Dialogue|appli wizard oz techniqu multimod human robot dialogu|Our overall program objective is to provide more natural ways for soldiers to interact and communicate with robots, much like how soldiers communicate with other soldiers today. We describe how the Wizard-of-Oz (WOz) method can be applied to multimodal human-robot dialogue in a collaborative exploration task. While the WOz method can help design robot behaviors, traditional approaches place the burden of decisions on a single wizard. In this work, we consider two wizards to stand in for robot navigation and dialogue management software components. The scenario used to elicit data is one in which a human-robot team is tasked with exploring an unknown environment: a human gives verbal instructions from a remote location and the robot follows them, clarifying possible misunderstandings as needed via dialogue. We found the division of labor between wizards to be workable, which holds promise for future software development.|overal program object provid natur way soldier interact communic robot much like soldier communic soldier today describ wizard oz woz method appli multimod human robot dialogu collabor explor task woz method help design robot behavior tradit approach place burden decis singl wizard work consid two wizard stand robot navig dialogu manag softwar compon scenario use elicit data one human robot team task explor unknown environ human give verbal instruct remot locat robot follow clarifi possibl misunderstand need via dialogu found divis labor wizard workabl hold promis futur softwar develop|['Matthew Marge', 'Claire Bonial', 'Brendan Byrne', 'Taylor Cassidy', 'A. William Evans', 'Susan G. Hill', 'Clare Voss']|['cs.CL', 'cs.AI', 'cs.HC', 'cs.RO']
2017-03-28T14:06:32Z|2017-03-10T12:59:52Z|http://arxiv.org/abs/1703.03666v1|http://arxiv.org/pdf/1703.03666v1|Comparison of SMT and RBMT; The Requirement of Hybridization for   Marathi-Hindi MT|comparison smt rbmt requir hybrid marathi hindi mt|We present in this paper our work on comparison between Statistical Machine Translation (SMT) and Rule-based machine translation for translation from Marathi to Hindi. Rule Based systems although robust take lots of time to build. On the other hand statistical machine translation systems are easier to create, maintain and improve upon. We describe the development of a basic Marathi-Hindi SMT system and evaluate its performance. Through a detailed error analysis, we, point out the relative strengths and weaknesses of both systems. Effectively, we shall see that even with a small amount of training corpus a statistical machine translation system has many advantages for high quality domain specific machine translation over that of a rule-based counterpart.|present paper work comparison statist machin translat smt rule base machin translat translat marathi hindi rule base system although robust take lot time build hand statist machin translat system easier creat maintain improv upon describ develop basic marathi hindi smt system evalu perform detail error analysi point relat strength weak system effect shall see even small amount train corpus statist machin translat system mani advantag high qualiti domain specif machin translat rule base counterpart|['Sreelekha. S', 'Pushpak Bhattacharyya']|['cs.CL']
2017-03-28T14:06:36Z|2017-03-10T11:58:48Z|http://arxiv.org/abs/1703.03640v1|http://arxiv.org/pdf/1703.03640v1|A Study of Metrics of Distance and Correlation Between Ranked Lists for   Compositionality Detection|studi metric distanc correl rank list composit detect|Compositionality in language refers to how much the meaning of some phrase can be decomposed into the meaning of its constituents and the way these constituents are combined. Based on the premise that substitution by synonyms is meaning-preserving, compositionality can be approximated as the semantic similarity between a phrase and a version of that phrase where words have been replaced by their synonyms. Different ways of representing such phrases exist (e.g., vectors [1] or language models [2]), and the choice of representation affects the measurement of semantic similarity.   We propose a new compositionality detection method that represents phrases as ranked lists of term weights. Our method approximates the semantic similarity between two ranked list representations using a range of well-known distance and correlation metrics. In contrast to most state-of-the-art approaches in compositionality detection, our method is completely unsupervised. Experiments with a publicly available dataset of 1048 human-annotated phrases shows that, compared to strong supervised baselines, our approach provides superior measurement of compositionality using any of the distance and correlation metrics considered.|composit languag refer much mean phrase decompos mean constitu way constitu combin base premis substitut synonym mean preserv composit approxim semant similar phrase version phrase word replac synonym differ way repres phrase exist vector languag model choic represent affect measur semant similar propos new composit detect method repres phrase rank list term weight method approxim semant similar two rank list represent use rang well known distanc correl metric contrast state art approach composit detect method complet unsupervis experi public avail dataset human annot phrase show compar strong supervis baselin approach provid superior measur composit use ani distanc correl metric consid|['Christina Lioma', 'Niels Dalum Hansen']|['cs.CL']
2017-03-28T14:06:36Z|2017-03-10T10:17:27Z|http://arxiv.org/abs/1703.03609v1|http://arxiv.org/abs/1703.03609v1|NetSpam: a Network-based Spam Detection Framework for Reviews in Online   Social Media|netspam network base spam detect framework review onlin social media|Nowadays, a big part of people rely on available content in social media in their decisions (e.g. reviews and feedback on a topic or product). The possibility that anybody can leave a review provide a golden opportunity for spammers to write spam reviews about products and services for different interests. Identifying these spammers and the spam content is a hot topic of research and although a considerable number of studies have been done recently toward this end, but so far the methodologies put forth still barely detect spam reviews, and none of them show the importance of each extracted feature type. In this study, we propose a novel framework, named NetSpam, which utilizes spam features for modeling review datasets as heterogeneous information networks to map spam detection procedure into a classification problem in such networks. Using the importance of spam features help us to obtain better results in terms of different metrics experimented on real-world review datasets from Yelp and Amazon websites. The results show that NetSpam outperforms the existing methods and among four categories of features; including review-behavioral, user-behavioral, reviewlinguistic, user-linguistic, the first type of features performs better than the other categories.|nowaday big part peopl reli avail content social media decis review feedback topic product possibl anybodi leav review provid golden opportun spammer write spam review product servic differ interest identifi spammer spam content hot topic research although consider number studi done recent toward end far methodolog put forth still bare detect spam review none show import extract featur type studi propos novel framework name netspam util spam featur model review dataset heterogen inform network map spam detect procedur classif problem network use import spam featur help us obtain better result term differ metric experi real world review dataset yelp amazon websit result show netspam outperform exist method among four categori featur includ review behavior user behavior reviewlinguist user linguist first type featur perform better categori|['Saeedreza Shehnepoor', 'Mostafa Salehi', 'Reza Farahbakhsh', 'Noel Crespi']|['cs.SI', 'cs.CL', 'cs.IR', 'physics.soc-ph']
2017-03-28T14:06:36Z|2017-03-09T19:50:00Z|http://arxiv.org/abs/1703.03442v1|http://arxiv.org/pdf/1703.03442v1|The cognitive roots of regularization in language|cognit root regular languag|Regularization occurs when the output a learner produces is less variable than the linguistic data they observed. In an artificial language learning experiment, we show that there exist at least two independent sources of regularization bias in cognition: a domain-general source based on cognitive load and a domain-specific source triggered by linguistic stimuli. Both of these factors modulate how frequency information is encoded and produced, but only the production-side modulations result in regularization (i.e. cause learners to eliminate variation from the observed input). We formalize the definition of regularization as the reduction of entropy and find that entropy measures are better at identifying regularization behavior than frequency-based analyses. We also use a model of cultural transmission to extrapolate from our experimental data in order to predict the amount of regularization which would develop in each experimental condition if the artificial language was transmitted over several generations of learners. Here we find an interaction between cognitive load and linguistic domain, suggesting that the effect of cognitive constraints can become more complex when put into the context of cultural evolution: although learning biases certainly carry information about the course of language evolution, we should not expect a one-to-one correspondence between the micro-level processes that regularize linguistic datasets and the macro-level evolution of linguistic regularity.|regular occur output learner produc less variabl linguist data observ artifici languag learn experi show exist least two independ sourc regular bias cognit domain general sourc base cognit load domain specif sourc trigger linguist stimuli factor modul frequenc inform encod produc onli product side modul result regular caus learner elimin variat observ input formal definit regular reduct entropi find entropi measur better identifi regular behavior frequenc base analys also use model cultur transmiss extrapol experiment data order predict amount regular would develop experiment condit artifici languag transmit sever generat learner find interact cognit load linguist domain suggest effect cognit constraint becom complex put context cultur evolut although learn bias certain carri inform cours languag evolut expect one one correspond micro level process regular linguist dataset macro level evolut linguist regular|['Vanessa Ferdinand', 'Simon Kirby', 'Kenny Smith']|['cs.CL', 'q-bio.NC']
2017-03-28T14:06:36Z|2017-03-09T19:16:14Z|http://arxiv.org/abs/1703.03429v1|http://arxiv.org/pdf/1703.03429v1|What can you do with a rock? Affordance extraction via word embeddings|rock afford extract via word embed|Autonomous agents must often detect affordances: the set of behaviors enabled by a situation. Affordance detection is particularly helpful in domains with large action spaces, allowing the agent to prune its search space by avoiding futile behaviors. This paper presents a method for affordance extraction via word embeddings trained on a Wikipedia corpus. The resulting word vectors are treated as a common knowledge database which can be queried using linear algebra. We apply this method to a reinforcement learning agent in a text-only environment and show that affordance-based action selection improves performance most of the time. Our method increases the computational complexity of each learning step but significantly reduces the total number of steps needed. In addition, the agent's action selections begin to resemble those a human would choose.|autonom agent must often detect afford set behavior enabl situat afford detect particular help domain larg action space allow agent prune search space avoid futil behavior paper present method afford extract via word embed train wikipedia corpus result word vector treat common knowledg databas queri use linear algebra appli method reinforc learn agent text onli environ show afford base action select improv perform time method increas comput complex learn step signific reduc total number step need addit agent action select begin resembl human would choos|['Nancy Fulda', 'Daniel Ricks', 'Ben Murdoch', 'David Wingate']|['cs.AI', 'cs.CL']
2017-03-28T14:06:36Z|2017-03-09T18:37:50Z|http://arxiv.org/abs/1703.03386v1|http://arxiv.org/pdf/1703.03386v1|Loyalty in Online Communities|loyalti onlin communiti|Loyalty is an essential component of multi-community engagement. When users have the choice to engage with a variety of different communities, they often become loyal to just one, focusing on that community at the expense of others. However, it is unclear how loyalty is manifested in user behavior, or whether loyalty is encouraged by certain community characteristics.   In this paper we operationalize loyalty as a user-community relation: users loyal to a community consistently prefer it over all others; loyal communities retain their loyal users over time. By exploring this relation using a large dataset of discussion communities from Reddit, we reveal that loyalty is manifested in remarkably consistent behaviors across a wide spectrum of communities. Loyal users employ language that signals collective identity and engage with more esoteric, less popular content, indicating they may play a curational role in surfacing new material. Loyal communities have denser user-user interaction networks and lower rates of triadic closure, suggesting that community-level loyalty is associated with more cohesive interactions and less fragmentation into subgroups. We exploit these general patterns to predict future rates of loyalty. Our results show that a user's propensity to become loyal is apparent from their first interactions with a community, suggesting that some users are intrinsically loyal from the very beginning.|loyalti essenti compon multi communiti engag user choic engag varieti differ communiti often becom loyal one focus communiti expens howev unclear loyalti manifest user behavior whether loyalti encourag certain communiti characterist paper operation loyalti user communiti relat user loyal communiti consist prefer loyal communiti retain loyal user time explor relat use larg dataset discuss communiti reddit reveal loyalti manifest remark consist behavior across wide spectrum communiti loyal user employ languag signal collect ident engag esoter less popular content indic may play curat role surfac new materi loyal communiti denser user user interact network lower rate triadic closur suggest communiti level loyalti associ cohes interact less fragment subgroup exploit general pattern predict futur rate loyalti result show user propens becom loyal appar first interact communiti suggest user intrins loyal veri begin|['William L. Hamilton', 'Justine Zhang', 'Cristian Danescu-Niculescu-Mizil', 'Dan Jurafsky', 'Jure Leskovec']|['cs.SI', 'cs.CL']
2017-03-28T14:06:36Z|2017-03-10T08:11:22Z|http://arxiv.org/abs/1703.03200v2|http://arxiv.org/pdf/1703.03200v2|Turkish PoS Tagging by Reducing Sparsity with Morpheme Tags in Small   Datasets|turkish pos tag reduc sparsiti morphem tag small dataset|Sparsity is one of the major problems in natural language processing. The problem becomes even more severe in agglutinating languages that are highly prone to be inflected. We deal with sparsity in Turkish by adopting morphological features for part-of-speech tagging. We learn inflectional and derivational morpheme tags in Turkish by using conditional random fields (CRF) and we employ the morpheme tags in part-of-speech (PoS) tagging by using hidden Markov models (HMMs) to mitigate sparsity. Results show that using morpheme tags in PoS tagging helps alleviate the sparsity in emission probabilities. Our model outperforms other hidden Markov model based PoS tagging models for small training datasets in Turkish. We obtain an accuracy of 94.1% in morpheme tagging and 89.2% in PoS tagging on a 5K training dataset.|sparsiti one major problem natur languag process problem becom even sever agglutin languag high prone inflect deal sparsiti turkish adopt morpholog featur part speech tag learn inflect deriv morphem tag turkish use condit random field crf employ morphem tag part speech pos tag use hidden markov model hmms mitig sparsiti result show use morphem tag pos tag help allevi sparsiti emiss probabl model outperform hidden markov model base pos tag model small train dataset turkish obtain accuraci morphem tag pos tag train dataset|['Burcu Can', 'Ahmet Üstün', 'Murathan Kurfalı']|['cs.CL']
2017-03-28T14:06:36Z|2017-03-09T06:20:49Z|http://arxiv.org/abs/1703.03149v1|http://arxiv.org/pdf/1703.03149v1|Detecting Sockpuppets in Deceptive Opinion Spam|detect sockpuppet decept opinion spam|This paper explores the problem of sockpuppet detection in deceptive opinion spam using authorship attribution and verification approaches. Two methods are explored. The first is a feature subsampling scheme that uses the KL-Divergence on stylistic language models of an author to find discriminative features. The second is a transduction scheme, spy induction that leverages the diversity of authors in the unlabeled test set by sending a set of spies (positive samples) from the training set to retrieve hidden samples in the unlabeled test set using nearest and farthest neighbors. Experiments using ground truth sockpuppet data show the effectiveness of the proposed schemes.|paper explor problem sockpuppet detect decept opinion spam use authorship attribut verif approach two method explor first featur subsampl scheme use kl diverg stylist languag model author find discrimin featur second transduct scheme spi induct leverag divers author unlabel test set send set spi posit sampl train set retriev hidden sampl unlabel test set use nearest farthest neighbor experi use ground truth sockpuppet data show effect propos scheme|['Marjan Hosseinia', 'Arjun Mukherjee']|['cs.CL']
2017-03-28T14:06:36Z|2017-03-09T04:42:30Z|http://arxiv.org/abs/1703.03130v1|http://arxiv.org/pdf/1703.03130v1|A Structured Self-attentive Sentence Embedding|structur self attent sentenc embed|This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.|paper propos new model extract interpret sentenc embed introduc self attent instead use vector use matrix repres embed row matrix attend differ part sentenc also propos self attent mechan special regular term model side effect embed come easi way visual specif part sentenc encod embed evalu model differ task author profil sentiment classif textual entail result show model yield signific perform gain compar sentenc embed method task|['Zhouhan Lin', 'Minwei Feng', 'Cicero Nogueira dos Santos', 'Mo Yu', 'Bing Xiang', 'Bowen Zhou', 'Yoshua Bengio']|['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE']
2017-03-28T14:06:36Z|2017-03-09T01:28:00Z|http://arxiv.org/abs/1703.03097v1|http://arxiv.org/abs/1703.03097v1|Information Extraction in Illicit Domains|inform extract illicit domain|Extracting useful entities and attribute values from illicit domains such as human trafficking is a challenging problem with the potential for widespread social impact. Such domains employ atypical language models, have `long tails' and suffer from the problem of concept drift. In this paper, we propose a lightweight, feature-agnostic Information Extraction (IE) paradigm specifically designed for such domains. Our approach uses raw, unlabeled text from an initial corpus, and a few (12-120) seed annotations per domain-specific attribute, to learn robust IE models for unobserved pages and websites. Empirically, we demonstrate that our approach can outperform feature-centric Conditional Random Field baselines by over 18\% F-Measure on five annotated sets of real-world human trafficking datasets in both low-supervision and high-supervision settings. We also show that our approach is demonstrably robust to concept drift, and can be efficiently bootstrapped even in a serial computing environment.|extract use entiti attribut valu illicit domain human traffick challeng problem potenti widespread social impact domain employ atyp languag model long tail suffer problem concept drift paper propos lightweight featur agnost inform extract ie paradigm specif design domain approach use raw unlabel text initi corpus seed annot per domain specif attribut learn robust ie model unobserv page websit empir demonstr approach outperform featur centric condit random field baselin measur five annot set real world human traffick dataset low supervis high supervis set also show approach demonstr robust concept drift effici bootstrap even serial comput environ|['Mayank Kejriwal', 'Pedro Szekely']|['cs.CL', 'cs.AI']
2017-03-28T14:06:36Z|2017-03-09T01:04:07Z|http://arxiv.org/abs/1703.03091v1|http://arxiv.org/pdf/1703.03091v1|Deep Learning applied to NLP|deep learn appli nlp|Convolutional Neural Network (CNNs) are typically associated with Computer Vision. CNNs are responsible for major breakthroughs in Image Classification and are the core of most Computer Vision systems today. More recently CNNs have been applied to problems in Natural Language Processing and gotten some interesting results. In this paper, we will try to explain the basics of CNNs, its different variations and how they have been applied to NLP.|convolut neural network cnns typic associ comput vision cnns respons major breakthrough imag classif core comput vision system today recent cnns appli problem natur languag process gotten interest result paper tri explain basic cnns differ variat appli nlp|['Marc Moreno Lopez', 'Jugal Kalita']|['cs.CL']
2017-04-07T11:27:14Z|2017-04-06T17:07:40Z|http://arxiv.org/abs/1704.01938v1|http://arxiv.org/pdf/1704.01938v1|The Interplay of Semantics and Morphology in Word Embeddings|interplay semant morpholog word embed|We explore the ability of word embeddings to capture both semantic and morphological similarity, as affected by the different types of linguistic properties (surface form, lemma, morphological tag) used to compose the representation of each word. We train several models, where each uses a different subset of these properties to compose its representations. By evaluating the models on semantic and morphological measures, we reveal some useful insights on the relationship between semantics and morphology.|explor abil word embed captur semant morpholog similar affect differ type linguist properti surfac form lemma morpholog tag use compos represent word train sever model use differ subset properti compos represent evalu model semant morpholog measur reveal use insight relationship semant morpholog|['Oded Avraham', 'Yoav Goldberg']|['cs.CL']
2017-04-07T11:27:14Z|2017-04-06T11:44:07Z|http://arxiv.org/abs/1704.01792v1|http://arxiv.org/pdf/1704.01792v1|Neural Question Generation from Text: A Preliminary Study|neural question generat text preliminari studi|Automatic question generation aims to generate questions from a text passage where the generated questions can be answered by certain sub-spans of the given passage. Traditional methods mainly use rigid heuristic rules to transform a sentence into related questions. In this work, we propose to apply the neural encoder-decoder model to generate meaningful and diverse questions from natural language sentences. The encoder reads the input text and the answer position, to produce an answer-aware input representation, which is fed to the decoder to generate an answer focused question. We conduct a preliminary study on neural question generation from text with the SQuAD dataset, and the experiment results show that our method can produce fluent and diverse questions.|automat question generat aim generat question text passag generat question answer certain sub span given passag tradit method main use rigid heurist rule transform sentenc relat question work propos appli neural encod decod model generat meaning divers question natur languag sentenc encod read input text answer posit produc answer awar input represent fed decod generat answer focus question conduct preliminari studi neural question generat text squad dataset experi result show method produc fluent divers question|['Qingyu Zhou', 'Nan Yang', 'Furu Wei', 'Chuanqi Tan', 'Hangbo Bao', 'Ming Zhou']|['cs.CL']
2017-04-07T11:27:14Z|2017-04-06T08:32:16Z|http://arxiv.org/abs/1704.01748v1|http://arxiv.org/pdf/1704.01748v1|MRA - Proof of Concept of a Multilingual Report Annotator Web   Application|mra proof concept multilingu report annot web applic|MRA (Multilingual Report Annotator) is a web application that translates Radiology text and annotates it with RadLex terms. Its goal is to explore the solution of translating non-English Radiology reports as a way to solve the problem of most of the Text Mining tools being developed for English. In this brief paper we explain the language barrier problem and shortly describe the application. MRA can be found at https://github.com/lasigeBioTM/MRA.|mra multilingu report annot web applic translat radiolog text annot radlex term goal explor solut translat non english radiolog report way solv problem text mine tool develop english brief paper explain languag barrier problem short describ applic mra found https github com lasigebiotm mra|['Luís Campos', 'Francisco Couto']|['cs.CL']
2017-04-07T11:27:14Z|2017-04-06T03:13:46Z|http://arxiv.org/abs/1704.01696v1|http://arxiv.org/pdf/1704.01696v1|A Syntactic Neural Model for General-Purpose Code Generation|syntact neural model general purpos code generat|We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches.|consid problem pars natur languag descript sourc code written general purpos program languag like python exist data driven method treat problem languag generat task without consid syntax target program languag inform previous work semant pars paper propos novel neural architectur power grammar model explicit captur target syntax prior knowledg experi find effect way scale generat complex program natur languag descript achiev state art result well outperform previous code generat semant pars approach|['Pengcheng Yin', 'Graham Neubig']|['cs.CL', 'cs.PL', 'cs.SE']
2017-04-07T11:27:14Z|2017-04-06T02:36:56Z|http://arxiv.org/abs/1704.01691v1|http://arxiv.org/pdf/1704.01691v1|Multi-space Variational Encoder-Decoders for Semi-supervised Labeled   Sequence Transduction|multi space variat encod decod semi supervis label sequenc transduct|Labeled sequence transduction is a task of transforming one sequence into another sequence that satisfies desiderata specified by a set of labels. In this paper we propose multi-space variational encoder-decoders, a new model for labeled sequence transduction with semi-supervised learning. The generative model can use neural networks to handle both discrete and continuous latent variables to exploit various features of data. Experiments show that our model provides not only a powerful supervised framework but also can effectively take advantage of the unlabeled data. On the SIGMORPHON morphological inflection benchmark, our model outperforms single-model state-of-art results by a large margin for the majority of languages.|label sequenc transduct task transform one sequenc anoth sequenc satisfi desiderata specifi set label paper propos multi space variat encod decod new model label sequenc transduct semi supervis learn generat model use neural network handl discret continu latent variabl exploit various featur data experi show model provid onli power supervis framework also effect take advantag unlabel data sigmorphon morpholog inflect benchmark model outperform singl model state art result larg margin major languag|['Chunting Zhou', 'Graham Neubig']|['cs.CL']
2017-04-07T11:27:14Z|2017-04-05T21:10:07Z|http://arxiv.org/abs/1704.01653v1|http://arxiv.org/pdf/1704.01653v1|Automatic Measurement of Pre-aspiration|automat measur pre aspir|Pre-aspiration is defined as the period of glottal friction occurring in sequences of vocalic/consonantal sonorants and phonetically voiceless obstruents. In this paper, we propose two machine learning methods for automatic measurement of pre-aspiration duration: feedforward neural network, which works at the frame level; and structured prediction model, which relies on manually designed feature functions, and works at the segment level. The input for both algorithms is a speech signal of an arbitrary length containing a single obstruent, and the output is a pair of times which constitutes the pre-aspiration boundaries. We train both models on a set of manually annotated examples. Results suggest that the structured model is superior to the frame-based model as it yields higher accuracy in predicting the boundaries and generalizes to new speakers and new languages. Finally, we demonstrate the applicability of our structured prediction algorithm by replicating linguistic analysis of pre-aspiration in Aberystwyth English with high correlation.|pre aspir defin period glottal friction occur sequenc vocal consonant sonor phonet voiceless obstruent paper propos two machin learn method automat measur pre aspir durat feedforward neural network work frame level structur predict model reli manual design featur function work segment level input algorithm speech signal arbitrari length contain singl obstruent output pair time constitut pre aspir boundari train model set manual annot exampl result suggest structur model superior frame base model yield higher accuraci predict boundari general new speaker new languag final demonstr applic structur predict algorithm replic linguist analysi pre aspir aberystwyth english high correl|['Yaniv Sheena', 'Míša Hejná', 'Yossi Adi', 'Joseph Keshet']|['cs.CL']
2017-04-07T11:27:14Z|2017-04-05T19:44:23Z|http://arxiv.org/abs/1704.01631v1|http://arxiv.org/pdf/1704.01631v1|Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder   Based Speech Recognition|multitask learn low level auxiliari task encod decod base speech recognit|End-to-end training of deep learning-based models allows for implicit learning of intermediate representations based on the final task loss. However, the end-to-end approach ignores the useful domain knowledge encoded in explicit intermediate-level supervision. We hypothesize that using intermediate representations as auxiliary supervision at lower levels of deep networks may be a good way of combining the advantages of end-to-end training and more traditional pipeline approaches. We present experiments on conversational speech recognition where we use lower-level tasks, such as phoneme recognition, in a multitask training approach with an encoder-decoder model for direct character transcription. We compare multiple types of lower-level tasks and analyze the effects of the auxiliary tasks. Our results on the Switchboard corpus show that this approach improves recognition accuracy over a standard encoder-decoder model on the Eval2000 test set.|end end train deep learn base model allow implicit learn intermedi represent base final task loss howev end end approach ignor use domain knowledg encod explicit intermedi level supervis hypothes use intermedi represent auxiliari supervis lower level deep network may good way combin advantag end end train tradit pipelin approach present experi convers speech recognit use lower level task phonem recognit multitask train approach encod decod model direct charact transcript compar multipl type lower level task analyz effect auxiliari task result switchboard corpus show approach improv recognit accuraci standard encod decod model eval test set|['Shubham Toshniwal', 'Hao Tang', 'Liang Lu', 'Karen Livescu']|['cs.CL', 'cs.AI']
2017-04-07T11:27:14Z|2017-04-05T18:21:39Z|http://arxiv.org/abs/1704.01599v1|http://arxiv.org/pdf/1704.01599v1|Rhetorical relations for information retrieval|rhetor relat inform retriev|Typically, every part in most coherent text has some plausible reason for its presence, some function that it performs to the overall semantics of the text. Rhetorical relations, e.g. contrast, cause, explanation, describe how the parts of a text are linked to each other. Knowledge about this socalled discourse structure has been applied successfully to several natural language processing tasks. This work studies the use of rhetorical relations for Information Retrieval (IR): Is there a correlation between certain rhetorical relations and retrieval performance? Can knowledge about a document's rhetorical relations be useful to IR? We present a language model modification that considers rhetorical relations when estimating the relevance of a document to a query. Empirical evaluation of different versions of our model on TREC settings shows that certain rhetorical relations can benefit retrieval effectiveness notably (> 10% in mean average precision over a state-of-the-art baseline).|typic everi part coher text plausibl reason presenc function perform overal semant text rhetor relat contrast caus explan describ part text link knowledg socal discours structur appli success sever natur languag process task work studi use rhetor relat inform retriev ir correl certain rhetor relat retriev perform knowledg document rhetor relat use ir present languag model modif consid rhetor relat estim relev document queri empir evalu differ version model trec set show certain rhetor relat benefit retriev effect notabl mean averag precis state art baselin|['Christina Lioma', 'Birger Larsen', 'Wei Lu']|['cs.IR', 'cs.CL']
2017-04-07T11:27:14Z|2017-04-05T16:54:20Z|http://arxiv.org/abs/1704.01523v1|http://arxiv.org/pdf/1704.01523v1|MIT at SemEval-2017 Task 10: Relation Extraction with Convolutional   Neural Networks|mit semev task relat extract convolut neural network|Over 50 million scholarly articles have been published: they constitute a unique repository of knowledge. In particular, one may infer from them relations between scientific concepts, such as synonyms and hyponyms. Artificial neural networks have been recently explored for relation extraction. In this work, we continue this line of work and present a system based on a convolutional neural network to extract relations. Our model ranked first in the SemEval-2017 task 10 (ScienceIE) for relation extraction in scientific articles (subtask C).|million scholar articl publish constitut uniqu repositori knowledg particular one may infer relat scientif concept synonym hyponym artifici neural network recent explor relat extract work continu line work present system base convolut neural network extract relat model rank first semev task sciencei relat extract scientif articl subtask|['Ji Young Lee', 'Franck Dernoncourt', 'Peter Szolovits']|['cs.CL', 'cs.AI', 'cs.NE', 'stat.ML']
2017-04-07T11:27:14Z|2017-04-06T09:48:20Z|http://arxiv.org/abs/1704.01444v2|http://arxiv.org/pdf/1704.01444v2|Learning to Generate Reviews and Discovering Sentiment|learn generat review discov sentiment|We explore the properties of byte-level recurrent language models. When given sufficient amounts of capacity, training data, and compute time, the representations learned by these models include disentangled features corresponding to high-level concepts. Specifically, we find a single unit which performs sentiment analysis. These representations, learned in an unsupervised manner, achieve state of the art on the binary subset of the Stanford Sentiment Treebank. They are also very data efficient. When using only a handful of labeled examples, our approach matches the performance of strong baselines trained on full datasets. We also demonstrate the sentiment unit has a direct influence on the generative process of the model. Simply fixing its value to be positive or negative generates samples with the corresponding positive or negative sentiment.|explor properti byte level recurr languag model given suffici amount capac train data comput time represent learn model includ disentangl featur correspond high level concept specif find singl unit perform sentiment analysi represent learn unsupervis manner achiev state art binari subset stanford sentiment treebank also veri data effici use onli hand label exampl approach match perform strong baselin train full dataset also demonstr sentiment unit direct influenc generat process model simpli fix valu posit negat generat sampl correspond posit negat sentiment|['Alec Radford', 'Rafal Jozefowicz', 'Ilya Sutskever']|['cs.LG', 'cs.CL', 'cs.NE']
2017-04-07T11:27:18Z|2017-04-05T13:38:01Z|http://arxiv.org/abs/1704.01419v1|http://arxiv.org/pdf/1704.01419v1|Linear Ensembles of Word Embedding Models|linear ensembl word embed model|This paper explores linear methods for combining several word embedding models into an ensemble. We construct the combined models using an iterative method based on either ordinary least squares regression or the solution to the orthogonal Procrustes problem.   We evaluate the proposed approaches on Estonian---a morphologically complex language, for which the available corpora for training word embeddings are relatively small. We compare both combined models with each other and with the input word embedding models using synonym and analogy tests. The results show that while using the ordinary least squares regression performs poorly in our experiments, using orthogonal Procrustes to combine several word embedding models into an ensemble model leads to 7-10% relative improvements over the mean result of the initial models in synonym tests and 19-47% in analogy tests.|paper explor linear method combin sever word embed model ensembl construct combin model use iter method base either ordinari least squar regress solut orthogon procrust problem evalu propos approach estonian morpholog complex languag avail corpora train word embed relat small compar combin model input word embed model use synonym analog test result show use ordinari least squar regress perform poor experi use orthogon procrust combin sever word embed model ensembl model lead relat improv mean result initi model synonym test analog test|['Avo Muromägi', 'Kairit Sirts', 'Sven Laur']|['cs.CL']
2017-04-07T11:27:18Z|2017-04-05T10:07:22Z|http://arxiv.org/abs/1704.01346v1|http://arxiv.org/pdf/1704.01346v1|CompiLIG at SemEval-2017 Task 1: Cross-Language Plagiarism Detection   Methods for Semantic Textual Similarity|compilig semev task cross languag plagiar detect method semant textual similar|We present our submitted systems for Semantic Textual Similarity (STS) Track 4 at SemEval-2017. Given a pair of Spanish-English sentences, each system must estimate their semantic similarity by a score between 0 and 5. In our submission, we use syntax-based, dictionary-based, context-based, and MT-based methods. We also combine these methods in unsupervised and supervised way. Our best run ranked 1st on track 4a with a correlation of 83.02% with human annotations.|present submit system semant textual similar sts track semev given pair spanish english sentenc system must estim semant similar score submiss use syntax base dictionari base context base mt base method also combin method unsupervis supervis way best run rank st track correl human annot|['Jeremy Ferrero', 'Frederic Agnes', 'Laurent Besacier', 'Didier Schwab']|['cs.CL']
2017-04-07T11:27:18Z|2017-04-05T08:58:44Z|http://arxiv.org/abs/1704.01314v1|http://arxiv.org/pdf/1704.01314v1|Character-based Joint Segmentation and POS Tagging for Chinese using   Bidirectional RNN-CRF|charact base joint segment pos tag chines use bidirect rnn crf|We present a character-based model for joint segmentation and POS tagging for Chinese. The bidirectional RNN-CRF architecture for general sequence tagging is adapted and applied with novel vector representations of Chinese characters that capture rich contextual information and lower-than-character level features. The proposed model is extensively evaluated and compared with a state-of-the-art tagger respectively on CTB5, CTB9 and UD Chinese. The experimental results indicate that our model is accurate and robust across datasets in different sizes, genres and annotation schemes. We obtain state- of-the-art performance on CTB5, achieving 94.38 F1-score for joint segmentation and POS tagging.|present charact base model joint segment pos tag chines bidirect rnn crf architectur general sequenc tag adapt appli novel vector represent chines charact captur rich contextu inform lower charact level featur propos model extens evalu compar state art tagger respect ctb ctb ud chines experiment result indic model accur robust across dataset differ size genr annot scheme obtain state art perform ctb achiev score joint segment pos tag|['Yan Shao', 'Christian Hardmeier', 'Jörg Tiedemann', 'Joakim Nivre']|['cs.CL']
2017-04-07T11:27:18Z|2017-04-04T15:44:48Z|http://arxiv.org/abs/1704.01074v1|http://arxiv.org/pdf/1704.01074v1|Emotional Chatting Machine: Emotional Conversation Generation with   Internal and External Memory|emot chat machin emot convers generat intern extern memori|Emotional intelligence is one of the key factors to the success of dialogue systems or conversational agents. In this paper, we propose Emotional Chatting Machine (ECM) which generates responses that are appropriate not only at the content level (relevant and grammatical) but also at the emotion level (consistent emotional expression). To the best of our knowledge, this is the first work that addresses the emotion factor in large-scale conversation generation. ECM addresses the factor in three ways: modeling high-level abstraction of emotion expression by embedding emotion categories, changing of implicit internal emotion states, and using explicit emotion expressions with an external emotion vocabulary. Experiments show that our model can generate responses appropriate not only in content but also in emotion.|emot intellig one key factor success dialogu system convers agent paper propos emot chat machin ecm generat respons appropri onli content level relev grammat also emot level consist emot express best knowledg first work address emot factor larg scale convers generat ecm address factor three way model high level abstract emot express embed emot categori chang implicit intern emot state use explicit emot express extern emot vocabulari experi show model generat respons appropri onli content also emot|['Hao Zhou', 'Minlie Huang', 'Tianyang Zhang', 'Xiaoyan Zhu', 'Bing Liu']|['cs.CL']
2017-04-07T11:27:18Z|2017-04-04T10:01:47Z|http://arxiv.org/abs/1704.00939v1|http://arxiv.org/pdf/1704.00939v1|Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring   Sentiment towards Brands from Financial News Headlines|fortia fbk semev task bullish bearish infer sentiment toward brand financi news headlin|In this paper, we describe a methodology to infer Bullish or Bearish sentiment towards companies/brands. More specifically, our approach leverages affective lexica and word embeddings in combination with convolutional neural networks to infer the sentiment of financial news headlines towards a target company. Such architecture was used and evaluated in the context of the SemEval 2017 challenge (task 5, subtask 2), in which it obtained the best performance.|paper describ methodolog infer bullish bearish sentiment toward compani brand specif approach leverag affect lexica word embed combin convolut neural network infer sentiment financi news headlin toward target compani architectur use evalu context semev challeng task subtask obtain best perform|['Youness Mansar', 'Lorenzo Gatti', 'Sira Ferradans', 'Marco Guerini', 'Jacopo Staiano']|['cs.CL', 'cs.CY']
2017-04-07T11:27:18Z|2017-04-04T09:08:46Z|http://arxiv.org/abs/1704.00924v1|http://arxiv.org/pdf/1704.00924v1|Japanese Sentiment Classification using a Tree-Structured Long   Short-Term Memory with Attention|japanes sentiment classif use tree structur long short term memori attent|Previous approaches to training syntax-based sentiment classification models required phrase-level annotated corpora, which are not readily available in many languages other than English. Thus, we propose the use of tree-structured Long Short-Term Memory with an attention mechanism that pays attention to each subtree of the parse tree. Experimental results indicate that our model achieves the state-of-the-art performance in a Japanese sentiment classification task.|previous approach train syntax base sentiment classif model requir phrase level annot corpora readili avail mani languag english thus propos use tree structur long short term memori attent mechan pay attent subtre pars tree experiment result indic model achiev state art perform japanes sentiment classif task|['Ryosuke Miyazaki', 'Mamoru Komachi']|['cs.CL']
2017-04-07T11:27:18Z|2017-04-04T07:24:15Z|http://arxiv.org/abs/1704.00898v1|http://arxiv.org/pdf/1704.00898v1|Interpretation of Semantic Tweet Representations|interpret semant tweet represent|Research in analysis of microblogging platforms is experiencing a renewed surge with a large number of works applying representation learning models for applications like sentiment analysis, semantic textual similarity computation, hashtag prediction, etc. Although the performance of the representation learning models has been better than the traditional baselines for such tasks, little is known about the elementary properties of a tweet encoded within these representations, or why particular representations work better for certain tasks. Our work presented here constitutes the first step in opening the black-box of vector embeddings for tweets. Traditional feature engineering methods for high-level applications have exploited various elementary properties of tweets. We believe that a tweet representation is effective for an application because it meticulously encodes the application-specific elementary properties of tweets. To understand the elementary properties encoded in a tweet representation, we evaluate the representations on the accuracy to which they can model each of those properties such as tweet length, presence of particular words, hashtags, mentions, capitalization, etc. Our systematic extensive study of nine supervised and four unsupervised tweet representations against most popular eight textual and five social elementary properties reveal that Bi-directional LSTMs (BLSTMs) and Skip-Thought Vectors (STV) best encode the textual and social properties of tweets respectively. FastText is the best model for low resource settings, providing very little degradation with reduction in embedding size. Finally, we draw interesting insights by correlating the model performance obtained for elementary property prediction tasks with the high-level downstream applications.|research analysi microblog platform experienc renew surg larg number work appli represent learn model applic like sentiment analysi semant textual similar comput hashtag predict etc although perform represent learn model better tradit baselin task littl known elementari properti tweet encod within represent whi particular represent work better certain task work present constitut first step open black box vector embed tweet tradit featur engin method high level applic exploit various elementari properti tweet believ tweet represent effect applic becaus meticul encod applic specif elementari properti tweet understand elementari properti encod tweet represent evalu represent accuraci model properti tweet length presenc particular word hashtag mention capit etc systemat extens studi nine supervis four unsupervis tweet represent popular eight textual five social elementari properti reveal bi direct lstms blstms skip thought vector stv best encod textual social properti tweet respect fasttext best model low resourc set provid veri littl degrad reduct embed size final draw interest insight correl model perform obtain elementari properti predict task high level downstream applic|['J Ganesh', 'Manish Gupta', 'Vasudeva Varma']|['cs.CL']
2017-04-07T11:27:18Z|2017-04-04T01:47:14Z|http://arxiv.org/abs/1704.00849v1|http://arxiv.org/pdf/1704.00849v1|Voice Conversion from Unaligned Corpora using Variational Autoencoding   Wasserstein Generative Adversarial Networks|voic convers unalign corpora use variat autoencod wasserstein generat adversari network|Building a voice conversion (VC) system from non-parallel speech corpora is challenging but highly valuable in real application scenarios. In most situations, the source and the target speakers do not repeat the same texts or they may even speak different languages. In this case, one possible, although indirect, solution is to build a generative model for speech. Generative models focus on explaining the observations with latent variables instead of learning a pairwise transformation function, thereby bypassing the requirement of speech frame alignment. In this paper, we propose a non-parallel VC framework with a Wasserstein generative adversarial network (W-GAN) that explicitly takes a VC-related objective into account. Experimental results corroborate the capability of our framework for building a VC system from unaligned data, and demonstrate improved conversion quality.|build voic convers vc system non parallel speech corpora challeng high valuabl real applic scenario situat sourc target speaker repeat text may even speak differ languag case one possibl although indirect solut build generat model speech generat model focus explain observ latent variabl instead learn pairwis transform function therebi bypass requir speech frame align paper propos non parallel vc framework wasserstein generat adversari network gan explicit take vc relat object account experiment result corrobor capabl framework build vc system unalign data demonstr improv convers qualiti|['Chin-Cheng Hsu', 'Hsin-Te Hwang', 'Yi-Chiao Wu', 'Yu Tsao', 'Hsin-Min Wang']|['cs.CL']
2017-04-07T11:27:18Z|2017-04-03T19:45:27Z|http://arxiv.org/abs/1704.00784v1|http://arxiv.org/pdf/1704.00784v1|Online and Linear-Time Attention by Enforcing Monotonic Alignments|onlin linear time attent enforc monoton align|Recurrent neural network models with an attention mechanism have proven to be extremely effective on a wide variety of sequence-to-sequence problems. However, the fact that soft attention mechanisms perform a pass over the entire input sequence when producing each element in the output sequence precludes their use in online settings and results in a quadratic time complexity. Based on the insight that the alignment between input and output sequence elements is monotonic in many problems of interest, we propose an end-to-end differentiable method for learning monotonic alignments which, at test time, enables computing attention online and in linear time. We validate our approach on sentence summarization, machine translation, and online speech recognition problems and achieve results competitive with existing sequence-to-sequence models.|recurr neural network model attent mechan proven extrem effect wide varieti sequenc sequenc problem howev fact soft attent mechan perform pass entir input sequenc produc element output sequenc preclud use onlin set result quadrat time complex base insight align input output sequenc element monoton mani problem interest propos end end differenti method learn monoton align test time enabl comput attent onlin linear time valid approach sentenc summar machin translat onlin speech recognit problem achiev result competit exist sequenc sequenc model|['Colin Raffel', 'Thang Luong', 'Peter J. Liu', 'Ron J. Weiss', 'Douglas Eck']|['cs.LG', 'cs.CL']
2017-04-07T11:27:18Z|2017-04-03T19:17:58Z|http://arxiv.org/abs/1704.00774v1|http://arxiv.org/pdf/1704.00774v1|Restricted Recurrent Neural Tensor Networks|restrict recurr neural tensor network|Increasing the capacity of recurrent neural networks (RNN) usually involves augmenting the size of the hidden layer, resulting in a significant increase of computational cost. An alternative is the recurrent neural tensor network (RNTN), which increases capacity by employing distinct hidden layer weights for each vocabulary word. The disadvantage of RNTNs is that memory usage scales linearly with vocabulary size, which can reach millions for word-level language models. In this paper, we introduce restricted recurrent neural tensor networks (r-RNTN) which reserve distinct hidden layer weights for frequent vocabulary words while sharing a single set of weights for infrequent words. Perplexity evaluations using the Penn Treebank corpus show that r-RNTNs improve language model performance over standard RNNs using only a small fraction of the parameters of unrestricted RNTNs.|increas capac recurr neural network rnn usual involv augment size hidden layer result signific increas comput cost altern recurr neural tensor network rntn increas capac employ distinct hidden layer weight vocabulari word disadvantag rntns memori usag scale linear vocabulari size reach million word level languag model paper introduc restrict recurr neural tensor network rntn reserv distinct hidden layer weight frequent vocabulari word share singl set weight infrequ word perplex evalu use penn treebank corpus show rntns improv languag model perform standard rnns use onli small fraction paramet unrestrict rntns|['Alexandre Salle', 'Aline Villavicencio']|['cs.CL']
2017-04-07T11:27:22Z|2017-04-03T17:58:07Z|http://arxiv.org/abs/1704.00717v1|http://arxiv.org/pdf/1704.00717v1|It Takes Two to Tango: Towards Theory of AI's Mind|take two tango toward theori ai mind|Theory of Mind is the ability to attribute mental states (beliefs, intents, knowledge, perspectives, etc.) to others and recognize that these mental states may differ from one's own. Theory of Mind is critical to effective communication and to teams demonstrating higher collective performance. To effectively leverage the progress in Artificial Intelligence (AI) to make our lives more productive, it is important for humans and AI to work well together in a team. Traditionally, there has been much emphasis on research to make AI more accurate, and (to a lesser extent) on having it better understand human intentions, tendencies, beliefs, and contexts. The latter involves making AI more human-like and having it develop a theory of our minds.   In this work, we argue that for human-AI teams to be effective, humans must also develop a theory of AI's mind - get to know its strengths, weaknesses, beliefs, and quirks. We instantiate these ideas within the domain of Visual Question Answering (VQA). We find that using just a few examples(50), lay people can be trained to better predict responses and oncoming failures of a complex VQA model. Surprisingly, we find that having access to the model's internal states - its confidence in its top-k predictions, explicit or implicit attention maps which highlight regions in the image (and words in the question) the model is looking at (and listening to) while answering a question about an image - do not help people better predict its behavior|theori mind abil attribut mental state belief intent knowledg perspect etc recogn mental state may differ one theori mind critic effect communic team demonstr higher collect perform effect leverag progress artifici intellig ai make live product import human ai work well togeth team tradit much emphasi research make ai accur lesser extent better understand human intent tendenc belief context latter involv make ai human like develop theori mind work argu human ai team effect human must also develop theori ai mind get know strength weak belief quirk instanti idea within domain visual question answer vqa find use exampl lay peopl train better predict respons oncom failur complex vqa model surpris find access model intern state confid top predict explicit implicit attent map highlight region imag word question model look listen answer question imag help peopl better predict behavior|['Arjun Chandrasekaran', 'Deshraj Yadav', 'Prithvijit Chattopadhyay', 'Viraj Prabhu', 'Devi Parikh']|['cs.CV', 'cs.AI', 'cs.CL']
2017-04-07T11:27:22Z|2017-04-03T15:57:44Z|http://arxiv.org/abs/1704.00656v1|http://arxiv.org/pdf/1704.00656v1|Detection and Resolution of Rumours in Social Media: A Survey|detect resolut rumour social media survey|Despite the increasing use of social media platforms for information and news gathering, its unmoderated nature often leads to the emergence and spread of rumours, i.e. pieces of information that are unverified at the time of posting. At the same time, the openness of social media platforms provides opportunities to study how users share and discuss rumours, and to explore how natural language processing and data mining techniques may be used to find ways of determining their veracity. In this survey we introduce and discuss two types of rumours that circulate on social media; long-standing rumours that circulate for long periods of time, and newly-emerging rumours spawned during fast-paced events such as breaking news, where reports are released piecemeal and often with an unverified status in their early stages. We provide an overview of research into social media rumours with the ultimate goal of developing a rumour classification system that consists of four components: rumour detection, rumour tracking, rumour stance classification and rumour veracity classification. We delve into the approaches presented in the scientific literature for the development of each of these four components. We summarise the efforts and achievements so far towards the development of rumour classification systems and conclude with suggestions for avenues for future research in social media mining for detection and resolution of rumours.|despit increas use social media platform inform news gather unmoder natur often lead emerg spread rumour piec inform unverifi time post time open social media platform provid opportun studi user share discuss rumour explor natur languag process data mine techniqu may use find way determin verac survey introduc discuss two type rumour circul social media long stand rumour circul long period time newli emerg rumour spawn dure fast pace event break news report releas piecem often unverifi status earli stage provid overview research social media rumour ultim goal develop rumour classif system consist four compon rumour detect rumour track rumour stanc classif rumour verac classif delv approach present scientif literatur develop four compon summaris effort achiev far toward develop rumour classif system conclud suggest avenu futur research social media mine detect resolut rumour|['Arkaitz Zubiaga', 'Ahmet Aker', 'Kalina Bontcheva', 'Maria Liakata', 'Rob Procter']|['cs.CL', 'cs.HC', 'cs.IR', 'cs.SI']
2017-04-07T11:27:22Z|2017-04-03T13:03:40Z|http://arxiv.org/abs/1704.00559v1|http://arxiv.org/pdf/1704.00559v1|Neural Lattice-to-Sequence Models for Uncertain Inputs|neural lattic sequenc model uncertain input|The input to a neural sequence-to-sequence model is often determined by an up-stream system, e.g. a word segmenter, part of speech tagger, or speech recognizer. These up-stream models are potentially error-prone. Representing inputs through word lattices allows making this uncertainty explicit by capturing alternative sequences and their posterior probabilities in a compact form. In this work, we extend the TreeLSTM (Tai et al., 2015) into a LatticeLSTM that is able to consume word lattices, and can be used as encoder in an attentional encoder-decoder model. We integrate lattice posterior scores into this architecture by extending the TreeLSTM's child-sum and forget gates and introducing a bias term into the attention mechanism. We experiment with speech translation lattices and report consistent improvements over baselines that translate either the 1-best hypothesis or the lattice without posterior scores.|input neural sequenc sequenc model often determin stream system word segment part speech tagger speech recogn stream model potenti error prone repres input word lattic allow make uncertainti explicit captur altern sequenc posterior probabl compact form work extend treelstm tai et al latticelstm abl consum word lattic use encod attent encod decod model integr lattic posterior score architectur extend treelstm child sum forget gate introduc bias term attent mechan experi speech translat lattic report consist improv baselin translat either best hypothesi lattic without posterior score|['Matthias Sperber', 'Graham Neubig', 'Jan Niehues', 'Alex Waibel']|['cs.CL']
2017-04-07T11:27:22Z|2017-04-04T10:51:51Z|http://arxiv.org/abs/1704.00552v2|http://arxiv.org/pdf/1704.00552v2|A Transition-Based Directed Acyclic Graph Parser for UCCA|transit base direct acycl graph parser ucca|We present the first parser for UCCA, a cross-linguistically applicable framework for semantic representation, which builds on extensive typological work and supports rapid annotation. UCCA poses a challenge for existing parsing techniques, as it exhibits reentrancy (resulting in DAG structures), discontinuous structures and non-terminal nodes corresponding to complex semantic units. To our knowledge, the conjunction of these formal properties is not supported by any existing parser. Our transition-based parser, which uses a novel transition set and features based on bidirectional LSTMs, has value not just for UCCA parsing: its ability to handle more general graph structures can inform the development of parsers for other semantic DAG structures, and in languages that frequently use discontinuous structures.|present first parser ucca cross linguist applic framework semant represent build extens typolog work support rapid annot ucca pose challeng exist pars techniqu exhibit reentranc result dag structur discontinu structur non termin node correspond complex semant unit knowledg conjunct formal properti support ani exist parser transit base parser use novel transit set featur base bidirect lstms valu ucca pars abil handl general graph structur inform develop parser semant dag structur languag frequent use discontinu structur|['Daniel Hershcovich', 'Omri Abend', 'Ari Rappoport']|['cs.CL']
2017-04-07T11:27:22Z|2017-04-03T10:25:22Z|http://arxiv.org/abs/1704.00514v1|http://arxiv.org/pdf/1704.00514v1|Multi-Task Learning of Keyphrase Boundary Classification|multi task learn keyphras boundari classif|Keyphrase boundary classification (KBC) is the task of detecting keyphrases in scientific articles and labelling them with respect to predefined types. Although important in practice, this task is so far underexplored, partly due to the lack of labelled data. To overcome this, we explore several auxiliary tasks, including semantic super-sense tagging and identification of multi-word expressions, and cast the task as a multi-task learning problem with deep recurrent neural networks. Our multi-task models perform significantly better than previous state of the art approaches on two scientific KBC datasets, particularly for long keyphrases.|keyphras boundari classif kbc task detect keyphras scientif articl label respect predefin type although import practic task far underexplor part due lack label data overcom explor sever auxiliari task includ semant super sens tag identif multi word express cast task multi task learn problem deep recurr neural network multi task model perform signific better previous state art approach two scientif kbc dataset particular long keyphras|['Isabelle Augenstein', 'Anders Søgaard']|['cs.CL', 'cs.AI', 'stat.ML']
2017-04-07T11:27:22Z|2017-04-03T06:22:04Z|http://arxiv.org/abs/1704.00440v1|http://arxiv.org/pdf/1704.00440v1|Combining Lexical and Syntactic Features for Detecting Content-dense   Texts in News|combin lexic syntact featur detect content dens text news|Content-dense news report important factual information about an event in direct, succinct manner. Information seeking applications such as information extraction, question answering and summarization normally assume all text they deal with is content-dense. Here we empirically test this assumption on news articles from the business, U.S. international relations, sports and science journalism domains. Our findings clearly indicate that about half of the news texts in our study are in fact not content-dense and motivate the development of a supervised content-density detector. We heuristically label a large training corpus for the task and train a two-layer classifying model based on lexical and unlexicalized syntactic features. On manually annotated data, we compare the performance of domain-specific classifiers, trained on data only from a given news domain and a general classifier in which data from all four domains is pooled together. Our annotation and prediction experiments demonstrate that the concept of content density varies depending on the domain and that naive annotators provide judgement biased toward the stereotypical domain label. Domain-specific classifiers are more accurate for domains in which content-dense texts are typically fewer. Domain independent classifiers reproduce better naive crowdsourced judgements. Classification prediction is high across all conditions, around 80%.|content dens news report import factual inform event direct succinct manner inform seek applic inform extract question answer summar normal assum text deal content dens empir test assumpt news articl busi intern relat sport scienc journal domain find clear indic half news text studi fact content dens motiv develop supervis content densiti detector heurist label larg train corpus task train two layer classifi model base lexic unlexic syntact featur manual annot data compar perform domain specif classifi train data onli given news domain general classifi data four domain pool togeth annot predict experi demonstr concept content densiti vari depend domain naiv annot provid judgement bias toward stereotyp domain label domain specif classifi accur domain content dens text typic fewer domain independ classifi reproduc better naiv crowdsourc judgement classif predict high across condit around|['Yinfei Yang', 'Ani Nenkova']|['cs.CL']
2017-04-07T11:27:22Z|2017-04-03T02:10:19Z|http://arxiv.org/abs/1704.00405v1|http://arxiv.org/pdf/1704.00405v1|Syntax Aware LSTM Model for Chinese Semantic Role Labeling|syntax awar lstm model chines semant role label|Traditional approaches to Semantic Role Labeling (SRL) depend heavily on manual feature engineering. Recurrent neural network (RNN) with long-short-term memory (LSTM) only treats sentence as sequence data and can not utilize higher level syntactic information. In this paper, we propose Syntax Aware LSTM (SA-LSTM) which gives RNN-LSTM ability to utilize higher level syntactic information gained from dependency relationship information. SA-LSTM also assigns different trainable weights to different types of dependency relationship automatically. Experiment results on Chinese Proposition Bank (CPB) show that, even without pre-training or introducing any other extra semantically annotated resources, our SA-LSTM model still outperforms the state of the art significantly base on Student's t-test ($p<0.05$). Trained weights of types of dependency relationship form a stable and self-explanatory pattern.|tradit approach semant role label srl depend heavili manual featur engin recurr neural network rnn long short term memori lstm onli treat sentenc sequenc data util higher level syntact inform paper propos syntax awar lstm sa lstm give rnn lstm abil util higher level syntact inform gain depend relationship inform sa lstm also assign differ trainabl weight differ type depend relationship automat experi result chines proposit bank cpb show even without pre train introduc ani extra semant annot resourc sa lstm model still outperform state art signific base student test train weight type depend relationship form stabl self explanatori pattern|['Feng Qian', 'Lei Sha', 'Baobao Chang', 'Lu-chen Liu', 'Ming Zhang']|['cs.CL']
2017-04-07T11:27:22Z|2017-04-02T22:36:56Z|http://arxiv.org/abs/1704.00380v1|http://arxiv.org/pdf/1704.00380v1|Word-Alignment-Based Segment-Level Machine Translation Evaluation using   Word Embeddings|word align base segment level machin translat evalu use word embed|One of the most important problems in machine translation (MT) evaluation is to evaluate the similarity between translation hypotheses with different surface forms from the reference, especially at the segment level. We propose to use word embeddings to perform word alignment for segment-level MT evaluation. We performed experiments with three types of alignment methods using word embeddings. We evaluated our proposed methods with various translation datasets. Experimental results show that our proposed methods outperform previous word embeddings-based methods.|one import problem machin translat mt evalu evalu similar translat hypothes differ surfac form refer especi segment level propos use word embed perform word align segment level mt evalu perform experi three type align method use word embed evalu propos method various translat dataset experiment result show propos method outperform previous word embed base method|['Junki Matsuo', 'Mamoru Komachi', 'Katsuhito Sudoh']|['cs.CL']
2017-04-07T11:27:22Z|2017-04-02T05:54:14Z|http://arxiv.org/abs/1704.00253v1|http://arxiv.org/pdf/1704.00253v1|Building a Neural Machine Translation System Using Only Synthetic   Parallel Data|build neural machin translat system use onli synthet parallel data|Recent works have proved that synthetic parallel data generated by existing translation models can be an effective solution to various neural machine translation (NMT) issues. In this study, we construct NMT systems using only synthetic parallel data. As an effective alternative to real parallel data, we also present a new type of synthetic parallel corpus. The proposed pseudo parallel data are distinct from previous approaches in that real and synthetic sentences are mixed on both sides of sentence pairs. Experiments on Czech-German and French-German translations demonstrate the efficacy of the proposed pseudo parallel corpus that guarantees not only both balanced and competitive performance for bidirectional translation but also substantial improvement with the aid of a real parallel corpus.|recent work prove synthet parallel data generat exist translat model effect solut various neural machin translat nmt issu studi construct nmt system use onli synthet parallel data effect altern real parallel data also present new type synthet parallel corpus propos pseudo parallel data distinct previous approach real synthet sentenc mix side sentenc pair experi czech german french german translat demonstr efficaci propos pseudo parallel corpus guarante onli balanc competit perform bidirect translat also substanti improv aid real parallel corpus|['Jaehong Park', 'Byunggook Na', 'Sungroh Yoon']|['cs.CL']
2017-04-07T11:27:22Z|2017-04-01T19:29:21Z|http://arxiv.org/abs/1704.00217v1|http://arxiv.org/pdf/1704.00217v1|Adversarial Connective-exploiting Networks for Implicit Discourse   Relation Classification|adversari connect exploit network implicit discours relat classif|Implicit discourse relation classification is of great challenge due to the lack of connectives as strong linguistic cues, which motivates the use of annotated implicit connectives to improve the recognition. We propose a feature imitation framework in which an implicit relation network is driven to learn from another neural network with access to connectives, and thus encouraged to extract similarly salient features for accurate classification. We develop an adversarial model to enable an adaptive imitation scheme through competition between the implicit network and a rival feature discriminator. Our method effectively transfers discriminability of connectives to the implicit features, and achieves state-of-the-art performance on the PDTB benchmark.|implicit discours relat classif great challeng due lack connect strong linguist cue motiv use annot implicit connect improv recognit propos featur imit framework implicit relat network driven learn anoth neural network access connect thus encourag extract similar salient featur accur classif develop adversari model enabl adapt imit scheme competit implicit network rival featur discrimin method effect transfer discrimin connect implicit featur achiev state art perform pdtb benchmark|['Lianhui Qin', 'Zhisong Zhang', 'Hai Zhao', 'Zhiting Hu', 'Eric P. Xing']|['cs.CL', 'cs.AI', 'cs.LG', 'stat.ML']
2017-04-07T11:27:26Z|2017-04-01T17:05:35Z|http://arxiv.org/abs/1704.00200v1|http://arxiv.org/pdf/1704.00200v1|Multimodal Dialogs (MMD): A large-scale dataset for studying multimodal   domain-aware conversations|multimod dialog mmd larg scale dataset studi multimod domain awar convers|Owing to the success of deep learning techniques for tasks such as Q/A and text-based dialog, there is an increasing demand for AI agents in several domains such as retail, travel, entertainment, etc. that can carry on multimodal conversations with humans employing both text and images within a dialog seamlessly. However, deep learning research is this area has been limited primarily due to the lack of availability of large-scale, open conversation datasets. To overcome this bottleneck, in this paper we introduce the task of multi-modal, domain-aware conversations, and propose the MMD benchmark dataset to- wards this task. This dataset was gathered by working in close coordination with large number of domain experts in the retail domain and consists of over 150K conversation sessions between shoppers and sales agents. With this dataset, we propose 5 new sub-tasks for multimodal conversations along with their evaluation methodology. We also propose two novel multi-modal deep learning models in the encode- attend-decode paradigm and demonstrate their performance on two of the sub-tasks, namely text response generation and best image response selection. These experiments serve to establish baseline performance numbers and open new directions of research for each of these sub-tasks.|owe success deep learn techniqu task text base dialog increas demand ai agent sever domain retail travel entertain etc carri multimod convers human employ text imag within dialog seamless howev deep learn research area limit primarili due lack avail larg scale open convers dataset overcom bottleneck paper introduc task multi modal domain awar convers propos mmd benchmark dataset ward task dataset gather work close coordin larg number domain expert retail domain consist convers session shopper sale agent dataset propos new sub task multimod convers along evalu methodolog also propos two novel multi modal deep learn model encod attend decod paradigm demonstr perform two sub task name text respons generat best imag respons select experi serv establish baselin perform number open new direct research sub task|['Amrita Saha', 'Mitesh Khapra', 'Karthik Sankaranarayanan']|['cs.CL']
2017-04-07T11:27:26Z|2017-04-01T14:53:54Z|http://arxiv.org/abs/1704.00177v1|http://arxiv.org/pdf/1704.00177v1|Sentiment Analysis of Citations Using Word2vec|sentiment analysi citat use wordvec|Citation sentiment analysis is an important task in scientific paper analysis. Existing machine learning techniques for citation sentiment analysis are focusing on labor-intensive feature engineering, which requires large annotated corpus. As an automatic feature extraction tool, word2vec has been successfully applied to sentiment analysis of short texts. In this work, I conducted empirical research with the question: how well does word2vec work on the sentiment analysis of citations? The proposed method constructed sentence vectors (sent2vec) by averaging the word embeddings, which were learned from Anthology Collections (ACL-Embeddings). I also investigated polarity-specific word embeddings (PS-Embeddings) for classifying positive and negative citations. The sentence vectors formed a feature space, to which the examined citation sentence was mapped to. Those features were input into classifiers (support vector machines) for supervised classification. Using 10-cross-validation scheme, evaluation was conducted on a set of annotated citations. The results showed that word embeddings are effective on classifying positive and negative citations. However, hand-crafted features performed better for the overall classification.|citat sentiment analysi import task scientif paper analysi exist machin learn techniqu citat sentiment analysi focus labor intens featur engin requir larg annot corpus automat featur extract tool wordvec success appli sentiment analysi short text work conduct empir research question well doe wordvec work sentiment analysi citat propos method construct sentenc vector sentvec averag word embed learn antholog collect acl embed also investig polar specif word embed ps embed classifi posit negat citat sentenc vector form featur space examin citat sentenc map featur input classifi support vector machin supervis classif use cross valid scheme evalu conduct set annot citat result show word embed effect classifi posit negat citat howev hand craft featur perform better overal classif|['Haixia Liu']|['cs.CL']
2017-04-07T11:27:26Z|2017-04-01T08:16:20Z|http://arxiv.org/abs/1704.00135v1|http://arxiv.org/pdf/1704.00135v1|Topic modeling of public repositories at scale using names in source   code|topic model public repositori scale use name sourc code|Programming languages themselves have a limited number of reserved keywords and character based tokens that define the language specification. However, programmers have a rich use of natural language within their code through comments, text literals and naming entities. The programmer defined names that can be found in source code are a rich source of information to build a high level understanding of the project. The goal of this paper is to apply topic modeling to names used in over 13.6 million repositories and perceive the inferred topics. One of the problems in such a study is the occurrence of duplicate repositories not officially marked as forks (obscure forks). We show how to address it using the same identifiers which are extracted for topic modeling.   We open with a discussion on naming in source code, we then elaborate on our approach to remove exact duplicate and fuzzy duplicate repositories using Locality Sensitive Hashing on the bag-of-words model and then discuss our work on topic modeling; and finally present the results from our data analysis together with open-access to the source code, tools and datasets.|program languag themselv limit number reserv keyword charact base token defin languag specif howev programm rich use natur languag within code comment text liter name entiti programm defin name found sourc code rich sourc inform build high level understand project goal paper appli topic model name use million repositori perceiv infer topic one problem studi occurr duplic repositori offici mark fork obscur fork show address use identifi extract topic model open discuss name sourc code elabor approach remov exact duplic fuzzi duplic repositori use local sensit hash bag word model discuss work topic model final present result data analysi togeth open access sourc code tool dataset|['Vadim Markovtsev', 'Eiso Kant']|['cs.PL', 'cs.CL']
2017-04-07T11:27:26Z|2017-04-01T04:31:37Z|http://arxiv.org/abs/1704.00119v1|http://arxiv.org/pdf/1704.00119v1|Psychological and Personality Profiles of Political Extremists|psycholog person profil polit extremist|Global recruitment into radical Islamic movements has spurred renewed interest in the appeal of political extremism. Is the appeal a rational response to material conditions or is it the expression of psychological and personality disorders associated with aggressive behavior, intolerance, conspiratorial imagination, and paranoia? Empirical answers using surveys have been limited by lack of access to extremist groups, while field studies have lacked psychological measures and failed to compare extremists with contrast groups. We revisit the debate over the appeal of extremism in the U.S. context by comparing publicly available Twitter messages written by over 355,000 political extremist followers with messages written by non-extremist U.S. users. Analysis of text-based psychological indicators supports the moral foundation theory which identifies emotion as a critical factor in determining political orientation of individuals. Extremist followers also differ from others in four of the Big Five personality traits.|global recruit radic islam movement spur renew interest appeal polit extrem appeal ration respons materi condit express psycholog person disord associ aggress behavior intoler conspiratori imagin paranoia empir answer use survey limit lack access extremist group field studi lack psycholog measur fail compar extremist contrast group revisit debat appeal extrem context compar public avail twitter messag written polit extremist follow messag written non extremist user analysi text base psycholog indic support moral foundat theori identifi emot critic factor determin polit orient individu extremist follow also differ four big five person trait|['Meysam Alizadeh', 'Ingmar Weber', 'Claudio Cioffi-Revilla', 'Santo Fortunato', 'Michael Macy']|['cs.CL', 'cs.CY', 'cs.SI', 'physics.soc-ph']
2017-04-07T11:27:26Z|2017-03-31T21:03:58Z|http://arxiv.org/abs/1704.00057v1|http://arxiv.org/pdf/1704.00057v1|Frames: A Corpus for Adding Memory to Goal-Oriented Dialogue Systems|frame corpus ad memori goal orient dialogu system|This paper presents the Frames dataset (Frames is available at http://datasets.maluuba.com/Frames), a corpus of 1369 human-human dialogues with an average of 15 turns per dialogue. We developed this dataset to study the role of memory in goal-oriented dialogue systems. Based on Frames, we introduce a task called frame tracking, which extends state tracking to a setting where several states are tracked simultaneously. We propose a baseline model for this task. We show that Frames can also be used to study memory in dialogue management and information presentation through natural language generation.|paper present frame dataset frame avail http dataset maluuba com frame corpus human human dialogu averag turn per dialogu develop dataset studi role memori goal orient dialogu system base frame introduc task call frame track extend state track set sever state track simultan propos baselin model task show frame also use studi memori dialogu manag inform present natur languag generat|['Layla El Asri', 'Hannes Schulz', 'Shikhar Sharma', 'Jeremie Zumer', 'Justin Harris', 'Emery Fine', 'Rahul Mehrotra', 'Kaheer Suleman']|['cs.CL']
2017-04-07T11:27:26Z|2017-03-31T20:39:38Z|http://arxiv.org/abs/1704.00052v1|http://arxiv.org/pdf/1704.00052v1|One-Shot Neural Cross-Lingual Transfer for Paradigm Completion|one shot neural cross lingual transfer paradigm complet|We present a novel cross-lingual transfer method for paradigm completion, the task of mapping a lemma to its inflected forms, using a neural encoder-decoder model, the state of the art for the monolingual task. We use labeled data from a high-resource language to increase performance on a low-resource language. In experiments on 21 language pairs from four different language families, we obtain up to 58% higher accuracy than without transfer and show that even zero-shot and one-shot learning are possible. We further find that the degree of language relatedness strongly influences the ability to transfer morphological knowledge.|present novel cross lingual transfer method paradigm complet task map lemma inflect form use neural encod decod model state art monolingu task use label data high resourc languag increas perform low resourc languag experi languag pair four differ languag famili obtain higher accuraci without transfer show even zero shot one shot learn possibl find degre languag related strong influenc abil transfer morpholog knowledg|['Katharina Kann', 'Ryan Cotterell', 'Hinrich Schütze']|['cs.CL']
2017-04-07T11:27:26Z|2017-03-31T20:39:10Z|http://arxiv.org/abs/1704.00051v1|http://arxiv.org/pdf/1704.00051v1|Reading Wikipedia to Answer Open-Domain Questions|read wikipedia answer open domain question|This paper proposes to tackle open-domain question answering using Wikipedia as the unique knowledge source: the answer to any factoid question is a text span in a Wikipedia article. This task of machine reading at scale combines the challenges of document retrieval - finding the relevant articles - with that of machine comprehension of text - identifying the answer spans from those articles. Our approach combines a search component based on bigram hashing and TF-IDF matching with a multi-layer recurrent neural network model trained to detect answers in Wikipedia paragraphs. Our experiments on multiple existing QA datasets indicate that (1) both modules are highly competitive with respect to existing counterparts and (2) multitask learning using distant supervision on their combination is an effective complete system on this challenging task.|paper propos tackl open domain question answer use wikipedia uniqu knowledg sourc answer ani factoid question text span wikipedia articl task machin read scale combin challeng document retriev find relev articl machin comprehens text identifi answer span articl approach combin search compon base bigram hash tf idf match multi layer recurr neural network model train detect answer wikipedia paragraph experi multipl exist qa dataset indic modul high competit respect exist counterpart multitask learn use distant supervis combin effect complet system challeng task|['Danqi Chen', 'Adam Fisch', 'Jason Weston', 'Antoine Bordes']|['cs.CL']
2017-04-07T11:27:26Z|2017-04-04T01:51:43Z|http://arxiv.org/abs/1704.00016v2|http://arxiv.org/pdf/1704.00016v2|Opinion Mining on Non-English Short Text|opinion mine non english short text|As the type and the number of such venues increase, automated analysis of sentiment on textual resources has become an essential data mining task. In this paper, we investigate the problem of mining opinions on the collection of informal short texts. Both positive and negative sentiment strength of texts are detected. We focus on a non-English language that has few resources for text mining. This approach would help enhance the sentiment analysis in languages where a list of opinionated words does not exist. We propose a new method projects the text into dense and low dimensional feature vectors according to the sentiment strength of the words. We detect the mixture of positive and negative sentiments on a multi-variant scale. Empirical evaluation of the proposed framework on Turkish tweets shows that our approach gets good results for opinion mining.|type number venu increas autom analysi sentiment textual resourc becom essenti data mine task paper investig problem mine opinion collect inform short text posit negat sentiment strength text detect focus non english languag resourc text mine approach would help enhanc sentiment analysi languag list opinion word doe exist propos new method project text dens low dimension featur vector accord sentiment strength word detect mixtur posit negat sentiment multi variant scale empir evalu propos framework turkish tweet show approach get good result opinion mine|['Esra Akbas']|['cs.CL', 'cs.IR']
2017-04-07T11:27:26Z|2017-03-31T15:55:00Z|http://arxiv.org/abs/1703.10960v1|http://arxiv.org/pdf/1703.10960v1|Learning Discourse-level Diversity for Neural Dialog Models using   Conditional Variational Autoencoders|learn discours level divers neural dialog model use condit variat autoencod|While recent neural encoder-decoder models have shown great promise in modeling open-domain conversations, they often generate dull and generic responses. Unlike past work that has focused on diversifying the output of the decoder at word-level to alleviate this problem, we present a novel framework based on conditional variational autoencoders that captures the discourse-level diversity in the encoder. Our model uses latent variables to learn a distribution over potential conversational intents and generates diverse responses using only greedy decoders. We have further developed a novel variant that is integrated with linguistic prior knowledge for better performance. Finally, the training procedure is improved by introducing a bag-of-word loss. Our proposed models have been validated to generate significantly more diverse responses than baseline approaches and exhibit competence in discourse-level decision-making.|recent neural encod decod model shown great promis model open domain convers often generat dull generic respons unlik past work focus diversifi output decod word level allevi problem present novel framework base condit variat autoencod captur discours level divers encod model use latent variabl learn distribut potenti convers intent generat divers respons use onli greedi decod develop novel variant integr linguist prior knowledg better perform final train procedur improv introduc bag word loss propos model valid generat signific divers respons baselin approach exhibit compet discours level decis make|['Tiancheng Zhao', 'Ran Zhao', 'Maxine Eskenazi']|['cs.CL', 'cs.AI']
2017-04-07T11:27:26Z|2017-03-31T15:05:45Z|http://arxiv.org/abs/1703.10931v1|http://arxiv.org/pdf/1703.10931v1|Sentence Simplification with Deep Reinforcement Learning|sentenc simplif deep reinforc learn|Sentence simplification aims to make sentences easier to read and understand. Most recent approaches draw on insights from machine translation to learn simplification rewrites from monolingual corpora of complex and simple sentences. We address the simplification problem with an encoder-decoder model coupled with a deep reinforcement learning framework. Our model explores the space of possible simplifications while learning to optimize a reward function that encourages outputs which are simple, fluent, and preserve the meaning of the input. Experiments on three datasets demonstrate that our model brings significant improvements over the state of the art.|sentenc simplif aim make sentenc easier read understand recent approach draw insight machin translat learn simplif rewrit monolingu corpora complex simpl sentenc address simplif problem encod decod model coupl deep reinforc learn framework model explor space possibl simplif learn optim reward function encourag output simpl fluent preserv mean input experi three dataset demonstr model bring signific improv state art|['Xingxing Zhang', 'Mirella Lapata']|['cs.CL', 'cs.LG']
2017-04-07T11:27:32Z|2017-03-31T07:10:30Z|http://arxiv.org/abs/1703.10772v1|http://arxiv.org/pdf/1703.10772v1|Joining Hands: Exploiting Monolingual Treebanks for Parsing of   Code-mixing Data|join hand exploit monolingu treebank pars code mix data|In this paper, we propose efficient and less resource-intensive strategies for parsing of code-mixed data. These strategies are not constrained by in-domain annotations, rather they leverage pre-existing monolingual annotated resources for training. We show that these methods can produce significantly better results as compared to an informed baseline. Besides, we also present a data set of 450 Hindi and English code-mixed tweets of Hindi multilingual speakers for evaluation. The data set is manually annotated with Universal Dependencies.|paper propos effici less resourc intens strategi pars code mix data strategi constrain domain annot rather leverag pre exist monolingu annot resourc train show method produc signific better result compar inform baselin besid also present data set hindi english code mix tweet hindi multilingu speaker evalu data set manual annot univers depend|['Irshad Ahmad Bhat', 'Riyaz Ahmad Bhat', 'Manish Shrivastava', 'Dipti Misra Sharma']|['cs.CL']
2017-04-07T11:27:32Z|2017-03-31T01:21:40Z|http://arxiv.org/abs/1703.10724v1|http://arxiv.org/pdf/1703.10724v1|N-gram Language Modeling using Recurrent Neural Network Estimation|gram languag model use recurr neural network estim|We investigate the effective memory depth of RNN models by using them for n-gram language model (LM) smoothing.   Experiments on a small corpus (UPenn Treebank, one million words of training data and 10k vocabulary) have found the LSTM cell with dropout to be the best model for encoding the n-gram state when compared with feed-forward and vanilla RNN models.   When preserving the sentence independence assumption the LSTM n-gram matches the LSTM LM performance for n=9 and slightly outperforms it for n=13. When allowing dependencies across sentence boundaries, the LSTM 13-gram almost matches the perplexity of the unlimited history LSTM LM.   LSTM n-gram smoothing also has the desirable property of improving with increasing n-gram order, unlike the Katz or Kneser-Ney back-off estimators. Using multinomial distributions as targets in training instead of the usual one-hot target is only slightly beneficial for low n-gram orders.   Experiments on the One Billion Words benchmark show that the results hold at larger scale.   Building LSTM n-gram LMs may be appealing for some practical situations: the state in a n-gram LM can be succinctly represented with (n-1)*4 bytes storing the identity of the words in the context and batches of n-gram contexts can be processed in parallel. On the downside, the n-gram context encoding computed by the LSTM is discarded, making the model more expensive than a regular recurrent LSTM LM.|investig effect memori depth rnn model use gram languag model lm smooth experi small corpus upenn treebank one million word train data vocabulari found lstm cell dropout best model encod gram state compar feed forward vanilla rnn model preserv sentenc independ assumpt lstm gram match lstm lm perform slight outperform allow depend across sentenc boundari lstm gram almost match perplex unlimit histori lstm lm lstm gram smooth also desir properti improv increas gram order unlik katz kneser ney back estim use multinomi distribut target train instead usual one hot target onli slight benefici low gram order experi one billion word benchmark show result hold larger scale build lstm gram lms may appeal practic situat state gram lm succinct repres byte store ident word context batch gram context process parallel downsid gram context encod comput lstm discard make model expens regular recurr lstm lm|['Ciprian Chelba', 'Mohammad Norouzi', 'Samy Bengio']|['cs.CL']
2017-04-07T11:27:32Z|2017-03-31T00:50:37Z|http://arxiv.org/abs/1703.10722v1|http://arxiv.org/pdf/1703.10722v1|Factorization tricks for LSTM networks|factor trick lstm network|"We present two simple ways of reducing the number of parameters and accelerating the training of large Long Short-Term Memory (LSTM) networks: the first one is ""matrix factorization by design"" of LSTM matrix into the product of two smaller matrices, and the second one is partitioning of LSTM matrix, its inputs and states into the independent groups. Both approaches allow us to train large LSTM networks significantly faster to the state-of the art perplexity. On the One Billion Word Benchmark we improve single model perplexity down to 24.29."|present two simpl way reduc number paramet acceler train larg long short term memori lstm network first one matrix factor design lstm matrix product two smaller matric second one partit lstm matrix input state independ group approach allow us train larg lstm network signific faster state art perplex one billion word benchmark improv singl model perplex|['Oleksii Kuchaiev', 'Boris Ginsburg']|['cs.CL', 'cs.NE', 'stat.ML']
2017-04-07T11:27:32Z|2017-03-30T21:57:37Z|http://arxiv.org/abs/1703.10698v1|http://arxiv.org/pdf/1703.10698v1|Neutral evolution and turnover over centuries of English word popularity|neutral evolut turnov centuri english word popular|Here we test Neutral models against the evolution of English word frequency and vocabulary at the population scale, as recorded in annual word frequencies from three centuries of English language books. Against these data, we test both static and dynamic predictions of two neutral models, including the relation between corpus size and vocabulary size, frequency distributions, and turnover within those frequency distributions. Although a commonly used Neutral model fails to replicate all these emergent properties at once, we find that modified two-stage Neutral model does replicate the static and dynamic properties of the corpus data. This two-stage model is meant to represent a relatively small corpus (population) of English books, analogous to a `canon', sampled by an exponentially increasing corpus of books in the wider population of authors. More broadly, this mode -- a smaller neutral model within a larger neutral model -- could represent more broadly those situations where mass attention is focused on a small subset of the cultural variants.|test neutral model evolut english word frequenc vocabulari popul scale record annual word frequenc three centuri english languag book data test static dynam predict two neutral model includ relat corpus size vocabulari size frequenc distribut turnov within frequenc distribut although common use neutral model fail replic emerg properti onc find modifi two stage neutral model doe replic static dynam properti corpus data two stage model meant repres relat small corpus popul english book analog canon sampl exponenti increas corpus book wider popul author broad mode smaller neutral model within larger neutral model could repres broad situat mass attent focus small subset cultur variant|['Damian Ruck', 'R. Alexander Bentley', 'Alberto Acerbi', 'Philip Garnett', 'Daniel J. Hruschka']|['cs.CL', 'physics.soc-ph']
2017-04-07T11:27:32Z|2017-03-30T13:54:51Z|http://arxiv.org/abs/1703.10476v1|http://arxiv.org/pdf/1703.10476v1|Speaking the Same Language: Matching Machine to Human Captions by   Adversarial Training|speak languag match machin human caption adversari train|While strong progress has been made in image captioning over the last years, machine and human captions are still quite distinct. A closer look reveals that this is due to the deficiencies in the generated word distribution, vocabulary size, and strong bias in the generators towards frequent captions. Furthermore, humans -- rightfully so -- generate multiple, diverse captions, due to the inherent ambiguity in the captioning task which is not considered in today's systems.   To address these challenges, we change the training objective of the caption generator from reproducing groundtruth captions to generating a set of captions that is indistinguishable from human generated captions. Instead of handcrafting such a learning target, we employ adversarial training in combination with an approximate Gumbel sampler to implicitly match the generated distribution to the human one. While our method achieves comparable performance to the state-of-the-art in terms of the correctness of the captions, we generate a set of diverse captions, that are significantly less biased and match the word statistics better in several aspects.|strong progress made imag caption last year machin human caption still quit distinct closer look reveal due defici generat word distribut vocabulari size strong bias generat toward frequent caption furthermor human right generat multipl divers caption due inher ambigu caption task consid today system address challeng chang train object caption generat reproduc groundtruth caption generat set caption indistinguish human generat caption instead handcraft learn target employ adversari train combin approxim gumbel sampler implicit match generat distribut human one method achiev compar perform state art term correct caption generat set divers caption signific less bias match word statist better sever aspect|['Rakshith Shetty', 'Marcus Rohrbach', 'Lisa Anne Hendricks', 'Mario Fritz', 'Bernt Schiele']|['cs.CV', 'cs.AI', 'cs.CL']
2017-04-07T11:27:32Z|2017-03-30T08:40:19Z|http://arxiv.org/abs/1703.10356v1|http://arxiv.org/pdf/1703.10356v1|End-to-End MAP Training of a Hybrid HMM-DNN Model|end end map train hybrid hmm dnn model|An hybrid of a hidden Markov model (HMM) and a deep neural network (DNN) is considered. End-to-end training using gradient descent is suggested, similarly to the training of connectionist temporal classification (CTC). We use a maximum a-posteriori (MAP) criterion with a simple language model in the training stage, and a standard HMM decoder without approximations. Recognition results are presented using speech databases. Our method compares favorably to CTC in terms of performance, robustness and quality of alignments.|hybrid hidden markov model hmm deep neural network dnn consid end end train use gradient descent suggest similar train connectionist tempor classif ctc use maximum posteriori map criterion simpl languag model train stage standard hmm decod without approxim recognit result present use speech databas method compar favor ctc term perform robust qualiti align|['Lior Fritz', 'David Burshtein']|['cs.LG', 'cs.CL', 'cs.NE']
2017-04-07T11:27:32Z|2017-03-30T07:56:42Z|http://arxiv.org/abs/1703.10344v1|http://arxiv.org/abs/1703.10344v1|Automated News Suggestions for Populating Wikipedia Entity Pages|autom news suggest popul wikipedia entiti page|Wikipedia entity pages are a valuable source of information for direct consumption and for knowledge-base construction, update and maintenance. Facts in these entity pages are typically supported by references. Recent studies show that as much as 20\% of the references are from online news sources. However, many entity pages are incomplete even if relevant information is already available in existing news articles. Even for the already present references, there is often a delay between the news article publication time and the reference time. In this work, we therefore look at Wikipedia through the lens of news and propose a novel news-article suggestion task to improve news coverage in Wikipedia, and reduce the lag of newsworthy references. Our work finds direct application, as a precursor, to Wikipedia page generation and knowledge-base acceleration tasks that rely on relevant and high quality input sources.   We propose a two-stage supervised approach for suggesting news articles to entity pages for a given state of Wikipedia. First, we suggest news articles to Wikipedia entities (article-entity placement) relying on a rich set of features which take into account the \emph{salience} and \emph{relative authority} of entities, and the \emph{novelty} of news articles to entity pages. Second, we determine the exact section in the entity page for the input article (article-section placement) guided by class-based section templates. We perform an extensive evaluation of our approach based on ground-truth data that is extracted from external references in Wikipedia. We achieve a high precision value of up to 93\% in the \emph{article-entity} suggestion stage and upto 84\% for the \emph{article-section placement}. Finally, we compare our approach against competitive baselines and show significant improvements.|wikipedia entiti page valuabl sourc inform direct consumpt knowledg base construct updat mainten fact entiti page typic support refer recent studi show much refer onlin news sourc howev mani entiti page incomplet even relev inform alreadi avail exist news articl even alreadi present refer often delay news articl public time refer time work therefor look wikipedia len news propos novel news articl suggest task improv news coverag wikipedia reduc lag newsworthi refer work find direct applic precursor wikipedia page generat knowledg base acceler task reli relev high qualiti input sourc propos two stage supervis approach suggest news articl entiti page given state wikipedia first suggest news articl wikipedia entiti articl entiti placement reli rich set featur take account emph salienc emph relat author entiti emph novelti news articl entiti page second determin exact section entiti page input articl articl section placement guid class base section templat perform extens evalu approach base ground truth data extract extern refer wikipedia achiev high precis valu emph articl entiti suggest stage upto emph articl section placement final compar approach competit baselin show signific improv|['Besnik Fetahu', 'Katja Markert', 'Avishek Anand']|['cs.IR', 'cs.CL', 'cs.SI']
2017-04-07T11:27:32Z|2017-03-30T07:48:31Z|http://arxiv.org/abs/1703.10339v1|http://arxiv.org/abs/1703.10339v1|Finding News Citations for Wikipedia|find news citat wikipedia|An important editing policy in Wikipedia is to provide citations for added statements in Wikipedia pages, where statements can be arbitrary pieces of text, ranging from a sentence to a paragraph. In many cases citations are either outdated or missing altogether.   In this work we address the problem of finding and updating news citations for statements in entity pages. We propose a two-stage supervised approach for this problem. In the first step, we construct a classifier to find out whether statements need a news citation or other kinds of citations (web, book, journal, etc.). In the second step, we develop a news citation algorithm for Wikipedia statements, which recommends appropriate citations from a given news collection. Apart from IR techniques that use the statement to query the news collection, we also formalize three properties of an appropriate citation, namely: (i) the citation should entail the Wikipedia statement, (ii) the statement should be central to the citation, and (iii) the citation should be from an authoritative source.   We perform an extensive evaluation of both steps, using 20 million articles from a real-world news collection. Our results are quite promising, and show that we can perform this task with high precision and at scale.|import edit polici wikipedia provid citat ad statement wikipedia page statement arbitrari piec text rang sentenc paragraph mani case citat either outdat miss altogeth work address problem find updat news citat statement entiti page propos two stage supervis approach problem first step construct classifi find whether statement need news citat kind citat web book journal etc second step develop news citat algorithm wikipedia statement recommend appropri citat given news collect apart ir techniqu use statement queri news collect also formal three properti appropri citat name citat entail wikipedia statement ii statement central citat iii citat authorit sourc perform extens evalu step use million articl real world news collect result quit promis show perform task high precis scale|['Besnik Fetahu', 'Katja Markert', 'Wolfgang Nejdl', 'Avishek Anand']|['cs.IR', 'cs.CL', 'cs.SI']
2017-04-07T11:27:32Z|2017-03-29T18:15:06Z|http://arxiv.org/abs/1703.10186v1|http://arxiv.org/pdf/1703.10186v1|Colors in Context: A Pragmatic Neural Model for Grounded Language   Understanding|color context pragmat neural model ground languag understand|We present a model of pragmatic referring expression interpretation in a grounded communication task (identifying colors from descriptions) that draws upon predictions from two recurrent neural network classifiers, a speaker and a listener, unified by a recursive pragmatic reasoning framework. Experiments show that this combined pragmatic model interprets color descriptions more accurately than the classifiers from which it is built. We observe that pragmatic reasoning helps primarily in the hardest cases: when the model must distinguish very similar colors, or when few utterances adequately express the target color. Our findings make use of a newly-collected corpus of human utterances in color reference games, which exhibit a variety of pragmatic behaviors. We also show that the embedded speaker model reproduces many of these pragmatic behaviors.|present model pragmat refer express interpret ground communic task identifi color descript draw upon predict two recurr neural network classifi speaker listen unifi recurs pragmat reason framework experi show combin pragmat model interpret color descript accur classifi built observ pragmat reason help primarili hardest case model must distinguish veri similar color utter adequ express target color find make use newli collect corpus human utter color refer game exhibit varieti pragmat behavior also show embed speaker model reproduc mani pragmat behavior|['Will Monroe', 'Robert X. D. Hawkins', 'Noah D. Goodman', 'Christopher Potts']|['cs.CL']
2017-04-07T11:27:32Z|2017-03-29T17:33:27Z|http://arxiv.org/abs/1703.10152v1|http://arxiv.org/pdf/1703.10152v1|Automatic Argumentative-Zoning Using Word2vec|automat argument zone use wordvec|In comparison with document summarization on the articles from social media and newswire, argumentative zoning (AZ) is an important task in scientific paper analysis. Traditional methodology to carry on this task relies on feature engineering from different levels. In this paper, three models of generating sentence vectors for the task of sentence classification were explored and compared. The proposed approach builds sentence representations using learned embeddings based on neural network. The learned word embeddings formed a feature space, to which the examined sentence is mapped to. Those features are input into the classifiers for supervised classification. Using 10-cross-validation scheme, evaluation was conducted on the Argumentative-Zoning (AZ) annotated articles. The results showed that simply averaging the word vectors in a sentence works better than the paragraph to vector algorithm and by integrating specific cuewords into the loss function of the neural network can improve the classification performance. In comparison with the hand-crafted features, the word2vec method won for most of the categories. However, the hand-crafted features showed their strength on classifying some of the categories.|comparison document summar articl social media newswir argument zone az import task scientif paper analysi tradit methodolog carri task reli featur engin differ level paper three model generat sentenc vector task sentenc classif explor compar propos approach build sentenc represent use learn embed base neural network learn word embed form featur space examin sentenc map featur input classifi supervis classif use cross valid scheme evalu conduct argument zone az annot articl result show simpli averag word vector sentenc work better paragraph vector algorithm integr specif cueword loss function neural network improv classif perform comparison hand craft featur wordvec method categori howev hand craft featur show strength classifi categori|['Haixia Liu']|['cs.CL']
2017-04-07T11:27:36Z|2017-03-29T16:55:13Z|http://arxiv.org/abs/1703.10135v1|http://arxiv.org/pdf/1703.10135v1|Tacotron: A Fully End-to-End Text-To-Speech Synthesis Model|tacotron fulli end end text speech synthesi model|A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. Building these components often requires extensive domain expertise and may contain brittle design choices. In this paper, we present Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters. Given <text, audio> pairs, the model can be trained completely from scratch with random initialization. We present several key techniques to make the sequence-to-sequence framework perform well for this challenging task. Tacotron achieves a 3.82 subjective 5-scale mean opinion score on US English, outperforming a production parametric system in terms of naturalness. In addition, since Tacotron generates speech at the frame level, it's substantially faster than sample-level autoregressive methods.|text speech synthesi system typic consist multipl stage text analysi frontend acoust model audio synthesi modul build compon often requir extens domain expertis may contain brittl design choic paper present tacotron end end generat text speech model synthes speech direct charact given text audio pair model train complet scratch random initi present sever key techniqu make sequenc sequenc framework perform well challeng task tacotron achiev subject scale mean opinion score us english outperform product parametr system term natur addit sinc tacotron generat speech frame level substanti faster sampl level autoregress method|['Yuxuan Wang', 'RJ Skerry-Ryan', 'Daisy Stanton', 'Yonghui Wu', 'Ron J. Weiss', 'Navdeep Jaitly', 'Zongheng Yang', 'Ying Xiao', 'Zhifeng Chen', 'Samy Bengio', 'Quoc Le', 'Yannis Agiomyrgiannakis', 'Rob Clark', 'Rif A. Saurous']|['cs.CL', 'cs.LG', 'cs.SD']
2017-04-07T11:27:36Z|2017-03-29T15:12:10Z|http://arxiv.org/abs/1703.10090v1|http://arxiv.org/pdf/1703.10090v1|A Short Review of Ethical Challenges in Clinical Natural Language   Processing|short review ethic challeng clinic natur languag process|Clinical NLP has an immense potential in contributing to how clinical practice will be revolutionized by the advent of large scale processing of clinical records. However, this potential has remained largely untapped due to slow progress primarily caused by strict data access policies for researchers. In this paper, we discuss the concern for privacy and the measures it entails. We also suggest sources of less sensitive data. Finally, we draw attention to biases that can compromise the validity of empirical research and lead to socially harmful applications.|clinic nlp immens potenti contribut clinic practic revolution advent larg scale process clinic record howev potenti remain larg untap due slow progress primarili caus strict data access polici research paper discuss concern privaci measur entail also suggest sourc less sensit data final draw attent bias compromis valid empir research lead social harm applic|['Simon Šuster', 'Stéphan Tulkens', 'Walter Daelemans']|['cs.CL', 'cs.CY']
2017-04-07T11:27:36Z|2017-03-29T14:26:13Z|http://arxiv.org/abs/1703.10065v1|http://arxiv.org/pdf/1703.10065v1|Hierarchical Classification for Spoken Arabic Dialect Identification   using Prosody: Case of Algerian Dialects|hierarch classif spoken arab dialect identif use prosodi case algerian dialect|In daily communications, Arabs use local dialects which are hard to identify automatically using conventional classification methods. The dialect identification challenging task becomes more complicated when dealing with an under-resourced dialects belonging to a same county/region. In this paper, we start by analyzing statistically Algerian dialects in order to capture their specificities related to prosody information which are extracted at utterance level after a coarse-grained consonant/vowel segmentation. According to these analysis findings, we propose a Hierarchical classification approach for spoken Arabic algerian Dialect IDentification (HADID). It takes advantage from the fact that dialects have an inherent property of naturally structured into hierarchy. Within HADID, a top-down hierarchical classification is applied, in which we use Deep Neural Networks (DNNs) method to build a local classifier for every parent node into the hierarchy dialect structure. Our framework is implemented and evaluated on Algerian Arabic dialects corpus. Whereas, the hierarchy dialect structure is deduced from historic and linguistic knowledges. The results reveal that within {\HD}, the best classifier is DNNs compared to Support Vector Machine. In addition, compared with a baseline Flat classification system, our HADID gives an improvement of 63.5% in term of precision. Furthermore, overall results evidence the suitability of our prosody-based HADID for speaker independent dialect identification while requiring less than 6s test utterances.|daili communic arab use local dialect hard identifi automat use convent classif method dialect identif challeng task becom complic deal resourc dialect belong counti region paper start analyz statist algerian dialect order captur specif relat prosodi inform extract utter level coars grain conson vowel segment accord analysi find propos hierarch classif approach spoken arab algerian dialect identif hadid take advantag fact dialect inher properti natur structur hierarchi within hadid top hierarch classif appli use deep neural network dnns method build local classifi everi parent node hierarchi dialect structur framework implement evalu algerian arab dialect corpus wherea hierarchi dialect structur deduc histor linguist knowledg result reveal within hd best classifi dnns compar support vector machin addit compar baselin flat classif system hadid give improv term precis furthermor overal result evid suitabl prosodi base hadid speaker independ dialect identif requir less test utter|['Soumia Bougrine', 'Hadda Cherroun', 'Djelloul Ziadi']|['cs.CL']
2017-04-07T11:27:36Z|2017-03-29T06:51:00Z|http://arxiv.org/abs/1703.09902v1|http://arxiv.org/pdf/1703.09902v1|Survey of the State of the Art in Natural Language Generation: Core   tasks, applications and evaluation|survey state art natur languag generat core task applic evalu|This paper surveys the current state of the art in Natural Language Generation (NLG), defined as the task of generating text or speech from non-linguistic input. A survey of NLG is timely in view of the changes that the field has undergone over the past decade or so, especially in relation to new (usually data-driven) methods, as well as new applications of NLG technology. This survey therefore aims to (a) give an up-to-date synthesis of research on the core tasks in NLG and the architectures adopted in which such tasks are organised; (b) highlight a number of relatively recent research topics that have arisen partly as a result of growing synergies between NLG and other areas of artificial intelligence; (c) draw attention to the challenges in NLG evaluation, relating them to similar challenges faced in other areas of Natural Language Processing, with an emphasis on different evaluation methods and the relationships between them.|paper survey current state art natur languag generat nlg defin task generat text speech non linguist input survey nlg time view chang field undergon past decad especi relat new usual data driven method well new applic nlg technolog survey therefor aim give date synthesi research core task nlg architectur adopt task organis highlight number relat recent research topic arisen part result grow synergi nlg area artifici intellig draw attent challeng nlg evalu relat similar challeng face area natur languag process emphasi differ evalu method relationship|['Albert Gatt', 'Emiel Krahmer']|['cs.CL', 'cs.AI', 'cs.NE', 'I.2.7; H.5']
2017-04-07T11:27:36Z|2017-03-28T22:29:53Z|http://arxiv.org/abs/1703.09831v1|http://arxiv.org/pdf/1703.09831v1|A Deep Compositional Framework for Human-like Language Acquisition in   Virtual Environment|deep composit framework human like languag acquisit virtual environ|We tackle a task where an agent learns to navigate in a 2D maze-like environment called XWORLD. In each session, the agent perceives a sequence of raw-pixel frames, a natural language command issued by a teacher, and a set of rewards. The agent learns the teacher's language from scratch in a grounded and compositional manner, such that after training it is able to correctly execute zero-shot commands: 1) the combination of words in the command never appeared before, and/or 2) the command contains new object concepts that are learned from another task but never learned from navigation. Our deep framework for the agent is trained end to end: it learns simultaneously the visual representations of the environment, the syntax and semantics of the language, and the action module that outputs actions. The zero-shot learning capability of our framework results from its compositionality and modularity with parameter tying. We visualize the intermediate outputs of the framework, demonstrating that the agent truly understands how to solve the problem. We believe that our results provide some preliminary insights on how to train an agent with similar abilities in a 3D environment.|tackl task agent learn navig maze like environ call xworld session agent perceiv sequenc raw pixel frame natur languag command issu teacher set reward agent learn teacher languag scratch ground composit manner train abl correct execut zero shot command combin word command never appear befor command contain new object concept learn anoth task never learn navig deep framework agent train end end learn simultan visual represent environ syntax semant languag action modul output action zero shot learn capabl framework result composit modular paramet tie visual intermedi output framework demonstr agent truli understand solv problem believ result provid preliminari insight train agent similar abil environ|['Haonan Yu', 'Haichao Zhang', 'Wei Xu']|['cs.CL', 'cs.LG']
2017-04-07T11:27:36Z|2017-03-28T22:05:20Z|http://arxiv.org/abs/1703.09825v1|http://arxiv.org/pdf/1703.09825v1|Semi-Supervised Affective Meaning Lexicon Expansion Using Semantic and   Distributed Word Representations|semi supervis affect mean lexicon expans use semant distribut word represent|In this paper, we propose an extension to graph-based sentiment lexicon induction methods by incorporating distributed and semantic word representations in building the similarity graph to expand a three-dimensional sentiment lexicon. We also implemented and evaluated the label propagation using four different word representations and similarity metrics. Our comprehensive evaluation of the four approaches was performed on a single data set, demonstrating that all four methods can generate a significant number of new sentiment assignments with high accuracy. The highest correlations (tau=0.51) and the lowest error (mean absolute error < 1.1%), obtained by combining both the semantic and the distributional features, outperformed the distributional-based and semantic-based label-propagation models and approached a supervised algorithm.|paper propos extens graph base sentiment lexicon induct method incorpor distribut semant word represent build similar graph expand three dimension sentiment lexicon also implement evalu label propag use four differ word represent similar metric comprehens evalu four approach perform singl data set demonstr four method generat signific number new sentiment assign high accuraci highest correl tau lowest error mean absolut error obtain combin semant distribut featur outperform distribut base semant base label propag model approach supervis algorithm|['Areej Alhothali', 'Jesse Hoey']|['cs.CL']
2017-04-07T11:27:36Z|2017-03-28T21:47:16Z|http://arxiv.org/abs/1703.09817v1|http://arxiv.org/pdf/1703.09817v1|Learning Similarity Function for Pronunciation Variations|learn similar function pronunci variat|A significant source of errors in Automatic Speech Recognition (ASR) systems is due to pronunciation variations which occur in spontaneous and conversational speech. Usually ASR systems use a finite lexicon that provides one or more pronunciations for each word. In this paper, we focus on learning a similarity function between two pronunciations. The pronunciation can be the canonical and the surface pronunciations of the same word or it can be two surface pronunciations of different words. This task generalizes problems such as lexical access (the problem of learning the mapping between words and their possible pronunciations), and defining word neighborhoods. It can also be used to dynamically increase the size of the pronunciation lexicon, or in predicting ASR errors. We propose two methods, which are based on recurrent neural networks, to learn the similarity function. The first is based on binary classification, and the second is based on learning the ranking of the pronunciations. We demonstrate the efficiency of our approach on the task of lexical access using a subset from the Switchboard conversational speech corpus. Results suggest that our method is superior to previous methods which are based on graphical Bayesian methods.|signific sourc error automat speech recognit asr system due pronunci variat occur spontan convers speech usual asr system use finit lexicon provid one pronunci word paper focus learn similar function two pronunci pronunci canon surfac pronunci word two surfac pronunci differ word task general problem lexic access problem learn map word possibl pronunci defin word neighborhood also use dynam increas size pronunci lexicon predict asr error propos two method base recurr neural network learn similar function first base binari classif second base learn rank pronunci demonstr effici approach task lexic access use subset switchboard convers speech corpus result suggest method superior previous method base graphic bayesian method|['Einat Naaman', 'Yossi Adi', 'Joseph Keshet']|['cs.CL']
2017-04-07T11:27:36Z|2017-03-28T17:48:07Z|http://arxiv.org/abs/1703.09684v1|http://arxiv.org/pdf/1703.09684v1|An Analysis of Visual Question Answering Algorithms|analysi visual question answer algorithm|In visual question answering (VQA), an algorithm must answer text-based questions about images. While multiple datasets for VQA have been created since late 2014, they all have flaws in both their content and the way algorithms are evaluated on them. As a result, evaluation scores are inflated and predominantly determined by answering easier questions, making it difficult to compare different methods. In this paper, we analyze existing VQA algorithms using a new dataset. It contains over 1.6 million questions organized into 12 different categories. We also introduce questions that are meaningless for a given image to force a VQA system to reason about image content. We propose new evaluation schemes that compensate for over-represented question-types and make it easier to study the strengths and weaknesses of algorithms. We analyze the performance of both baseline and state-of-the-art VQA models, including multi-modal compact bilinear pooling (MCB), neural module networks, and recurrent answering units. Our experiments establish how attention helps certain categories more than others, determine which models work better than others, and explain how simple models (e.g. MLP) can surpass more complex models (MCB) by simply learning to answer large, easy question categories.|visual question answer vqa algorithm must answer text base question imag multipl dataset vqa creat sinc late flaw content way algorithm evalu result evalu score inflat predomin determin answer easier question make difficult compar differ method paper analyz exist vqa algorithm use new dataset contain million question organ differ categori also introduc question meaningless given imag forc vqa system reason imag content propos new evalu scheme compens repres question type make easier studi strength weak algorithm analyz perform baselin state art vqa model includ multi modal compact bilinear pool mcb neural modul network recurr answer unit experi establish attent help certain categori determin model work better explain simpl model mlp surpass complex model mcb simpli learn answer larg easi question categori|['Kushal Kafle', 'Christopher Kanan']|['cs.CV', 'cs.AI', 'cs.CL']
2017-04-07T11:27:36Z|2017-03-28T15:20:52Z|http://arxiv.org/abs/1703.10252v1|http://arxiv.org/pdf/1703.10252v1|Linguistic Matrix Theory|linguist matrix theori|Recent research in computational linguistics has developed algorithms which associate matrices with adjectives and verbs, based on the distribution of words in a corpus of text. These matrices are linear operators on a vector space of context words. They are used to construct the meaning of composite expressions from that of the elementary constituents, forming part of a compositional distributional approach to semantics. We propose a Matrix Theory approach to this data, based on permutation symmetry along with Gaussian weights and their perturbations. A simple Gaussian model is tested against word matrices created from a large corpus of text. We characterize the cubic and quartic departures from the model, which we propose, alongside the Gaussian parameters, as signatures for comparison of linguistic corpora. We propose that perturbed Gaussian models with permutation symmetry provide a promising framework for characterizing the nature of universality in the statistical properties of word matrices. The matrix theory framework developed here exploits the view of statistics as zero dimensional perturbative quantum field theory. It perceives language as a physical system realizing a universality class of matrix statistics characterized by permutation symmetry.|recent research comput linguist develop algorithm associ matric adject verb base distribut word corpus text matric linear oper vector space context word use construct mean composit express elementari constitu form part composit distribut approach semant propos matrix theori approach data base permut symmetri along gaussian weight perturb simpl gaussian model test word matric creat larg corpus text character cubic quartic departur model propos alongsid gaussian paramet signatur comparison linguist corpora propos perturb gaussian model permut symmetri provid promis framework character natur univers statist properti word matric matrix theori framework develop exploit view statist zero dimension perturb quantum field theori perceiv languag physic system realiz univers class matrix statist character permut symmetri|['Dimitrios Kartsaklis', 'Sanjaye Ramgoolam', 'Mehrnoosh Sadrzadeh']|['cs.CL', 'hep-th', 'math.CO']
2017-04-07T11:27:36Z|2017-03-28T12:08:46Z|http://arxiv.org/abs/1703.09527v1|http://arxiv.org/abs/1703.09527v1|Is This a Joke? Detecting Humor in Spanish Tweets|joke detect humor spanish tweet|While humor has been historically studied from a psychological, cognitive and linguistic standpoint, its study from a computational perspective is an area yet to be explored in Computational Linguistics. There exist some previous works, but a characterization of humor that allows its automatic recognition and generation is far from being specified. In this work we build a crowdsourced corpus of labeled tweets, annotated according to its humor value, letting the annotators subjectively decide which are humorous. A humor classifier for Spanish tweets is assembled based on supervised learning, reaching a precision of 84% and a recall of 69%.|humor histor studi psycholog cognit linguist standpoint studi comput perspect area yet explor comput linguist exist previous work character humor allow automat recognit generat far specifi work build crowdsourc corpus label tweet annot accord humor valu let annot subject decid humor humor classifi spanish tweet assembl base supervis learn reach precis recal|['Santiago Castro', 'Matías Cubero', 'Diego Garat', 'Guillermo Moncecchi']|['cs.CL', 'cs.AI']
2017-04-07T11:27:41Z|2017-03-28T07:47:27Z|http://arxiv.org/abs/1703.09439v1|http://arxiv.org/pdf/1703.09439v1|A practical approach to dialogue response generation in closed domains|practic approach dialogu respons generat close domain|We describe a prototype dialogue response generation model for the customer service domain at Amazon. The model, which is trained in a weakly supervised fashion, measures the similarity between customer questions and agent answers using a dual encoder network, a Siamese-like neural network architecture. Answer templates are extracted from embeddings derived from past agent answers, without turn-by-turn annotations. Responses to customer inquiries are generated by selecting the best template from the final set of templates. We show that, in a closed domain like customer service, the selected templates cover $>$70\% of past customer inquiries. Furthermore, the relevance of the model-selected templates is significantly higher than templates selected by a standard tf-idf baseline.|describ prototyp dialogu respons generat model custom servic domain amazon model train weak supervis fashion measur similar custom question agent answer use dual encod network siames like neural network architectur answer templat extract embed deriv past agent answer without turn turn annot respons custom inquiri generat select best templat final set templat show close domain like custom servic select templat cover past custom inquiri furthermor relev model select templat signific higher templat select standard tf idf baselin|['Yichao Lu', 'Phillip Keung', 'Shaonan Zhang', 'Jason Sun', 'Vikas Bhardwaj']|['cs.CL', 'cs.NE']
2017-04-07T11:27:41Z|2017-03-28T05:07:38Z|http://arxiv.org/abs/1703.09400v1|http://arxiv.org/pdf/1703.09400v1|Diving Deep into Clickbaits: Who Use Them to What Extents in Which   Topics with What Effects?|dive deep clickbait use extent topic effect|The use of alluring headlines (clickbait) to tempt the readers has become a growing practice nowadays. For the sake of existence in the highly competitive media industry, most of the on-line media including the mainstream ones, have started following this practice. Although the wide-spread practice of clickbait makes the reader's reliability on media vulnerable, a large scale analysis to reveal this fact is still absent. In this paper, we analyze 1.67 million Facebook posts created by 153 media organizations to understand the extent of clickbait practice, its impact and user engagement by using our own developed clickbait detection model. The model uses distributed sub-word embeddings learned from a large corpus. The accuracy of the model is 98.3%. Powered with this model, we further study the distribution of topics in clickbait and non-clickbait contents.|use allur headlin clickbait tempt reader becom grow practic nowaday sake exist high competit media industri line media includ mainstream one start follow practic although wide spread practic clickbait make reader reliabl media vulner larg scale analysi reveal fact still absent paper analyz million facebook post creat media organ understand extent clickbait practic impact user engag use develop clickbait detect model model use distribut sub word embed learn larg corpus accuraci model power model studi distribut topic clickbait non clickbait content|['Md Main Uddin Rony', 'Naeemul Hassan', 'Mohammad Yousuf']|['cs.SI', 'cs.CL']
2017-04-07T11:27:41Z|2017-03-28T04:47:11Z|http://arxiv.org/abs/1703.09398v1|http://arxiv.org/pdf/1703.09398v1|This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive   Content in Text Body, More Similar to Satire than Real News|fake news pack lot titl use simpler repetit content text bodi similar satir real news|The problem of fake news has gained a lot of attention as it is claimed to have had a significant impact on 2016 US Presidential Elections. Fake news is not a new problem and its spread in social networks is well-studied. Often an underlying assumption in fake news discussion is that it is written to look like real news, fooling the reader who does not check for reliability of the sources or the arguments in its content. Through a unique study of three data sets and features that capture the style and the language of articles, we show that this assumption is not true. Fake news in most cases is more similar to satire than to real news, leading us to conclude that persuasion in fake news is achieved through heuristics rather than the strength of arguments. We show overall title structure and the use of proper nouns in titles are very significant in differentiating fake from real. This leads us to conclude that fake news is targeted for audiences who are not likely to read beyond titles and is aimed at creating mental associations between entities and claims.|problem fake news gain lot attent claim signific impact us presidenti elect fake news new problem spread social network well studi often assumpt fake news discuss written look like real news fool reader doe check reliabl sourc argument content uniqu studi three data set featur captur style languag articl show assumpt true fake news case similar satir real news lead us conclud persuas fake news achiev heurist rather strength argument show overal titl structur use proper noun titl veri signific differenti fake real lead us conclud fake news target audienc like read beyond titl aim creat mental associ entiti claim|['Benjamin D. Horne', 'Sibel Adali']|['cs.SI', 'cs.CL']
2017-04-07T11:27:41Z|2017-03-27T15:13:49Z|http://arxiv.org/abs/1703.09137v1|http://arxiv.org/pdf/1703.09137v1|Where to put the Image in an Image Caption Generator|put imag imag caption generat|When a neural language model is used for caption generation, the image information can be fed to the neural network either by directly incorporating it in a recurrent neural network -- conditioning the language model by injecting image features -- or in a layer following the recurrent neural network -- conditioning the language model by merging the image features. While merging implies that visual features are bound at the end of the caption generation process, injecting can bind the visual features at a variety stages. In this paper we empirically show that late binding is superior to early binding in terms of different evaluation metrics. This suggests that the different modalities (visual and linguistic) for caption generation should not be jointly encoded by the RNN; rather, the multimodal integration should be delayed to a subsequent stage. Furthermore, this suggests that recurrent neural networks should not be viewed as actually generating text, but only as encoding it for prediction in a subsequent layer.|neural languag model use caption generat imag inform fed neural network either direct incorpor recurr neural network condit languag model inject imag featur layer follow recurr neural network condit languag model merg imag featur merg impli visual featur bound end caption generat process inject bind visual featur varieti stage paper empir show late bind superior earli bind term differ evalu metric suggest differ modal visual linguist caption generat joint encod rnn rather multimod integr delay subsequ stage furthermor suggest recurr neural network view actual generat text onli encod predict subsequ layer|['Marc Tanti', 'Albert Gatt', 'Kenneth P. Camilleri']|['cs.NE', 'cs.CL', 'cs.CV']
2017-04-07T11:27:41Z|2017-03-27T13:11:33Z|http://arxiv.org/abs/1703.09046v1|http://arxiv.org/pdf/1703.09046v1|Bootstrapping a Lexicon for Emotional Arousal in Software Engineering|bootstrap lexicon emot arous softwar engin|Emotional arousal increases activation and performance but may also lead to burnout in software development. We present the first version of a Software Engineering Arousal lexicon (SEA) that is specifically designed to address the problem of emotional arousal in the software developer ecosystem. SEA is built using a bootstrapping approach that combines word embedding model trained on issue-tracking data and manual scoring of items in the lexicon. We show that our lexicon is able to differentiate between issue priorities, which are a source of emotional activation and then act as a proxy for arousal. The best performance is obtained by combining SEA (428 words) with a previously created general purpose lexicon by Warriner et al. (13,915 words) and it achieves Cohen's d effect sizes up to 0.5.|emot arous increas activ perform may also lead burnout softwar develop present first version softwar engin arous lexicon sea specif design address problem emot arous softwar develop ecosystem sea built use bootstrap approach combin word embed model train issu track data manual score item lexicon show lexicon abl differenti issu prioriti sourc emot activ act proxi arous best perform obtain combin sea word previous creat general purpos lexicon warrin et al word achiev cohen effect size|['Mika V. Mäntylä', 'Nicole Novielli', 'Filippo Lanubile', 'Maëlick Claes', 'Miikka Kuutila']|['cs.SE', 'cs.CL']
2017-04-07T11:27:41Z|2017-03-27T11:15:58Z|http://arxiv.org/abs/1703.09013v1|http://arxiv.org/pdf/1703.09013v1|A Sentence Simplification System for Improving Relation Extraction|sentenc simplif system improv relat extract|In this demo paper, we present a text simplification approach that is directed at improving the performance of state-of-the-art Open Relation Extraction (RE) systems. As syntactically complex sentences often pose a challenge for current Open RE approaches, we have developed a simplification framework that performs a pre-processing step by taking a single sentence as input and using a set of syntactic-based transformation rules to create a textual input that is easier to process for subsequently applied Open RE systems.|demo paper present text simplif approach direct improv perform state art open relat extract system syntact complex sentenc often pose challeng current open approach develop simplif framework perform pre process step take singl sentenc input use set syntact base transform rule creat textual input easier process subsequ appli open system|['Christina Niklaus', 'Bernhard Bermeitinger', 'Siegfried Handschuh', 'André Freitas']|['cs.CL']
2017-04-07T11:27:41Z|2017-03-27T02:18:36Z|http://arxiv.org/abs/1703.09570v1|http://arxiv.org/pdf/1703.09570v1|A Tidy Data Model for Natural Language Processing using cleanNLP|tidi data model natur languag process use cleannlp|The package cleanNLP provides a set of fast tools for converting a textual corpus into a set of normalized tables. The underlying natural language processing pipeline utilizes Stanford's CoreNLP library, exposing a number of annotation tasks for text written in English, French, German, and Spanish. Annotators include tokenization, part of speech tagging, named entity recognition, entity linking, sentiment analysis, dependency parsing, coreference resolution, and information extraction.|packag cleannlp provid set fast tool convert textual corpus set normal tabl natur languag process pipelin util stanford corenlp librari expos number annot task text written english french german spanish annot includ token part speech tag name entiti recognit entiti link sentiment analysi depend pars corefer resolut inform extract|['Taylor Arnold']|['cs.CL', 'stat.CO']
2017-04-07T11:27:41Z|2017-03-26T23:48:06Z|http://arxiv.org/abs/1703.08885v1|http://arxiv.org/pdf/1703.08885v1|Question Answering from Unstructured Text by Retrieval and Comprehension|question answer unstructur text retriev comprehens|Open domain Question Answering (QA) systems must interact with external knowledge sources, such as web pages, to find relevant information. Information sources like Wikipedia, however, are not well structured and difficult to utilize in comparison with Knowledge Bases (KBs). In this work we present a two-step approach to question answering from unstructured text, consisting of a retrieval step and a comprehension step. For comprehension, we present an RNN based attention model with a novel mixture mechanism for selecting answers from either retrieved articles or a fixed vocabulary. For retrieval we introduce a hand-crafted model and a neural model for ranking relevant articles. We achieve state-of-the-art performance on W IKI M OVIES dataset, reducing the error by 40%. Our experimental results further demonstrate the importance of each of the introduced components.|open domain question answer qa system must interact extern knowledg sourc web page find relev inform inform sourc like wikipedia howev well structur difficult util comparison knowledg base kbs work present two step approach question answer unstructur text consist retriev step comprehens step comprehens present rnn base attent model novel mixtur mechan select answer either retriev articl fix vocabulari retriev introduc hand craft model neural model rank relev articl achiev state art perform iki ovi dataset reduc error experiment result demonstr import introduc compon|['Yusuke Watanabe', 'Bhuwan Dhingra', 'Ruslan Salakhutdinov']|['cs.CL']
2017-04-07T11:27:41Z|2017-03-26T20:02:44Z|http://arxiv.org/abs/1703.08864v1|http://arxiv.org/pdf/1703.08864v1|Learning Simpler Language Models with the Delta Recurrent Neural Network   Framework|learn simpler languag model delta recurr neural network framework|Learning useful information across long time lags is a critical and difficult problem for temporal neural models in tasks like language modeling. Existing architectures that address the issue are often complex and costly to train. The Delta Recurrent Neural Network (Delta-RNN) framework is a simple and high-performing design that unifies previously proposed gated neural models. The Delta-RNN models maintain longer-term memory by learning to interpolate between a fast-changing data-driven representation and a slowly changing, implicitly stable state. This requires hardly any more parameters than a classical simple recurrent network. The models outperform popular complex architectures, such as the Long Short Term Memory (LSTM) and the Gated Recurrent Unit (GRU) and achieve state-of-the art performance in language modeling at character and word levels and yield comparable performance at the subword level.|learn use inform across long time lag critic difficult problem tempor neural model task like languag model exist architectur address issu often complex cost train delta recurr neural network delta rnn framework simpl high perform design unifi previous propos gate neural model delta rnn model maintain longer term memori learn interpol fast chang data driven represent slowli chang implicit stabl state requir hard ani paramet classic simpl recurr network model outperform popular complex architectur long short term memori lstm gate recurr unit gru achiev state art perform languag model charact word level yield compar perform subword level|['Alexander G. Ororbia II', 'Tomas Mikolov', 'David Reitter']|['cs.CL']
2017-04-07T11:27:41Z|2017-03-26T00:30:38Z|http://arxiv.org/abs/1703.08748v1|http://arxiv.org/pdf/1703.08748v1|LEPOR: An Augmented Machine Translation Evaluation Metric|lepor augment machin translat evalu metric|Machine translation (MT) was developed as one of the hottest research topics in the natural language processing (NLP) literature. One important issue in MT is that how to evaluate the MT system reasonably and tell us whether the translation system makes an improvement or not. The traditional manual judgment methods are expensive, time-consuming, unrepeatable, and sometimes with low agreement. On the other hand, the popular automatic MT evaluation methods have some weaknesses. Firstly, they tend to perform well on the language pairs with English as the target language, but weak when English is used as source. Secondly, some methods rely on many additional linguistic features to achieve good performance, which makes the metric unable to replicate and apply to other language pairs easily. Thirdly, some popular metrics utilize incomprehensive factors, which result in low performance on some practical tasks. In this thesis, to address the existing problems, we design novel MT evaluation methods and investigate their performances on different languages. Firstly, we design augmented factors to yield highly accurate evaluation.Secondly, we design a tunable evaluation model where weighting of factors can be optimised according to the characteristics of languages. Thirdly, in the enhanced version of our methods, we design concise linguistic feature using POS to show that our methods can yield even higher performance when using some external linguistic resources. Finally, we introduce the practical performance of our metrics in the ACL-WMT workshop shared tasks, which show that the proposed methods are robust across different languages.|machin translat mt develop one hottest research topic natur languag process nlp literatur one import issu mt evalu mt system reason tell us whether translat system make improv tradit manual judgment method expens time consum unrepeat sometim low agreement hand popular automat mt evalu method weak first tend perform well languag pair english target languag weak english use sourc second method reli mani addit linguist featur achiev good perform make metric unabl replic appli languag pair easili third popular metric util incomprehens factor result low perform practic task thesi address exist problem design novel mt evalu method investig perform differ languag first design augment factor yield high accur evalu second design tunabl evalu model weight factor optimis accord characterist languag third enhanc version method design concis linguist featur use pos show method yield even higher perform use extern linguist resourc final introduc practic perform metric acl wmt workshop share task show propos method robust across differ languag|['Lifeng Han']|['cs.CL']
2017-04-07T11:27:45Z|2017-03-25T15:37:09Z|http://arxiv.org/abs/1703.08705v1|http://arxiv.org/pdf/1703.08705v1|Comparing Rule-Based and Deep Learning Models for Patient Phenotyping|compar rule base deep learn model patient phenotyp|Objective: We investigate whether deep learning techniques for natural language processing (NLP) can be used efficiently for patient phenotyping. Patient phenotyping is a classification task for determining whether a patient has a medical condition, and is a crucial part of secondary analysis of healthcare data. We assess the performance of deep learning algorithms and compare them with classical NLP approaches.   Materials and Methods: We compare convolutional neural networks (CNNs), n-gram models, and approaches based on cTAKES that extract pre-defined medical concepts from clinical notes and use them to predict patient phenotypes. The performance is tested on 10 different phenotyping tasks using 1,610 discharge summaries extracted from the MIMIC-III database.   Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The average F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our model having an F1-score up to 37 points higher than alternative approaches. We additionally assess the interpretability of our model by presenting a method that extracts the most salient phrases for a particular prediction.   Conclusion: We show that NLP methods based on deep learning improve the performance of patient phenotyping. Our CNN-based algorithm automatically learns the phrases associated with each patient phenotype. As such, it reduces the annotation complexity for clinical domain experts, who are normally required to develop task-specific annotation rules and identify relevant phrases. Our method performs well in terms of both performance and interpretability, which indicates that deep learning is an effective approach to patient phenotyping based on clinicians' notes.|object investig whether deep learn techniqu natur languag process nlp use effici patient phenotyp patient phenotyp classif task determin whether patient medic condit crucial part secondari analysi healthcar data assess perform deep learn algorithm compar classic nlp approach materi method compar convolut neural network cnns gram model approach base ctake extract pre defin medic concept clinic note use predict patient phenotyp perform test differ phenotyp task use discharg summari extract mimic iii databas result cnns outperform phenotyp algorithm task averag score model ppv sensit model score point higher altern approach addit assess interpret model present method extract salient phrase particular predict conclus show nlp method base deep learn improv perform patient phenotyp cnn base algorithm automat learn phrase associ patient phenotyp reduc annot complex clinic domain expert normal requir develop task specif annot rule identifi relev phrase method perform well term perform interpret indic deep learn effect approach patient phenotyp base clinician note|['Sebastian Gehrmann', 'Franck Dernoncourt', 'Yeran Li', 'Eric T. Carlson', 'Joy T. Wu', 'Jonathan Welt', 'John Foote Jr.', 'Edward T. Moseley', 'David W. Grant', 'Patrick D. Tyler', 'Leo Anthony Celi']|['cs.CL', 'cs.AI', 'cs.NE', 'stat.ML']
2017-04-07T11:27:45Z|2017-03-25T14:56:27Z|http://arxiv.org/abs/1703.08701v1|http://arxiv.org/pdf/1703.08701v1|Morphological Analysis for the Maltese Language: The Challenges of a   Hybrid System|morpholog analysi maltes languag challeng hybrid system|Maltese is a morphologically rich language with a hybrid morphological system which features both concatenative and non-concatenative processes. This paper analyses the impact of this hybridity on the performance of machine learning techniques for morphological labelling and clustering. In particular, we analyse a dataset of morphologically related word clusters to evaluate the difference in results for concatenative and nonconcatenative clusters. We also describe research carried out in morphological labelling, with a particular focus on the verb category. Two evaluations were carried out, one using an unseen dataset, and another one using a gold standard dataset which was manually labelled. The gold standard dataset was split into concatenative and non-concatenative to analyse the difference in results between the two morphological systems.|maltes morpholog rich languag hybrid morpholog system featur concaten non concaten process paper analys impact hybrid perform machin learn techniqu morpholog label cluster particular analys dataset morpholog relat word cluster evalu differ result concaten nonconcaten cluster also describ research carri morpholog label particular focus verb categori two evalu carri one use unseen dataset anoth one use gold standard dataset manual label gold standard dataset split concaten non concaten analys differ result two morpholog system|['Claudia Borg', 'Albert Gatt']|['cs.CL', 'I.2.7']
2017-04-07T11:27:45Z|2017-03-25T04:25:21Z|http://arxiv.org/abs/1703.08646v1|http://arxiv.org/pdf/1703.08646v1|Simplifying the Bible and Wikipedia Using Statistical Machine   Translation|simplifi bibl wikipedia use statist machin translat|"I started this work with the hope of generating a text synthesizer (like a musical synthesizer) that can imitate certain linguistic styles. Most of the report focuses on text simplification using statistical machine translation (SMT) techniques. I applied MOSES to a parallel corpus of the Bible (King James Version and Easy-to-Read Version) and that of Wikipedia articles (normal and simplified). I report the importance of the three main components of SMT---phrase translation, language model, and recording---by changing their weights and comparing the resulting quality of simplified text in terms of METEOR and BLEU. Toward the end of the report will be presented some examples of text ""synthesized"" into the King James style."|start work hope generat text synthes like music synthes imit certain linguist style report focus text simplif use statist machin translat smt techniqu appli mose parallel corpus bibl king jame version easi read version wikipedia articl normal simplifi report import three main compon smt phrase translat languag model record chang weight compar result qualiti simplifi text term meteor bleu toward end report present exampl text synthes king jame style|['Yohan Jo']|['cs.CL']
2017-04-07T11:27:45Z|2017-03-24T19:45:24Z|http://arxiv.org/abs/1703.08581v1|http://arxiv.org/pdf/1703.08581v1|Sequence-to-Sequence Models Can Directly Transcribe Foreign Speech|sequenc sequenc model direct transcrib foreign speech|We present a recurrent encoder-decoder deep neural network architecture that directly translates speech in one language into text in another. The model does not explicitly transcribe the speech into text in the source language, nor does it require supervision from the ground truth source language transcription during training. We apply a slightly modified sequence-to-sequence with attention architecture that has previously been used for speech recognition and show that it can be repurposed for this more complex task, illustrating the power of attention-based models. A single model trained end-to-end obtains state-of-the-art performance on the Fisher Callhome Spanish-English speech translation task, outperforming a cascade of independently trained sequence-to-sequence speech recognition and machine translation models by 1.8 BLEU points on the Fisher test set. In addition, we find that making use of the training data in both languages by multi-task training sequence-to-sequence speech translation and recognition models with a shared encoder network can improve performance by a further 1.4 BLEU points.|present recurr encod decod deep neural network architectur direct translat speech one languag text anoth model doe explicit transcrib speech text sourc languag doe requir supervis ground truth sourc languag transcript dure train appli slight modifi sequenc sequenc attent architectur previous use speech recognit show repurpos complex task illustr power attent base model singl model train end end obtain state art perform fisher callhom spanish english speech translat task outperform cascad independ train sequenc sequenc speech recognit machin translat model bleu point fisher test set addit find make use train data languag multi task train sequenc sequenc speech translat recognit model share encod network improv perform bleu point|['Ron J. Weiss', 'Jan Chorowski', 'Navdeep Jaitly', 'Yonghui Wu', 'Zhifeng Chen']|['cs.CL', 'cs.LG', 'stat.ML']
2017-04-07T11:27:45Z|2017-03-24T17:55:33Z|http://arxiv.org/abs/1703.08537v1|http://arxiv.org/pdf/1703.08537v1|Crowdsourcing Universal Part-Of-Speech Tags for Code-Switching|crowdsourc univers part speech tag code switch|Code-switching is the phenomenon by which bilingual speakers switch between multiple languages during communication. The importance of developing language technologies for codeswitching data is immense, given the large populations that routinely code-switch. High-quality linguistic annotations are extremely valuable for any NLP task, and performance is often limited by the amount of high-quality labeled data. However, little such data exists for code-switching. In this paper, we describe crowd-sourcing universal part-of-speech tags for the Miami Bangor Corpus of Spanish-English code-switched speech. We split the annotation task into three subtasks: one in which a subset of tokens are labeled automatically, one in which questions are specifically designed to disambiguate a subset of high frequency words, and a more general cascaded approach for the remaining data in which questions are displayed to the worker following a decision tree structure. Each subtask is extended and adapted for a multilingual setting and the universal tagset. The quality of the annotation process is measured using hidden check questions annotated with gold labels. The overall agreement between gold standard labels and the majority vote is between 0.95 and 0.96 for just three labels and the average recall across part-of-speech tags is between 0.87 and 0.99, depending on the task.|code switch phenomenon bilingu speaker switch multipl languag dure communic import develop languag technolog codeswitch data immens given larg popul routin code switch high qualiti linguist annot extrem valuabl ani nlp task perform often limit amount high qualiti label data howev littl data exist code switch paper describ crowd sourc univers part speech tag miami bangor corpus spanish english code switch speech split annot task three subtask one subset token label automat one question specif design disambigu subset high frequenc word general cascad approach remain data question display worker follow decis tree structur subtask extend adapt multilingu set univers tagset qualiti annot process measur use hidden check question annot gold label overal agreement gold standard label major vote three label averag recal across part speech tag depend task|['Victor Soto', 'Julia Hirschberg']|['cs.CL']
2017-04-07T11:27:45Z|2017-03-24T17:13:08Z|http://arxiv.org/abs/1703.08513v1|http://arxiv.org/pdf/1703.08513v1|Interactive Natural Language Acquisition in a Multi-modal Recurrent   Neural Architecture|interact natur languag acquisit multi modal recurr neural architectur|The human brain is one of the most complex dynamic systems that enables us to communicate in natural language. We have a good understanding of some principles underlying natural languages and language processing, some knowledge about socio-cultural conditions framing acquisition, and some insights about where activity is occurring in the brain. However, we were not yet able to understand the behavioural and mechanistic characteristics for natural language and how mechanisms in the brain allow to acquire and process language.   In an effort to bridge the gap between insights from behavioural psychology and neuroscience, the goal of this paper is to contribute a computational understanding of the appropriate characteristics that favour language acquisition, in a brain-inspired neural architecture. Accordingly, we provide concepts and refinements in cognitive modelling regarding principles and mechanisms in the brain - such as the hierarchical abstraction of context - in a plausible recurrent architecture. On this basis, we propose neurocognitively plausible model for embodied language acquisition from real world interaction of a humanoid robot with its environment. The model is capable of learning language production grounded in both, temporal dynamic somatosensation and vision. In particular, the architecture consists of a continuous time recurrent neural network, where parts have different leakage characteristics and thus operate on multiple timescales for every modality and the association of the higher level nodes of all modalities into cell assemblies. Thus, this model features hierarchical concept abstraction in sensation as well as concept decomposition in production, multi-modal integration, and self-organisation of latent representations.|human brain one complex dynam system enabl us communic natur languag good understand principl natur languag languag process knowledg socio cultur condit frame acquisit insight activ occur brain howev yet abl understand behaviour mechanist characterist natur languag mechan brain allow acquir process languag effort bridg gap insight behaviour psycholog neurosci goal paper contribut comput understand appropri characterist favour languag acquisit brain inspir neural architectur accord provid concept refin cognit model regard principl mechan brain hierarch abstract context plausibl recurr architectur basi propos neurocognit plausibl model embodi languag acquisit real world interact humanoid robot environ model capabl learn languag product ground tempor dynam somatosens vision particular architectur consist continu time recurr neural network part differ leakag characterist thus oper multipl timescal everi modal associ higher level node modal cell assembl thus model featur hierarch concept abstract sensat well concept decomposit product multi modal integr self organis latent represent|['Stefan Heinrich', 'Stefan Wermter']|['cs.CL', 'q-bio.NC']
2017-04-07T11:27:45Z|2017-03-24T15:40:19Z|http://arxiv.org/abs/1703.08471v1|http://arxiv.org/pdf/1703.08471v1|Batch-normalized joint training for DNN-based distant speech recognition|batch normal joint train dnn base distant speech recognit|Improving distant speech recognition is a crucial step towards flexible human-machine interfaces. Current technology, however, still exhibits a lack of robustness, especially when adverse acoustic conditions are met. Despite the significant progress made in the last years on both speech enhancement and speech recognition, one potential limitation of state-of-the-art technology lies in composing modules that are not well matched because they are not trained jointly. To address this concern, a promising approach consists in concatenating a speech enhancement and a speech recognition deep neural network and to jointly update their parameters as if they were within a single bigger network. Unfortunately, joint training can be difficult because the output distribution of the speech enhancement system may change substantially during the optimization procedure. The speech recognition module would have to deal with an input distribution that is non-stationary and unnormalized. To mitigate this issue, we propose a joint training approach based on a fully batch-normalized architecture. Experiments, conducted using different datasets, tasks and acoustic conditions, revealed that the proposed framework significantly overtakes other competitive solutions, especially in challenging environments.|improv distant speech recognit crucial step toward flexibl human machin interfac current technolog howev still exhibit lack robust especi advers acoust condit met despit signific progress made last year speech enhanc speech recognit one potenti limit state art technolog lie compos modul well match becaus train joint address concern promis approach consist concaten speech enhanc speech recognit deep neural network joint updat paramet within singl bigger network unfortun joint train difficult becaus output distribut speech enhanc system may chang substanti dure optim procedur speech recognit modul would deal input distribut non stationari unnorm mitig issu propos joint train approach base fulli batch normal architectur experi conduct use differ dataset task acoust condit reveal propos framework signific overtak competit solut especi challeng environ|['Mirco Ravanelli', 'Philemon Brakel', 'Maurizio Omologo', 'Yoshua Bengio']|['cs.CL', 'cs.LG']
2017-04-07T11:27:45Z|2017-03-30T02:50:33Z|http://arxiv.org/abs/1703.08544v2|http://arxiv.org/pdf/1703.08544v2|Data-Mining Textual Responses to Uncover Misconception Patterns|data mine textual respons uncov misconcept pattern|An important, yet largely unstudied, problem in student data analysis is to detect misconceptions from students' responses to open-response questions. Misconception detection enables instructors to deliver more targeted feedback on the misconceptions exhibited by many students in their class, thus improving the quality of instruction. In this paper, we propose a new natural language processing-based framework to detect the common misconceptions among students' textual responses to short-answer questions. We propose a probabilistic model for students' textual responses involving misconceptions and experimentally validate it on a real-world student-response dataset. Experimental results show that our proposed framework excels at classifying whether a response exhibits one or more misconceptions. More importantly, it can also automatically detect the common misconceptions exhibited across responses from multiple students to multiple questions; this property is especially important at large scale, since instructors will no longer need to manually specify all possible misconceptions that students might exhibit.|import yet larg unstudi problem student data analysi detect misconcept student respons open respons question misconcept detect enabl instructor deliv target feedback misconcept exhibit mani student class thus improv qualiti instruct paper propos new natur languag process base framework detect common misconcept among student textual respons short answer question propos probabilist model student textual respons involv misconcept experiment valid real world student respons dataset experiment result show propos framework excel classifi whether respons exhibit one misconcept import also automat detect common misconcept exhibit across respons multipl student multipl question properti especi import larg scale sinc instructor longer need manual specifi possibl misconcept student might exhibit|['Joshua J. Michalenko', 'Andrew S. Lan', 'Richard G. Baraniuk']|['stat.ML', 'cs.CL']
2017-04-07T11:27:45Z|2017-03-24T14:40:31Z|http://arxiv.org/abs/1703.08428v1|http://arxiv.org/abs/1703.08428v1|Calendar.help: Designing a Workflow-Based Scheduling Agent with Humans   in the Loop|calendar help design workflow base schedul agent human loop|Although information workers may complain about meetings, they are an essential part of their work life. Consequently, busy people spend a significant amount of time scheduling meetings. We present Calendar.help, a system that provides fast, efficient scheduling through structured workflows. Users interact with the system via email, delegating their scheduling needs to the system as if it were a human personal assistant. Common scheduling scenarios are broken down using well-defined workflows and completed as a series of microtasks that are automated when possible and executed by a human otherwise. Unusual scenarios fall back to a trained human assistant who executes them as unstructured macrotasks. We describe the iterative approach we used to develop Calendar.help, and share the lessons learned from scheduling thousands of meetings during a year of real-world deployments. Our findings provide insight into how complex information tasks can be broken down into repeatable components that can be executed efficiently to improve productivity.|although inform worker may complain meet essenti part work life consequ busi peopl spend signific amount time schedul meet present calendar help system provid fast effici schedul structur workflow user interact system via email deleg schedul need system human person assist common schedul scenario broken use well defin workflow complet seri microtask autom possibl execut human otherwis unusu scenario fall back train human assist execut unstructur macrotask describ iter approach use develop calendar help share lesson learn schedul thousand meet dure year real world deploy find provid insight complex inform task broken repeat compon execut effici improv product|['Justin Cranshaw', 'Emad Elwany', 'Todd Newman', 'Rafal Kocielnik', 'Bowen Yu', 'Sandeep Soni', 'Jaime Teevan', 'Andrés Monroy-Hernández']|['cs.HC', 'cs.AI', 'cs.CL']
2017-04-07T11:27:45Z|2017-03-24T09:32:23Z|http://arxiv.org/abs/1703.08324v1|http://arxiv.org/pdf/1703.08324v1|Are crossing dependencies really scarce?|cross depend realli scarc|The syntactic structure of a sentence can be modelled as a tree, where vertices correspond to words and edges indicate syntactic dependencies. It has been claimed recurrently that the number of edge crossings in real sentences is small. However, a baseline or null hypothesis has been lacking. Here we quantify the amount of crossings of real sentences and compare it to the predictions of a series of baselines. We conclude that crossings are really scarce in real sentences. Their scarcity is unexpected by the hubiness of the trees. Indeed, real sentences are close to linear trees, where the potential number of crossings is maximized.|syntact structur sentenc model tree vertic correspond word edg indic syntact depend claim recurr number edg cross real sentenc small howev baselin null hypothesi lack quantifi amount cross real sentenc compar predict seri baselin conclud cross realli scarc real sentenc scarciti unexpect hubi tree inde real sentenc close linear tree potenti number cross maxim|['Ramon Ferrer-i-Cancho', 'Carlos Gomez-Rodriguez', 'J. L. Esteban']|['physics.soc-ph', 'cond-mat.stat-mech', 'cs.CL', 'physics.data-an']
2017-04-07T11:27:49Z|2017-03-24T08:46:48Z|http://arxiv.org/abs/1703.08314v1|http://arxiv.org/pdf/1703.08314v1|Interacting Conceptual Spaces I : Grammatical Composition of Concepts|interact conceptu space grammat composit concept|The categorical compositional approach to meaning has been successfully applied in natural language processing, outperforming other models in mainstream empirical language processing tasks. We show how this approach can be generalized to conceptual space models of cognition. In order to do this, first we introduce the category of convex relations as a new setting for categorical compositional semantics, emphasizing the convex structure important to conceptual space applications. We then show how to construct conceptual spaces for various types such as nouns, adjectives and verbs. Finally we show by means of examples how concepts can be systematically combined to establish the meanings of composite phrases from the meanings of their constituent parts. This provides the mathematical underpinnings of a new compositional approach to cognition.|categor composit approach mean success appli natur languag process outperform model mainstream empir languag process task show approach general conceptu space model cognit order first introduc categori convex relat new set categor composit semant emphas convex structur import conceptu space applic show construct conceptu space various type noun adject verb final show mean exampl concept systemat combin establish mean composit phrase mean constitu part provid mathemat underpin new composit approach cognit|['Joe Bolt', 'Bob Coecke', 'Fabrizio Genovese', 'Martha Lewis', 'Dan Marsden', 'Robin Piedeleu']|['cs.LO', 'cs.CL']
2017-04-07T11:27:49Z|2017-03-23T22:20:45Z|http://arxiv.org/abs/1703.08244v1|http://arxiv.org/pdf/1703.08244v1|TokTrack: A Complete Token Provenance and Change Tracking Dataset for   the English Wikipedia|toktrack complet token proven chang track dataset english wikipedia|We present a dataset that contains every instance of all tokens (~ words) ever written in undeleted, non-redirect English Wikipedia articles until October 2016, in total 13,545,349,787 instances. Each token is annotated with (i) the article revision it was originally created in, and (ii) lists with all the revisions in which the token was ever deleted and (potentially) re-added and re-deleted from its article, enabling a complete and straightforward tracking of its history. This data would be exceedingly hard to create by an average potential user as it is (i) very expensive to compute and as (ii) accurately tracking the history of each token in revisioned documents is a non-trivial task. Adapting a state-of-the-art algorithm, we have produced a dataset that allows for a range of analyses and metrics, already popular in research and going beyond, to be generated on complete-Wikipedia scale; ensuring quality and allowing researchers to forego expensive text-comparison computation, which so far has hindered scalable usage. We show how this data enables, on token-level, computation of provenance, measuring survival of content over time, very detailed conflict metrics, and fine-grained interactions of editors like partial reverts, re-additions and other metrics, in the process gaining several novel insights.|present dataset contain everi instanc token word ever written undelet non redirect english wikipedia articl octob total instanc token annot articl revis origin creat ii list revis token ever delet potenti ad delet articl enabl complet straightforward track histori data would exceed hard creat averag potenti user veri expens comput ii accur track histori token revis document non trivial task adapt state art algorithm produc dataset allow rang analys metric alreadi popular research go beyond generat complet wikipedia scale ensur qualiti allow research forego expens text comparison comput far hinder scalabl usag show data enabl token level comput proven measur surviv content time veri detail conflict metric fine grain interact editor like partial revert addit metric process gain sever novel insight|['Fabian Flöck', 'Kenan Erdogan', 'Maribel Acosta']|['cs.CL']
2017-04-07T11:27:49Z|2017-03-23T16:46:00Z|http://arxiv.org/abs/1703.08136v1|http://arxiv.org/pdf/1703.08136v1|Visually grounded learning of keyword prediction from untranscribed   speech|visual ground learn keyword predict untranscrib speech|"During language acquisition, infants have the benefit of visual cues to ground spoken language. Robots similarly have access to audio and visual sensors. Recent work has shown that images and spoken captions can be mapped into a meaningful common space, allowing images to be retrieved using speech and vice versa. In this setting of images paired with untranscribed spoken captions, we consider whether computer vision systems can be used to obtain textual labels for the speech. Concretely, we use an image-to-words multi-label visual classifier to tag images with soft textual labels, and then train a neural network to map from the speech to these soft targets. We show that the resulting speech system is able to predict which words occur in an utterance---acting as a spoken bag-of-words classifier---without seeing any parallel speech and text. We find that the model often confuses semantically related words, e.g. ""man"" and ""person"", making it even more effective as a semantic keyword spotter."|dure languag acquisit infant benefit visual cue ground spoken languag robot similar access audio visual sensor recent work shown imag spoken caption map meaning common space allow imag retriev use speech vice versa set imag pair untranscrib spoken caption consid whether comput vision system use obtain textual label speech concret use imag word multi label visual classifi tag imag soft textual label train neural network map speech soft target show result speech system abl predict word occur utter act spoken bag word classifi without see ani parallel speech text find model often confus semant relat word man person make even effect semant keyword spotter|['Herman Kamper', 'Shane Settle', 'Gregory Shakhnarovich', 'Karen Livescu']|['cs.CL', 'cs.CV']
2017-04-07T11:27:49Z|2017-03-23T16:45:22Z|http://arxiv.org/abs/1703.08135v1|http://arxiv.org/pdf/1703.08135v1|An embedded segmental k-means model for unsupervised segmentation and   clustering of speech|embed segment mean model unsupervis segment cluster speech|Unsupervised segmentation and clustering of unlabelled speech are core problems in zero-resource speech processing. Most competitive approaches lie at methodological extremes: some follow a Bayesian approach, defining probabilistic models with convergence guarantees, while others opt for more efficient heuristic techniques. Here we introduce an approximation to a segmental Bayesian model that falls in between, with a clear objective function but using hard clustering and segmentation rather than full Bayesian inference. Like its Bayesian counterpart, this embedded segmental k-means model (ES-KMeans) represents arbitrary-length word segments as fixed-dimensional acoustic word embeddings. On English and Xitsonga data, ES-KMeans outperforms a leading heuristic method in word segmentation, giving similar scores to the Bayesian model while being five times faster with fewer hyperparameters. However, there is a trade-off in cluster purity, with the Bayesian model's purer clusters yielding about 10% better unsupervised word error rates.|unsupervis segment cluster unlabel speech core problem zero resourc speech process competit approach lie methodolog extrem follow bayesian approach defin probabilist model converg guarante opt effici heurist techniqu introduc approxim segment bayesian model fall clear object function use hard cluster segment rather full bayesian infer like bayesian counterpart embed segment mean model es kmean repres arbitrari length word segment fix dimension acoust word embed english xitsonga data es kmean outperform lead heurist method word segment give similar score bayesian model five time faster fewer hyperparamet howev trade cluster puriti bayesian model purer cluster yield better unsupervis word error rate|['Herman Kamper', 'Karen Livescu', 'Sharon Goldwater']|['cs.CL', 'cs.LG']
2017-04-07T11:27:49Z|2017-03-23T15:57:23Z|http://arxiv.org/abs/1703.08120v1|http://arxiv.org/pdf/1703.08120v1|Recurrent and Contextual Models for Visual Question Answering|recurr contextu model visual question answer|We propose a series of recurrent and contextual neural network models for multiple choice visual question answering on the Visual7W dataset. Motivated by divergent trends in model complexities in the literature, we explore the balance between model expressiveness and simplicity by studying incrementally more complex architectures. We start with LSTM-encoding of input questions and answers; build on this with context generation by LSTM-encodings of neural image and question representations and attention over images; and evaluate the diversity and predictive power of our models and the ensemble thereof. All models are evaluated against a simple baseline inspired by the current state-of-the-art, consisting of involving simple concatenation of bag-of-words and CNN representations for the text and images, respectively. Generally, we observe marked variation in image-reasoning performance between our models not obvious from their overall performance, as well as evidence of dataset bias. Our standalone models achieve accuracies up to $64.6\%$, while the ensemble of all models achieves the best accuracy of $66.67\%$, within $0.5\%$ of the current state-of-the-art for Visual7W.|propos seri recurr contextu neural network model multipl choic visual question answer visualw dataset motiv diverg trend model complex literatur explor balanc model express simplic studi increment complex architectur start lstm encod input question answer build context generat lstm encod neural imag question represent attent imag evalu divers predict power model ensembl thereof model evalu simpl baselin inspir current state art consist involv simpl concaten bag word cnn represent text imag respect general observ mark variat imag reason perform model obvious overal perform well evid dataset bias standalon model achiev accuraci ensembl model achiev best accuraci within current state art visualw|['Abhijit Sharang', 'Eric Lau']|['cs.CL', 'cs.CV']
2017-04-07T11:27:49Z|2017-03-28T15:28:08Z|http://arxiv.org/abs/1703.08098v2|http://arxiv.org/pdf/1703.08098v2|An overview of embedding models of entities and relationships for   knowledge base completion|overview embed model entiti relationship knowledg base complet|Knowledge bases of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform knowledge base completion, i.e., predict whether a relationship not in the knowledge base is likely to be true. This article presents an overview of embedding models of entities and relationships for knowledge base completion, with up-to-date experimental results on two standard evaluation tasks of link prediction (i.e. entity prediction) and triple classification.|knowledg base real world fact entiti relationship use resourc varieti natur languag process task howev becaus knowledg base typic incomplet use abl perform knowledg base complet predict whether relationship knowledg base like true articl present overview embed model entiti relationship knowledg base complet date experiment result two standard evalu task link predict entiti predict tripl classif|['Dat Quoc Nguyen']|['cs.CL', 'cs.AI', 'cs.IR']
2017-04-07T11:27:49Z|2017-03-25T00:00:00Z|http://arxiv.org/abs/1703.08088v2|http://arxiv.org/abs/1703.08088v2|Rapid-Rate: A Framework for Semi-supervised Real-time Sentiment Trend   Detection in Unstructured Big Data|rapid rate framework semi supervis real time sentiment trend detect unstructur big data|Commercial establishments like restaurants, service centres and retailers have several sources of customer feedback about products and services, most of which need not be as structured as rated reviews provided by services like Yelp, or Amazon, in terms of sentiment conveyed. For instance, Amazon provides a fine-grained score on a numeric scale for product reviews. Some sources, however, like social media (Twitter, Facebook), mailing lists (Google Groups) and forums (Quora) contain text data that is much more voluminous, but unstructured and unlabelled. It might be in the best interests of a business establishment to assess the general sentiment towards their brand on these platforms as well. This text could be pipelined into a system with a built-in prediction model, with the objective of generating real-time graphs on opinion and sentiment trends. Although such tasks like the one described about have been explored with respect to document classification problems in the past, the implementation described in this paper, by virtue of learning a continuous function rather than a discrete one, offers a lot more depth of insight as compared to document classification approaches. This study aims to explore the validity of such a continuous function predicting model to quantify sentiment about an entity, without the additional overhead of manual labelling, and computational preprocessing & feature extraction. This research project also aims to design and implement a re-usable document regression pipeline as a framework, Rapid-Rate, that can be used to predict document scores in real-time.|commerci establish like restaur servic centr retail sever sourc custom feedback product servic need structur rate review provid servic like yelp amazon term sentiment convey instanc amazon provid fine grain score numer scale product review sourc howev like social media twitter facebook mail list googl group forum quora contain text data much volumin unstructur unlabel might best interest busi establish assess general sentiment toward brand platform well text could pipelin system built predict model object generat real time graph opinion sentiment trend although task like one describ explor respect document classif problem past implement describ paper virtu learn continu function rather discret one offer lot depth insight compar document classif approach studi aim explor valid continu function predict model quantifi sentiment entiti without addit overhead manual label comput preprocess featur extract research project also aim design implement usabl document regress pipelin framework rapid rate use predict document score real time|['Vineet John']|['cs.CL', '68T50']
2017-04-07T11:27:49Z|2017-03-23T14:20:52Z|http://arxiv.org/abs/1703.08084v1|http://arxiv.org/pdf/1703.08084v1|Multimodal Compact Bilinear Pooling for Multimodal Neural Machine   Translation|multimod compact bilinear pool multimod neural machin translat|In state-of-the-art Neural Machine Translation, an attention mechanism is used during decoding to enhance the translation. At every step, the decoder uses this mechanism to focus on different parts of the source sentence to gather the most useful information before outputting its target word. Recently, the effectiveness of the attention mechanism has also been explored for multimodal tasks, where it becomes possible to focus both on sentence parts and image regions. Approaches to pool two modalities usually include element-wise product, sum or concatenation. In this paper, we evaluate the more advanced Multimodal Compact Bilinear pooling method, which takes the outer product of two vectors to combine the attention features for the two modalities. This has been previously investigated for visual question answering. We try out this approach for multimodal image caption translation and show improvements compared to basic combination methods.|state art neural machin translat attent mechan use dure decod enhanc translat everi step decod use mechan focus differ part sourc sentenc gather use inform befor output target word recent effect attent mechan also explor multimod task becom possibl focus sentenc part imag region approach pool two modal usual includ element wise product sum concaten paper evalu advanc multimod compact bilinear pool method take outer product two vector combin attent featur two modal previous investig visual question answer tri approach multimod imag caption translat show improv compar basic combin method|['Jean-Benoit Delbrouck', 'Stephane Dupont']|['cs.CL']
2017-04-07T11:27:49Z|2017-03-23T13:48:45Z|http://arxiv.org/abs/1703.08068v1|http://arxiv.org/pdf/1703.08068v1|Sequential Recurrent Neural Networks for Language Modeling|sequenti recurr neural network languag model|Feedforward Neural Network (FNN)-based language models estimate the probability of the next word based on the history of the last N words, whereas Recurrent Neural Networks (RNN) perform the same task based only on the last word and some context information that cycles in the network. This paper presents a novel approach, which bridges the gap between these two categories of networks. In particular, we propose an architecture which takes advantage of the explicit, sequential enumeration of the word history in FNN structure while enhancing each word representation at the projection layer through recurrent context information that evolves in the network. The context integration is performed using an additional word-dependent weight matrix that is also learned during the training. Extensive experiments conducted on the Penn Treebank (PTB) and the Large Text Compression Benchmark (LTCB) corpus showed a significant reduction of the perplexity when compared to state-of-the-art feedforward as well as recurrent neural network architectures.|feedforward neural network fnn base languag model estim probabl next word base histori last word wherea recurr neural network rnn perform task base onli last word context inform cycl network paper present novel approach bridg gap two categori network particular propos architectur take advantag explicit sequenti enumer word histori fnn structur enhanc word represent project layer recurr context inform evolv network context integr perform use addit word depend weight matrix also learn dure train extens experi conduct penn treebank ptb larg text compress benchmark ltcb corpus show signific reduct perplex compar state art feedforward well recurr neural network architectur|['Youssef Oualil', 'Clayton Greenberg', 'Mittul Singh', 'Dietrich Klakow']|['cs.CL']
2017-04-07T11:27:49Z|2017-03-23T13:00:14Z|http://arxiv.org/abs/1703.08052v1|http://arxiv.org/pdf/1703.08052v1|Dynamic Bernoulli Embeddings for Language Evolution|dynam bernoulli embed languag evolut|Word embeddings are a powerful approach for unsupervised analysis of language. Recently, Rudolph et al. (2016) developed exponential family embeddings, which cast word embeddings in a probabilistic framework. Here, we develop dynamic embeddings, building on exponential family embeddings to capture how the meanings of words change over time. We use dynamic embeddings to analyze three large collections of historical texts: the U.S. Senate speeches from 1858 to 2009, the history of computer science ACM abstracts from 1951 to 2014, and machine learning papers on the Arxiv from 2007 to 2015. We find dynamic embeddings provide better fits than classical embeddings and capture interesting patterns about how language changes.|word embed power approach unsupervis analysi languag recent rudolph et al develop exponenti famili embed cast word embed probabilist framework develop dynam embed build exponenti famili embed captur mean word chang time use dynam embed analyz three larg collect histor text senat speech histori comput scienc acm abstract machin learn paper arxiv find dynam embed provid better fit classic embed captur interest pattern languag chang|['Maja Rudolph', 'David Blei']|['stat.ML', 'cs.CL']
2017-04-07T11:27:53Z|2017-03-23T11:02:47Z|http://arxiv.org/abs/1703.08002v1|http://arxiv.org/pdf/1703.08002v1|A network of deep neural networks for distant speech recognition|network deep neural network distant speech recognit|Despite the remarkable progress recently made in distant speech recognition, state-of-the-art technology still suffers from a lack of robustness, especially when adverse acoustic conditions characterized by non-stationary noises and reverberation are met. A prominent limitation of current systems lies in the lack of matching and communication between the various technologies involved in the distant speech recognition process. The speech enhancement and speech recognition modules are, for instance, often trained independently. Moreover, the speech enhancement normally helps the speech recognizer, but the output of the latter is not commonly used, in turn, to improve the speech enhancement. To address both concerns, we propose a novel architecture based on a network of deep neural networks, where all the components are jointly trained and better cooperate with each other thanks to a full communication scheme between them. Experiments, conducted using different datasets, tasks and acoustic conditions, revealed that the proposed framework can overtake other competitive solutions, including recent joint training approaches.|despit remark progress recent made distant speech recognit state art technolog still suffer lack robust especi advers acoust condit character non stationari nois reverber met promin limit current system lie lack match communic various technolog involv distant speech recognit process speech enhanc speech recognit modul instanc often train independ moreov speech enhanc normal help speech recogn output latter common use turn improv speech enhanc address concern propos novel architectur base network deep neural network compon joint train better cooper thank full communic scheme experi conduct use differ dataset task acoust condit reveal propos framework overtak competit solut includ recent joint train approach|['Mirco Ravanelli', 'Philemon Brakel', 'Maurizio Omologo', 'Yoshua Bengio']|['cs.CL', 'cs.LG']
2017-04-07T11:27:53Z|2017-03-22T18:20:07Z|http://arxiv.org/abs/1703.07805v1|http://arxiv.org/abs/1703.07805v1|Supervised Typing of Big Graphs using Semantic Embeddings|supervis type big graph use semant embed|We propose a supervised algorithm for generating type embeddings in the same semantic vector space as a given set of entity embeddings. The algorithm is agnostic to the derivation of the underlying entity embeddings. It does not require any manual feature engineering, generalizes well to hundreds of types and achieves near-linear scaling on Big Graphs containing many millions of triples and instances by virtue of an incremental execution. We demonstrate the utility of the embeddings on a type recommendation task, outperforming a non-parametric feature-agnostic baseline while achieving 15x speedup and near-constant memory usage on a full partition of DBpedia. Using state-of-the-art visualization, we illustrate the agreement of our extensionally derived DBpedia type embeddings with the manually curated domain ontology. Finally, we use the embeddings to probabilistically cluster about 4 million DBpedia instances into 415 types in the DBpedia ontology.|propos supervis algorithm generat type embed semant vector space given set entiti embed algorithm agnost deriv entiti embed doe requir ani manual featur engin general well hundr type achiev near linear scale big graph contain mani million tripl instanc virtu increment execut demonstr util embed type recommend task outperform non parametr featur agnost baselin achiev speedup near constant memori usag full partit dbpedia use state art visual illustr agreement extension deriv dbpedia type embed manual curat domain ontolog final use embed probabilist cluster million dbpedia instanc type dbpedia ontolog|['Mayank Kejriwal', 'Pedro Szekely']|['cs.CL', 'cs.AI']
2017-04-07T11:27:53Z|2017-03-22T17:17:16Z|http://arxiv.org/abs/1703.07754v1|http://arxiv.org/pdf/1703.07754v1|Direct Acoustics-to-Word Models for English Conversational Speech   Recognition|direct acoust word model english convers speech recognit|Recent work on end-to-end automatic speech recognition (ASR) has shown that the connectionist temporal classification (CTC) loss can be used to convert acoustics to phone or character sequences. Such systems are used with a dictionary and separately-trained Language Model (LM) to produce word sequences. However, they are not truly end-to-end in the sense of mapping acoustics directly to words without an intermediate phone representation. In this paper, we present the first results employing direct acoustics-to-word CTC models on two well-known public benchmark tasks: Switchboard and CallHome. These models do not require an LM or even a decoder at run-time and hence recognize speech with minimal complexity. However, due to the large number of word output units, CTC word models require orders of magnitude more data to train reliably compared to traditional systems. We present some techniques to mitigate this issue. Our CTC word model achieves a word error rate of 13.0%/18.8% on the Hub5-2000 Switchboard/CallHome test sets without any LM or decoder compared with 9.6%/16.0% for phone-based CTC with a 4-gram LM. We also present rescoring results on CTC word model lattices to quantify the performance benefits of a LM, and contrast the performance of word and phone CTC models.|recent work end end automat speech recognit asr shown connectionist tempor classif ctc loss use convert acoust phone charact sequenc system use dictionari separ train languag model lm produc word sequenc howev truli end end sens map acoust direct word without intermedi phone represent paper present first result employ direct acoust word ctc model two well known public benchmark task switchboard callhom model requir lm even decod run time henc recogn speech minim complex howev due larg number word output unit ctc word model requir order magnitud data train reliabl compar tradit system present techniqu mitig issu ctc word model achiev word error rate hub switchboard callhom test set without ani lm decod compar phone base ctc gram lm also present rescor result ctc word model lattic quantifi perform benefit lm contrast perform word phone ctc model|['Kartik Audhkhasi', 'Bhuvana Ramabhadran', 'George Saon', 'Michael Picheny', 'David Nahamoo']|['cs.CL', 'cs.NE', 'stat.ML']
2017-04-07T11:27:53Z|2017-03-22T15:42:28Z|http://arxiv.org/abs/1703.07713v1|http://arxiv.org/pdf/1703.07713v1|Hierarchical RNN with Static Sentence-Level Attention for Text-Based   Speaker Change Detection|hierarch rnn static sentenc level attent text base speaker chang detect|Traditional speaker change detection in dialogues is typically based on audio input. In some scenarios, however, researchers can only obtain text, and do not have access to raw audio signals. Moreover, with the increasing need of deep semantic processing, text-based dialogue understanding is attracting more attention in the community. These raise the problem of text-based speaker change detection. In this paper, we formulate the task as a matching problem of utterances before and after a certain decision point; we propose a hierarchical recurrent neural network (RNN) with static sentence-level attention. Our model comprises three main components: a sentence encoder with a long short term memory (LSTM)-based RNN, a context encoder with another LSTM-RNN, and a static sentence-level attention mechanism, which allows rich information interaction. Experimental results show that neural networks consistently achieve better performance than feature-based approaches, and that our attention-based model significantly outperforms non-attention neural networks.|tradit speaker chang detect dialogu typic base audio input scenario howev research onli obtain text access raw audio signal moreov increas need deep semant process text base dialogu understand attract attent communiti rais problem text base speaker chang detect paper formul task match problem utter befor certain decis point propos hierarch recurr neural network rnn static sentenc level attent model compris three main compon sentenc encod long short term memori lstm base rnn context encod anoth lstm rnn static sentenc level attent mechan allow rich inform interact experiment result show neural network consist achiev better perform featur base approach attent base model signific outperform non attent neural network|['Zhao Meng', 'Lili Mou', 'Zhi Jin']|['cs.CL']
2017-04-07T11:27:53Z|2017-03-22T10:08:51Z|http://arxiv.org/abs/1703.07588v1|http://arxiv.org/pdf/1703.07588v1|Gate Activation Signal Analysis for Gated Recurrent Neural Networks and   Its Correlation with Phoneme Boundaries|gate activ signal analysi gate recurr neural network correl phonem boundari|In this paper we analyze the gate activation signals inside the gated recurrent neural networks, and find the temporal structure of such signals is highly correlated with the phoneme boundaries. This correlation is further verified by a set of experiments for phoneme segmentation, in which better results compared to standard approaches were obtained.|paper analyz gate activ signal insid gate recurr neural network find tempor structur signal high correl phonem boundari correl verifi set experi phonem segment better result compar standard approach obtain|['Yu-Hsuan Wang', 'Cheng-Tao Chung', 'Hung-yi Lee']|['cs.SD', 'cs.CL', 'cs.LG']
2017-04-07T11:27:53Z|2017-03-22T00:37:33Z|http://arxiv.org/abs/1703.07476v1|http://arxiv.org/pdf/1703.07476v1|Topic Identification for Speech without ASR|topic identif speech without asr|Modern topic identification (topic ID) systems for speech use automatic speech recognition (ASR) to produce speech transcripts, and perform supervised classification on such ASR outputs. However, under resource-limited conditions, the manually transcribed speech required to develop standard ASR systems can be severely limited or unavailable. In this paper, we investigate alternative unsupervised solutions to obtaining tokenizations of speech in terms of a vocabulary of automatically discovered word-like or phoneme-like units, without depending on the supervised training of ASR systems. Moreover, using automatic phoneme-like tokenizations, we demonstrate that a convolutional neural network based framework for learning spoken document representations provides competitive performance compared to a standard bag-of-words representation, as evidenced by comprehensive topic ID evaluations on both single-label and multi-label classification tasks.|modern topic identif topic id system speech use automat speech recognit asr produc speech transcript perform supervis classif asr output howev resourc limit condit manual transcrib speech requir develop standard asr system sever limit unavail paper investig altern unsupervis solut obtain token speech term vocabulari automat discov word like phonem like unit without depend supervis train asr system moreov use automat phonem like token demonstr convolut neural network base framework learn spoken document represent provid competit perform compar standard bag word represent evidenc comprehens topic id evalu singl label multi label classif task|['Chunxi Liu', 'Jan Trmal', 'Matthew Wiesner', 'Craig Harman', 'Sanjeev Khudanpur']|['cs.CL']
2017-04-07T11:27:53Z|2017-03-21T21:36:28Z|http://arxiv.org/abs/1703.07438v1|http://arxiv.org/pdf/1703.07438v1|The NLTK FrameNet API: Designing for Discoverability with a Rich   Linguistic Resource|nltk framenet api design discover rich linguist resourc|A new Python API, integrated within the NLTK suite, offers access to the FrameNet 1.7 lexical database. The lexicon (structured in terms of frames) as well as annotated sentences can be processed programatically, or browsed with human-readable displays via the interactive Python prompt.|new python api integr within nltk suit offer access framenet lexic databas lexicon structur term frame well annot sentenc process programat brows human readabl display via interact python prompt|['Nathan Schneider', 'Chuck Wooters']|['cs.CL']
2017-04-07T11:27:53Z|2017-03-21T15:34:28Z|http://arxiv.org/abs/1703.09749v1|http://arxiv.org/pdf/1703.09749v1|Developpement de Methodes Automatiques pour la Reutilisation des   Composants Logiciels|developp de method automatiqu pour la reutilis des compos logiciel|The large amount of information and the increasing complexity of applications constrain developers to have stand-alone and reusable components from libraries and component markets.Our approach consists in developing methods to evaluate the quality of the software component of these libraries, on the one hand and moreover to optimize the financial cost and the adaptation's time of these selected components. Our objective function defines a metric that maximizes the value of the software component quality by minimizing the financial cost and maintenance time. This model should make it possible to classify the components and order them in order to choose the most optimized.   MOTS-CLES : d{\'e}veloppement de m{\'e}thode, r{\'e}utilisation, composants logiciels, qualit{\'e} de composant   KEYWORDS:method development, reuse, software components, component quality .|larg amount inform increas complex applic constrain develop stand alon reusabl compon librari compon market approach consist develop method evalu qualiti softwar compon librari one hand moreov optim financi cost adapt time select compon object function defin metric maxim valu softwar compon qualiti minim financi cost mainten time model make possibl classifi compon order order choos optim mot cles velopp de thode utilis compos logiciel qualit de compos keyword method develop reus softwar compon compon qualiti|['Kouakou Ive Arsene Koffi', 'Konan Marcellin Brou', 'Souleymane Oumtanaga']|['cs.SE', 'cs.CL', 'cs.DB']
2017-04-07T11:27:53Z|2017-03-21T08:24:50Z|http://arxiv.org/abs/1703.07090v1|http://arxiv.org/pdf/1703.07090v1|Deep LSTM for Large Vocabulary Continuous Speech Recognition|deep lstm larg vocabulari continu speech recognit|Recurrent neural networks (RNNs), especially long short-term memory (LSTM) RNNs, are effective network for sequential task like speech recognition. Deeper LSTM models perform well on large vocabulary continuous speech recognition, because of their impressive learning ability. However, it is more difficult to train a deeper network. We introduce a training framework with layer-wise training and exponential moving average methods for deeper LSTM models. It is a competitive framework that LSTM models of more than 7 layers are successfully trained on Shenma voice search data in Mandarin and they outperform the deep LSTM models trained by conventional approach. Moreover, in order for online streaming speech recognition applications, the shallow model with low real time factor is distilled from the very deep model. The recognition accuracy have little loss in the distillation process. Therefore, the model trained with the proposed training framework reduces relative 14\% character error rate, compared to original model which has the similar real-time capability. Furthermore, the novel transfer learning strategy with segmental Minimum Bayes-Risk is also introduced in the framework. The strategy makes it possible that training with only a small part of dataset could outperform full dataset training from the beginning.|recurr neural network rnns especi long short term memori lstm rnns effect network sequenti task like speech recognit deeper lstm model perform well larg vocabulari continu speech recognit becaus impress learn abil howev difficult train deeper network introduc train framework layer wise train exponenti move averag method deeper lstm model competit framework lstm model layer success train shenma voic search data mandarin outperform deep lstm model train convent approach moreov order onlin stream speech recognit applic shallow model low real time factor distil veri deep model recognit accuraci littl loss distil process therefor model train propos train framework reduc relat charact error rate compar origin model similar real time capabl furthermor novel transfer learn strategi segment minimum bay risk also introduc framework strategi make possibl train onli small part dataset could outperform full dataset train begin|['Xu Tian', 'Jun Zhang', 'Zejun Ma', 'Yi He', 'Juan Wei', 'Peihao Wu', 'Wenchang Situ', 'Shuai Li', 'Yang Zhang']|['cs.CL']
2017-04-07T11:27:53Z|2017-03-21T04:56:14Z|http://arxiv.org/abs/1703.07055v1|http://arxiv.org/pdf/1703.07055v1|Investigation of Language Understanding Impact for Reinforcement   Learning Based Dialogue Systems|investig languag understand impact reinforc learn base dialogu system|Language understanding is a key component in a spoken dialogue system. In this paper, we investigate how the language understanding module influences the dialogue system performance by conducting a series of systematic experiments on a task-oriented neural dialogue system in a reinforcement learning based setting. The empirical study shows that among different types of language understanding errors, slot-level errors can have more impact on the overall performance of a dialogue system compared to intent-level errors. In addition, our experiments demonstrate that the reinforcement learning based dialogue system is able to learn when and what to confirm in order to achieve better performance and greater robustness.|languag understand key compon spoken dialogu system paper investig languag understand modul influenc dialogu system perform conduct seri systemat experi task orient neural dialogu system reinforc learn base set empir studi show among differ type languag understand error slot level error impact overal perform dialogu system compar intent level error addit experi demonstr reinforc learn base dialogu system abl learn confirm order achiev better perform greater robust|['Xiujun Li', 'Yun-Nung Chen', 'Lihong Li', 'Jianfeng Gao', 'Asli Celikyilmaz']|['cs.CL', 'cs.AI', 'cs.LG']
