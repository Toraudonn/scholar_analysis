2017-02-28T17:21:57Z,2017-02-27T18:07:12Z,http://arxiv.org/abs/1702.08405v1,http://arxiv.org/pdf/1702.08405v1,Game-Theoretic Semantics for ATL+ with Applications to Model Checking,"We develop game-theoretic semantics (GTS) for the fragment ATL+ of the full
Alternating-time Temporal Logic ATL* essentially extending a recently
introduced GTS for ATL. We first show that the new game-theoretic semantics is
equivalent to the standard semantics of ATL+ (based on perfect recall
strategies). We then provide an analysis based on the new semantics of the
memory and time resources needed for model checking ATL+. Based on that we
establish that strategies that use only a very limited amount of memory suffice
for ATL+. Furthermore using the GTS we provide a new algorithm for model
checking of ATL+ and identify a natural hierarchy of tractable fragments of
ATL+ that extend ATL.",Valentin Goranko|Antti Kuusisto|Raine Rönnholm,math.LO|cs.GT|cs.LO|F.4.1; I.2.11
2017-02-28T17:21:57Z,2017-02-27T15:41:56Z,http://arxiv.org/abs/1702.08334v1,http://arxiv.org/pdf/1702.08334v1,"Stochastic Stability Analysis of Perturbed Learning Automata with
  Constant Step-Size in Strategic-Form Games","This paper considers a class of reinforcement-learning that belongs to the
family of Learning Automata and provides a stochastic-stability analysis in
strategic-form games. For this class of dynamics convergence to pure Nash
equilibria has been demonstrated only for the fine class of potential games.
Prior work primarily provides convergence properties of the dynamics through
stochastic approximations where the asymptotic behavior can be associated with
the limit points of an ordinary-differential equation (ODE). However analyzing
global convergence through the ODE-approximation requires the existence of a
Lyapunov or a potential function which naturally restricts the applicabity of
these algorithms to a fine class of games. To overcome these limitations this
paper introduces an alternative framework for analyzing stochastic-stability
that is based upon an explicit characterization of the (unique) invariant
probability measure of the induced Markov chain.",Georgios C. Chasparis,cs.GT
2017-02-28T17:21:57Z,2017-02-27T13:54:44Z,http://arxiv.org/abs/1702.08286v1,http://arxiv.org/pdf/1702.08286v1,"Balancing Lexicographic Fairness and a Utilitarian Objective with
  Application to Kidney Exchange","Balancing fairness and efficiency in resource allocation is a classical
economic and computational problem. The price of fairness measures the
worst-case loss of economic efficiency when using an inefficient but fair
allocation rule; for indivisible goods in many settings this price is
unacceptably high. In this work we propose a hybrid fairness rule that
balances a strict lexicographic preference ordering over classes of agents and
a utilitarian objective that maximizes economic efficiency. We develop a
utility function that favors disadvantaged groups lexicographically; but if
cost to overall efficiency becomes too high it smoothly switches to a
utilitarian objective. This rule has only one parameter which is proportional
to a bound on the price of fairness and can be adjusted by policymakers. We
apply this rule to kidney exchange where needy patients swap willing but
incompatible donors and demonstrate on real data from a large exchange that
our hybrid rule produces more reliable outcomes than other fairness rules.",Duncan C. McElfresh|John P. Dickerson,cs.GT|cs.AI|I.2.11; J.4
2017-02-28T17:21:57Z,2017-02-26T03:24:31Z,http://arxiv.org/abs/1702.07984v1,http://arxiv.org/abs/1702.07984v1,"Collaborative Optimization for Collective Decision-making in Continuous
  Spaces","Many societal decision problems lie in high-dimensional continuous spaces not
amenable to the voting techniques common for their discrete or
single-dimensional counterparts. These problems are typically discretized
before running an election or decided upon through negotiation by
representatives. We propose a meta-algorithm called \emph{Iterative Local
Voting} for collective decision-making in this setting in which voters are
sequentially sampled and asked to modify a candidate solution within some local
neighborhood of its current value as defined by a ball in some chosen norm. In
general such schemes do not converge or when they do the resulting solution
does not have a natural description.
  We first prove the convergence of this algorithm under appropriate choices of
neighborhoods to plausible solutions in certain natural settings: when the
voters' utilities can be expressed in terms of some form of distance from their
ideal solution and when these utilities are additively decomposable across
dimensions. In many of these cases we obtain convergence to the societal
welfare maximizing solution.
  We then describe an experiment in which we test our algorithm for the
decision of the U.S. Federal Budget on Mechanical Turk with over 4000 workers
employing neighborhoods defined by $\mathcal{L}^1 \mathcal{L}^2$ and
$\mathcal{L}^\infty$ balls. We make several observations that inform future
implementations of such a procedure.",Nikhil Garg|Vijay Kamble|Ashish Goel|David Marn|Kamesh Munagala,cs.MA|cs.CY|cs.GT
2017-02-28T17:21:57Z,2017-02-25T17:56:07Z,http://arxiv.org/abs/1702.07932v1,http://arxiv.org/pdf/1702.07932v1,The role of quantum correlations in Cop and Robber game,"We introduce and study quantized versions of Cop and Robber game. We achieve
this by using graph-preserving unitary operations which are the quantum
analogue of stochastic operations preserving the graph. We provide the tight
bound for the number of operations required to reach the given state. By
extending them to controlled operations we define a quantum controlled Cop and
Robber game which expands the classical Cop and Robber game as well as
classically controlled quantum Cop and Robber game. In contrast to the typical
scheme for introducing quantum games we assume that both parties can utilise
full information about the opponent's strategy. We show that the utilisation of
the full knowledge about the opponent's state does not provide the advantage.
Moreover the chances of catching the Robber decreases for classically cop-win
graphs. The result does not depend on the chosen model of evolution. On the
other hand the possibility to execute controlled quantum operations allows
catching the Robber on almost all classically cop-win graphs. To provide
interesting non-trivial quantized Cop and Robber game we need to enrich the
structure of correlations between the players' systems. This result
demonstrates that the ability to utilise quantum controlled operations is
significantly stronger that the control restricted operating on classical
selecting quantum operations only.",Adam Glos|Jarosław Adam Miszczak,"quant-ph|cs.DM|cs.GT|05C57 (Primary), 91A46, 81P40 (Secondary)|G.2.2"
2017-02-28T17:21:57Z,2017-02-25T15:07:59Z,http://arxiv.org/abs/1702.07902v1,http://arxiv.org/pdf/1702.07902v1,Approval Voting with Intransitive Preferences,"We extend Approval voting to the settings where voters may have intransitive
preferences. The major obstacle to applying Approval voting in these settings
is that voters are not able to clearly determine who they should approve or
disapprove due to the intransitivity of their preferences. An approach to
address this issue is to apply tournament solutions to help voters make the
decision. We study a class of voting systems where first each voter casts a
vote defined as a tournament then a well-defined tournament solution is
applied to select the candidates who are assumed to be approved by the voter.
Winners are the ones receiving the most approvals. We study axiomatic
properties of this class of voting systems and complexity of control and
bribery problems for these voting systems.",Yongjie Yang,cs.GT|cs.CC|cs.DM
2017-02-28T17:21:57Z,2017-02-25T00:05:57Z,http://arxiv.org/abs/1702.07810v1,http://arxiv.org/pdf/1702.07810v1,A Decomposition of Forecast Error in Prediction Markets,"We introduce and analyze sources of error in prediction market forecasts in
order to characterize and bound the difference between a security's price and
its ground truth value. We consider cost-function-based prediction markets in
which an automated market maker adjusts security prices according to the
history of trade. We decompose the forecasting error into four components:
\emph{sampling error} occurring because traders only possess noisy estimates
of ground truth; \emph{risk-aversion effect} arising because traders reveal
beliefs only through self-interested trade; \emph{market-maker bias} resulting
from the use of a particular market maker (i.e. cost function) to facilitate
trade; and finally \emph{convergence error} arising because at any point in
time market prices may still be in flux. Our goal is to understand the
tradeoffs between these error components and how they are influenced by design
decisions such as the functional form of the cost function and the amount of
liquidity in the market. We specifically consider a model in which traders have
exponential utility and exponential-family beliefs drawn with an independent
noise relative to ground truth. In this setting sampling error and
risk-aversion effect vanish as the number of traders grows but there is a
tradeoff between the other two components: decreasing the market maker's
liquidity results in smaller market-maker bias but may also slow down
convergence. We provide both upper and lower bounds on market-maker bias and
convergence error and demonstrate via numerical simulations that these bounds
are tight. Our results yield new insights into the question of how to set the
market's liquidity parameter and into the extent to which markets that enforce
coherent prices across securities produce better predictions than markets that
price securities independently.",Miroslav Dudík|Sébastien Lahaie|Ryan Rogers|Jennifer Wortman Vaughan,cs.GT
2017-02-28T17:21:57Z,2017-02-25T00:00:36Z,http://arxiv.org/abs/1702.07806v1,http://arxiv.org/pdf/1702.07806v1,"When Does Diversity of User Preferences Improve Outcomes in Selfish
  Routing?","We seek to understand when heterogeneity in user preferences yields improved
outcomes in terms of overall cost. That this might be hoped for is based on the
common belief that diversity is advantageous in many settings. We investigate
this in the context of routing. Our main result is a sharp characterization of
the network settings in which diversity always helps versus those in which it
is sometimes harmful.
  Specifically we consider routing games where diversity arises in the way
that users trade-off two criteria (such as time and money or in the case of
stochastic delays expectation and variance of delay). We consider both linear
and non-linear combinations of the two criteria and view our main contributions
as the following: 1) A participant-oriented measure of cost in the presence of
user diversity together with the identification of the natural benchmark: the
same cost measure for an appropriately defined average of the diversity. 2) A
full characterization of those network topologies for which diversity always
helps for all latency functions and demands. For single-commodity routings
these are series-parallel graphs while for multi-commodity routings they are
the newly-defined ""block-matching"" networks. The latter comprise a suitable
interweaving of multiple series-parallel graphs each connecting a distinct
source-sink pair.
  While the result for the single-commodity case may seem intuitive in light of
the well-known Braess paradox the two problems are different. But the main
technical challenge is to establish the ""only if"" direction of the result for
multi-commodity networks. This follows by constructing an instance where
diversity hurts and showing how to embed it in any network which is not
block-matching by carefully exploiting the way the simple source-sink paths of
the commodities intersect in the ""non-block-matching"" portion of the network.",Richard Cole|Thanasis Lianeas|Evdokia Nikolova,cs.GT
2017-02-28T17:21:57Z,2017-02-24T17:09:22Z,http://arxiv.org/abs/1702.07665v1,http://arxiv.org/pdf/1702.07665v1,Truthful Mechanisms for Delivery with Mobile Agents,"We study the game-theoretic task of selecting mobile agents to deliver
multiple items on a network. An instance is given by $m$ messages (physical
objects) which have to be transported between specified source-target pairs in
a weighted undirected graph and $k$ mobile heterogeneous agents each being
able to transport one message at a time. Following a recent model by
[B\""artschi et al. 2016] each agent $i$ consumes energy proportional to the
distance it travels in the graph where the different rates of energy
consumption are given by weight factors $w_i$. We are interested in optimizing
or approximating the total energy consumption over all selected agents.
  Unlike previous research we assume the weights to be private values known
only to the respective agents. We present three different mechanisms which
select route and pay the agents in a truthful way that guarantees voluntary
participation of the agents while approximating the optimum energy consumption
by a constant factor. To this end we analyze a previous structural result and
an approximation algorithm given by [B\""artschi et al. 2017]. Finally we show
that for some instances in the case of a single message ($m=1$) the sum of the
payments can be bounded in terms of the optimum as well.",Andreas Bärtschi|Daniel Graf|Paolo Penna,cs.GT|cs.DS
2017-02-28T17:21:57Z,2017-02-24T02:30:15Z,http://arxiv.org/abs/1702.07450v1,http://arxiv.org/pdf/1702.07450v1,Strongly-Typed Agents are Guaranteed to Interact Safely,"As artificial agents proliferate it is becoming increasingly important to
ensure that their interactions with one another are well-behaved. In this
paper we formalize a common-sense notion of when algorithms are well-behaved:
an algorithm is safe if it does no harm. Motivated by recent progress in deep
learning we focus on the specific case where agents update their actions
according to gradient descent. The first result is that gradient descent
converges to a Nash equilibrium in safe games.
  The paper provides sufficient conditions that guarantee safe interactions.
The main contribution is to define strongly-typed agents and show they are
guaranteed to interact safely. A series of examples show that strong-typing
generalizes certain key features of convexity and is closely related to blind
source separation. The analysis introduce a new perspective on classical
multilinear games based on tensor decomposition.",David Balduzzi,cs.LG|cs.AI|cs.GT
2017-02-28T17:22:01Z,2017-02-24T01:51:48Z,http://arxiv.org/abs/1702.07444v1,http://arxiv.org/pdf/1702.07444v1,Bandits with Movement Costs and Adaptive Pricing,"We extend the model of Multi-armed Bandit with unit switching cost to
incorporate a metric between the actions. We consider the case where the metric
over the actions can be modeled by a complete binary tree and the distance
between two leaves is the size of the subtree of their least common ancestor
which abstracts the case that the actions are points on the continuous interval
$[01]$ and the switching cost is their distance. In this setting we give a
new algorithm that establishes a regret of $\widetilde{O}(\sqrt{kT} + T/k)$
where $k$ is the number of actions and $T$ is the time horizon. When the set of
actions corresponds to whole $[01]$ interval we can exploit our method for the
task of bandit learning with Lipschitz loss functions where our algorithm
achieves an optimal regret rate of $\widetilde{\Theta}(T^{2/3})$ which is the
same rate one obtains when there is no penalty for movements. As our main
application we use our new algorithm to solve an adaptive pricing problem.
Specifically we consider the case of a single seller faced with a stream of
patient buyers. Each buyer has a private value and a window of time in which
they are interested in buying and they buy at the lowest price in the window
if it is below their value. We show that with an appropriate discretization of
the prices the seller can achieve a regret of $\widetilde{O}(T^{2/3})$
compared to the best fixed price in hindsight which outperform the previous
regret bound of $\widetilde{O}(T^{3/4})$ for the problem.",Tomer Koren|Roi Livni|Yishay Mansour,cs.LG|cs.GT
2017-02-28T17:22:01Z,2017-02-23T17:54:28Z,http://arxiv.org/abs/1702.07311v1,http://arxiv.org/abs/1702.07311v1,ERA: A Framework for Economic Resource Allocation for the Cloud,"Cloud computing has reached significant maturity from a systems perspective
but currently deployed solutions rely on rather basic economics mechanisms that
yield suboptimal allocation of the costly hardware resources. In this paper we
present Economic Resource Allocation (ERA) a complete framework for scheduling
and pricing cloud resources aimed at increasing the efficiency of cloud
resources usage by allocating resources according to economic principles. The
ERA architecture carefully abstracts the underlying cloud infrastructure
enabling the development of scheduling and pricing algorithms independently of
the concrete lower-level cloud infrastructure and independently of its
concerns. Specifically ERA is designed as a flexible layer that can sit on top
of any cloud system and interfaces with both the cloud resource manager and
with the users who reserve resources to run their jobs. The jobs are scheduled
based on prices that are dynamically calculated according to the predicted
demand. Additionally ERA provides a key internal API to pluggable algorithmic
modules that include scheduling pricing and demand prediction. We provide a
proof-of-concept software and demonstrate the effectiveness of the architecture
by testing ERA over both public and private cloud systems -- Azure Batch of
Microsoft and Hadoop/YARN. A broader intent of our work is to foster
collaborations between economics and system communities. To that end we have
developed a simulation platform via which economics and system experts can test
their algorithmic implementations.",Moshe Babaioff|Yishay Mansour|Noam Nisan|Gali Noti|Carlo Curino|Nar Ganapathy|Ishai Menache|Omer Reingold|Moshe Tennenholtz|Erez Timnat,cs.GT|cs.DC
2017-02-28T17:22:01Z,2017-02-23T17:49:40Z,http://arxiv.org/abs/1702.07309v1,http://arxiv.org/pdf/1702.07309v1,Bounding the inefficiency of compromise,"Social networks on the Internet have seen an enormous growth recently and
play a crucial role in different aspects of today's life. They have facilitated
information dissemination in ways that have been beneficial for their users but
they are often used strategically in order to spread information that only
serves the objectives of particular users. These properties have inspired a
revision of classical opinion formation models from sociology using
game-theoretic notions and tools. We follow the same modeling approach
focusing on scenarios where the opinion expressed by each user is a compromise
between her internal belief and the opinions of a small number of neighbors
among her social acquaintances. We formulate simple games that capture this
behavior and quantify the inefficiency of equilibria using the well-known
notion of the price of anarchy. Our results indicate that compromise comes at a
cost that strongly depends on the neighborhood size.",Ioannis Caragiannis|Panagiotis Kanellopoulos|Alexandros A. Voudouris,cs.GT
2017-02-28T17:22:01Z,2017-02-22T22:43:45Z,http://arxiv.org/abs/1702.07032v1,http://arxiv.org/pdf/1702.07032v1,On the Complexity of Bundle-Pricing and Simple Mechanisms,"We show that the problem of finding an optimal bundle-pricing for a single
additive buyer is #P-hard even when the distributions have support size 2 for
each item and the optimal solution is guaranteed to be a simple one: the seller
picks a price for the grand bundle and a price for each individual item; the
buyer can purchase either the grand bundle at the given price or any bundle of
items at their total individual prices. We refer to this simple and natural
family of pricing schemes as discounted item-pricings. In addition to the
hardness result we show that when the distributions are i.i.d. with support
size 2 a discounted item-pricing can achieve the optimal revenue obtainable by
lottery-pricings and it can be found in polynomial time.",Xi Chen|George Matikas|Dimitris Paparas|Mihalis Yannakakis,cs.GT|cs.CC|cs.DS
2017-02-28T17:22:01Z,2017-02-22T22:34:57Z,http://arxiv.org/abs/1702.07031v1,http://arxiv.org/pdf/1702.07031v1,"Proactive Resource Management in LTE-U Systems: A Deep Learning
  Perspective","LTE in unlicensed spectrum (LTE-U) is a promising approach to overcome the
wireless spectrum scarcity. However to reap the benefits of LTE-U a fair
coexistence mechanism with other incumbent WiFi deployments is required. In
this paper a novel deep learning approach is proposed for modeling the
resource allocation problem of LTE-U small base stations (SBSs). The proposed
approach enables multiple SBSs to proactively perform dynamic channel
selection carrier aggregation and fractional spectrum access while
guaranteeing fairness with existing WiFi networks and other LTE-U operators.
Adopting a proactive coexistence mechanism enables future delay-intolerant
LTE-U data demands to be served within a given prediction window ahead of their
actual arrival time thus avoiding the underutilization of the unlicensed
spectrum during off-peak hours while maximizing the total served LTE-U traffic
load. To this end a noncooperative game model is formulated in which SBSs are
modeled as Homo Egualis agents that aim at predicting a sequence of future
actions and thus achieving long-term equal weighted fairness with WLAN and
other LTE-U operators over a given time horizon. The proposed deep learning
algorithm is then shown to reach a mixed-strategy Nash equilibrium (NE) when
it converges. Simulation results using real data traces show that the proposed
scheme can yield up to 28% and 11% gains over a conventional reactive approach
and a proportional fair coexistence mechanism respectively. The results also
show that the proposed framework prevents WiFi performance degradation for a
densely deployed LTE-U network.",Ursula Challita|Li Dong|Walid Saad,cs.IT|cs.AI|cs.GT|math.IT
2017-02-28T17:22:01Z,2017-02-22T18:06:24Z,http://arxiv.org/abs/1702.06922v1,http://arxiv.org/pdf/1702.06922v1,Formation of coalition structures as a non-cooperative game,"The paper defines a family of nested non-cooperative simultaneous finite
games to study coalition structure formation with intra and inter-coalition
externalities. Every game has two outcomes - an allocation of players over
coalitions and a payoff profile for every player.
  Every game in the family has an equilibrium in mixed strategies. The
equilibrium can generate more than one coalition with a presence of intra and
inter group externalities. These properties make it different from the Shapley
value strong Nash coalition-proof equilibrium core kernel nucleolus. The
paper demonstrates some applications: non-cooperative cooperation Bayesian
game stochastic games and construction of a non-cooperative criterion of
coalition structure stability for studying focal points. An example
demonstrates that a payoff profile in the Prisoners' Dilemma is non-informative
to deduce a cooperation of players.",Dmitry Levando,math.OC|cs.GT
2017-02-28T17:22:01Z,2017-02-22T15:39:12Z,http://arxiv.org/abs/1702.06858v1,http://arxiv.org/pdf/1702.06858v1,Emptiness of zero automata is decidable,"Zero automata are a probabilistic extension of parity automata on infinite
trees. The satisfiability of a certain probabilistic variant of mso called
tmso + zero reduces to the emptiness problem for zero automata. We introduce a
variant of zero automata called nonzero automata. We prove that for every zero
automaton there is an equivalent nonzero automaton of quadratic size and the
emptiness problem of nonzero automata is decidable with complexity np. These
results imply that tmso + zero has decidable satisfiability.",Mikolaj Bojańczyk|Hugo Gimbert|Edon Kelmendi,cs.FL|cs.GT
2017-02-28T17:22:01Z,2017-02-25T23:52:16Z,http://arxiv.org/abs/1702.06810v2,http://arxiv.org/pdf/1702.06810v2,"Pricing average price advertisement options when underlying spot market
  prices are discontinuous","Advertisement (ad) options have been recently studied as a novel guaranteed
delivery (GD) system in online advertising. In essence an ad option is a
contract that gives an advertiser a right but not obligation to enter into
transactions to purchase ad inventories such as page views or link clicks from
a specific slot at one or multiple pre-specified prices in a specific future
period. Compared to guaranteed contracts the advertiser pays a lower upfront
fee but can have greater flexibility and more control in advertising. So far ad
option studies have been restricted to the situations where the option payoff
is determined by the underlying auction payment price at a specific time point
and the price evolution over time is assumed to be continuous. The former leads
to a biased option payoff calculation and the latter is invalid empirically for
many ad slots. This paper discusses a new option pricing framework which can be
applied to a general situation. The option payoff is calculated based on the
average price over a specific future period. As we use the general mean our
framework contains different payoff functions as special cases. Further we use
jump-diffusion stochastic models to describe the auction payment price
movement which have Markov and price discontinuity properties and those
properties are validated by our statistical investigation of ad auctions from
different datasets. In the paper we propose a general option pricing solution
based on Monte Carlo simulation and also give an explicit pricing formula for a
special case. The latter is also a generalisation of the option pricing models
in some other recent developments.",Bowei Chen|Mohan S. Kankanhalli,cs.GT
2017-02-28T17:22:01Z,2017-02-22T02:07:25Z,http://arxiv.org/abs/1702.06645v1,http://arxiv.org/pdf/1702.06645v1,"Resource Sharing Among mmWave Cellular Service Providers in a Vertically
  Differentiated Duopoly","With the increasing interest in the use of millimeter wave bands for 5G
cellular systems comes renewed interest in resource sharing. Properties of
millimeter wave bands such as massive bandwidth highly directional antennas
high penetration loss and susceptibility to shadowing suggest technical
advantages to spectrum and infrastructure sharing in millimeter wave cellular
networks. However technical advantages do not necessarily translate to
increased profit for service providers or increased consumer surplus. In this
paper detailed network simulations are used to better understand the economic
implications of resource sharing in a vertically differentiated duopoly market
for cellular service. The results suggest that resource sharing is less often
profitable for millimeter wave service providers compared to microwave cellular
service providers and does not necessarily increase consumer surplus.",Fraida Fund|Shahram Shahsavari|Shivendra S. Panwar|Elza Erkip|Sundeep Rangan,cs.NI|cs.GT
2017-02-28T17:22:01Z,2017-02-21T15:30:28Z,http://arxiv.org/abs/1702.06439v1,http://arxiv.org/pdf/1702.06439v1,Admissibility in Concurrent Games,"In this paper we study the notion of admissibility for randomised strategies
in concurrent games. Intuitively an admissible strategy is one where the
player plays `as well as possible' because there is no other strategy that
dominates it i.e. that wins (almost surely) against a super set of
adversarial strategies. We prove that admissible strategies always exist in
concurrent games and we characterise them precisely. Then when the objectives
of the players are omega-regular we show how to perform assume-admissible
synthesis i.e. how to compute admissible strategies that win (almost surely)
under the hypothesis that the other players play admissible",Nicolas Basset|Gilles Geeraerts|Jean-François Raskin|Ocan Sankur,cs.GT|cs.LO
2017-02-28T17:22:05Z,2017-02-21T15:19:56Z,http://arxiv.org/abs/1702.06436v1,http://arxiv.org/pdf/1702.06436v1,"Contract-Theoretic Resource Allocation for Critical Infrastructure
  Protection","Critical infrastructure protection (CIP) is envisioned to be one of the most
challenging security problems in the coming decade. One key challenge in CIP is
the ability to allocate resources either personnel or cyber to critical
infrastructures with different vulnerability and criticality levels. In this
work a contract-theoretic approach is proposed to solve the problem of
resource allocation in critical infrastructure with asymmetric information. A
control center (CC) is used to design contracts and offer them to
infrastructures' owners. A contract can be seen as an agreement between the CC
and infrastructures using which the CC allocates resources and gets rewards in
return. Contracts are designed in a way to maximize the CC's benefit and
motivate each infrastructure to accept a contract and obtain proper resources
for its protection. Infrastructures are defined by both vulnerability levels
and criticality levels which are unknown to the CC. Therefore each
infrastructure can claim that it is the most vulnerable or critical to gain
more resources. A novel mechanism is developed to handle such an asymmetric
information while providing the optimal contract that motivates each
infrastructure to reveal its actual type. The necessary and sufficient
conditions for such resource allocation contracts under asymmetric information
are derived. Simulation results show that the proposed contract-theoretic
approach maximizes the CC's utility while ensuring that no infrastructure has
an incentive to ask for another contract despite the lack of exact information
at the CC.",AbdelRahman Eldosouky|Walid Saad|Charles Kamhoua|and Kevin Kwiat,cs.CR|cs.GT
2017-02-28T17:22:05Z,2017-02-20T21:54:26Z,http://arxiv.org/abs/1702.06189v1,http://arxiv.org/pdf/1702.06189v1,A Graphical Evolutionary Game Approach to Social Learning,"In this work we study the social learning problem in which agents of a
networked system collaborate to detect the state of the nature based on their
private signals. A novel distributed graphical evolutionary game theoretic
learning method is proposed. In the proposed game-theoretic method agents only
need to communicate their binary decisions rather than the real-valued beliefs
with their neighbors which endows the method with low communication
complexity. Under mean field approximations we theoretically analyze the
steady state equilibria of the game and show that the evolutionarily stable
states (ESSs) coincide with the decisions of the benchmark centralized
detector. Numerical experiments are implemented to confirm the effectiveness of
the proposed game-theoretic learning method.",Xuanyu Cao|K. J. Ray Liu,cs.GT
2017-02-28T17:22:05Z,2017-02-22T01:48:29Z,http://arxiv.org/abs/1702.06062v2,http://arxiv.org/pdf/1702.06062v2,Simple vs Optimal Mechanisms in Auctions with Convex Payments,"We investigate approximately optimal mechanisms in settings where bidders'
utility functions are non-linear; specifically convex with respect to
payments (such settings arise for instance in procurement auctions for
energy). We provide constant factor approximation guarantees for mechanisms
that are independent of bidders' private information (i.e. prior-free) and
for mechanisms that rely to an increasing extent on that information (i.e.
detail free). We also describe experiments which show that for randomly drawn
monotone hazard rate distributions our mechanisms achieve at least 80\% of the
optimal revenue on average. Both our theoretical and experimental results show
that in the convex payment setting it is desirable to allocate across multiple
bidders rather than only to bidders with the highest (virtual) value as in
the traditional quasi-linear utility setting.",Amy Greenwald|Takehiro Oyakawa|Vasilis Syrgkanis,cs.GT
2017-02-28T17:22:05Z,2017-02-20T00:34:00Z,http://arxiv.org/abs/1702.05825v1,http://arxiv.org/pdf/1702.05825v1,Sustainable Fair Division,"In this paper I summarize our work on online fair division. In particular I
present two models for online fair division: (1) one existing model for fair
division in food banks and (2) one new model for fair division of deceased
organs to patients. I further discuss simple mechanisms for these models that
allocate the resources as they arrive to agents. In practice agents are often
risk-averse having imperfect information. Within this assumption I report
several interesting axiomatic and complexity results for these mechanisms and
conclude with future work.",Martin Aleksandrov,cs.GT
2017-02-28T17:22:05Z,2017-02-19T18:23:47Z,http://arxiv.org/abs/1702.05778v1,http://arxiv.org/pdf/1702.05778v1,The Absent-Minded Driver Problem Redux,"This paper reconsiders the problem of the absent-minded driver who must
choose between alternatives with different payoff with imperfect recall and
varying degrees of knowledge of the system. The classical absent-minded driver
problem represents the case with limited information and it has bearing on the
general area of communication and learning social choice mechanism design
auctions theories of knowledge belief and rational agency. Within the
framework of extensive games this problem has applications to many artificial
intelligence scenarios. It is obvious that the performance of the agent
improves as information available increases. It is shown that a non-uniform
assignment strategy for successive choices does better than a fixed probability
strategy. We consider both classical and quantum approaches to the problem. We
argue that the superior performance of quantum decisions with access to
entanglement cannot be fairly compared to a classical algorithm. If the
cognitive systems of agents are taken to have access to quantum resources or
have a quantum mechanical basis then that can be leveraged into superior
performance.",Subhash Kak,cs.AI|cs.GT
2017-02-28T17:22:05Z,2017-02-18T18:23:17Z,http://arxiv.org/abs/1702.05640v1,http://arxiv.org/pdf/1702.05640v1,Obvious Strategyproofness Needs Monitoring for Good Approximations,"Obvious strategyproofness (OSP) is an appealing concept as it allows to
maintain incentive compatibility even in the presence of agents that are not
fully rational e.g. those who struggle with contingent reasoning [Li 2015].
However it has been shown to impose some limitations e.g. no OSP mechanism
can return a stable matching [Ashlagi and Gonczarowski 2015].
  We here deepen the study of the limitations of OSP mechanisms by looking at
their approximation guarantees for basic optimization problems paradigmatic of
the area i.e. machine scheduling and facility location. We prove a number of
bounds on the approximation guarantee of OSP mechanisms which show that OSP
can come at a significant cost. However rather surprisingly we prove that OSP
mechanisms can return optimal solutions when they use monitoring -- a novel
mechanism design paradigm that introduces a mild level of scrutiny on agents'
declarations [Kovacs et al. 2015].",Diodato Ferraioli|Carmine Ventre,cs.GT
2017-02-28T17:22:05Z,2017-02-17T22:39:37Z,http://arxiv.org/abs/1702.05536v1,http://arxiv.org/pdf/1702.05536v1,"Beyond the Hazard Rate: More Perturbation Algorithms for Adversarial
  Multi-armed Bandits","Recent work on follow the perturbed leader (FTPL) algorithms for the
adversarial multi-armed bandit problem has highlighted the role of the hazard
rate of the distribution generating the perturbations. Assuming that the hazard
rate is bounded it is possible to provide regret analyses for a variety of
FTPL algorithms for the multi-armed bandit problem. This paper pushes the
inquiry into regret bounds for FTPL algorithms beyond the bounded hazard rate
condition. There are good reasons to do so: natural distributions such as the
uniform and Gaussian violate the condition. We give regret bounds for both
bounded support and unbounded support distributions without assuming the hazard
rate condition. We also disprove a conjecture that the Gaussian distribution
cannot lead to a low-regret algorithm. In fact it turns out that it leads to
near optimal regret up to logarithmic factors. A key ingredient in our
approach is the introduction of a new notion called the generalized hazard
rate.",Zifan Li|Ambuj Tewari,cs.LG|cs.GT|stat.ML
2017-02-28T17:22:05Z,2017-02-17T18:52:11Z,http://arxiv.org/abs/1702.05472v1,http://arxiv.org/pdf/1702.05472v1,"Threshold Constraints with Guarantees for Parity Objectives in Markov
  Decision Processes","The beyond worst-case synthesis problem was introduced recently by Bruy\`ere
et al. [BFRR14]: it aims at building system controllers that provide strict
worst-case performance guarantees against an antagonistic environment while
ensuring higher expected performance against a stochastic model of the
environment. Our work extends the framework of [BFRR14] and follow-up papers
which focused on quantitative objectives by addressing the case of
$\omega$-regular conditions encoded as parity objectives a natural way to
represent functional requirements of systems.
  We build strategies that satisfy a main parity objective on all plays while
ensuring a secondary one with sufficient probability. This setting raises new
challenges in comparison to quantitative objectives as one cannot easily mix
different strategies without endangering the functional properties of the
system. We establish that for all variants of this problem deciding the
existence of a strategy lies in ${\sf NP} \cap {\sf coNP}$ the same complexity
class as classical parity games. Hence our framework provides additional
modeling power while staying in the same complexity class.
  [BFRR14] V\'eronique Bruy\`ere Emmanuel Filiot Mickael Randour and
Jean-Fran\c{c}ois Raskin. Meet your expectations with guarantees: Beyond
worst-case synthesis in quantitative games. In Ernst W. Mayr and Natacha
Portier editors 31st International Symposium on Theoretical Aspects of
Computer Science STACS 2014 March 5-8 2014 Lyon France volume 25 of
LIPIcs pages 199-213. Schloss Dagstuhl - Leibniz - Zentrum fuer Informatik
2014.",Raphaël Berthon|Mickael Randour|Jean-François Raskin,cs.LO|cs.AI|cs.FL|cs.GT|math.PR
2017-02-28T17:22:05Z,2017-02-25T08:57:27Z,http://arxiv.org/abs/1702.05371v2,http://arxiv.org/pdf/1702.05371v2,Distributionally Robust Games Part I: f-Divergence and Learning,"In this paper we introduce the novel framework of distributionally robust
games. These are multi-player games where each player models the state of
nature using a worst-case distribution also called adversarial distribution.
Thus each player's payoff depends on the other players' decisions and on the
decision of a virtual player (nature) who selects an adversarial distribution
of scenarios. This paper provides three main contributions. Firstly the
distributionally robust game is formulated using the statistical notions of
f-divergence between two distributions here represented by the adversarial
distribution and the exact distribution. Secondly the complexity of the
problem is significantly reduced by means of triality theory. Thirdly
stochastic Bregman learning algorithms are proposed to speedup the computation
of robust equilibria. Finally the theoretical findings are illustrated in a
convex setting and its limitations are tested with a non-convex non-concave
function.",Dario Bauso|Jian Gao|Hamidou Tembine,math.OC|cs.GT
2017-02-28T17:22:05Z,2017-02-25T09:20:25Z,http://arxiv.org/abs/1702.05361v2,http://arxiv.org/pdf/1702.05361v2,Empathy in One-Shot Prisoner Dilemma,"Strategic decision making involves affective and cognitive functions like
reasoning cognitive and emotional empathy which may be subject to age and
gender differences. However empathy-related changes in strategic
decision-making and their relation to age gender and neuropsychological
functions have not been studied widely. In this article we study a one-shot
prisoner dilemma from a psychological game theory viewpoint. Forty seven
participants (28 women and 19 men) aged 18 to 42 years were tested with a
empathy questionnaire and a one-shot prisoner dilemma questionnaire comprising
a closiness option with the other participant. The percentage of cooperation
and defection decisions was analyzed. A new empathetic payoff model was
calculated to fit the observations from the test whether multi-dimensional
empathy levels matter in the outcome. A significant level of cooperation is
observed in the experimental one-shot game. The collected data suggests that
perspective taking empathic concern and fantasy scale are strongly correlated
and have an important effect on cooperative decisions. However their effect in
the payoff is not additive. Mixed scales as well as other non-classified
subscales (25+8 out of 47) were observed from the data.",Giulia Rossi|Alain Tcheukam|Hamidou Tembine,cs.GT
2017-02-28T17:22:09Z,2017-02-25T09:23:38Z,http://arxiv.org/abs/1702.05355v2,http://arxiv.org/pdf/1702.05355v2,"How Much Does Users' Psychology Matter in Engineering Mean-Field-Type
  Games","Until now mean-field-type game theory was not focused on
cognitively-plausible models of choices in humans animals machines robots
software-defined and mobile devices strategic interactions. This work presents
some effects of users' psychology in mean-field-type games. In addition to the
traditional ""material"" payoff modelling psychological patterns are introduced
in order to better capture and understand behaviors that are observed in
engineering practice or in experimental settings. The psychological payoff
value depends upon choices mean-field states mean-field actions empathy and
beliefs. It is shown that the affective empathy enforces mean-field equilibrium
payoff equity and improves fairness between the players. It establishes
equilibrium systems for such interactive decision-making problems. Basic
empathy concepts are illustrated in several important problems in engineering
including resource sharing packet collision minimization energy markets and
forwarding in Device-to-Device communications. The work conducts also an
experiment with 47 people who have to decide whether to cooperate or not. The
basic Interpersonal Reactivity Index of empathy metrics were used to measure
the empathy distribution of each participant. Android app called Empathizer is
developed to analyze systematically the data obtained from the participants.
The experimental results reveal that the dominated strategies of the classical
game theory are not dominated any more when users' psychology is involved and
a significant level of cooperation is observed among the users who are
positively partially empathetic.",Giulia Rossi|Alain Tcheukam|Hamidou Tembine,cs.GT|cs.MA
2017-02-28T17:22:09Z,2017-02-16T19:23:12Z,http://arxiv.org/abs/1702.05119v1,http://arxiv.org/pdf/1702.05119v1,Evolutionary prisoner's dilemma games coevolving on adaptive networks,"We study a model for switching strategies in the Prisoner's Dilemma game on
adaptive networks of player pairings that coevolve as players attempt to
maximize their return. We use a node-based strategy model with each player
following one strategy (cooperate or defect) at a time with all of its
neighbors. We improve on the existing pair approximation (PA) model for this
system by using approximate master equations (AMEs). We explore the parameter
space demonstrating the accuracy of the approximation as compared with
simulations. We study two variations of this partner-switching model to
investigate the evolution predict stationary states and compare the total
utilities and other qualitative differences between these two variants.",Hsuan-Wei Lee|Nishant Malik|Peter J. Mucha,cs.SI|cs.GT|91
2017-02-28T17:22:09Z,2017-02-16T03:39:07Z,http://arxiv.org/abs/1702.04849v1,http://arxiv.org/pdf/1702.04849v1,Theoretical and Practical Advances on Smoothing for Extensive-Form Games,"Sparse iterative methods in particular first-order methods are known to be
among the most effective in solving large-scale two-player zero-sum
extensive-form games. The convergence rates of these methods depend heavily on
the properties of the distance-generating function that they are based on. We
investigate the acceleration of first-order methods for solving extensive-form
games through better design of the dilated entropy function---a class of
distance-generating functions related to the domains associated with the
extensive-form games. By introducing a new weighting scheme for the dilated
entropy function we develop the first distance-generating function for the
strategy spaces of sequential games that has no dependence on the branching
factor of the player. This result improves the convergence rate of several
first-order methods by a factor of $\Omega(b^dd)$ where $b$ is the branching
factor of the player and $d$ is the depth of the game tree.
  Thus far counterfactual regret minimization methods have been faster in
practice and more popular than first-order methods despite their
theoretically inferior convergence rates. Using our new weighting scheme and
practical tuning we show that for the first time the excessive gap technique
can be made faster than the fastest counterfactual regret minimization
algorithm CFR+ in practice.",Christian Kroer|Kevin Waugh|Fatma Kilinc-Karzan|Tuomas Sandholm,cs.GT|cs.AI
2017-02-28T17:22:09Z,2017-02-16T17:04:36Z,http://arxiv.org/abs/1702.04254v2,http://arxiv.org/pdf/1702.04254v2,"A ""Quantal Regret"" Method for Structural Econometrics in Repeated Games","We suggest a general method for inferring players' values from their actions
in repeated games. The method extends and improves upon the recent suggestion
of (Nekipelov et al. EC 2015) and is based on the assumption that players are
more likely to exhibit sequences of actions that have lower regret.
  We evaluate this ""quantal regret"" method on two different datasets from
experiments of repeated games with controlled player values: those of (Selten
and Chmura AER 2008) on a variety of two-player 2x2 games and our own
experiment on ad-auctions (Noti et al. WWW 2014). We find that the quantal
regret method is consistently and significantly more precise than either
""classic"" econometric methods that are based on Nash equilibria or the
""min-regret"" method of (Nekipelov et al. EC 2015).",Noam Nisan|Gali Noti,cs.GT
2017-02-28T17:22:09Z,2017-02-14T10:13:15Z,http://arxiv.org/abs/1702.04138v1,http://arxiv.org/pdf/1702.04138v1,Agent Failures in All-Pay Auctions,"All-pay auctions a common mechanism for various human and agent
interactions suffers like many other mechanisms from the possibility of
players' failure to participate in the auction. We model such failures and
fully characterize equilibrium for this class of games we present a symmetric
equilibrium and show that under some conditions the equilibrium is unique. We
reveal various properties of the equilibrium such as the lack of influence of
the most-likely-to-participate player on the behavior of the other players. We
perform this analysis with two scenarios: the sum-profit model where the
auctioneer obtains the sum of all submitted bids and the max-profit model of
crowdsourcing contests where the auctioneer can only use the best submissions
and thus obtains only the winning bid.
  Furthermore we examine various methods of influencing the probability of
participation such as the effects of misreporting one's own probability of
participating and how influencing another player's participation chances
changes the player's strategy.",Yoad Lewenberg|Omer Lev|Yoram Bachrach|Jeffrey S. Rosenschein,cs.GT|cs.MA
2017-02-28T17:22:09Z,2017-02-13T20:37:18Z,http://arxiv.org/abs/1702.03978v1,http://arxiv.org/pdf/1702.03978v1,Multicast Capacity Through Perfect Domination,"The capacity of wireless networks is a classic and important topic of study.
Informally the capacity of a network is simply the total amount of information
which it can transfer. In the context of models of wireless radio networks
this has usually meant the total number of point-to-point messages which can be
sent or received in one time step. This definition has seen intensive study in
recent years particularly with respect to more accurate models of radio
networks such as the SINR model. This paper is motivated by an obvious fact:
radio antennae are (at least traditionally) omnidirectional and hence
point-to-point connections are not necessarily the best definition of capacity.
To fix this we introduce a new definition of capacity as the maximum number of
messages which can be received in one round and show that this is related to a
new optimization problem we call the Maximum Perfect Dominated Set (MaxPDS)
problem. Using this relationship we give tight upper and lower bounds for
approximating the capacity. We also analyze this notion of capacity under
game-theoretic constraints giving tight bounds on both the Price of Anarchy
and the Price of Stability.",Michael Dinitz|Naomi Ephraim,cs.GT
2017-02-28T17:22:09Z,2017-02-13T04:29:14Z,http://arxiv.org/abs/1702.03627v1,http://arxiv.org/pdf/1702.03627v1,Mechanism Design in Social Networks,"This paper studies an auction design problem for a seller to sell a commodity
in a social network where each individual (the seller or a buyer) can only
communicate with her neighbors. The challenge to the seller is to design a
mechanism to incentivize the buyers who are aware of the auction to further
propagate the information to their neighbors so that more buyers will
participate in the auction and hence the seller will be able to make a higher
revenue. We propose a novel auction mechanism called information diffusion
mechanism (IDM) which incentivizes the buyers to not only truthfully report
their valuations on the commodity to the seller but also further propagate the
auction information to all their neighbors. In comparison the direct extension
of the well-known Vickrey-Clarke-Groves (VCG) mechanism in social networks can
also incentivize the information diffusion but it will decrease the seller's
revenue or even lead to a deficit sometimes. The formalization of the problem
has not yet been addressed in the literature of mechanism design and our
solution is very significant in the presence of large-scale online social
networks.",Bin Li|Dong Hao|Dengji Zhao|Tao Zhou,cs.GT
2017-02-28T17:22:09Z,2017-02-13T04:08:17Z,http://arxiv.org/abs/1702.03620v1,http://arxiv.org/pdf/1702.03620v1,Complexity of mixed equilibria in Boolean games,"Boolean games are a succinct representation of strategic games wherein a
player seeks to satisfy a formula of propositional logic by selecting a truth
assignment to a set of propositional variables under his control.
  The framework has proven popular within the multiagent community however
almost invariably the work to date has been restricted to the case of pure
strategies. Such a focus is highly restrictive as the notion of randomised play
is fundamental to the theory of strategic games -- even very simple games can
fail to have pure-strategy equilibria but every finite game has at least one
equilibrium in mixed strategies.
  To address this the present work focuses on the complexity of algorithmic
problems dealing with mixed strategies in Boolean games. The main result is
that the problem of determining whether a two-player game has an equilibrium
satisfying a given payoff constraint is NEXP-complete. Based on this result we
then demonstrate that a number of other decision problems such as the
uniqueness of an equilibrium or the satisfaction of a given formula in
equilibrium are either NEXP or coNEXP-complete. The proof techniques developed
in the course of this are then used to show that the problem of deciding
whether a given profile is in equilibrium is coNP^#P-hard and the problem of
deciding whether a Boolean game has a rational-valued equilibrium is NEXP-hard
and whether a two-player Boolean game has an irrational-valued equilibrium is
NEXP-complete. Finally we show that determining whether the value of a
two-player zero-sum game exceeds a given threshold is EXP-complete.",Egor Ianovski,cs.GT
2017-02-28T17:22:09Z,2017-02-13T03:07:49Z,http://arxiv.org/abs/1702.03615v1,http://arxiv.org/pdf/1702.03615v1,Online Prediction with Selfish Experts,"We consider the problem of binary prediction with expert advice in settings
where experts have agency and seek to maximize their credibility. This paper
makes three main contributions. First it defines a model to reason formally
about settings with selfish experts and demonstrates that ""incentive
compatible"" (IC) algorithms are closely related to the design of proper scoring
rules. Designing a good IC algorithm is easy if the designer's loss function is
quadratic but for other loss functions novel techniques are required. Second
we design IC algorithms with good performance guarantees for the absolute loss
function. Third we give a formal separation between the power of online
prediction with selfish experts and online prediction with honest experts by
proving lower bounds for both IC and non-IC algorithms. In particular with
selfish experts and the absolute loss function there is no (randomized)
algorithm for online prediction-IC or otherwise-with asymptotically vanishing
regret.",Tim Roughgarden|Okke Schrijvers,cs.GT
2017-02-28T17:22:09Z,2017-02-11T00:29:30Z,http://arxiv.org/abs/1702.04240v1,http://arxiv.org/pdf/1702.04240v1,"Prospect Theory for Enhanced Cyber-Physical Security of Drone Delivery
  Systems: A Network Interdiction Game","The use of unmanned aerial vehicles (UAVs) as delivery systems of online
goods is rapidly becoming a global norm as corroborated by Amazon's ""Prime
Air"" and Google's ""Project Wing"" projects. However the real-world deployment
of such drone delivery systems faces many cyber-physical security challenges.
In this paper a novel mathematical framework for analyzing and enhancing the
security of drone delivery systems is introduced. In this regard a zero-sum
network interdiction game is formulated between a vendor operating a drone
delivery system and a malicious attacker. In this game the vendor seeks to
find the optimal path that its UAV should follow to deliver a purchase from
the vendor's warehouse to a customer location to minimize the delivery time.
Meanwhile an attacker seeks to choose an optimal location to interdict the
potential paths of the UAVs so as to inflict cyber or physical damage to it
thus maximizing its delivery time. First the Nash equilibrium point of this
game is characterized. Then to capture the subjective behavior of both the
vendor and attacker new notions from prospect theory are incorporated into the
game. These notions allow capturing the vendor's and attacker's i) subjective
perception of attack success probabilities and ii) their disparate subjective
valuations of the achieved delivery times relative to a certain target delivery
time. Simulation results have shown that the subjective decision making of the
vendor and attacker leads to adopting risky path selection strategies which
inflict delays to the delivery thus yielding unexpected delivery times which
surpass the target delivery time set by the vendor.",Anibal Sanjab|Walid Saad|Tamer Başar,cs.GT|cs.IT|math.IT
2017-02-28T17:22:12Z,2017-02-10T01:48:40Z,http://arxiv.org/abs/1702.03037v1,http://arxiv.org/pdf/1702.03037v1,Multi-agent Reinforcement Learning in Sequential Social Dilemmas,"Matrix games like Prisoner's Dilemma have guided research on social dilemmas
for decades. However they necessarily treat the choice to cooperate or defect
as an atomic action. In real-world social dilemmas these choices are temporally
extended. Cooperativeness is a property that applies to policies not
elementary actions. We introduce sequential social dilemmas that share the
mixed incentive structure of matrix game social dilemmas but also require
agents to learn policies that implement their strategic intentions. We analyze
the dynamics of policies learned by multiple self-interested independent
learning agents each using its own deep Q-network on two Markov games we
introduce here: 1. a fruit Gathering game and 2. a Wolfpack hunting game. We
characterize how learned behavior in each domain changes as a function of
environmental factors including resource abundance. Our experiments show how
conflict can emerge from competition over shared resources and shed light on
how the sequential nature of real world social dilemmas affects cooperation.",Joel Z. Leibo|Vinicius Zambaldi|Marc Lanctot|Janusz Marecki|Thore Graepel,cs.MA|cs.AI|cs.GT|cs.LG
2017-02-28T17:22:12Z,2017-02-09T23:48:27Z,http://arxiv.org/abs/1702.03018v1,http://arxiv.org/pdf/1702.03018v1,"Counterexamples to conjectures about Subset Takeaway and counting linear
  extensions of a Boolean lattice","We study the game known as Subset Takeaway (Chomp on a hypercube) and give
unexpected answers to questions of Gale and Neyman. We show that the number of
linear extensions of the lattice of a 7-cube is
630470261306055898099742878692134361829979979674711225065761605059425237453564989302659882866111738567871048772795838071474370002961694720
(roughly $6.3 \cdot 10^{137}$).",Andries E. Brouwer|J. Daniel Christensen,"math.CO|cs.GT|91A46, 06A07"
2017-02-28T17:22:12Z,2017-02-09T17:45:02Z,http://arxiv.org/abs/1702.02915v1,http://arxiv.org/pdf/1702.02915v1,Game-Theoretic Approaches to Energy Trading: A Survey,"The global move towards producing and consuming energy in a clean efficient
and economical way along with the need for meeting rising consumer demand has
led to significant advancements in the design of the smart grid infrastructure.
However the potential of the smart grid remains limited without the
integration of renewable energy sources. Energy trading is one way forward.
This refers to the transfer of energy from an entity producing surplus energy
to one with a deficit within a certain timeframe. In this paper we present a
detailed review of the literature surrounding the application of game theoretic
(GT) methods to scenarios in energy trading. Two levels (layers) of trading are
identified and the latest achievements within them are summarised. An extensive
description of a complete GT-based energy trading framework is presented
including a taxonomy of GT and an introduction to the smart grid architecture
with a focus on renewable energy generation and energy storage. Finally we
present a critical evaluation of the current shortcomings and identify areas
for future research.",Matthias Pilz|Luluwah Al-Fagih,cs.GT
2017-02-28T17:22:12Z,2017-02-09T06:40:10Z,http://arxiv.org/abs/1702.02722v1,http://arxiv.org/pdf/1702.02722v1,Mobile Data Trading: Behavioral Economics Analysis and Algorithm Design,"Motivated by the recently launched mobile data trading markets (e.g. China
Mobile Hong Kong's 2nd exChange Market) in this paper we study the mobile data
trading problem under the future data demand uncertainty. We introduce a
brokerage-based market where sellers and buyers propose their selling and
buying quantities respectively to the trading platform that matches the
market supply and demand. To understand the users' realistic trading behaviors
a prospect theory (PT) model from behavioral economics is proposed which
includes the widely adopted expected utility theory (EUT) as a special case.
Although the PT modeling leads to a challenging non-convex optimization
problem the optimal solution can be characterized by exploiting the unimodal
structure of the objective function. Building upon our analysis we design an
algorithm to help estimate the user's risk preference and provide trading
recommendations dynamically considering the latest market and usage
information. It is shown in our simulation that the risk preferences have a
significant impact on the user's decision and outcome: a risk-averse dominant
user can guarantee a higher minimum profit in the trading while a risk-seeking
dominant user can achieve a higher maximum profit. By comparing with the EUT
benchmark it is shown that a PT user with a low reference point is more
willing to buy mobile data. Moreover when the probability of high future data
demand is low a PT user is more willing to buy mobile data due to the
probability distortion comparing with an EUT user.",Junlin Yu|Man Hon Cheung|Jianwei Huang|H. Vincent Poor,cs.GT
2017-02-28T17:22:12Z,2017-02-09T01:35:31Z,http://arxiv.org/abs/1702.04299v1,http://arxiv.org/pdf/1702.04299v1,"Cyclic Dominance in the Spatial Coevolutionary Optional Prisoner's
  Dilemma Game","This paper studies scenarios of cyclic dominance in a coevolutionary spatial
model in which game strategies and links between agents adaptively evolve over
time. The Optional Prisoner's Dilemma (OPD) game is employed. The OPD is an
extended version of the traditional Prisoner's Dilemma where players have a
third option to abstain from playing the game. We adopt an agent-based
simulation approach and use Monte Carlo methods to perform the OPD with
coevolutionary rules. The necessary conditions to break the scenarios of cyclic
dominance are also investigated. This work highlights that cyclic dominance is
essential in the sustenance of biodiversity. Moreover we also discuss the
importance of a spatial coevolutionary model in maintaining cyclic dominance in
adverse conditions.",Marcos Cardinot|Josephine Griffith|Colm O'Riordan,cs.GT|cs.MA|math.DS|physics.soc-ph
2017-02-28T17:22:12Z,2017-02-07T17:38:34Z,http://arxiv.org/abs/1702.02113v1,http://arxiv.org/pdf/1702.02113v1,Rare Nash Equilibria and the Price of Anarchy in Large Static Games,"We study a static game played by a finite number of agents in which agents
are assigned independent and identically distributed random types and each
agent minimizes its objective function by choosing from a set of admissible
actions that depends on its type. The game is anonymous in the sense that the
objective function of each agent depends on the actions of other agents only
through the empirical distribution of their type-action pairs. We study the
asymptotic behavior of Nash equilibria as the number of agents tends to
infinity first by deriving laws of large numbers characterizes almost sure
limit points of Nash equilibria in terms of so-called Cournot-Nash equilibria
of an associated nonatomic game. Our main results are large deviation
principles that characterize the probability of rare Nash equilibria and
associated conditional limit theorems describing the behavior of equilibria
conditioned on a rare event. The results cover situations when neither the
finite-player game nor the associated nonatomic game has a unique equilibrium.
In addition we study the asymptotic behavior of the price of anarchy
complementing existing worst-case bounds with new probabilistic bounds in the
context of congestion games which are used to model traffic routing in
networks.",Daniel Lacker|Kavita Ramanan,math.PR|cs.GT|math.OC
2017-02-28T17:22:12Z,2017-02-23T13:40:57Z,http://arxiv.org/abs/1702.01953v3,http://arxiv.org/pdf/1702.01953v3,"A short proof of correctness of the quasi-polynomial time algorithm for
  parity games","Recently Cristian S. Calude Sanjay Jain Bakhadyr Khoussainov Wei Li and
Frank Stephan proposed a quasi-polynomial time algorithm for parity games. This
paper proposes a short proof of correctness of their algorithm.",Hugo Gimbert|Rasmus Ibsen-Jensen,cs.FL|cs.GT
2017-02-28T17:22:12Z,2017-02-06T21:53:09Z,http://arxiv.org/abs/1702.01803v1,http://arxiv.org/pdf/1702.01803v1,"A General Framework for Evaluating Callout Mechanisms in Repeated
  Auctions","Motivated by online display ad exchanges we study a setting in which an
exchange repeatedly interacts with bidders who have quota making decisions
about which subsets of bidders are called to participate in ad-slot-specific
auctions. A bidder with quota cannot respond to more than a certain number of
calls per second. In practice random throttling is the principal solution by
which these constraints are enforced. Given the repeated nature of the
interaction with its bidders the exchange has access to data containing
information about each bidder's segments of interest. This information can be
utilized to design smarter callout mechanisms --- with the potential of
improving the exchange's long-term revenue. In this work we present a general
framework for evaluating and comparing the performance of various callout
mechanisms using historical auction data only. To measure the impact of a
callout mechanism on long-term revenue we propose a strategic model that
captures the repeated interaction between the exchange and bidders. Our model
leads us to two metrics for performance: immediate revenue impact and social
welfare. Next we present an empirical framework for estimating these two
metrics from historical data. For the baseline to compare against we consider
random throttling as well as a greedy algorithm with certain theoretical
guarantees. We propose several natural callout mechanisms and investigate them
through our framework on both synthetic and real auction data. We characterize
the conditions under which each heuristic performs well and show that in
addition to being computationally faster in practice our heuristics
consistently and significantly outperform the baselines.",Hossein Azari|William D. Heavlin|Hoda Heidari|Max Lin|Sonia Todorova,cs.GT
2017-02-28T17:22:12Z,2017-02-05T15:40:12Z,http://arxiv.org/abs/1702.01416v1,http://arxiv.org/pdf/1702.01416v1,From Bayesian to Crowdsourced Bayesian Auctions,"A strong assumption in Bayesian mechanism design is that the distributions of
the players' private types are common knowledge to the designer and the
players--the common prior assumption. An important problem that has received a
lot of attention in both economics and computer science is to repeatedly weaken
this assumption in game theory--the ""Wilson's Doctrine"". In this work we
consider for the first time in the literature multi-item auctions where the
knowledge about the players' value distributions is scattered among the players
and the seller. Each one of them privately knows some or none of the value
distributions no constraint is imposed on who knows which distributions and
the seller does not know who knows what. In such an unstructured information
setting we design mechanisms for unit-demand and additive auctions whose
expected revenue approximates that of the optimal Bayesian mechanisms by
""crowdsourcing"" the players' and the seller's knowledge. Our mechanisms are
2-step dominant-strategy truthful and the revenue increases gracefully with the
amount of knowledge the players have. In particular the revenue starts from a
constant fraction of the revenue of the best known dominant-strategy truthful
Bayesian mechanisms and approaches 100 percent of the later when the amount of
knowledge increases. Our results greatly improve the literature on the
relationship between the amount of knowledge in the system and what mechanism
design can achieve. In some sense our results show that the common prior
assumption is without much loss of generality in Bayesian auctions if one is
willing to give up a fraction of the revenue.",Jing Chen|Bo Li|Yingkai Li,cs.GT
2017-02-28T17:22:12Z,2017-02-02T17:37:44Z,http://arxiv.org/abs/1702.01017v1,http://arxiv.org/pdf/1702.01017v1,"Emergence of Distributed Coordination in the Kolkata Paise Restaurant
  Problem with Finite Information","In this paper we study a large-scale distributed coordination problem and
propose efficient adaptive strategies to solve the problem. The basic problem
is to allocate finite number of resources to individual agents such that there
is as little congestion as possible and the fraction of unutilized resources is
reduced as far as possible. In the absence of a central planner and global
information agents can employ adaptive strategies that uses only finite
knowledge about the competitors. In this paper we show that a combination of
finite information sets and reinforcement learning can increase the utilization
rate of resources substantially.",Diptesh Ghosh|Anindya S. Chakrabarti,cs.GT|q-fin.EC
2017-02-28T17:22:16Z,2017-02-02T11:07:53Z,http://arxiv.org/abs/1702.00616v1,http://arxiv.org/pdf/1702.00616v1,Competitive division of a mixed manna,"A mixed manna contains goods (that everyone likes) bads (that everyone
dislikes) as well as items that are goods to some agents but bads or satiated
to others.
  If all items are goods and utility functions are homothetic concave (and
monotone) the Competitive Equilibrium with Equal Incomes maximizes the Nash
product of utilities: hence it is welfarist (determined utility-wise by the
feasible set of profiles) single-valued and easy to compute.
  We generalize the Gale-Eisenberg Theorem to a mixed manna. The Competitive
division is still welfarist and related to the product of utilities or
disutilities. If the zero utility profile (before any manna) is Pareto
dominated the competitive profile is unique and still maximizes the product of
utilities. If the zero profile is unfeasible the competitive profiles are the
critical points of the product of disutilities on the efficiency frontier and
multiplicity is pervasive. In particular the task of dividing a mixed manna is
either good news for everyone or bad news for everyone.
  We refine our results in the practically important case of linear
preferences where the axiomatic comparison between the division of goods and
that of bads is especially sharp. When we divide goods and the manna improves
everyone weakly benefits under the competitive rule; but no reasonable rule to
divide bads can be similarly Resource Monotonic. Also the much larger set of
Non Envious and Efficient divisions of bads can be disconnected so that it will
admit no continuous selection.",Anna Bogomolnaia|Herve Moulin|Fedor Sandomirskiy|Elena Yanovskaya,"cs.GT|math.OC|91B32, 91B50, 52A41"
2017-02-28T17:22:16Z,2017-01-31T02:45:57Z,http://arxiv.org/abs/1701.08896v1,http://arxiv.org/pdf/1701.08896v1,On the Role of a Market Maker in Networked Cournot Competition,"We study Cournot competition among firms in a networked marketplace that is
centrally managed by a market maker. In particular we study a situation in
which a market maker facilitates trade between geographically separate markets
via a constrained transport network. Our focus is on understanding the
consequences of the design of the market maker and on providing tools for
optimal design. To that end we provide a characterisation of the equilibrium
outcomes of the game between firms and the market maker. Our results highlight
that the equilibrium structure is impacted dramatically by the market maker
objective - depending on the objective there may be a unique equilibrium
multiple equilibria or no equilibria. Further the game may be a potential
game (as in the case of classical Cournot competition) or not. Beyond
characterizing the equilibria of the game we provide an approach for designing
the market maker in order to optimize a design objective (e.g. social welfare)
at the equilibrium of the game. Additionally we use our results to explore the
value of transport (trade) and the efficiency of the market maker (as compared
to a single aggregate market).",Desmond Cai|Subhonmesh Bose|Adam Wierman,cs.GT
2017-02-28T17:22:16Z,2017-01-30T15:18:03Z,http://arxiv.org/abs/1701.08644v1,http://arxiv.org/pdf/1701.08644v1,"Security Game with Non-additive Utilities and Multiple Attacker
  Resources","There has been significant interest in studying security games for modeling
the interplay of attacks and defenses on various systems involving critical
infrastructure financial system security political campaigns and civil
safeguarding. However existing security game models typically either assume
additive utility functions or that the attacker can attack only one target.
Such assumptions lead to tractable analysis but miss key inherent dependencies
that exist among different targets in current complex networks. In this paper
we generalize the classical security game models to allow for non-additive
utility functions. We also allow attackers to be able to attack multiple
targets. We examine such a general security game from a theoretical perspective
and provide a unified view. In particular we show that each security game is
equivalent to a combinatorial optimization problem over a set system
$\varepsilon$ which consists of defender's pure strategy space. The key
technique we use is based on the transformation projection of a polytope and
the elipsoid method. This work settles several open questions in security game
domain and significantly extends the state of-the-art of both the polynomial
solvable and NP-hard class of the security game.",Sinong Wang|Ness Shroff,cs.GT|cs.CR
2017-02-28T17:22:16Z,2017-01-30T12:58:00Z,http://arxiv.org/abs/1701.08573v1,http://arxiv.org/pdf/1701.08573v1,Debunking van Enk-Pike's criterion for quantum games,"S. J. van Enk and R. Pike in PRA 66 024306 (2002) argue that in a quantum
game the payoff's obtained are not better than the payoffs obtained in
classical games hence they conclude that the quantum game does not solve the
classical game. In this work we debunk this criterion by showing that a random
strategy in a particular quantum (Hawk-Dove) game can give us a better payoff
than what is achievable in a classical game. In fact for a particular pure
strategy we get the maximum payoff. Moreover we provide an analytical solution
to the quantum $2\times2$ strategic form Hawk-Dove game using random mixed
strategies. The random strategies which we describe are evolutionary stable
implying both Pareto optimality and Nash equilibrium.",Nilesh Vyas|Colin Benjamin,quant-ph|cond-mat.other|cs.GT|math-ph|math.MP
2017-02-28T17:22:16Z,2017-01-27T19:08:40Z,http://arxiv.org/abs/1702.02090v1,http://arxiv.org/pdf/1702.02090v1,A Bayesian Game without epsilon equilibria,"We present a three player Bayesian game for which there is no epsilon
equilibria in Borel measurable strategies for small enough epsilon however
there are non-measurable equilibria.",Robert Samuel Simon|Grzegorz Tomkowicz,cs.GT|math.PR|91A60
2017-02-28T17:22:16Z,2017-01-27T16:37:45Z,http://arxiv.org/abs/1701.08108v1,http://arxiv.org/pdf/1701.08108v1,"Existence of Evolutionarily Stable Strategies Remains Hard to Decide for
  a Wide Range of Payoff Values","The concept of an evolutionarily stable strategy (ESS) introduced by Smith
and Price is a refinement of Nash equilibrium in 2-player symmetric games in
order to explain counter-intuitive natural phenomena whose existence is not
guaranteed in every game. The problem of deciding whether a game possesses an
ESS has been shown to be $\Sigma_{2}^{P}$-complete by Conitzer using the
preceding important work by Etessami and Lochbihler. The latter among other
results proved that deciding the existence of ESS is both NP-hard and
coNP-hard. In this paper we introduce a ""reduction robustness"" notion and we
show that deciding the existence of an ESS remains coNP-hard for a wide range
of games even if we arbitrarily perturb within some intervals the payoff values
of the game under consideration. In contrast ESS exist almost surely for large
games with random and independent payoffs chosen from the same distribution.",Themistoklis Melissourgos|Paul Spirakis,cs.CC|cs.GT|68Q01
2017-02-28T17:22:16Z,2017-01-27T14:15:12Z,http://arxiv.org/abs/1701.08058v1,http://arxiv.org/pdf/1701.08058v1,"Optimal Communication Strategies in Networked Cyber-Physical Systems
  with Adversarial Elements","This paper studies optimal communication and coordination strategies in
cyber-physical systems for both defender and attacker within a game-theoretic
framework. We model the communication network of a cyber-physical system as a
sensor network which involves one single Gaussian source observed by many
sensors subject to additive independent Gaussian observation noises. The
sensors communicate with the estimator over a coherent Gaussian multiple access
channel. The aim of the receiver is to reconstruct the underlying source with
minimum mean squared error. The scenario of interest here is one where some of
the sensors are captured by the attacker and they act as the adversary
(jammer): they strive to maximize distortion. The receiver (estimator) knows
the captured sensors but still cannot simply ignore them due to the multiple
access channel i.e. the outputs of all sensors are summed to generate the
estimator input. We show that the ability of transmitter sensors to secretly
agree on a random event that is ""coordination"" plays a key role in the
analysis...",Emrah Akyol|Kenneth Rose|Tamer Basar|Cedric Langbort,cs.GT|cs.CR|cs.IT|cs.MA|math.IT
2017-02-28T17:22:16Z,2017-01-27T12:11:12Z,http://arxiv.org/abs/1701.08023v1,http://arxiv.org/pdf/1701.08023v1,"The Condorcet Principle for Multiwinner Elections: From Shortlisting to
  Proportionality","We study two notions of stability in multiwinner elections that are based on
the Condorcet criterion. The first notion was introduced by Gehrlein: A
committee is stable if each committee member is preferred to each non-member by
a (possibly weak) majority of voters. The second notion is called local
stability (introduced in this paper): A size-$k$ committee is locally stable in
an election with $n$ voters if there is no candidate $c$ and no group of more
than $\frac{n}{k+1}$ voters such that each voter in this group prefers $c$ to
each committee member. We argue that Gehrlein-stable committees are appropriate
for shortlisting tasks and that locally stable committees are better suited
for applications that require proportional representation. The goal of this
paper is to analyze these notions in detail explore their compatibility with
notions of proportionality and investigate the computational complexity of
related algorithmic tasks.",Haris Aziz|Edith Elkind|Piotr Faliszewski|Martin Lackner|Piotr Skowron,cs.GT
2017-02-28T17:22:16Z,2017-01-27T10:02:13Z,http://arxiv.org/abs/1701.07991v1,http://arxiv.org/pdf/1701.07991v1,A Mood Value for Fair Resource Allocations,"In networking and computing resource allocation is typically addressed using
classical sharing protocols as for instance the proportional division rule
the max-min fair allocation  or other solutions inspired by cooperative game
theory. In this paper we argue that describing the resource allocation
problem as a cooperative game such classical resource allocation approaches
as well as associated notions of fairness show important limitations. We
identify in the individual satisfaction rate the key aspect of the challenge of
defining a new notion of fairness and consequently a resource allocation
algorithm more appropriate for the cooperative context. We generalize the
concept of user satisfaction considering the set of admissible solutions for
bankruptcy games. We adapt the Jain's fairness index to include the new user
satisfaction rate. Accordingly we propose a new allocation rule we call 'Mood
Value'. For each user it equalizes our novel game-theoretic definition of user
satisfaction with respect to a distribution of the resource. We test the mood
value and the new fairness index through extensive simulations showing how they
better support the fairness analysis.",Francesca Fossati|Stefano Moretti|Stefano Secci,cs.NI|cs.GT
2017-02-28T17:22:16Z,2017-01-27T06:47:02Z,http://arxiv.org/abs/1701.07956v1,http://arxiv.org/pdf/1701.07956v1,Simple approximate equilibria in games with many players,"We consider $\epsilon$-equilibria notions for constant value of $\epsilon$ in
$n$-player $m$-actions games where $m$ is a constant. We focus on the following
question: What is the largest grid size over the mixed strategies such that
$\epsilon$-equilibrium is guaranteed to exist over this grid.
  For Nash equilibrium we prove that constant grid size (that depends on
$\epsilon$ and $m$ but not on $n$) is sufficient to guarantee existence of
weak approximate equilibrium. This result implies a polynomial (in the input)
algorithm for weak approximate equilibrium.
  For approximate Nash equilibrium we introduce a closely related question and
prove its \emph{equivalence} to the well-known Beck-Fiala conjecture from
discrepancy theory. To the best of our knowledge this is the first result
introduces a connection between game theory and discrepancy theory.
  For correlated equilibrium we prove a $O(\frac{1}{\log n})$ lower-bound on
the grid size which matches the known upper bound of $\Omega(\frac{1}{\log
n})$. Our result implies an $\Omega(\log n)$ lower bound on the rate of
convergence of dynamics (any dynamic) to approximate correlated (and coarse
correlated) equilibrium. Again this lower bound matches the $O(\log n)$ upper
bound that is achieved by regret minimizing algorithms.",Itai Arieli|Yakov Babichenko,cs.GT
2017-02-28T17:22:20Z,2017-01-26T08:33:38Z,http://arxiv.org/abs/1701.07614v1,http://arxiv.org/pdf/1701.07614v1,"Tight Inefficiency Bounds for Perception-Parameterized Affine Congestion
  Games","Congestion games constitute an important class of non-cooperative games which
was introduced by Rosenthal in 1973. In recent years several extensions of
these games were proposed to incorporate aspects that are not captured by the
standard model. Examples of such extensions include the incorporation of risk
sensitive players the modeling of altruistic player behavior and the
imposition of taxes on the resources. These extensions were studied intensively
with the goal to obtain a precise understanding of the inefficiency of
equilibria of these games. In this paper we introduce a new model of
congestion games that captures these extensions (and additional ones) in a
unifying way. The key idea here is to parameterize both the perceived cost of
each player and the social cost function of the system designer. Intuitively
each player perceives the load induced by the other players by an extent of
{\rho} while the system designer estimates that each player perceives the load
of all others by an extent of {\sigma}. The above mentioned extensions reduce
to special cases of our model by choosing the parameters {\rho} and {\sigma}
accordingly. As in most related works we concentrate on congestion games with
affine latency functions here. Despite the fact that we deal with a more
general class of congestion games we manage to derive tight bounds on the
price of anarchy and the price of stability for a large range of pa- rameters.
Our bounds provide a complete picture of the inefficiency of equilibria for
these perception-parameterized congestion games. As a result we obtain tight
bounds on the price of anarchy and the price of stability for the above
mentioned extensions. Our results also reveal how one should ""design"" the cost
functions of the players in order to reduce the price of anar- chy.",Pieter Kleer|Guido Schäfer,cs.GT
2017-02-28T17:22:20Z,2017-01-25T18:44:48Z,http://arxiv.org/abs/1701.07419v1,http://arxiv.org/abs/1701.07419v1,A gentle introduction to the minimal Naming Game,"Social conventions govern countless behaviors all of us engage in every day
from how we greet each other to the languages we speak. But how can shared
conventions emerge spontaneously in the absence of a central coordinating
authority? The Naming Game model shows that networks of locally interacting
individuals can spontaneously self-organize to produce global coordination.
Here we provide a gentle introduction to the main features of the model from
the dynamics observed in homogeneously mixing populations to the role played by
more complex social networks and to how slight modifications of the basic
interaction rules give origin to a richer phenomenology in which more
conventions can co-exist indefinitely.",Andrea Baronchelli,physics.soc-ph|cs.GT|cs.MA|q-bio.PE
2017-02-28T17:22:20Z,2017-01-25T13:35:51Z,http://arxiv.org/abs/1701.07304v1,http://arxiv.org/pdf/1701.07304v1,Congestion Games with Complementarities,"We study a model of selfish resource allocation that seeks to incorporate
dependencies among resources as they exist in modern networked environments.
Our model is inspired by utility functions with constant elasticity of
substitution (CES) which is a well-studied model in economics. We consider
congestion games with different aggregation functions. In particular we study
$L_p$ norms and analyze the existence and complexity of (approximate) pure Nash
equilibria. Additionally we give an almost tight characterization based on
monotonicity properties to describe the set of aggregation functions that
guarantee the existence of pure Nash equilibria.",Matthias Feldotto|Lennart Leder|Alexander Skopalik,cs.GT
2017-02-28T17:22:20Z,2017-01-24T22:28:19Z,http://arxiv.org/abs/1701.07096v1,http://arxiv.org/abs/1701.07096v1,A new quantum scheme for normal-form games,"We give a strict mathematical description for a refinement of the
Marinatto-Weber quantum game scheme. The model allows the players to choose
projector operators that determine the state on which they perform their local
operators. The game induced by the scheme generalizes finite strategic form
game. In particular it covers normal representations of extensive games i.e.
strategic games generated by extensive ones. We illustrate our idea with an
example of extensive game and prove that rational choices in the classical game
and its quantum counterpart may lead to significantly different outcomes.",Piotr Frąckiewicz,cs.GT
2017-02-28T17:22:20Z,2017-01-24T19:47:14Z,http://arxiv.org/abs/1701.07058v1,http://arxiv.org/pdf/1701.07058v1,Computing the advertising value of users by tapping on RTB,"Online advertising is progressively moving towards a targeted model of
programmatic ad buying in which advertisers bid for ad-slots on a
per-impression basis. This model runs over the Real Time Bidding (RTB) protocol
and is driven by the information provided by a large ecosystem of data
collection companies that track users online. Concern about online tracking has
spurred a huge public debate around data protection as well as intense
innovation around personal information management systems markets and
business models. Core to all the above is being able to know the value of
users' personal information.
  In this study we develop a first of its kind methodology for computing
exactly that - the value of a single user for the programmatic ad buying
ecosystem. Our goal is to increase user awareness for the value of their data
as well as to inspire new online economies where users give access to their
data in exchange for discounted services. Our approach is based on tapping on
the RTB protocol to collect cleartext and encrypted prices for winning bids. To
estimate the value of the latter we train a machine learning model using as
ground truth prices obtained by running our own ""probe"" ad-campaigns. We
validate our methodology using a one year long trace of mobile user browsing
data as well as two real world mobile ad-campaigns.",Panagiotis Papadopoulos|Nicolas Kourtellis|Pablo Rodriguez Rodriguez|Nikolaos Laoutaris,cs.GT|cs.CY|cs.IR
2017-02-28T17:22:20Z,2017-01-24T10:53:36Z,http://arxiv.org/abs/1701.06807v1,http://arxiv.org/pdf/1701.06807v1,Linear Representation of Symmetric Games,"Using semi-tensor product of matrices the structures of several kinds of
symmetric games are investigated via the linear representation of symmetric
group in the structure vector of games as its representation space. First the
symmetry described as the action of symmetric group on payoff functions is
converted into the product of permutation matrices with structure vectors of
payoff functions. Using the linear representation of the symmetric group in
structure vectors the algebraic conditions for the ordinary weighted
renaming and name-irrelevant symmetries are obtained respectively as the
invariance under the corresponding linear representations. Secondly using the
linear representations the relationship between symmetric games and potential
games is investigated. This part is mainly focused on Boolean games. It is
proved that ordinary renaming and weighted symmetric Boolean games are also
potential ones. The corresponding potential functions are also obtained.
Finally an example is given to show that some other Boolean games could also
be potential games.",Daizhan Cheng|Ting Liu,cs.GT|math.OC
2017-02-28T17:22:20Z,2017-01-22T20:18:26Z,http://arxiv.org/abs/1701.06220v1,http://arxiv.org/pdf/1701.06220v1,"Distributed Clustering for Multiuser Networks through Coalition
  Formation","Clustering mechanisms are essential in certain multiuser networks for
achieving efficient resource utilization. This lecture note presents the theory
of coalition formation as a useful tool for distributed clustering problems. We
reveal the generality of the theory and study complexity aspects which must be
considered in multiuser networks.",Rami Mochaourab|Eduard Jorswieck|Mats Bengtsson,cs.GT|cs.IT|math.IT
2017-02-28T17:22:20Z,2017-01-21T23:25:44Z,http://arxiv.org/abs/1701.06100v1,http://arxiv.org/pdf/1701.06100v1,Strong isomorphism in Marinatto-Weber type quantum games,"Our purpose is to focus attention on a new criterion for quantum schemes by
bringing together the notions of quantum game and game isomorphism. A quantum
game scheme is required to generate the classical game as a special case. Now
given a quantum game scheme and two isomorphic classical games we additionally
require the resulting quantum games to be isomorphic as well. We show how this
isomorphism condition influences the players' strategy sets. We are concerned
with the Marinatto-Weber type quantum game scheme and the strong isomorphism
between games in strategic form.",Piotr Frąckiewicz,cs.GT|quant-ph
2017-02-28T17:22:20Z,2017-01-21T15:22:51Z,http://arxiv.org/abs/1701.06038v1,http://arxiv.org/pdf/1701.06038v1,"Asymptotic efficiency of the proportional compensation scheme for a
  large number of producers","We consider a manager who allocates some fixed total payment amount between
$N$ rational agents in order to maximize the aggregate production. The profit
of $i$-th agent is the difference between the compensation (reward) obtained
from the manager and the production cost. We compare (i) the \emph{normative}
compensation scheme where the manager enforces the agents to follow an optimal
cooperative strategy; (ii) the \emph{linear piece rates} compensation scheme
where the manager announces an optimal reward per unit good; (iii) the
\emph{proportional} compensation scheme where agent's reward is proportional
to his contribution to the total output. Denoting the correspondent total
production levels by $s^*$ $\hat s$ and $\overline s$ respectively where the
last one is related to the unique Nash equilibrium we examine the limits of
the prices of anarchy $\mathscr A_N=s^*/\overline s$ $\mathscr A_N'=\hat
s/\overline s$ as $N\to\infty$. These limits are calculated for the cases of
identical convex costs with power asymptotics at the origin and for power
costs corresponding to the Coob-Douglas and generalized CES production
functions with decreasing returns to scale. Our results show that
asymptotically no performance is lost in terms of $\mathscr A'_N$ and in terms
of $\mathscr A_N$ the loss does not exceed $31\%$.",Dmitry B. Rokhlin|Anatoly Usov,"q-fin.EC|cs.GT|91B32, 91B40, 91B38"
2017-02-28T17:22:20Z,2017-01-20T23:24:39Z,http://arxiv.org/abs/1701.05948v1,http://arxiv.org/pdf/1701.05948v1,Sponsored Search Auctions with Rich Ads,"The generalized second price (GSP) auction has served as the core selling
mechanism for sponsored search ads for over a decade. However recent trends
expanding the set of allowed ad formats---to include a variety of sizes
decorations and other distinguishing features---have raised critical problems
for GSP-based platforms. Alternatives such as the Vickrey-Clarke-Groves (VCG)
auction raise different complications because they fundamentally change the way
prices are computed. In this paper we report on our efforts to redesign a
search ad selling system from the ground up in this new context proposing a
mechanism that optimizes an entire slate of ads globally and computes prices
that achieve properties analogous to those held by GSP in the original simpler
setting of uniform ads. A careful algorithmic coupling of
allocation-optimization and pricing-computation allows our auction to operate
within the strict timing constraints inherent in real-time ad auctions. We
report performance results of the auction in Yahoo's Gemini Search platform.",Ruggiero Cavallo|Prabhakar Krishnamurthy|Maxim Sviridenko|Christopher A. Wilkens,cs.GT
2017-02-28T17:22:24Z,2017-01-20T23:10:37Z,http://arxiv.org/abs/1701.05946v1,http://arxiv.org/pdf/1701.05946v1,GSP - The Cinderella of Mechanism Design,"Nearly fifteen years ago Google unveiled the generalized second price (GSP)
auction. By all theoretical accounts including their own [Varian 14] this was
the wrong auction --- the Vickrey-Clarke-Groves (VCG) auction would have been
the proper choice --- yet GSP has succeeded spectacularly.
  We give a deep justification for GSP's success: advertisers' preferences map
to a model we call value maximization they do not maximize profit as the
standard theory would believe. For value maximizers GSP is the truthful
auction [Aggarwal 09]. Moreover this implies an axiomatization of GSP --- it
is an auction whose prices are truthful for value maximizers --- that can be
applied much more broadly than the simple model for which GSP was originally
designed. In particular applying it to arbitrary single-parameter domains
recovers the folklore definition of GSP. Through the lens of value
maximization GSP metamorphosizes into a powerful auction sound in its
principles and elegant in its simplicity.",Christopher A. Wilkens|Ruggiero Cavallo|Rad Niazadeh,cs.GT
2017-02-28T17:22:24Z,2017-01-20T16:12:01Z,http://arxiv.org/abs/1701.05842v1,http://arxiv.org/pdf/1701.05842v1,A game theoretic approach to a network cloud storage problem,"The use of game theory in the design and control of large scale networked
systems is becoming increasingly more important. In this paper we follow this
approach to efficiently solve a network allocation problem motivated by
peer-to- peer cloud storage models as alternatives to classical centralized
cloud storage services. To this aim we propose an allocation algorithm that
allows the units to use their neighbors to store a back up of their data. We
prove convergence characterize the final allocation and corroborate our
analysis with extensive numerical simulation that shows the good performance of
the algorithm in terms of scalability complexity and structure of the
solution.",Fabio Fagnani|Barbara Franci,math.OC|cs.GT
2017-02-28T17:22:24Z,2017-01-19T22:40:36Z,http://arxiv.org/abs/1701.05633v1,http://arxiv.org/abs/1701.05633v1,Strong isomorphism in Eisert-Wilkens-Lewenstein type quantum games,"The aim of this paper is to bring together the notions of quantum game and
game isomorphism. The work is intended as an attempt to introduce a new
criterion for quantum game schemes. The generally accepted requirement forces a
quantum scheme to generate the classical game in a particular case. Now given
a quantum game scheme and two isomorphic classical games we additionally
require the resulting quantum games to be isomorphic as well. We are concerned
with the Eisert-Wilkens-Lewenstein quantum game scheme and the strong
isomorphism between games in strategic form.",Piotr Frackiewicz,cs.GT|quant-ph
2017-02-28T17:22:24Z,2017-01-18T19:57:36Z,http://arxiv.org/abs/1701.05219v1,http://arxiv.org/pdf/1701.05219v1,"Risk-aware dynamic reserve prices of programmatic guarantee in display
  advertising","Display advertising is an important online advertising type where banner
advertisements (shortly ad) on websites are usually measured by how many times
they are viewed by online users. There are two major channels to sell ad views.
They can be auctioned off in real time or be directly sold through guaranteed
contracts in advance. The former is also known as real-time bidding (RTB) in
which media buyers come to a common marketplace to compete for a single ad view
and this inventory will be allocated to a buyer in milliseconds by an auction
model. Unlike RTB buying and selling guaranteed contracts are not usually
programmatic but through private negotiations as advertisers would like to
customise their requests and purchase ad views in bulk. In this paper we
propose a simple model that facilitates the automation of direct sales. In our
model a media seller puts future ad views on sale and receives buy requests
sequentially over time until the future delivery period. The seller maintains a
hidden yet dynamically changing reserve price in order to decide whether to
accept a buy request or not. The future supply and demand are assumed to be
well estimated and static and the model's revenue management is using
inventory control theory where each computed reverse price is based on the
updated supply and demand and the unsold future ad views will be auctioned off
in RTB to the meet the unfulfilled demand. The model has several desirable
properties. First it is not limited to the demand arrival assumption. Second
it will not affect the current equilibrium between RTB and direct sales as
there are no posted guaranteed prices. Third the model uses the expected
revenue from RTB as a lower bound for inventory control and we show that a
publisher can receive expected total revenue greater than or equal to those
from only RTB if she uses the computed dynamic reserves prices for direct
sales.",Bowei Chen,cs.GT
2017-02-28T17:22:24Z,2017-01-18T15:59:42Z,http://arxiv.org/abs/1701.05125v1,http://arxiv.org/pdf/1701.05125v1,"Caching Meets Millimeter Wave Communications for Enhanced Mobility
  Management in 5G Networks","One of the most promising approaches to overcome the uncertainty and dynamic
channel variations of millimeter wave (mmW) communications is to deploy
dual-mode base stations that integrate both mmW and microwave ($\mu$W)
frequencies. If properly designed such dual-mode base stations can enhance
mobility and handover in highly mobile wireless environments. In this paper a
novel approach for analyzing and managing mobility in joint $\mu$W-mmW networks
is proposed. The proposed approach leverages device-level caching along with
the capabilities of dual-mode base stations to minimize handover failures
reduce inter-frequency measurement energy consumption and provide seamless
mobility in emerging dense heterogeneous networks. First fundamental results
on the caching capabilities including caching probability and cache duration
are derived for the proposed dual-mode network scenario. Second the average
achievable rate of caching is derived for mobile users. Third the proposed
cache-enabled mobility management problem is formulated as a dynamic matching
game between mobile user equipments (MUEs) and small base stations (SBSs). The
goal of this game is to find a distributed handover mechanism that subject to
the network constraints on HOFs and limited cache sizes allows each MUE to
choose between executing an HO to a target SBS being connected to the
macrocell base station (MBS) or perform a transparent HO by using the cached
content. The formulated matching game allows capturing the dynamics of the
mobility management problem caused by HOFs. To solve this dynamic matching
problem a novel algorithm is proposed and its convergence to a two-sided
dynamically stable HO policy is proved. Numerical results corroborate the
analytical derivations and show that the proposed solution will provides
significant reductions in both the HOF and energy consumption by MUEs.",Omid Semiari|Walid Saad|Mehdi Bennis,cs.GT|cs.IT|math.IT
2017-02-28T17:22:24Z,2017-01-17T21:16:43Z,http://arxiv.org/abs/1701.04870v1,http://arxiv.org/pdf/1701.04870v1,"Positive feedback in coordination games: stochastic evolutionary
  dynamics and the logit choice rule","We show that under the logit dynamics positive feedback among agents (also
called bandwagon property) induces evolutionary paths along which agents repeat
the same actions consecutively so as to minimize the payoff loss incurred by
the feedback effects. In particular for paths escaping the domain of
attraction of a given equilibrium-called a convention-positive feedback implies
that along the minimum cost escaping paths agents always switch first from the
status quo convention strategy before switching from other strategies. In
addition the relative strengths of positive feedback effects imply that the
same transitions occur repeatedly in the cost minimizing escape paths. By
combining these two effects we show that in an escaping transition from one
convention to another the least unlikely escape paths from the status quo
convention consist of only the repeated identical mistakes of agents. Using our
results on the exit problem we then characterize the stochastically stable
states under the logit choice rule for a class of non-potential games with an
arbitrary number of strategies.",Sung-Ha Hwang|Luc Rey-Bellet,cs.GT
2017-02-28T17:22:24Z,2017-01-17T17:25:06Z,http://arxiv.org/abs/1701.04776v1,http://arxiv.org/pdf/1701.04776v1,Equilibrium and efficient clustering of arrival times to a queue,"We consider a game of decentralized timing of jobs to a single server
(machine) with a penalty for deviation from some due date and no delay costs.
The jobs sizes are homogeneous and deterministic. Each job belongs to a single
decision maker a customer who aims to arrive at a time that minimizes his
deviation penalty. If multiple customers arrive at the same time then their
order is determined by a uniform random draw. If the cost function has a
weighted absolute deviation form then any Nash equilibrium is pure and
symmetric that is all customers arrive together. Furthermore we show that
there exist multiple in fact a continuum of equilibrium arrival times and
provide necessary and sufficient conditions for the socially optimal arrival
time to be an equilibrium. The base model is solved explicitly but the
prevalence of a pure symmetric equilibrium is shown to be robust to several
relaxations of the assumptions: inclusion of small waiting costs stochastic
job sizes random sized population heterogeneous due dates and non-linear
deviation penalties.",Amihai Glazer|Refael Hassin|Liron Ravner,cs.GT
2017-02-28T17:22:24Z,2017-01-17T09:05:30Z,http://arxiv.org/abs/1701.04577v1,http://arxiv.org/pdf/1701.04577v1,"Optimal Distributed Channel Assignment in D2D Networks Using Learning in
  Noisy Potential Games","We present a novel solution for Channel Assignment Problem (CAP) in
Device-to-Device (D2D) wireless networks that takes into account the throughput
estimation noise. CAP is known to be NP-hard in the literature and there is no
practical optimal learning algorithm that takes into account the estimation
noise. In this paper we first formulate the CAP as a stochastic optimization
problem to maximize the expected sum data rate. To capture the estimation
noise CAP is modeled as a noisy potential game a novel notion we introduce in
this paper. Then we propose a distributed Binary Log-linear Learning Algorithm
(BLLA) that converges to the optimal channel assignments. Convergence of BLLA
is proved for bounded and unbounded noise. Proofs for fixed and decreasing
temperature parameter of BLLA are provided. A sufficient number of estimation
samples is given that guarantees the convergence to the optimal state. We
assess the performance of BLLA by extensive simulations which show that the
sum data rate increases with the number of channels and users. Contrary to the
better response algorithm the proposed algorithm achieves the optimal channel
assignments distributively even in presence of estimation noise.",Mohd. Shabbir Ali|Pierre Coucheney|Marceau Coupechoux,cs.NI|cs.GT|cs.IT|math.IT
2017-02-28T17:22:24Z,2017-01-17T08:21:00Z,http://arxiv.org/abs/1701.04562v1,http://arxiv.org/pdf/1701.04562v1,"A Game-Theoretic Model for Analysis and Design of Self-Organization
  Mechanisms in IoT","We propose a framework based on Network Formation Game for self-organization
in the Internet of Things (IoT) in which heterogeneous and multi-interface
nodes are modeled as self-interested agents who individually decide on
establishment and severance of links to other agents. Through analysis of the
static game we formally confirm the emergence of realistic topologies from our
model and analytically establish the criteria that lead to stable multi-hop
network structures.",Vahid Behzadan|Banafsheh Rekabdar,cs.GT|cs.NI
2017-02-28T17:22:24Z,2017-01-14T13:47:52Z,http://arxiv.org/abs/1701.03922v1,http://arxiv.org/pdf/1701.03922v1,"Computing Resource Allocation in Three-Tier IoT Fog Networks: a Joint
  Optimization Approach Combining Stackelberg Game and Matching","Fog computing is a promising architecture to provide economic and low latency
data services for future Internet of things (IoT)-based network systems. It
relies on a set of low-power fog nodes that are close to the end users to
offload the services originally targeting at cloud data centers. In this paper
we consider a specific fog computing network consisting of a set of data
service operators (DSOs) each of which controls a set of fog nodes to provide
the required data service to a set of data service subscribers (DSSs). How to
allocate the limited computing resources of fog nodes (FNs) to all the DSSs to
achieve an optimal and stable performance is an important problem. In this
paper we propose a joint optimization framework for all FNs DSOs and DSSs to
achieve the optimal resource allocation schemes in a distributed fashion. In
the framework we first formulate a Stackelberg game to analyze the pricing
problem for the DSOs as well as the resource allocation problem for the DSSs.
Under the scenarios that the DSOs can know the expected amount of resource
purchased by the DSSs a many-to-many matching game is applied to investigate
the pairing problem between DSOs and FNs. Finally within the same DSO we
apply another layer of many-to-many matching between each of the paired FNs and
serving DSSs to solve the FN-DSS pairing problem. Simulation results show that
our proposed framework can significantly improve the performance of the
IoT-based network systems.",Huaqing Zhang|Yong Xiao|Shengrong Bu|Dusit Niyato|Richard Yu|Zhu Han,cs.GT|cs.DC
2017-02-28T17:22:28Z,2017-01-31T13:10:54Z,http://arxiv.org/abs/1701.03716v2,http://arxiv.org/pdf/1701.03716v2,Optimal Reachability in Divergent Weighted Timed Games,"Weighted timed games are played by two players on a timed automaton equipped
with weights: one player wants to minimise the accumulated weight while
reaching a target while the other has an opposite objective. Used in a
reactive synthesis perspective this quantitative extension of timed games
allows one to measure the quality of controllers. Weighted timed games are
notoriously difficult and quickly undecidable even when restricted to
non-negative weights. Decidability results exist for subclasses of one-clock
games and for a subclass with non-negative weights defined by a semantical
restriction on the weights of cycles. In this work we introduce the class of
divergent weighted timed games as a generalisation of this semantical
restriction to arbitrary weights. We show how to compute their optimal value
yielding the first decidable class of weighted timed games with negative
weights and an arbitrary number of clocks. In addition we prove that
divergence can be decided in polynomial space. Last we prove that for untimed
games this restriction yields a class of games for which the value can be
computed in polynomial time.",Damien Busatto-Gaston|Benjamin Monmege|Pierre-Alain Reynier,cs.GT
2017-02-28T17:22:28Z,2017-01-13T01:08:35Z,http://arxiv.org/abs/1701.03537v1,http://arxiv.org/pdf/1701.03537v1,Perishability of Data: Dynamic Pricing under Varying-Coefficient Models,"We consider a firm that sells a large number of products to its customers in
an online fashion. Each product is described by a high dimensional feature
vector and the market value of a product is assumed to be linear in the values
of its features. Parameters of the valuation model are unknown and can change
over time. The firm sequentially observes a product's features and can use the
historical sales data (binary sale/no sale feedbacks) to set the price of
current product with the objective of maximizing the collected revenue. We
measure the performance of a dynamic pricing policy via regret which is the
expected revenue loss compared to a clairvoyant that knows the sequence of
model parameters in advance.
  We propose a pricing policy based on projected stochastic gradient descent
(PSGD) and characterize its regret in terms of time $T$ features dimension
$d$ and the temporal variability in the model parameters $\delta_t$. We
consider two settings. In the first one feature vectors are chosen
antagonistically by nature and we prove that the regret of PSGD pricing policy
is of order $O(\sqrt{T} + \sum_{t=1}^T \sqrt{t}\delta_t)$. In the second
setting (referred to as stochastic features model) the feature vectors are
drawn independently from an unknown distribution. We show that in this case
the regret of PSGD pricing policy is of order $O(d^2 \log T + \sum_{t=1}^T
t\delta_t)$.",Adel Javanmard,cs.GT|cs.LG|stat.ML
2017-02-28T17:22:28Z,2017-01-12T13:55:46Z,http://arxiv.org/abs/1701.03341v1,http://arxiv.org/pdf/1701.03341v1,Price dynamics on a risk-averse market with asymmetric information,"A market with asymmetric information can be viewed as a repeated exchange
game between the informed sector and the uninformed one. In a market with
risk-neutral agents De Meyer [2010] proves that the price process should be a
particular kind of Brownian martingale called CMMV. This type of dynamics is
due to the strategic use of their private information by the informed agents.
In the current paper we consider the more realistic case where agents on the
market are risk-averse. This case is much more complex to analyze as it leads
to a non-zero-sum game. Our main result is that the price process is still a
CMMV under a martingale equivalent measure. This paper provides thus a
theoretical justification for the use of the CMMV class of dynamics in
financial analysis. This class contains as a particular case the Black and
Scholes dynamics.",Bernard De Meyer|Gaëtan Fournier,math.OC|cs.GT
2017-02-28T17:22:28Z,2017-01-12T13:46:58Z,http://arxiv.org/abs/1701.03340v1,http://arxiv.org/pdf/1701.03340v1,"Reactive Power Compensation Game under Prospect-Theoretic Framing
  Effects","Reactive power compensation is an important challenge in current and future
smart power systems. However in the context of reactive power compensation
most existing studies assume that customers can assess their compensation
value i.e. Var unit objectively. In this paper customers are assumed to
make decisions that pertain to reactive power coordination. In consequence the
way in which those customers evaluate the compensation value resulting from
their individual decisions will impact the overall grid performance. In
particular a behavioral framework based on the framing effect of prospect
theory (PT) is developed to study the effect of both objective value and
subjective evaluation in a reactive power compensation game. For example such
effect allows customers to optimize a subjective value of their utility which
essentially frames the objective utility with respect to a reference point.
This game enables customers to coordinate the use of their electrical devices
to compensate reactive power. For the proposed game both the objective case
using expected utility theory (EUT) and the PT consideration are solved via a
learning algorithm that converges to a mixed-strategy Nash equilibrium. In
addition several key properties of this game are derived analytically.
Simulation results show that under PT customers are likely to make decisions
that differ from those predicted by classical models. For instance using an
illustrative two-customer case we show that a PT customer will increase the
conservative strategy (achieving a high power factor) by 29% compared to a
conventional customer. Similar insights are also observed for a case with three
customers.",Yunpeng Wang|Walid Saad|Arif I. Sarwat|Choong Seon Hong,cs.GT
2017-02-28T17:22:28Z,2017-01-11T09:48:53Z,http://arxiv.org/abs/1701.02903v1,http://arxiv.org/pdf/1701.02903v1,On Delay and Regret Determinization of Max-Plus Automata,"Decidability of the determinization problem for weighted automata over the
semiring $(\mathbb{Z} \cup {-\infty} \max +)$ WA for short is a
long-standing open question. We propose two ways of approaching it by
constraining the search space of deterministic WA: k-delay and r-regret. A WA N
is k-delay determinizable if there exists a deterministic automaton D that
defines the same function as N and for all words {\alpha} in the language of N
the accepting run of D on {\alpha} is always at most k-away from a maximal
accepting run of N on {\alpha}. That is along all prefixes of the same length
the absolute difference between the running sums of weights of the two runs is
at most k. A WA N is r-regret determinizable if for all words {\alpha} in its
language its non-determinism can be resolved on the fly to construct a run of
N such that the absolute difference between its value and the value assigned to
{\alpha} by N is at most r.
  We show that a WA is determinizable if and only if it is k-delay
determinizable for some k. Hence deciding the existence of some k is as
difficult as the general determinization problem. When k and r are given as
input the k-delay and r-regret determinization problems are shown to be
EXPtime-complete. We also show that determining whether a WA is r-regret
determinizable for some r is in EXPtime.",Emmanuel Filiot|Ismaël Jecker|Nathan Lhote|Guillermo A. Pérez|Jean-François Raskin,cs.FL|cs.GT|cs.LO
2017-02-28T17:22:28Z,2017-01-12T01:37:39Z,http://arxiv.org/abs/1701.02490v2,http://arxiv.org/abs/1701.02490v2,Real-Time Bidding by Reinforcement Learning in Display Advertising,"The majority of online display ads are served through real-time bidding (RTB)
--- each ad display impression is auctioned off in real-time when it is just
being generated from a user visit. To place an ad automatically and optimally
it is critical for advertisers to devise a learning algorithm to cleverly bid
an ad impression in real-time. Most previous works consider the bid decision as
a static optimization problem of either treating the value of each impression
independently or setting a bid price to each segment of ad volume. However the
bidding for a given ad campaign would repeatedly happen during its life span
before the budget runs out. As such each bid is strategically correlated by
the constrained budget and the overall effectiveness of the campaign (e.g. the
rewards from generated clicks) which is only observed after the campaign has
completed. Thus it is of great interest to devise an optimal bidding strategy
sequentially so that the campaign budget can be dynamically allocated across
all the available impressions on the basis of both the immediate and future
rewards. In this paper we formulate the bid decision process as a
reinforcement learning problem where the state space is represented by the
auction information and the campaign's real-time parameters while an action is
the bid price to set. By modeling the state transition via auction competition
we build a Markov Decision Process framework for learning the optimal bidding
policy to optimize the advertising performance in the dynamic real-time bidding
environment. Furthermore the scalability problem from the large real-world
auction volume and campaign budget is well handled by state value approximation
using neural networks.",Han Cai|Kan Ren|Weinan Zhang|Kleanthis Malialis|Jun Wang|Yong Yu|Defeng Guo,cs.LG|cs.AI|cs.GT
2017-02-28T17:22:28Z,2017-01-20T11:44:39Z,http://arxiv.org/abs/1701.02433v2,http://arxiv.org/abs/1701.02433v2,Managing Risk of Bidding in Display Advertising,"In this paper we deal with the uncertainty of bidding for display
advertising. Similar to the financial market trading real-time bidding (RTB)
based display advertising employs an auction mechanism to automate the
impression level media buying; and running a campaign is no different than an
investment of acquiring new customers in return for obtaining additional
converted sales. Thus how to optimally bid on an ad impression to drive the
profit and return-on-investment becomes essential. However the large
randomness of the user behaviors and the cost uncertainty caused by the auction
competition may result in a significant risk from the campaign performance
estimation. In this paper we explicitly model the uncertainty of user
click-through rate estimation and auction competition to capture the risk. We
borrow an idea from finance and derive the value at risk for each ad display
opportunity. Our formulation results in two risk-aware bidding strategies that
penalize risky ad impressions and focus more on the ones with higher expected
return and lower risk. The empirical study on real-world data demonstrates the
effectiveness of our proposed risk-aware bidding strategies: yielding profit
gains of 15.4% in offline experiments and up to 17.5% in an online A/B test on
a commercial RTB platform over the widely applied bidding strategies.",Haifeng Zhang|Weinan Zhang|Yifei Rong|Kan Ren|Wenxin Li|Jun Wang,cs.GT
2017-02-28T17:22:28Z,2017-01-23T08:57:55Z,http://arxiv.org/abs/1701.02396v2,http://arxiv.org/pdf/1701.02396v2,Generalizations of Divisor Methods to Approval and Score Voting,"We introduce several electoral systems for multi-winner elections with
approval ballots generalizing the classical methods of Sainte-Lagu\""e and
D'Hondt. Our approach is based on the works of Phragm\'en and Thiele. In the
last section we discuss possible generalizations to score voting.",Martin Djukanović,"cs.GT|91B12, 91B14"
2017-02-28T17:22:28Z,2017-01-09T23:00:36Z,http://arxiv.org/abs/1701.02384v1,http://arxiv.org/pdf/1701.02384v1,The Impact of Small-Cell Bandwidth Requirements on Strategic Operators,"Small-cell deployment in licensed and unlicensed spectrum is considered to be
one of the key approaches to cope with the ongoing wireless data demand
explosion. Compared to traditional cellular base stations with large
transmission power small-cells typically have relatively low transmission
power which makes them attractive for some spectrum bands that have strict
power regulations for example the 3.5GHz band [1]. In this paper we consider
a heterogeneous wireless network consisting of one or more service providers
(SPs). Each SP operates in both macro-cells and small-cells and provides
service to two types of users: mobile and fixed. Mobile users can only
associate with macro-cells whereas fixed users can connect to either macro- or
small-cells. The SP charges a price per unit rate for each type of service.
Each SP is given a fixed amount of bandwidth and splits it between macro- and
small-cells. Motivated by bandwidth regulations such as those for the 3.5Gz
band we assume a minimum amount of bandwidth has to be set aside for
small-cells. We study the optimal pricing and bandwidth allocation strategies
in both monopoly and competitive scenarios. In the monopoly scenario the
strategy is unique. In the competitive scenario there exists a unique Nash
equilibrium which depends on the regulatory constraints. We also analyze the
social welfare achieved and compare it to that without the small-cell
bandwidth constraints. Finally we discuss implications of our results on the
effectiveness of the minimum bandwidth constraint on influencing small-cell
deployments.",Cheng Chen|Randall A. Berry|Michael L. Honig|Vijay G. Subramanian,cs.IT|cs.GT|cs.NI|math.IT
2017-02-28T17:22:28Z,2017-01-09T13:26:22Z,http://arxiv.org/abs/1701.02168v1,http://arxiv.org/pdf/1701.02168v1,Games with Costs and Delays,"We demonstrate the usefulness of adding delay to infinite games with
quantitative winning conditions. In a delay game one of the players may delay
her moves to obtain a lookahead on her opponent's moves. We show that
determining the winner of delay games with winning conditions given by parity
automata with costs is EXPTIME-complete and that exponential bounded lookahead
is both sufficient and in general necessary. Thus although the parity
condition with costs is a quantitative extension of the parity condition our
results show that adding costs does not increase the complexity of delay games
with parity conditions.
  Furthermore we study a new phenomenon that appears in quantitative delay
games: lookahead can be traded for the quality of winning strategies and vice
versa. We determine the extent of this tradeoff. In particular even the
smallest lookahead allows to improve the quality of an optimal strategy from
the worst possible value to almost the smallest possible one. Thus the benefit
of introducing lookahead is twofold: not only does it allow the delaying player
to win games she would lose without but lookahead also allows her to improve
the quality of her winning strategies in games she wins even without lookahead.",Martin Zimmermann,cs.GT|cs.FL
2017-02-28T17:22:31Z,2017-01-08T14:32:54Z,http://arxiv.org/abs/1701.01963v1,http://arxiv.org/pdf/1701.01963v1,"Resource Management in Cloud Networking Using Economic Analysis and
  Pricing Models: A Survey","This paper presents a comprehensive literature review on applications of
economic and pricing models for resource management in cloud networking. To
achieve sustainable profit advantage cost reduction and flexibility in
provisioning of cloud resources resource management in cloud networking
requires adaptive and robust designs to address many issues e.g. resource
allocation bandwidth reservation request allocation and workload allocation.
Economic and pricing models have received a lot of attention as they can lead
to desirable performance in terms of social welfare fairness truthfulness
profit user satisfaction and resource utilization. This paper reviews
applications of the economic and pricing models to develop adaptive algorithms
and protocols for resource management in cloud networking. Besides we survey a
variety of incentive mechanisms using the pricing strategies in sharing
resources in edge computing. In addition we consider using pricing models in
cloud-based Software Defined Wireless Networking (cloud-based SDWN). Finally
we highlight important challenges open issues and future research directions
of applying economic and pricing models to cloud networking",Nguyen Cong Luong|Ping Wang|Dusit Niyato|Wen Yonggang|Zhu Han,cs.GT|cs.DC|cs.NI
2017-02-28T17:22:31Z,2017-01-07T09:48:28Z,http://arxiv.org/abs/1701.01810v1,http://arxiv.org/pdf/1701.01810v1,"Urban Rail Transit System Operation Optimization A Game Theoretical
  Methodology","The Urban Rail Transit (URT) has been one of the major trip modes in cities
worldwide. As the passengers arrive at variable rates in different time slots
e.g. rush and non-rush hours the departure frequency at a site directly
relates to perceived service quality of passengers; the high departure
frequency however incurs more operation cost to URT. Therefore a tradeoff
between the interest of railway operator and the service quality of passengers
needs to be addressed. In this paper we develop a model on the operation
method of train operation scheduling using a Stackelberg game model. The
railway operator is modeled as the game leader and the passengers as the game
follower and an optimal departure frequency can be determine the tradeoff
between passengers' service quality and operation cost. We present several
numerical examples based on the operation data from Nanjing transit subway at
China. The results demonstrate that the proposed model can significantly
improve the traffic efficiency.",Jiao Ma|Changle Li|Weiwei Dong|Zhe Liu|Tom H. Luan|Lina Zhu|Lei Xiong,cs.GT
2017-02-28T17:22:31Z,2017-01-06T16:07:10Z,http://arxiv.org/abs/1701.01677v1,http://arxiv.org/pdf/1701.01677v1,The Shapley Value of Digraph Games,"In this paper the Shapley value of digraph (directed graph) games are
considered. Digraph games are transferable utility (TU) games with limited
cooperation among players where players are represented by nodes. A
restrictive relation between two adjacent players is established by a directed
line segment. Directed line segments connecting the initial player with the
terminal player form the coalition among players. Dominance relation is
established between players and this relation determines whether or not a
player wants to cooperate. To cooperate we assume player joins coalition where
he/she is not dominated by any other players. The Shapley value is defines as
the average of marginal contribution vectors corresponding to all permutations
that do not violate the subordination of players. The Shapley value for various
digraph games is calculated and analyzed. For a given characteristic function
a quick way to calculated Shapley values is formulated.",Krishna Khatri,cs.GT|q-fin.EC|91A43
2017-02-28T17:22:31Z,2017-01-06T03:27:16Z,http://arxiv.org/abs/1701.01533v1,http://arxiv.org/pdf/1701.01533v1,CENTURION: Incentivizing Multi-Requester Mobile Crowd Sensing,"The recent proliferation of increasingly capable mobile devices has given
rise to mobile crowd sensing (MCS) systems that outsource the collection of
sensory data to a crowd of participating workers that carry various mobile
devices. Aware of the paramount importance of effectively incentivizing
participation in such systems the research community has proposed a wide
variety of incentive mechanisms. However different from most of these existing
mechanisms which assume the existence of only one data requester we consider
MCS systems with multiple data requesters which are actually more common in
practice. Specifically our incentive mechanism is based on double auction and
is able to stimulate the participation of both data requesters and workers. In
real practice the incentive mechanism is typically not an isolated module but
interacts with the data aggregation mechanism that aggregates workers' data.
For this reason we propose CENTURION a novel integrated framework for
multi-requester MCS systems consisting of the aforementioned incentive and
data aggregation mechanism. CENTURION's incentive mechanism satisfies
truthfulness individual rationality computational efficiency as well as
guaranteeing non-negative social welfare and its data aggregation mechanism
generates highly accurate aggregated results. The desirable properties of
CENTURION are validated through both theoretical analysis and extensive
simulations.",Haiming Jin|Lu Su|Klara Nahrstedt,cs.GT
2017-02-28T17:22:31Z,2017-01-10T16:06:30Z,http://arxiv.org/abs/1701.01302v2,http://arxiv.org/pdf/1701.01302v2,"Toward negotiable reinforcement learning: shifting priorities in Pareto
  optimal sequential decision-making","Existing multi-objective reinforcement learning (MORL) algorithms do not
account for objectives that arise from players with differing beliefs.
Concretely consider two players with different beliefs and utility functions
who may cooperate to build a machine that takes actions on their behalf. A
representation is needed for how much the machine's policy will prioritize each
player's interests over time. Assuming the players have reached common
knowledge of their situation this paper derives a recursion that any Pareto
optimal policy must satisfy. Two qualitative observations can be made from the
recursion: the machine must (1) use each player's own beliefs in evaluating how
well an action will serve that player's utility function and (2) shift the
relative priority it assigns to each player's expected utilities over time by
a factor proportional to how well that player's beliefs predict the machine's
inputs. Observation (2) represents a substantial divergence from na\""{i}ve
linear utility aggregation (as in Harsanyi's utilitarian theorem and existing
MORL algorithms) which is shown here to be inadequate for Pareto optimal
sequential decision-making on behalf of players with different beliefs.",Andrew Critch,cs.AI|cs.GT|cs.LG
2017-02-28T17:22:31Z,2017-01-05T05:44:25Z,http://arxiv.org/abs/1701.01216v1,http://arxiv.org/abs/1701.01216v1,Crowdsourcing with Tullock contests: A new perspective,"Incentive mechanisms for crowdsourcing have been extensively studied under
the framework of all-pay auctions. Along a distinct line this paper proposes
to use Tullock contests as an alternative tool to design incentive mechanisms
for crowdsourcing. We are inspired by the conduciveness of Tullock contests to
attracting user entry (yet not necessarily a higher revenue) in other domains.
In this paper we explore a new dimension in optimal Tullock contest design by
superseding the contest prize---which is fixed in conventional Tullock
contests---with a prize function that is dependent on the (unknown) winner's
contribution in order to maximize the crowdsourcer's utility. We show that
this approach leads to attractive practical advantages: (a) it is well-suited
for rapid prototyping in fully distributed web agents and smartphone apps; (b)
it overcomes the disincentive to participate caused by players' antagonism to
an increasing number of rivals. Furthermore we optimize conventional
fixed-prize Tullock contests to construct the most superior benchmark to
compare against our mechanism. Through extensive evaluations we show that our
mechanism significantly outperforms the optimal benchmark by over three folds
on the crowdsourcer's utility cum profit and up to nine folds on the players'
social welfare.",T. Luo|S. S. Kanhere|H-P. Tan|F. Wu|H. Wu,cs.GT|cs.HC|cs.MA|cs.NI
2017-02-28T17:22:31Z,2017-01-04T10:44:04Z,http://arxiv.org/abs/1701.00958v1,http://arxiv.org/pdf/1701.00958v1,"Charging and Discharging of Plug-In Electric Vehicles (PEVs) in
  Vehicle-to-Grid (V2G) Systems: A Cyber Insurance-Based Model","In addition to being environment-friendly vehicle-to-grid (V2G) systems can
help the plug-in electric vehicle (PEV) users in reducing their energy costs
and can also help stabilizing energy demand in the power grid. In V2G systems
since the PEV users need to obtain system information (e.g. locations of
charging/discharging stations current load and supply of the power grid) to
achieve the best charging and discharging performance data communication plays
a crucial role. However since the PEV users are highly mobile information
from V2G systems is not always available for many reasons e.g. wireless link
failures and cyber attacks. Therefore in this paper we introduce a novel
concept using cyber insurance to ""transfer"" cyber risks e.g. unavailable
information of a PEV user to a third party e.g. a cyber insurance company.
Under the insurance coverage even without information about V2G systems a PEV
user is always guaranteed the best price for charging/discharging. In
particular we formulate the optimal energy cost problem for the PEV user by
adopting a Markov decision process framework. We then propose a learning
algorithm to help the PEV user make optimal decisions e.g. to charge or
discharge and to buy or not to buy insurance in an online fashion. Through
simulations we show that cyber insurance is an efficient solution not only in
dealing with cyber risks but also in maximizing revenue of the PEV user.",Dinh Thai Hoang|Ping Wang|Dusit Niyato|Ekram Hossain,cs.GT|cs.CY
2017-02-28T17:22:31Z,2017-01-03T22:06:46Z,http://arxiv.org/abs/1701.00849v1,http://arxiv.org/pdf/1701.00849v1,Effect of selfish choices in deferred acceptance with short lists,"We study the outcome of deferred acceptance when prospective medical
residents can only apply to a limited set of hospitals. This limitation
requires residents to make a strategic choice about the quality of hospitals
they apply to. Through a mix of theoretical and experimental results we study
the effect of this strategic choice on the preferences submitted by
participants as well as on the overall welfare. We find that residents'
choices in our model mimic the behavior observed in real systems where
individuals apply to a mix of positions consisting mostly of places where they
are reasonably likely to get accepted as well as a few ""reach"" applications to
hospitals of very high quality and a few ""safe"" applications to hospitals of
lower than their expected level. Surprisingly the number of such ""safe""
applications is not monotone in the number of allowed applications. We also
find that selfish behavior can hurt social welfare but the deterioration of
overall welfare is very minimal.",Hedyeh Beyhaghi|Daniela Saban|Eva Tardos,cs.GT
2017-02-28T17:22:31Z,2017-02-01T18:18:33Z,http://arxiv.org/abs/1701.06539v2,http://arxiv.org/pdf/1701.06539v2,On the aggregation of incomplete preferences,"Assume a set of objects is given with information about their bilateral
relationships allowing for incomplete and multiple comparisons as well as
different preference intensities. An axiomatic approach is applied for the
problem of ranking the objects. Consistency requires the preservation of
relative ranking if two sets of such preferences are aggregated.
Self-consistency assigns the same rank for objects with the same performance
furthermore an object should be ranked strictly higher if it shows an
obviously better performance than another. It is revealed that these two
properties cannot be satisfied simultaneously. The impossibility holds under
various restrictions on the domain. However a positive result emerges if only
the aggregation of ranking problems with the same comparison structure is
allowed for example we have two round-robin tournaments.",László Csató,"cs.GT|15A06, 91B14"
2017-02-28T17:22:31Z,2017-01-02T21:26:03Z,http://arxiv.org/abs/1701.00529v1,http://arxiv.org/pdf/1701.00529v1,Truthful Facility Location with Additive Errors,"We address the problem of locating facilities on the $[01]$ interval based
on reports from strategic agents. The cost of each agent is her distance to the
closest facility and the global objective is to minimize either the maximum
cost of an agent or the social cost.
  As opposed to the extensive literature on facility location which considers
the multiplicative error we focus on minimizing the worst-case additive error.
Minimizing the additive error incentivizes mechanisms to adapt to the size of
the instance. I.e. mechanisms can sacrifice little efficiency in small
instances (location profiles in which all agents are relatively close to one
another) in order to gain more [absolute] efficiency in large instances. We
argue that this measure is better suited for many manifestations of the
facility location problem in various domains.
  We present tight bounds for mechanisms locating a single facility in both
deterministic and randomized cases. We further provide several extensions for
locating multiple facilities.",Iddan Golomb|Christos Tzamos,cs.GT|cs.AI
