2017-03-16T23:28:27Z|2017-03-15T17:01:20Z|http://arxiv.org/abs/1703.05260v1|http://arxiv.org/pdf/1703.05260v1|InScript: Narrative texts annotated with script information|This paper presents the InScript corpus (Narrative Texts Instantiating Script structure). InScript is a corpus of 1,000 stories centered around 10 different scenarios. Verbs and noun phrases are annotated with event and participant types, respectively. Additionally, the text is annotated with coreference information. The corpus shows rich lexical variation and will serve as a unique resource for the study of the role of script knowledge in natural language processing.|['Ashutosh Modi', 'Tatjana Anikina', 'Simon Ostermann', 'Manfred Pinkal']|['cs.CL', 'cs.AI']
2017-03-16T23:28:27Z|2017-03-15T15:19:28Z|http://arxiv.org/abs/1703.05204v1|http://arxiv.org/pdf/1703.05204v1|On Inconsistency Indices and Inconsistency Axioms in Pairwise   Comparisons|Pairwise comparisons are an important tool of modern (multiple criteria) decision making. Since human judgments are often inconsistent, many studies focused on the ways how to express and measure this inconsistency, and several inconsistency indices were proposed as an alternative to Saaty inconsistency index and inconsistency ratio for reciprocal pairwise comparisons matrices. This paper aims to: firstly, introduce a new measure of inconsistency of pairwise comparisons and to prove its basic properties; secondly, to postulate an additional axiom, an upper boundary axiom, to an existing set of axioms; and the last, but not least, the paper provides proofs of satisfaction of this additional axiom by selected inconsistency indices as well as it provides their numerical comparison.|['Jiri Mazurek']|['cs.AI']
2017-03-16T23:28:27Z|2017-03-15T15:13:42Z|http://arxiv.org/abs/1703.05201v1|http://arxiv.org/pdf/1703.05201v1|Fuzzy Rankings: Properties and Applications|In practice, a ranking of objects with respect to given set of criteria is of considerable importance. However, due to lack of knowledge, information of time pressure, decision makers might not be able to provide a (crisp) ranking of objects from the top to the bottom. Instead, some objects might be ranked equally, or better than other objects only to some degree. In such cases, a generalization of crisp rankings to fuzzy rankings can be more useful. The aim of the article is to introduce the notion of a fuzzy ranking and to discuss its several properties, namely orderings, similarity and indecisiveness. The proposed approach can be used both for group decision making or multiple criteria decision making when uncertainty is involved.|['Jiří Mazurek']|['cs.AI']
2017-03-16T23:28:27Z|2017-03-15T07:57:51Z|http://arxiv.org/abs/1703.04990v1|http://arxiv.org/pdf/1703.04990v1|Neural Programming by Example|Programming by Example (PBE) targets at automatically inferring a computer program for accomplishing a certain task from sample input and output. In this paper, we propose a deep neural networks (DNN) based PBE model called Neural Programming by Example (NPBE), which can learn from input-output strings and induce programs that solve the string manipulation problems. Our NPBE model has four neural network based components: a string encoder, an input-output analyzer, a program generator, and a symbol selector. We demonstrate the effectiveness of NPBE by training it end-to-end to solve some common string manipulation problems in spreadsheet systems. The results show that our model can induce string manipulation programs effectively. Our work is one step towards teaching DNN to generate computer programs.|['Chengxun Shu', 'Hongyu Zhang']|['cs.AI', 'cs.NE', 'cs.SE']
2017-03-16T23:28:27Z|2017-03-15T05:43:48Z|http://arxiv.org/abs/1703.04940v1|http://arxiv.org/pdf/1703.04940v1|Resilience: A Criterion for Learning in the Presence of Arbitrary   Outliers|We introduce a criterion, resilience, which allows properties of a dataset (such as its mean or best low rank approximation) to be robustly computed, even in the presence of a large fraction of arbitrary additional data. Resilience is a weaker condition than most other properties considered so far in the literature, and yet enables robust estimation in a broader variety of settings, including the previously unstudied problem of robust mean estimation in $\ell_p$-norms.|['Jacob Steinhardt', 'Moses Charikar', 'Gregory Valiant']|['cs.LG', 'cs.AI', 'cs.CC', 'cs.CR', 'stat.ML']
2017-03-16T23:28:27Z|2017-03-15T03:53:25Z|http://arxiv.org/abs/1703.04912v1|http://arxiv.org/pdf/1703.04912v1|Syntax-Preserving Belief Change Operators for Logic Programs|Recent methods have adapted the well-established AGM and belief base frameworks for belief change to cover belief revision in logic programs. In this study here, we present two new sets of belief change operators for logic programs. They focus on preserving the explicit relationships expressed in the rules of a program, a feature that is missing in purely semantic approaches that consider programs only in their entirety. In particular, operators of the latter class fail to satisfy preservation and support, two important properties for belief change in logic programs required to ensure intuitive results.   We address this shortcoming of existing approaches by introducing partial meet and ensconcement constructions for logic program belief change, which allow us to define syntax-preserving operators that satisfy preservation and support. Our work is novel in that our constructions not only preserve more information from a logic program during a change operation than existing ones, but they also facilitate natural definitions of contraction operators, the first in the field to the best of our knowledge.   In order to evaluate the rationality of our operators, we translate the revision and contraction postulates from the AGM and belief base frameworks to the logic programming setting. We show that our operators fully comply with the belief base framework and formally state the interdefinability between our operators. We further propose an algorithm that is based on modularising a logic program to reduce partial meet and ensconcement revisions or contractions to performing the operation only on the relevant modules of that program. Finally, we compare our approach to two state-of-the-art logic program revision methods and demonstrate that our operators address the shortcomings of one and generalise the other method.|['Sebastian Binnewies', 'Zhiqiang Zhuang', 'Kewen Wang', 'Bela Stantic']|['cs.AI', 'I.2.3; I.2.4; F.4.1']
2017-03-16T23:28:27Z|2017-03-15T03:30:13Z|http://arxiv.org/abs/1703.04908v1|http://arxiv.org/pdf/1703.04908v1|Emergence of Grounded Compositional Language in Multi-Agent Populations|By capturing statistical patterns in large corpora, machine learning has enabled significant advances in natural language processing, including in machine translation, question answering, and sentiment analysis. However, for agents to intelligently interact with humans, simply capturing the statistical patterns is insufficient. In this paper we investigate if, and how, grounded compositional language can emerge as a means to achieve goals in multi-agent populations. Towards this end, we propose a multi-agent learning environment and learning methods that bring about emergence of a basic compositional language. This language is represented as streams of abstract discrete symbols uttered by agents over time, but nonetheless has a coherent structure that possesses a defined vocabulary and syntax. We also observe emergence of non-verbal communication such as pointing and guiding when language communication is unavailable.|['Igor Mordatch', 'Pieter Abbeel']|['cs.AI', 'cs.CL']
2017-03-16T23:28:27Z|2017-03-15T01:04:49Z|http://arxiv.org/abs/1703.04862v1|http://arxiv.org/pdf/1703.04862v1|Exploring the Combination Rules of D Numbers From a Perspective of   Conflict Redistribution|Dempster-Shafer theory of evidence is widely applied to uncertainty modelling and knowledge reasoning because of its advantages in dealing with uncertain information. But some conditions or requirements, such as exclusiveness hypothesis and completeness constraint, limit the development and application of that theory to a large extend. To overcome the shortcomings and enhance its capability of representing the uncertainty, a novel model, called D numbers, has been proposed recently. However, many key issues, for example how to implement the combination of D numbers, remain unsolved. In the paper, we have explored the combination of D Numbers from a perspective of conflict redistribution, and proposed two combination rules being suitable for different situations for the fusion of two D numbers. The proposed combination rules can reduce to the classical Dempster's rule in Dempster-Shafer theory under a certain conditions. Numerical examples and discussion about the proposed rules are also given in the paper.|['Xinyang Deng', 'Wen Jiang']|['cs.AI']
2017-03-16T23:28:27Z|2017-03-14T23:09:45Z|http://arxiv.org/abs/1703.04816v1|http://arxiv.org/pdf/1703.04816v1|FastQA: A Simple and Efficient Neural Architecture for Question   Answering|Recent development of large-scale question answering (QA) datasets triggered a substantial amount of research into end-to-end neural architectures for QA. Increasingly complex systems have been conceived without comparison to a simpler neural baseline system that would justify their complexity. In this work, we propose a simple heuristic that guided the development of FastQA, an efficient end-to-end neural model for question answering that is very competitive with existing models. We further demonstrate, that an extended version (FastQAExt) achieves state-of-the-art results on recent benchmark datasets, namely SQuAD, NewsQA and MsMARCO, outperforming most existing models. However, we show that increasing the complexity of FastQA to FastQAExt does not yield any systematic improvements. We argue that the same holds true for most existing systems that are similar to FastQAExt. A manual analysis reveals that our proposed heuristic explains most predictions of our model, which indicates that modeling a simple heuristic is enough to achieve strong performance on extractive QA datasets. The overall strong performance of FastQA puts results of existing, more complex models into perspective.|['Dirk Weissenborn', 'Georg Wiese', 'Laura Seiffe']|['cs.CL', 'cs.AI', 'cs.NE']
2017-03-16T23:28:27Z|2017-03-14T22:13:20Z|http://arxiv.org/abs/1703.04756v1|http://arxiv.org/pdf/1703.04756v1|Weighted Voting Via No-Regret Learning|Voting systems typically treat all voters equally. We argue that perhaps they should not: Voters who have supported good choices in the past should be given higher weight than voters who have supported bad ones. To develop a formal framework for desirable weighting schemes, we draw on no-regret learning. Specifically, given a voting rule, we wish to design a weighting scheme such that applying the voting rule, with voters weighted by the scheme, leads to choices that are almost as good as those endorsed by the best voter in hindsight. We derive possibility and impossibility results for the existence of such weighting schemes, depending on whether the voting rule and the weighting scheme are deterministic or randomized, as well as on the social choice axioms satisfied by the voting rule.|['Nika Haghtalab', 'Ritesh Noothigattu', 'Ariel D. Procaccia']|['cs.GT', 'cs.AI', 'cs.LG', 'cs.MA']
2017-03-16T23:28:31Z|2017-03-14T21:46:04Z|http://arxiv.org/abs/1703.04741v1|http://arxiv.org/pdf/1703.04741v1|Towards Moral Autonomous Systems|Both the ethics of autonomous systems and the problems of their technical implementation have by now been studied in some detail. Less attention has been given to the areas in which these two separate concerns meet. This paper, written by both philosophers and engineers of autonomous systems, addresses a number of issues in machine ethics that are located at precisely the intersection between ethics and engineering. We first discuss different approaches towards the conceptual design of autonomous systems and their implications on the ethics implementation in such systems. Then we examine problematic areas regarding the specification and verification of ethical behavior in autonomous systems, particularly with a view towards the requirements of future legislation. We discuss transparency and accountability issues that will be crucial for any future wide deployment of autonomous systems in society. Finally we consider the, often overlooked, possibility of intentional misuse of AI systems and the possible dangers arising out of deliberately unethical design, implementation, and use of autonomous robots.|['Vicky Charisi', 'Louise Dennis', 'Michael Fisher Robert Lieck', 'Andreas Matthias', 'Marija Slavkovik Janina Sombetzki', 'Alan F. T. Winfield', 'Roman Yampolskiy']|['cs.AI']
2017-03-16T23:28:31Z|2017-03-14T21:07:01Z|http://arxiv.org/abs/1703.04730v1|http://arxiv.org/pdf/1703.04730v1|Understanding Black-box Predictions via Influence Functions|How can we explain the predictions of a black-box model? In this paper, we use influence functions -- a classic technique from robust statistics -- to trace a model's prediction through the learning algorithm and back to its training data, identifying the points most responsible for a given prediction. Applying ideas from second-order optimization, we scale up influence functions to modern machine learning settings and show that they can be applied to high-dimensional black-box models, even in non-convex and non-differentiable settings. We give a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for many different purposes: to understand model behavior, debug models and detect dataset errors, and even identify and exploit vulnerabilities to adversarial training-set attacks.|['Pang Wei Koh', 'Percy Liang']|['stat.ML', 'cs.AI', 'cs.LG']
2017-03-16T23:28:31Z|2017-03-14T19:14:32Z|http://arxiv.org/abs/1703.04677v1|http://arxiv.org/pdf/1703.04677v1|A computational investigation of sources of variability in sentence   comprehension difficulty in aphasia|We present a computational evaluation of three hypotheses about sources of deficit in sentence comprehension in aphasia: slowed processing, intermittent deficiency, and resource reduction. The ACT-R based Lewis & Vasishth 2005 model is used to implement these three proposals. Slowed processing is implemented as slowed default production-rule firing time; intermittent deficiency as increased random noise in activation of chunks in memory; and resource reduction as reduced goal activation. As data, we considered subject vs. object relatives presented in a self-paced listening modality to 56 individuals with aphasia (IWA) and 46 matched controls. The participants heard the sentences and carried out a picture verification task to decide on an interpretation of the sentence. These response accuracies are used to identify the best parameters (for each participant) that correspond to the three hypotheses mentioned above. We show that controls have more tightly clustered (less variable) parameter values than IWA; specifically, compared to controls, among IWA there are more individuals with low goal activations, high noise, and slow default action times. This suggests that (i) individual patients show differential amounts of deficit along the three dimensions of slowed processing, intermittent deficient, and resource reduction, (ii) overall, there is evidence for all three sources of deficit playing a role, and (iii) IWA have a more variable range of parameter values than controls. In sum, this study contributes a proof of concept of a quantitative implementation of, and evidence for, these three accounts of comprehension deficits in aphasia.|['Paul Mätzig', 'Shravan Vasishth', 'Felix Engelmann', 'David Caplan']|['cs.CL', 'cs.AI']
2017-03-16T23:28:31Z|2017-03-14T17:15:42Z|http://arxiv.org/abs/1703.04587v1|http://arxiv.org/pdf/1703.04587v1|Minimizing Maximum Regret in Commitment Constrained Sequential Decision   Making|In cooperative multiagent planning, it can often be beneficial for an agent to make commitments about aspects of its behavior to others, allowing them in turn to plan their own behaviors without taking the agent's detailed behavior into account. Extending previous work in the Bayesian setting, we consider instead a worst-case setting in which the agent has a set of possible environments (MDPs) it could be in, and develop a commitment semantics that allows for probabilistic guarantees on the agent's behavior in any of the environments it could end up facing. Crucially, an agent receives observations (of reward and state transitions) that allow it to potentially eliminate possible environments and thus obtain higher utility by adapting its policy to the history of observations. We develop algorithms and provide theory and some preliminary empirical results showing that they ensure an agent meets its commitments with history-dependent policies while minimizing maximum regret over the possible environments.|['Qi Zhang', 'Satinder Singh', 'Edmund Durfee']|['cs.AI']
2017-03-16T23:28:31Z|2017-03-13T17:58:36Z|http://arxiv.org/abs/1703.04529v1|http://arxiv.org/pdf/1703.04529v1|Task-based End-to-end Model Learning|As machine learning techniques have become more ubiquitous, it has become common to see machine learning prediction algorithms operating within some larger process. However, the criteria by which we train machine learning algorithms often differ from the ultimate criteria on which we evaluate them. This paper proposes an end-to-end approach for learning probabilistic machine learning models within the context of stochastic programming, in a manner that directly captures the ultimate task-based objective for which they will be used. We then present two experimental evaluations of the proposed approach, one as applied to a generic inventory stock problem and the second to a real-world electrical grid scheduling task. In both cases, we show that the proposed approach can outperform both a traditional modeling approach and a purely black-box policy optimization approach.|['Priya L. Donti', 'Brandon Amos', 'J. Zico Kolter']|['cs.LG', 'cs.AI']
2017-03-16T23:28:31Z|2017-03-13T17:34:18Z|http://arxiv.org/abs/1703.04498v1|http://arxiv.org/pdf/1703.04498v1|High-Throughput and Language-Agnostic Entity Disambiguation and Linking   on User Generated Data|The Entity Disambiguation and Linking (EDL) task matches entity mentions in text to a unique Knowledge Base (KB) identifier such as a Wikipedia or Freebase id. It plays a critical role in the construction of a high quality information network, and can be further leveraged for a variety of information retrieval and NLP tasks such as text categorization and document tagging. EDL is a complex and challenging problem due to ambiguity of the mentions and real world text being multi-lingual. Moreover, EDL systems need to have high throughput and should be lightweight in order to scale to large datasets and run on off-the-shelf machines. More importantly, these systems need to be able to extract and disambiguate dense annotations from the data in order to enable an Information Retrieval or Extraction task running on the data to be more efficient and accurate. In order to address all these challenges, we present the Lithium EDL system and algorithm - a high-throughput, lightweight, language-agnostic EDL system that extracts and correctly disambiguates 75% more entities than state-of-the-art EDL systems and is significantly faster than them.|['Preeti Bhargava', 'Nemanja Spasojevic', 'Guoning Hu']|['cs.IR', 'cs.AI', 'cs.CL']
2017-03-16T23:28:31Z|2017-03-13T17:13:51Z|http://arxiv.org/abs/1703.04489v1|http://arxiv.org/pdf/1703.04489v1|Reinforcement Learning for Transition-Based Mention Detection|This paper describes an application of reinforcement learning to the mention detection task. We define a novel action-based formulation for the mention detection task, in which a model can flexibly revise past labeling decisions by grouping together tokens and assigning partial mention labels. We devise a method to create mention-level episodes and we train a model by rewarding correctly labeled complete mentions, irrespective of the inner structure created. The model yields results which are on par with a competitive supervised counterpart while being more flexible in terms of achieving targeted behavior through reward modeling and generating internal mention structure, especially on longer mentions.|['Georgiana Dinu', 'Wael Hamza', 'Radu Florian']|['cs.CL', 'cs.AI']
2017-03-16T23:28:31Z|2017-03-13T13:45:13Z|http://arxiv.org/abs/1703.04389v1|http://arxiv.org/pdf/1703.04389v1|Bayesian Optimization with Gradients|In recent years, Bayesian optimization has proven successful for global optimization of expensive-to-evaluate multimodal objective functions. However, unlike most optimization methods, Bayesian optimization typically does not use derivative information. In this paper we show how Bayesian optimization can exploit derivative information to decrease the number of objective function evaluations required for good performance. In particular, we develop a novel Bayesian optimization algorithm, the derivative-enabled knowledge-gradient (dKG), for which we show one-step Bayes-optimality, asymptotic consistency, and greater one-step value of information than is possible in the derivative-free setting. Our procedure accommodates noisy and incomplete derivative information, and comes in both sequential and batch forms. We show dKG provides state-of-the-art performance compared to a wide range of optimization procedures with and without gradients, on benchmarks including logistic regression, kernel learning, and k-nearest neighbors.|['Jian Wu', 'Matthias Poloczek', 'Andrew Gordon Wilson', 'Peter I. Frazier']|['stat.ML', 'cs.AI', 'cs.LG', 'math.OC']
2017-03-16T23:28:31Z|2017-03-13T13:32:46Z|http://arxiv.org/abs/1703.04382v1|http://arxiv.org/pdf/1703.04382v1|Cost-Based Intuitionist Probabilities on Spaces of Graphs, Hypergraphs   and Theorems|A novel partial order is defined on the space of digraphs or hypergraphs, based on assessing the cost of producing a graph via a sequence of elementary transformations. Leveraging work by Knuth and Skilling on the foundations of inference, and the structure of Heyting algebras on graph space, this partial order is used to construct an intuitionistic probability measure that applies to either digraphs or hypergraphs. As logical inference steps can be represented as transformations on hypergraphs representing logical statements, this also yields an intuitionistic probability measure on spaces of theorems. The central result is also extended to yield intuitionistic probabilities based on more general weighted rule systems defined over bicartesian closed categories.|['Ben Goertzel']|['cs.AI']
2017-03-16T23:28:31Z|2017-03-13T13:06:49Z|http://arxiv.org/abs/1703.04368v1|http://arxiv.org/pdf/1703.04368v1|Symbol Grounding via Chaining of Morphisms|"A new model of symbol grounding is presented, in which the structures of natural language, logical semantics, perception and action are represented categorically, and symbol grounding is modeled via the composition of morphisms between the relevant categories. This model gives conceptual insight into the fundamentally systematic nature of symbol grounding, and also connects naturally to practical real-world AI systems in current research and commercial use. Specifically, it is argued that the structure of linguistic syntax can be modeled as a certain asymmetric monoidal category, as e.g. implicit in the link grammar formalism; the structure of spatiotemporal relationships and action plans can be modeled similarly using ""image grammars"" and ""action grammars""; and common-sense logical semantic structure can be modeled using dependently-typed lambda calculus with uncertain truth values. Given these formalisms, the grounding of linguistic descriptions in spatiotemporal perceptions and coordinated actions consists of following morphisms from language to logic through to spacetime and body (for comprehension), and vice versa (for generation). The mapping is indicated between the spatial relationships in the Region Connection Calculus and Allen Interval Algebra and corresponding entries in the link grammar syntax parsing dictionary. Further, the abstractions introduced here are shown to naturally model the structures and systems currently being deployed in the context of using the OpenCog cognitive architecture to control Hanson Robotics humanoid robots."|['Ruiting Lian', 'Ben Goertzel', 'Linas Vepstas', 'David Hanson', 'Changle Zhou']|['cs.AI']
2017-03-16T23:28:35Z|2017-03-13T12:49:20Z|http://arxiv.org/abs/1703.04363v1|http://arxiv.org/pdf/1703.04363v1|Deep Value Networks Learn to Evaluate and Iteratively Refine Structured   Outputs|We approach structured output prediction by learning a deep value network (DVN) that evaluates different output structures for a given input. For example, when applied to image segmentation, the value network takes an image and a segmentation mask as inputs and predicts a scalar score evaluating the mask quality and its correspondence with the image. Once the value network is optimized, at inference, it finds output structures that maximize the score of the value net via gradient descent on continuous relaxations of structured outputs. Thus DVN takes advantage of the joint modeling of the inputs and outputs. Our framework applies to a wide range of structured output prediction problems. We conduct experiments on multi-label classification based on text data and on image segmentation problems. DVN outperforms several strong baselines and the state-of-the-art results on these benchmarks. In addition, on image segmentation, the proposed deep value network learns complex shape priors and effectively combines image information with the prior to obtain competitive segmentation results.|['Michael Gygli', 'Mohammad Norouzi', 'Anelia Angelova']|['cs.LG', 'cs.AI', 'cs.CV']
2017-03-16T23:28:35Z|2017-03-13T12:48:15Z|http://arxiv.org/abs/1703.04361v1|http://arxiv.org/pdf/1703.04361v1|Toward a Formal Model of Cognitive Synergy|"""Cognitive synergy"" refers to a dynamic in which multiple cognitive processes, cooperating to control the same cognitive system, assist each other in overcoming bottlenecks encountered during their internal processing. Cognitive synergy has been posited as a key feature of real-world general intelligence, and has been used explicitly in the design of the OpenCog cognitive architecture. Here category theory and related concepts are used to give a formalization of the cognitive synergy concept.   A series of formal models of intelligent agents is proposed, with increasing specificity and complexity: simple reinforcement learning agents; ""cognit"" agents with an abstract memory and processing model; hypergraph-based agents (in which ""cognit"" operations are carried out via hypergraphs); hypergraph agents with a rich language of nodes and hyperlinks (such as the OpenCog framework provides); ""PGMC"" agents whose rich hypergraphs are endowed with cognitive processes guided via Probabilistic Growth and Mining of Combinations; and finally variations of the PrimeAGI design, which is currently being built on top of OpenCog.   A notion of cognitive synergy is developed for cognitive processes acting within PGMC agents, based on developing a formal notion of ""stuckness,"" and defining synergy as a relationship between cognitive processes in which they can help each other out when they get stuck. It is proposed that cognitive processes relating to each other synergetically, associate in a certain way with functors that map into each other via natural transformations. Cognitive synergy is proposed to correspond to a certain inequality regarding the relative costs of different paths through certain commutation diagrams.   Applications of this notion of cognitive synergy to particular cognitive phenomena, and specific cognitive processes in the PrimeAGI design, are discussed."|['Ben Goertzel']|['cs.AI']
2017-03-16T23:28:35Z|2017-03-13T03:29:23Z|http://arxiv.org/abs/1703.04232v1|http://arxiv.org/pdf/1703.04232v1|Numerical Integration and Dynamic Discretization in Heuristic Search   Planning over Hybrid Domains|In this paper we look into the problem of planning over hybrid domains, where change can be both discrete and instantaneous, or continuous over time. In addition, it is required that each state on the trajectory induced by the execution of plans complies with a given set of global constraints. We approach the computation of plans for such domains as the problem of searching over a deterministic state model. In this model, some of the successor states are obtained by solving numerically the so-called initial value problem over a set of ordinary differential equations (ODE) given by the current plan prefix. These equations hold over time intervals whose duration is determined dynamically, according to whether zero crossing events take place for a set of invariant conditions. The resulting planner, FS+, incorporates these features together with effective heuristic guidance. FS+ does not impose any of the syntactic restrictions on process effects often found on the existing literature on Hybrid Planning. A key concept of our approach is that a clear separation is struck between planning and simulation time steps. The former is the time allowed to observe the evolution of a given dynamical system before committing to a future course of action, whilst the later is part of the model of the environment. FS+ is shown to be a robust planner over a diverse set of hybrid domains, taken from the existing literature on hybrid planning and systems.|['Miquel Ramirez', 'Enrico Scala', 'Patrik Haslum', 'Sylvie Thiebaux']|['cs.AI', 'I.2.8; F.2.2; I.6; J.2']
2017-03-16T23:28:35Z|2017-03-13T01:49:27Z|http://arxiv.org/abs/1703.04221v1|http://arxiv.org/pdf/1703.04221v1|A Hierarchical Framework of Cloud Resource Allocation and Power   Management Using Deep Reinforcement Learning|Automatic decision-making approaches, such as reinforcement learning (RL), have been applied to (partially) solve the resource allocation problem adaptively in the cloud computing system. However, a complete cloud resource allocation framework exhibits high dimensions in state and action spaces, which prohibit the usefulness of traditional RL techniques. In addition, high power consumption has become one of the critical concerns in design and control of cloud computing systems, which degrades system reliability and increases cooling cost. An effective dynamic power management (DPM) policy should minimize power consumption while maintaining performance degradation within an acceptable level. Thus, a joint virtual machine (VM) resource allocation and power management framework is critical to the overall cloud computing system. Moreover, novel solution framework is necessary to address the even higher dimensions in state and action spaces. In this paper, we propose a novel hierarchical framework for solving the overall resource allocation and power management problem in cloud computing systems. The proposed hierarchical framework comprises a global tier for VM resource allocation to the servers and a local tier for distributed power management of local servers. The emerging deep reinforcement learning (DRL) technique, which can deal with complicated control problems with large state space, is adopted to solve the global tier problem. Furthermore, an autoencoder and a novel weight sharing structure are adopted to handle the high-dimensional state space and accelerate the convergence speed. On the other hand, the local tier of distributed server power managements comprises an LSTM based workload predictor and a model-free RL based power manager, operating in a distributed manner.|['Ning Liu', 'Zhe Li', 'Zhiyuan Xu', 'Jielong Xu', 'Sheng Lin', 'Qinru Qiu', 'Jian Tang', 'Yanzhi Wang']|['cs.DC', 'cs.AI']
2017-03-16T23:28:35Z|2017-03-15T08:16:37Z|http://arxiv.org/abs/1703.04159v2|http://arxiv.org/pdf/1703.04159v2|Any-Angle Pathfinding for Multiple Agents Based on SIPP Algorithm|The problem of finding conflict-free trajectories for multiple agents of identical circular shape, operating in shared 2D workspace, is addressed in the paper and decoupled, e.g., prioritized, approach is used to solve this problem. Agents' workspace is tessellated into the square grid on which any-angle moves are allowed, e.g. each agent can move into an arbitrary direction as long as this move follows the straight line segment whose endpoints are tied to the distinct grid elements. A novel any-angle planner based on Safe Interval Path Planning (SIPP) algorithm is proposed to find trajectories for an agent moving amidst dynamic obstacles (other agents) on a grid. This algorithm is then used as part of a prioritized multi-agent planner AA-SIPP(m). On the theoretical, side we show that AA-SIPP(m) is complete under well-defined conditions. On the experimental side, in simulation tests with up to 200 agents involved, we show that our planner finds much better solutions in terms of cost (up to 20%) compared to the planners relying on cardinal moves only.|['Konstantin Yakovlev', 'Anton Andreychuk']|['cs.AI']
2017-03-16T23:28:35Z|2017-03-12T13:17:08Z|http://arxiv.org/abs/1703.04115v1|http://arxiv.org/pdf/1703.04115v1|BetaRun 2017 Team Description Paper: Variety, Complexity, and Learning|RoboCup offers a set of benchmark problems for Artificial Intelligence in form of official world championships since 1997. The most tactical advanced and richest in terms of behavioural complexity of these is the 2D Soccer Simulation League, a simulated robotic soccer competition. BetaRun is a new attempt combining both machine learning and manual programming approaches, with the ultimate goal to arrive at a team that is trained entirely from observing and playing games, and a successor of the World Champion team Gliders 2016.|['Olivia Michael', 'Oliver Obst']|['cs.AI']
2017-03-16T23:28:35Z|2017-03-12T05:07:00Z|http://arxiv.org/abs/1703.04071v1|http://arxiv.org/pdf/1703.04071v1|A Compact DNN: Approaching GoogLeNet-Level Accuracy of Classification   and Domain Adaptation|Recently, DNN model compression based on network architecture design, e.g., SqueezeNet, attracted a lot attention. No accuracy drop on image classification is observed on these extremely compact networks, compared to well-known models. An emerging question, however, is whether these model compression techniques hurt DNN's learning ability other than classifying images on a single dataset. Our preliminary experiment shows that these compression methods could degrade domain adaptation (DA) ability, though the classification performance is preserved. Therefore, we propose a new compact network architecture and unsupervised DA method in this paper. The DNN is built on a new basic module Conv-M which provides more diverse feature extractors without significantly increasing parameters. The unified framework of our DA method will simultaneously learn invariance across domains, reduce divergence of feature representations, and adapt label prediction. Our DNN has 4.1M parameters, which is only 6.7% of AlexNet or 59% of GoogLeNet. Experiments show that our DNN obtains GoogLeNet-level accuracy both on classification and DA, and our DA method slightly outperforms previous competitive ones. Put all together, our DA strategy based on our DNN achieves state-of-the-art on sixteen of total eighteen DA tasks on popular Office-31 and Office-Caltech datasets.|['Chunpeng Wu', 'Wei Wen', 'Tariq Afzal', 'Yongmei Zhang', 'Yiran Chen', 'Hai Li']|['cs.CV', 'cs.AI', 'cs.NE']
2017-03-16T23:28:35Z|2017-03-11T20:24:06Z|http://arxiv.org/abs/1703.04565v1|http://arxiv.org/pdf/1703.04565v1|Fuzzy Model Tree For Early Effort Estimation|Use Case Points (UCP) is a well-known method to estimate the project size, based on Use Case diagram, at early phases of software development. Although the Use Case diagram is widely accepted as a de-facto model for analyzing object oriented software requirements over the world, UCP method did not take sufficient amount of attention because, as yet, there is no consensus on how to produce software effort from UCP. This paper aims to study the potential of using Fuzzy Model Tree to derive effort estimates ...|['Mohammad Azzeh', 'Ali Bou Nassif']|['cs.SE', 'cs.AI']
2017-03-16T23:28:35Z|2017-03-11T20:19:05Z|http://arxiv.org/abs/1703.04567v1|http://arxiv.org/pdf/1703.04567v1|Learning best K analogies from data distribution for case-based software   effort estimation|Case-Based Reasoning (CBR) has been widely used to generate good software effort estimates. The predictive performance of CBR is a dataset dependent and subject to extremely large space of configuration possibilities. Regardless of the type of adaptation technique, deciding on the optimal number of similar cases to be used before applying CBR is a key challenge. In this paper we propose a new technique based on Bisecting k-medoids clustering algorithm to better understanding the structure of a dataset and discovering the ...|['Mohammad Azzeh', 'Yousef Elsheikh']|['cs.SE', 'cs.AI']
2017-03-16T23:28:35Z|2017-03-11T09:08:48Z|http://arxiv.org/abs/1703.03933v1|http://arxiv.org/pdf/1703.03933v1|Micro-Objective Learning : Accelerating Deep Reinforcement Learning   through the Discovery of Continuous Subgoals|Recently, reinforcement learning has been successfully applied to the logical game of Go, various Atari games, and even a 3D game, Labyrinth, though it continues to have problems in sparse reward settings. It is difficult to explore, but also difficult to exploit, a small number of successes when learning policy. To solve this issue, the subgoal and option framework have been proposed. However, discovering subgoals online is too expensive to be used to learn options in large state spaces. We propose Micro-objective learning (MOL) to solve this problem. The main idea is to estimate how important a state is while training and to give an additional reward proportional to its importance. We evaluated our algorithm in two Atari games: Montezuma's Revenge and Seaquest. With three experiments to each game, MOL significantly improved the baseline scores. Especially in Montezuma's Revenge, MOL achieved two times better results than the previous state-of-the-art model.|['Sungtae Lee', 'Sang-Woo Lee', 'Jinyoung Choi', 'Dong-Hyun Kwak', 'Byoung-Tak Zhang']|['cs.AI']
2017-03-16T23:28:40Z|2017-03-11T07:46:51Z|http://arxiv.org/abs/1703.03924v1|http://arxiv.org/pdf/1703.03924v1|Real-Time Machine Learning: The Missing Pieces|Machine learning applications are increasingly deployed not only to serve predictions using static models, but also as tightly-integrated components of feedback loops involving dynamic, real-time decision making. These applications pose a new set of requirements, none of which are difficult to achieve in isolation, but the combination of which creates a challenge for existing distributed execution frameworks: computation with millisecond latency at high throughput, adaptive construction of arbitrary task graphs, and execution of heterogeneous kernels over diverse sets of resources. We assert that a new distributed execution framework is needed for such ML applications and propose a candidate approach with a proof-of-concept architecture that achieves a 63x performance improvement over a state-of-the-art execution framework for a representative application.|['Robert Nishihara', 'Philipp Moritz', 'Stephanie Wang', 'Alexey Tumanov', 'William Paul', 'Johann Schleier-Smith', 'Richard Liaw', 'Michael I. Jordan', 'Ion Stoica']|['cs.DC', 'cs.AI', 'cs.LG']
2017-03-16T23:28:40Z|2017-03-11T06:37:09Z|http://arxiv.org/abs/1703.03916v1|http://arxiv.org/pdf/1703.03916v1|Axioms in Model-based Planners|Axioms can be used to model derived predicates in domain- independent planning models. Formulating models which use axioms can sometimes result in problems with much smaller search spaces and shorter plans than the original model. Previous work on axiom-aware planners focused solely on state- space search planners. We propose axiom-aware planners based on answer set programming and integer programming. We evaluate them on PDDL domains with axioms and show that they can exploit additional expressivity of axioms.|['Shuwa Miura', 'Alex Fukunaga']|['cs.AI']
2017-03-16T23:28:40Z|2017-03-11T05:35:09Z|http://arxiv.org/abs/1703.03912v1|http://arxiv.org/pdf/1703.03912v1|The Curse of Correlation in Security Games and Principle of Max-Entropy|In this paper, we identify and study a fundamental, yet underexplored, phenomenon in security games, which we term the Curse of Correlation (CoC). Specifically, we observe that there is inevitable correlation among the protection status of different targets. Such correlation is a crucial concern, especially in spatio-temporal domains like conservation area patrolling, where attackers can monitor patrollers at certain areas and then infer their patrolling routes using such correlation. To mitigate this issue, we introduce the principle of max-entropy to security games, and focus on designing entropy-maximizing defending strategies for the spatio-temporal security game -- a major victim of CoC. We prove that the problem is #P-hard in general, but propose efficient algorithms in well-motivated special settings. Our experiments show significant advantages of the max-entropy algorithms against previous algorithms.|['Haifeng Xu', 'Milind Tambe', 'Shaddin Dughmi', 'Venil Loyd Noronha']|['cs.GT', 'cs.AI', 'cs.CR']
2017-03-16T23:28:40Z|2017-03-11T01:18:14Z|http://arxiv.org/abs/1703.03888v1|http://arxiv.org/pdf/1703.03888v1|Segmentation of skin lesions based on fuzzy classification of pixels and   histogram thresholding|This paper proposes an innovative method for segmentation of skin lesions in dermoscopy images developed by the authors, based on fuzzy classification of pixels and histogram thresholding.|['Jose Luis Garcia-Arroyo', 'Begonya Garcia-Zapirain']|['cs.CV', 'cs.AI', 'stat.ML']
2017-03-16T23:28:40Z|2017-03-10T23:19:50Z|http://arxiv.org/abs/1703.03868v1|http://arxiv.org/pdf/1703.03868v1|Front-to-End Bidirectional Heuristic Search with Near-Optimal Node   Expansions|"It is well-known that any admissible unidirectional heuristic search algorithm must expand all states whose $f$-value is smaller than the optimal solution cost when using a consistent heuristic. Such states are called ""surely expanded"" (s.e.). A recent study characterized s.e. pairs of states for bidirectional search with consistent heuristics: if a pair of states is s.e. then at least one of the two states must be expanded. In this paper, we derive a lower bound, VC, on the minimum possible number of expansions required to cover all s.e. pairs, and present a new admissible front-to-end bidirectional heuristic search algorithm, Near-Optimal Bidirectional Search (NBS), that is guaranteed to do no more than 2VC expansions. We further prove that no front-to-end algorithm has a worst case better than 2VC. Experimental results demonstrate that NBS competes with or outperforms existing bidirectional search algorithms, and often outperforms A* as well."|['Jingwei Chen', 'Robert C. Holte', 'Sandra Zilles', 'Nathan R. Sturtevant']|['cs.AI']
2017-03-16T23:28:40Z|2017-03-10T23:02:19Z|http://arxiv.org/abs/1703.03864v1|http://arxiv.org/pdf/1703.03864v1|Evolution Strategies as a Scalable Alternative to Reinforcement Learning|We explore the use of Evolution Strategies, a class of black box optimization algorithms, as an alternative to popular RL techniques such as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show that ES is a viable solution strategy that scales extremely well with the number of CPUs available: By using hundreds to thousands of parallel workers, ES can solve 3D humanoid walking in 10 minutes and obtain competitive results on most Atari games after one hour of training time. In addition, we highlight several advantages of ES as a black box optimization technique: it is invariant to action frequency and delayed rewards, tolerant of extremely long horizons, and does not need temporal discounting or value function approximation.|['Tim Salimans', 'Jonathan Ho', 'Xi Chen', 'Ilya Sutskever']|['stat.ML', 'cs.AI', 'cs.LG', 'cs.NE']
2017-03-16T23:28:40Z|2017-03-10T22:09:20Z|http://arxiv.org/abs/1703.03854v1|http://arxiv.org/pdf/1703.03854v1|Convolutional Spike Timing Dependent Plasticity based Feature Learning   in Spiking Neural Networks|Brain-inspired learning models attempt to mimic the cortical architecture and computations performed in the neurons and synapses constituting the human brain to achieve its efficiency in cognitive tasks. In this work, we present convolutional spike timing dependent plasticity based feature learning with biologically plausible leaky-integrate-and-fire neurons in Spiking Neural Networks (SNNs). We use shared weight kernels that are trained to encode representative features underlying the input patterns thereby improving the sparsity as well as the robustness of the learning model. We demonstrate that the proposed unsupervised learning methodology learns several visual categories for object recognition with fewer number of examples and outperforms traditional fully-connected SNN architectures while yielding competitive accuracy. Additionally, we observe that the learning model performs out-of-set generalization further making the proposed biologically plausible framework a viable and efficient architecture for future neuromorphic applications.|['Priyadarshini Panda', 'Gopalakrishnan Srinivasan', 'Kaushik Roy']|['cs.NE', 'cs.AI', 'cs.CV']
2017-03-16T23:28:40Z|2017-03-10T15:27:45Z|http://arxiv.org/abs/1703.03714v1|http://arxiv.org/pdf/1703.03714v1|Applying the Wizard-of-Oz Technique to Multimodal Human-Robot Dialogue|Our overall program objective is to provide more natural ways for soldiers to interact and communicate with robots, much like how soldiers communicate with other soldiers today. We describe how the Wizard-of-Oz (WOz) method can be applied to multimodal human-robot dialogue in a collaborative exploration task. While the WOz method can help design robot behaviors, traditional approaches place the burden of decisions on a single wizard. In this work, we consider two wizards to stand in for robot navigation and dialogue management software components. The scenario used to elicit data is one in which a human-robot team is tasked with exploring an unknown environment: a human gives verbal instructions from a remote location and the robot follows them, clarifying possible misunderstandings as needed via dialogue. We found the division of labor between wizards to be workable, which holds promise for future software development.|['Matthew Marge', 'Claire Bonial', 'Brendan Byrne', 'Taylor Cassidy', 'A. William Evans', 'Susan G. Hill', 'Clare Voss']|['cs.CL', 'cs.AI', 'cs.HC', 'cs.RO']
2017-03-16T23:28:40Z|2017-03-13T02:45:49Z|http://arxiv.org/abs/1703.03633v2|http://arxiv.org/pdf/1703.03633v2|Learning Gradient Descent: Better Generalization and Longer Horizons|Training deep neural networks is a highly nontrivial task, involving carefully selecting appropriate training algorithms, scheduling step sizes and tuning other hyperparameters. Trying different combinations can be quite labor-intensive and time consuming. Recently, researchers have tried to use deep learning algorithms to exploit the landscape of the loss function of the training problem of interest, and learn how to optimize over it in an automatic way. In this paper, we propose a new learning-to-learn model and some useful and practical tricks. Our optimizer outperforms generic, hand-crafted optimization algorithms and state-of-the-art learning-to-learn optimizers by DeepMind in many tasks. We demonstrate the effectiveness of our algorithms on a number of tasks, including deep MLPs, CNNs, and simple LSTMs.|['Kaifeng Lv', 'Shunhua Jiang', 'Jian Li']|['cs.LG', 'cs.AI']
2017-03-16T23:28:40Z|2017-03-10T04:41:29Z|http://arxiv.org/abs/1703.03543v1|http://arxiv.org/pdf/1703.03543v1|Communications that Emerge through Reinforcement Learning Using a   (Recurrent) Neural Network|Communication is not only an action of choosing a signal, but needs to consider the context and sensor signals. It also needs to decide what information is communicated and how it is represented in or understood from signals. Therefore, communication should be realized comprehensively together with its purpose and other functions.   The recent successful results in end-to-end reinforcement learning (RL) show the importance of comprehensive learning and the usefulness of end-to-end RL. Although little is known, we have shown that a variety of communications emerge through RL using a (recurrent) neural network (NN). Here, three of them are introduced.   In the 1st one, negotiation to avoid conflicts among 4 randomly-picked agents was learned. Each agent generates a binary signal from the output of its recurrent NN (RNN), and receives 4 signals from the agents three times. After learning, each agent made an appropriate final decision after negotiation for any combination of 4 agents. Differentiation of individuality among the agents also could be seen.   The 2nd one focused on discretization of communication signal. A sender agent perceives the receiver's location and generates a continuous signal twice by its RNN. A receiver agent receives them sequentially, and moves according to its RNN's output to reach the sender's location. When noises were added to the signal, it was binarized through learning and 2-bit communication was established.   The 3rd one focused on end-to-end comprehensive communication. A sender receives 1,785 pixel real camera image on which a real robot can be seen, and sends two sounds whose frequencies are computed by its NN. A receiver receives them, and two motion commands for the robot are generated by its NN. After learning, the robot could reach the goal successfully from any initial location though some preliminary learning was necessary.|['Katsunari Shibata']|['cs.AI']
2017-03-16T23:28:43Z|2017-03-10T02:48:29Z|http://arxiv.org/abs/1703.03524v1|http://arxiv.org/pdf/1703.03524v1|The Ontological Multidimensional Data Model|In this extended abstract we describe, mainly by examples, the main elements of the Ontological Multidimensional Data Model, which considerably extends a relational reconstruction of the multidimensional data model proposed by Hurtado and Mendelzon by means of tuple-generating dependencies, equality-generating dependencies, and negative constraints as found in Datalog+-. We briefly mention some good computational properties of the model.|['Leopoldo Bertossi', 'Mostafa Milani']|['cs.DB', 'cs.AI']
2017-03-16T23:28:43Z|2017-03-09T20:21:36Z|http://arxiv.org/abs/1703.03453v1|http://arxiv.org/pdf/1703.03453v1|Using Options for Long-Horizon Off-Policy Evaluation|Evaluating a policy by deploying it in the real world can be risky and costly. Off-policy evaluation (OPE) algorithms use historical data collected from running a previous policy to evaluate a new policy, which provides a means for evaluating a policy without requiring it to ever be deployed. Importance sampling is a popular OPE method because it is robust to partial observability and works with continuous states and actions. However, we show that the amount of historical data required by importance sampling can scale exponentially with the horizon of the problem: the number of sequential decisions that are made. We propose using policies over temporally extended actions, called options, to address this long-horizon problem. We show theoretically and experimentally that combining importance sampling with options-based policies can significantly improve performance for long-horizon problems.|['Zhaohan Daniel Guo', 'Philip S. Thomas', 'Emma Brunskill']|['cs.AI']
2017-03-16T23:28:43Z|2017-03-09T19:16:14Z|http://arxiv.org/abs/1703.03429v1|http://arxiv.org/pdf/1703.03429v1|What can you do with a rock? Affordance extraction via word embeddings|Autonomous agents must often detect affordances: the set of behaviors enabled by a situation. Affordance detection is particularly helpful in domains with large action spaces, allowing the agent to prune its search space by avoiding futile behaviors. This paper presents a method for affordance extraction via word embeddings trained on a Wikipedia corpus. The resulting word vectors are treated as a common knowledge database which can be queried using linear algebra. We apply this method to a reinforcement learning agent in a text-only environment and show that affordance-based action selection improves performance most of the time. Our method increases the computational complexity of each learning step but significantly reduces the total number of steps needed. In addition, the agent's action selections begin to resemble those a human would choose.|['Nancy Fulda', 'Daniel Ricks', 'Ben Murdoch', 'David Wingate']|['cs.AI', 'cs.CL']
2017-03-16T23:28:43Z|2017-03-09T18:58:03Z|http://arxiv.org/abs/1703.03400v1|http://arxiv.org/pdf/1703.03400v1|Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks|We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on a few-shot image classification benchmark, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.|['Chelsea Finn', 'Pieter Abbeel', 'Sergey Levine']|['cs.LG', 'cs.AI', 'cs.CV', 'cs.NE']
2017-03-16T23:28:43Z|2017-03-15T01:37:18Z|http://arxiv.org/abs/1703.03372v3|http://arxiv.org/pdf/1703.03372v3|LesionSeg: Semantic segmentation of skin lesions using Deep   Convolutional Neural Network|We present a method for skin lesion segmentation for the ISIC 2017 Skin Lesion Segmentation Challenge. Our approach is based on a Fully Convolutional Network architecture which is trained end to end, from scratch, on a limited dataset. Our semantic segmentation architecture utilizes several recent innovations in particularly in the combined use of (i) use of atrous convolutions to increase the effective field of view of the network's receptive field without increasing the number of parameters, (ii) the use of network-in-network $1\times1$ convolution layers to add capacity to the network and (iii) state-of-art super-resolution upsampling of predictions using subpixel CNN layers. We reported a mean IOU score of 0.642 on the validation set provided by the organisers.|['Dhanesh Ramachandram', 'Terrance DeVries']|['cs.CV', 'cs.AI', 'cs.NE']
2017-03-16T23:28:43Z|2017-03-09T13:22:48Z|http://arxiv.org/abs/1703.03255v1|http://arxiv.org/pdf/1703.03255v1|Counterfactuals, indicative conditionals, and negation under   uncertainty: Are there cross-cultural differences?|In this paper we study selected argument forms involving counterfactuals and indicative conditionals under uncertainty. We selected argument forms to explore whether people with an Eastern cultural background reason differently about conditionals compared to Westerners, because of the differences in the location of negations. In a 2x2 between-participants design, 63 Japanese university students were allocated to four groups, crossing indicative conditionals and counterfactuals, and each presented in two random task orders. The data show close agreement between the responses of Easterners and Westerners. The modal responses provide strong support for the hypothesis that conditional probability is the best predictor for counterfactuals and indicative conditionals. Finally, the grand majority of the responses are probabilistically coherent, which endorses the psychological plausibility of choosing coherence-based probability logic as a rationality framework for psychological reasoning research.|['Niki Pfeifer', 'Hiroshi Yama']|['cs.AI', 'math.LO', 'math.PR']
2017-03-16T23:28:43Z|2017-03-12T19:52:18Z|http://arxiv.org/abs/1703.03254v2|http://arxiv.org/pdf/1703.03254v2|Abductive, Causal, and Counterfactual Conditionals Under Incomplete   Probabilistic Knowledge|"We study abductive, causal, and non-causal conditionals in indicative and counterfactual formulations using probabilistic truth table tasks under incomplete probabilistic knowledge (N = 80). We frame the task as a probability-logical inference problem. The most frequently observed response type across all conditions was a class of conditional event interpretations of conditionals; it was followed by conjunction interpretations. An interesting minority of participants neglected some of the relevant imprecision involved in the premises when inferring lower or upper probability bounds on the target conditional/counterfactual (""halfway responses""). We discuss the results in the light of coherence-based probability logic and the new paradigm psychology of reasoning."|['Niki Pfeifer', 'Leena Tulkki']|['cs.AI', 'math.PR']
2017-03-16T23:28:43Z|2017-03-09T11:31:38Z|http://arxiv.org/abs/1703.03233v1|http://arxiv.org/pdf/1703.03233v1|Modeling the Ellsberg Paradox by Argument Strength|We present a formal measure of argument strength, which combines the ideas that conclusions of strong arguments are (i) highly probable and (ii) their uncertainty is relatively precise. Likewise, arguments are weak when their conclusion probability is low or when it is highly imprecise. We show how the proposed measure provides a new model of the Ellsberg paradox. Moreover, we further substantiate the psychological plausibility of our approach by an experiment (N = 60). The data show that the proposed measure predicts human inferences in the original Ellsberg task and in corresponding argument strength tasks. Finally, we report qualitative data taken from structured interviews on folk psychological conceptions on what argument strength means.|['Niki Pfeifer', 'Hanna Pankka']|['cs.AI', 'math.LO', 'math.PR']
2017-03-16T23:28:43Z|2017-03-09T09:30:01Z|http://arxiv.org/abs/1703.03193v1|http://arxiv.org/pdf/1703.03193v1|Embedding Tarskian Semantics in Vector Spaces|We propose a new linear algebraic approach to the computation of Tarskian semantics in logic. We embed a finite model M in first-order logic with N entities in N-dimensional Euclidean space R^N by mapping entities of M to N dimensional one-hot vectors and k-ary relations to order-k adjacency tensors (multi-way arrays). Second given a logical formula F in prenex normal form, we compile F into a set Sigma_F of algebraic formulas in multi-linear algebra with a nonlinear operation. In this compilation, existential quantifiers are compiled into a specific type of tensors, e.g., identity matrices in the case of quantifying two occurrences of a variable. It is shown that a systematic evaluation of Sigma_F in R^N gives the truth value, 1(true) or 0(false), of F in M. Based on this framework, we also propose an unprecedented way of computing the least models defined by Datalog programs in linear spaces via matrix equations and empirically show its effectiveness compared to state-of-the-art approaches.|['Taisuke Sato']|['cs.AI', 'cs.LO']
2017-03-16T23:28:43Z|2017-03-09T07:05:28Z|http://arxiv.org/abs/1703.03161v1|http://arxiv.org/abs/1703.03161v1|Behavior-based Navigation of Mobile Robot in Unknown Environments Using   Fuzzy Logic and Multi-Objective Optimization|This study proposes behavior-based navigation architecture, named BBFM, to deal with the problem of navigating the mobile robot in unknown environments in the presence of obstacles and local minimum regions. In the architecture, the complex navigation task is split into principal sub-tasks or behaviors. Each behavior is implemented by a fuzzy controller and executed independently to deal with a specific problem of navigation. The fuzzy controller is modified to contain only the fuzzification and inference procedures so that its output is a membership function representing the behavior's objective. The membership functions of all controllers are then used as the objective functions for a multi-objective optimization process to coordinate all behaviors. The result of this process is an overall control signal, which is Pareto-optimal, used to control the robot. A number of simulations, comparisons, and experiments were conducted. The results show that the proposed architecture outperforms some popular behavior-based architectures in term of accuracy, smoothness, traveled distance, and time response.|['Thi Thanh Van Nguyen', 'Manh Duong Phung', 'Quang Vinh Tran']|['cs.RO', 'cs.AI', 'cs.SY']
2017-03-16T23:28:48Z|2017-03-09T04:42:30Z|http://arxiv.org/abs/1703.03130v1|http://arxiv.org/pdf/1703.03130v1|A Structured Self-attentive Sentence Embedding|This paper proposes a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks.|['Zhouhan Lin', 'Minwei Feng', 'Cicero Nogueira dos Santos', 'Mo Yu', 'Bing Xiang', 'Bowen Zhou', 'Yoshua Bengio']|['cs.CL', 'cs.AI', 'cs.LG', 'cs.NE']
2017-03-16T23:28:48Z|2017-03-09T01:28:00Z|http://arxiv.org/abs/1703.03097v1|http://arxiv.org/abs/1703.03097v1|Information Extraction in Illicit Domains|Extracting useful entities and attribute values from illicit domains such as human trafficking is a challenging problem with the potential for widespread social impact. Such domains employ atypical language models, have `long tails' and suffer from the problem of concept drift. In this paper, we propose a lightweight, feature-agnostic Information Extraction (IE) paradigm specifically designed for such domains. Our approach uses raw, unlabeled text from an initial corpus, and a few (12-120) seed annotations per domain-specific attribute, to learn robust IE models for unobserved pages and websites. Empirically, we demonstrate that our approach can outperform feature-centric Conditional Random Field baselines by over 18\% F-Measure on five annotated sets of real-world human trafficking datasets in both low-supervision and high-supervision settings. We also show that our approach is demonstrably robust to concept drift, and can be efficiently bootstrapped even in a serial computing environment.|['Mayank Kejriwal', 'Pedro Szekely']|['cs.CL', 'cs.AI']
2017-03-16T23:28:48Z|2017-03-08T23:54:09Z|http://arxiv.org/abs/1703.03076v1|http://arxiv.org/pdf/1703.03076v1|Efficient Simulation of Financial Stress Testing Scenarios with   Suppes-Bayes Causal Networks|The most recent financial upheavals have cast doubt on the adequacy of some of the conventional quantitative risk management strategies, such as VaR (Value at Risk), in many common situations. Consequently, there has been an increasing need for verisimilar financial stress testings, namely simulating and analyzing financial portfolios in extreme, albeit rare scenarios. Unlike conventional risk management which exploits statistical correlations among financial instruments, here we focus our analysis on the notion of probabilistic causation, which is embodied by Suppes-Bayes Causal Networks (SBCNs), SBCNs are probabilistic graphical models that have many attractive features in terms of more accurate causal analysis for generating financial stress scenarios. In this paper, we present a novel approach for conducting stress testing of financial portfolios based on SBCNs in combination with classical machine learning classification tools. The resulting method is shown to be capable of correctly discovering the causal relationships among financial factors that affect the portfolios and thus, simulating stress testing scenarios with a higher accuracy and lower computational complexity than conventional Monte Carlo Simulations.|['Gelin Gao', 'Bud Mishra', 'Daniele Ramazzotti']|['cs.LG', 'cs.AI', 'cs.CE']
2017-03-16T23:28:48Z|2017-03-08T23:50:19Z|http://arxiv.org/abs/1703.03074v1|http://arxiv.org/pdf/1703.03074v1|Learning the Probabilistic Structure of Cumulative Phenomena with   Suppes-Bayes Causal Networks|"One of the critical issues when adopting Bayesian networks (BNs) to model dependencies among random variables is to ""learn"" their structure, given the huge search space of possible solutions, i.e., all the possible direct acyclic graphs. This is a well-known NP-hard problem, which is also complicated by known pitfalls such as the issue of I-equivalence among different structures. In this work we restrict the investigations on BN structure learning to a specific class of networks, i.e., those representing the dynamics of phenomena characterized by the monotonic accumulation of events. Such phenomena allow to set specific structural constraints based on Suppes' theory of probabilistic causation and, accordingly, to define constrained BNs, named Suppes-Bayes Causal Networks (SBCNs). We here investigate the structure learning of SBCNs via extensive simulations with various state-of-the-art search strategies, such as canonical local search techniques and Genetic Algorithms. Among the main results we show that Suppes' constraints deeply simplify the learning task, by reducing the solution search space and providing a temporal ordering on the variables."|['Daniele Ramazzotti', 'Marco S. Nobile', 'Marco Antoniotti', 'Alex Graudenzi']|['cs.LG', 'cs.AI']
2017-03-16T23:28:48Z|2017-03-08T22:09:38Z|http://arxiv.org/abs/1703.03055v1|http://arxiv.org/pdf/1703.03055v1|Interpretable Structure-Evolving LSTM|This paper develops a general framework for learning interpretable data representation via Long Short-Term Memory (LSTM) recurrent neural networks over hierarchal graph structures. Instead of learning LSTM models over the pre-fixed structures, we propose to further learn the intermediate interpretable multi-level graph structures in a progressive and stochastic way from data during the LSTM network optimization. We thus call this model the structure-evolving LSTM. In particular, starting with an initial element-level graph representation where each node is a small data element, the structure-evolving LSTM gradually evolves the multi-level graph representations by stochastically merging the graph nodes with high compatibilities along the stacked LSTM layers. In each LSTM layer, we estimate the compatibility of two connected nodes from their corresponding LSTM gate outputs, which is used to generate a merging probability. The candidate graph structures are accordingly generated where the nodes are grouped into cliques with their merging probabilities. We then produce the new graph structure with a Metropolis-Hasting algorithm, which alleviates the risk of getting stuck in local optimums by stochastic sampling with an acceptance probability. Once a graph structure is accepted, a higher-level graph is then constructed by taking the partitioned cliques as its nodes. During the evolving process, representation becomes more abstracted in higher-levels where redundant information is filtered out, allowing more efficient propagation of long-range data dependencies. We evaluate the effectiveness of structure-evolving LSTM in the application of semantic object parsing and demonstrate its advantage over state-of-the-art LSTM models on standard benchmarks.|['Xiaodan Liang', 'Liang Lin', 'Xiaohui Shen', 'Jiashi Feng', 'Shuicheng Yan', 'Eric P. Xing']|['cs.CV', 'cs.AI', 'cs.LG']
2017-03-16T23:28:48Z|2017-03-08T22:09:10Z|http://arxiv.org/abs/1703.03054v1|http://arxiv.org/pdf/1703.03054v1|Deep Variation-structured Reinforcement Learning for Visual Relationship   and Attribute Detection|Despite progress in visual perception tasks such as image classification and detection, computers still struggle to understand the interdependency of objects in the scene as a whole, e.g., relations between objects or their attributes. Existing methods often ignore global context cues capturing the interactions among different object instances, and can only recognize a handful of types by exhaustively training individual detectors for all possible relationships. To capture such global interdependency, we propose a deep Variation-structured Reinforcement Learning (VRL) framework to sequentially discover object relationships and attributes in the whole image. First, a directed semantic action graph is built using language priors to provide a rich and compact representation of semantic correlations between object categories, predicates, and attributes. Next, we use a variation-structured traversal over the action graph to construct a small, adaptive action set for each step based on the current state and historical actions. In particular, an ambiguity-aware object mining scheme is used to resolve semantic ambiguity among object categories that the object detector fails to distinguish. We then make sequential predictions using a deep RL framework, incorporating global context cues and semantic embeddings of previously extracted phrases in the state vector. Our experiments on the Visual Relationship Detection (VRD) dataset and the large-scale Visual Genome dataset validate the superiority of VRL, which can achieve significantly better detection results on datasets involving thousands of relationship and attribute types. We also demonstrate that VRL is able to predict unseen types embedded in our action graph by learning correlations on shared graph nodes.|['Xiaodan Liang', 'Lisa Lee', 'Eric P. Xing']|['cs.CV', 'cs.AI', 'cs.LG']
2017-03-16T23:28:48Z|2017-03-08T21:39:52Z|http://arxiv.org/abs/1703.03693v1|http://arxiv.org/pdf/1703.03693v1|On Quantum Decision Trees|Quantum decision systems are being increasingly considered for use in artificial intelligence applications. Classical and quantum nodes can be distinguished based on certain correlations in their states. This paper investigates some properties of the states obtained in a decision tree structure. How these correlations may be mapped to the decision tree is considered. Classical tree representations and approximations to quantum states are provided.|['Subhash Kak']|['cs.AI']
2017-03-16T23:28:48Z|2017-03-08T21:36:01Z|http://arxiv.org/abs/1703.03041v1|http://arxiv.org/abs/1703.03041v1|Combining Bayesian Approaches and Evolutionary Techniques for the   Inference of Breast Cancer Networks|Gene and protein networks are very important to model complex large-scale systems in molecular biology. Inferring or reverseengineering such networks can be defined as the process of identifying gene/protein interactions from experimental data through computational analysis. However, this task is typically complicated by the enormously large scale of the unknowns in a rather small sample size. Furthermore, when the goal is to study causal relationships within the network, tools capable of overcoming the limitations of correlation networks are required. In this work, we make use of Bayesian Graphical Models to attach this problem and, specifically, we perform a comparative study of different state-of-the-art heuristics, analyzing their performance in inferring the structure of the Bayesian Network from breast cancer data.|['Stefano Beretta', 'Mauro Castelli', 'Ivo Goncalves', 'Ivan Merelli', 'Daniele Ramazzotti']|['cs.LG', 'cs.AI']
2017-03-16T23:28:48Z|2017-03-08T18:09:32Z|http://arxiv.org/abs/1703.02949v1|http://arxiv.org/pdf/1703.02949v1|Learning Invariant Feature Spaces to Transfer Skills with Reinforcement   Learning|"People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where two agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of ""analogy making"", or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven."|['Abhishek Gupta', 'Coline Devin', 'YuXuan Liu', 'Pieter Abbeel', 'Sergey Levine']|['cs.AI', 'cs.RO']
2017-03-16T23:28:48Z|2017-03-08T16:38:21Z|http://arxiv.org/abs/1703.02905v1|http://arxiv.org/pdf/1703.02905v1|Learning a Unified Control Policy for Safe Falling|Being able to fall safely is a necessary motor skill for humanoids performing highly dynamic tasks, such as running and jumping. We propose a new method to learn a policy that minimizes the maximal impulse during the fall. The optimization solves for both a discrete contact planning problem and a continuous optimal control problem. Once trained, the policy can compute the optimal next contacting body part (e.g. left foot, right foot, or hands), contact location and timing, and the required joint actuation. We represent the policy as a mixture of actor-critic neural network, which consists of n control policies and the corresponding value functions. Each pair of actor-critic is associated with one of the n possible contacting body parts. During execution, the policy corresponding to the highest value function will be executed while the associated body part will be the next contact with the ground. With this mixture of actor-critic architecture, the discrete contact sequence planning is solved through the selection of the best critics while the continuous control problem is solved by the optimization of actors. We show that our policy can achieve comparable, sometimes even higher, rewards than a recursive search of the action space using dynamic programming, while enjoying 50 to 400 times of speed gain during online execution.|['Visak CV Kumar', 'Sehoon Ha', 'C Karen Liu']|['cs.RO', 'cs.AI', 'cs.LG']
2017-03-16T23:28:52Z|2017-03-08T15:50:35Z|http://arxiv.org/abs/1703.02883v1|http://arxiv.org/abs/1703.02883v1|Memory Enriched Big Bang Big Crunch Optimization Algorithm for Data   Clustering|Cluster analysis plays an important role in decision making process for many knowledge-based systems. There exist a wide variety of different approaches for clustering applications including the heuristic techniques, probabilistic models, and traditional hierarchical algorithms. In this paper, a novel heuristic approach based on big bang-big crunch algorithm is proposed for clustering problems. The proposed method not only takes advantage of heuristic nature to alleviate typical clustering algorithms such as k-means, but it also benefits from the memory based scheme as compared to its similar heuristic techniques. Furthermore, the performance of the proposed algorithm is investigated based on several benchmark test functions as well as on the well-known datasets. The experimental results show the significant superiority of the proposed method over the similar algorithms.|['Kayvan Bijari', 'Hadi Zare', 'Hadi Veisi', 'Hossein Bobarshad']|['cs.AI', 'cs.LG']
2017-03-16T23:28:52Z|2017-03-08T12:53:21Z|http://arxiv.org/abs/1703.02819v1|http://arxiv.org/abs/1703.02819v1|Introduction to Formal Concept Analysis and Its Applications in   Information Retrieval and Related Fields|This paper is a tutorial on Formal Concept Analysis (FCA) and its applications. FCA is an applied branch of Lattice Theory, a mathematical discipline which enables formalisation of concepts as basic units of human thinking and analysing data in the object-attribute form. Originated in early 80s, during the last three decades, it became a popular human-centred tool for knowledge representation and data analysis with numerous applications. Since the tutorial was specially prepared for RuSSIR 2014, the covered FCA topics include Information Retrieval with a focus on visualisation aspects, Machine Learning, Data Mining and Knowledge Discovery, Text Mining and several others.|['Dmitry I. Ignatov']|['cs.IR', 'cs.AI', 'cs.CL', 'cs.DM', 'stat.ML', '68P20, 06B99, 68T30', 'H.3.3; G.2; I.2']
2017-03-16T23:28:52Z|2017-03-08T12:35:52Z|http://arxiv.org/abs/1703.02810v1|http://arxiv.org/pdf/1703.02810v1|An Integrated and Scalable Platform for Proactive Event-Driven Traffic   Management|Traffic on freeways can be managed by means of ramp meters from Road Traffic Control rooms. Human operators cannot efficiently manage a network of ramp meters. To support them, we present an intelligent platform for traffic management which includes a new ramp metering coordination scheme in the decision making module, an efficient dashboard for interacting with human operators, machine learning tools for learning event definitions and Complex Event Processing tools able to deal with uncertainties inherent to the traffic use case. Unlike the usual approach, the devised event-driven platform is able to predict a congestion up to 4 minutes before it really happens. Proactive decision making can then be established leading to significant improvement of traffic conditions.|['Alain Kibangou', 'Alexander Artikis', 'Evangelos Michelioudakis', 'Georgios Paliouras', 'Marius Schmitt', 'John Lygeros', 'Chris Baber', 'Natan Morar', 'Fabiana Fournier', 'Inna Skarbovsky']|['cs.AI', 'cs.LG', 'cs.SY']
2017-03-16T23:28:52Z|2017-03-08T04:58:51Z|http://arxiv.org/abs/1703.02702v1|http://arxiv.org/pdf/1703.02702v1|Robust Adversarial Reinforcement Learning|Deep neural networks coupled with fast simulation and improved computation have led to recent successes in the field of reinforcement learning (RL). However, most current RL-based approaches fail to generalize since: (a) the gap between simulation and real world is so large that policy-learning approaches fail to transfer; (b) even if policy learning is done in real world, the data scarcity leads to failed generalization from training to test scenarios (e.g., due to different friction or object masses). Inspired from H-infinity control methods, we note that both modeling errors and differences in training and test scenarios can be viewed as extra forces/disturbances in the system. This paper proposes the idea of robust adversarial reinforcement learning (RARL), where we train an agent to operate in the presence of a destabilizing adversary that applies disturbance forces to the system. The jointly trained adversary is reinforced -- that is, it learns an optimal destabilization policy. We formulate the policy learning as a zero-sum, minimax objective function. Extensive experiments in multiple environments (InvertedPendulum, HalfCheetah, Swimmer, Hopper and Walker2d) conclusively demonstrate that our method (a) improves training stability; (b) is robust to differences in training/test conditions; and c) outperform the baseline even in the absence of the adversary.|['Lerrel Pinto', 'James Davidson', 'Rahul Sukthankar', 'Abhinav Gupta']|['cs.LG', 'cs.AI', 'cs.MA', 'cs.RO']
2017-03-16T23:28:52Z|2017-03-08T01:33:51Z|http://arxiv.org/abs/1703.02660v1|http://arxiv.org/pdf/1703.02660v1|Towards Generalization and Simplicity in Continuous Control|This work shows that policies with simple linear and RBF parameterizations can be trained to solve a variety of continuous control tasks, including the OpenAI gym benchmarks. The performance of these trained policies are competitive with state of the art results, obtained with more elaborate parameterizations such as fully connected neural networks. Furthermore, existing training and testing scenarios are shown to be very limited and prone to over-fitting, thus giving rise to only trajectory-centric policies. Training with a diverse initial state distribution is shown to produce more global policies with better generalization. This allows for interactive control scenarios where the system recovers from large on-line perturbations; as shown in the supplementary video.|['Aravind Rajeswaran', 'Kendall Lowrey', 'Emanuel Todorov', 'Sham Kakade']|['cs.LG', 'cs.AI', 'cs.RO', 'cs.SY']
2017-03-16T23:28:52Z|2017-03-08T00:15:54Z|http://arxiv.org/abs/1703.02645v1|http://arxiv.org/pdf/1703.02645v1|Cost-Optimal Learning of Causal Graphs|We consider the problem of learning a causal graph over a set of variables with interventions. We study the cost-optimal causal graph learning problem: For a given skeleton (undirected version of the causal graph), design the set of interventions with minimum total cost, that can uniquely identify any causal graph with the given skeleton. We show that this problem is solvable in polynomial time. Later, we consider the case when the number of interventions is limited. For this case, we provide polynomial time algorithms when the skeleton is a tree or a clique tree. For a general chordal skeleton, we develop an efficient greedy algorithm, which can be improved when the causal graph skeleton is an interval graph.|['Murat Kocaoglu', 'Alexandros G. Dimakis', 'Sriram Vishwanath']|['cs.AI', 'cs.IT', 'math.IT', 'stat.ML']
2017-03-16T23:28:52Z|2017-03-07T21:53:44Z|http://arxiv.org/abs/1703.02610v1|http://arxiv.org/pdf/1703.02610v1|Multi-Robot Active Information Gathering with Periodic Communication|A team of robots sharing a common goal can benefit from coordination of the activities of team members, helping the team to reach the goal more reliably or quickly. We address the problem of coordinating the actions of a team of robots with periodic communication capability executing an information gathering task. We cast the problem as a multi-agent optimal decision-making problem with an information theoretic objective function. We show that appropriate techniques for solving decentralized partially observable Markov decision processes (Dec-POMDPs) are applicable in such information gathering problems. We quantify the usefulness of coordinated information gathering through simulation studies, and demonstrate the feasibility of the method in a real-world target tracking domain.|['Mikko Lauri', 'Eero Heinänen', 'Simone Frintrop']|['cs.RO', 'cs.AI']
2017-03-16T23:28:52Z|2017-03-07T18:19:11Z|http://arxiv.org/abs/1703.02507v1|http://arxiv.org/pdf/1703.02507v1|Unsupervised Learning of Sentence Embeddings using Compositional n-Gram   Features|The recent tremendous success of unsupervised word embeddings in a multitude of applications raises the obvious question if similar methods could be derived to improve embeddings (i.e. semantic representations) of word sequences as well. We present a simple but efficient unsupervised objective to train distributed representations of sentences. Our method outperforms the state-of-the-art unsupervised models on most benchmark tasks, and on many tasks even beats supervised models, highlighting the robustness of the produced sentence embeddings.|['Matteo Pagliardini', 'Prakhar Gupta', 'Martin Jaggi']|['cs.CL', 'cs.AI', 'cs.IR', 'I.2.7']
2017-03-16T23:28:52Z|2017-03-07T10:16:45Z|http://arxiv.org/abs/1703.02310v1|http://arxiv.org/pdf/1703.02310v1|Deep Robust Kalman Filter|A Robust Markov Decision Process (RMDP) is a sequential decision making model that accounts for uncertainty in the parameters of dynamic systems. This uncertainty introduces difficulties in learning an optimal policy, especially for environments with large state spaces. We propose two algorithms, RTD-DQN and Deep-RoK, for solving large-scale RMDPs using nonlinear approximation schemes such as deep neural networks. The RTD-DQN algorithm incorporates the robust Bellman temporal difference error into a robust loss function, yielding robust policies for the agent. The Deep-RoK algorithm is a robust Bayesian method, based on the Extended Kalman Filter (EKF), that accounts for both the uncertainty in the weights of the approximated value function and the uncertainty in the transition probabilities, improving the robustness of the agent. We provide theoretical results for our approach and test the proposed algorithms on a continuous state domain.|['Shirli Di-Castro Shashua', 'Shie Mannor']|['cs.AI', 'cs.LG', 'stat.ML']
2017-03-16T23:28:52Z|2017-03-08T15:29:05Z|http://arxiv.org/abs/1703.02245v2|http://arxiv.org/pdf/1703.02245v2|Design of the Artificial: lessons from the biological roots of general   intelligence|Our desire and fascination with intelligent machines dates back to the antiquity's mythical automaton Talos, Aristotle's mode of mechanical thought (syllogism) and Heron of Alexandria's mechanical machines and automata. However, the quest for Artificial General Intelligence (AGI) is troubled with repeated failures of strategies and approaches throughout the history. This decade has seen a shift in interest towards bio-inspired software and hardware, with the assumption that such mimicry entails intelligence. Though these steps are fruitful in certain directions and have advanced automation, their singular design focus renders them highly inefficient in achieving AGI. Which set of requirements have to be met in the design of AGI? What are the limits in the design of the artificial? Here, a careful examination of computation in biological systems hints that evolutionary tinkering of contextual processing of information enabled by a hierarchical architecture is the key to build AGI.|['Nima Dehghani']|['cs.AI', 'cs.NE', 'nlin.AO', 'q-bio.NC']
2017-03-16T23:28:56Z|2017-03-07T06:51:19Z|http://arxiv.org/abs/1703.02239v1|http://arxiv.org/pdf/1703.02239v1|Functions that Emerge through End-to-end Reinforcement Learning|"Recently, triggered by the impressive results in TV-games or game of Go by Google DeepMind, end-to-end reinforcement learning (RL) is collecting attentions. Although little is known, the author's group has propounded this framework for around 20 years and already has shown a variety of functions that emerge in a neural network (NN) through RL. In this paper, they are introduced again at this timing.   ""Function Modularization"" approach is deeply penetrated subconsciously. The inputs and outputs for a learning system can be raw sensor signals and motor commands. ""State space"" or ""action space"" generally used in RL show the existence of functional modules. That has limited reinforcement learning to learning only for the action-planning module. In order to extend reinforcement learning to learning of the entire function on a huge degree of freedom of a massively parallel learning system and to explain or develop human-like intelligence, the author has believed that end-to-end RL from sensors to motors using a recurrent NN (RNN) becomes an essential key. Especially in the higher functions, this approach is very effective by being free from the need to decide their inputs or outputs.   The functions that emerge, we have confirmed, through RL using a NN cover a broad range from real robot learning with raw camera pixel inputs to acquisition of dynamic functions in a RNN. Those are (1)image recognition, (2)color constancy (optical illusion), (3)sensor motion (active recognition), (4)hand-eye coordination and hand reaching movement, (5)explanation of brain activities, (6)communication, (7)knowledge transfer, (8)memory, (9)selective attention, (10)prediction, (11)exploration. The end-to-end RL enables the emergence of very flexible comprehensive functions that consider many things in parallel although it is difficult to give the boundary of each function clearly."|['Katsunari Shibata']|['cs.AI']
2017-03-16T23:28:56Z|2017-03-07T03:16:22Z|http://arxiv.org/abs/1703.02196v1|http://arxiv.org/abs/1703.02196v1|Cooperative Epistemic Multi-Agent Planning for Implicit Coordination|Epistemic planning can be used for decision making in multi-agent situations with distributed knowledge and capabilities. Recently, Dynamic Epistemic Logic (DEL) has been shown to provide a very natural and expressive framework for epistemic planning. We extend the DEL-based epistemic planning framework to include perspective shifts, allowing us to define new notions of sequential and conditional planning with implicit coordination. With these, it is possible to solve planning tasks with joint goals in a decentralized manner without the agents having to negotiate about and commit to a joint policy at plan time. First we define the central planning notions and sketch the implementation of a planning system built on those notions. Afterwards we provide some case studies in order to evaluate the planner empirically and to show that the concept is useful for multi-agent systems in practice.|['Thorsten Engesser', 'Thomas Bolander', 'Robert Mattmüller', 'Bernhard Nebel']|['cs.AI', 'cs.LO', 'cs.MA']
2017-03-16T23:28:56Z|2017-03-07T03:15:08Z|http://arxiv.org/abs/1703.02192v1|http://arxiv.org/abs/1703.02192v1|A Gentle Introduction to Epistemic Planning: The DEL Approach|Epistemic planning can be used for decision making in multi-agent situations with distributed knowledge and capabilities. Dynamic Epistemic Logic (DEL) has been shown to provide a very natural and expressive framework for epistemic planning. In this paper, we aim to give an accessible introduction to DEL-based epistemic planning. The paper starts with the most classical framework for planning, STRIPS, and then moves towards epistemic planning in a number of smaller steps, where each step is motivated by the need to be able to model more complex planning scenarios.|['Thomas Bolander']|['cs.AI', 'cs.LO', 'cs.MA']
2017-03-16T23:28:56Z|2017-03-07T00:09:31Z|http://arxiv.org/abs/1703.02156v1|http://arxiv.org/pdf/1703.02156v1|On the Limits of Learning Representations with Label-Based Supervision|Advances in neural network based classifiers have transformed automatic feature learning from a pipe dream of stronger AI to a routine and expected property of practical systems. Since the emergence of AlexNet every winning submission of the ImageNet challenge has employed end-to-end representation learning, and due to the utility of good representations for transfer learning, representation learning has become as an important and distinct task from supervised learning. At present, this distinction is inconsequential, as supervised methods are state-of-the-art in learning transferable representations. But recent work has shown that generative models can also be powerful agents of representation learning. Will the representations learned from these generative methods ever rival the quality of those from their supervised competitors? In this work, we argue in the affirmative, that from an information theoretic perspective, generative models have greater potential for representation learning. Based on several experimentally validated assumptions, we show that supervised learning is upper bounded in its capacity for representation learning in ways that certain generative models, such as Generative Adversarial Networks (GANs) are not. We hope that our analysis will provide a rigorous motivation for further exploration of generative representation learning.|['Jiaming Song', 'Russell Stewart', 'Shengjia Zhao', 'Stefano Ermon']|['cs.LG', 'cs.AI', 'stat.ML']
2017-03-16T23:28:56Z|2017-03-06T20:28:23Z|http://arxiv.org/abs/1703.02100v1|http://arxiv.org/pdf/1703.02100v1|Guarantees for Greedy Maximization of Non-submodular Functions with   Applications|We investigate the performance of the Greedy algorithm for cardinality constrained maximization of non-submodular nondecreasing set functions. While there are strong theoretical guarantees on the performance of Greedy for maximizing submodular functions, there are few guarantees for non-submodular ones. However, Greedy enjoys strong empirical performance for many important non-submodular functions, e.g., the Bayesian A-optimality objective in experimental design. We prove theoretical guarantees supporting the empirical performance. Our guarantees are characterized by the (generalized) submodularity ratio $\gamma$ and the (generalized) curvature $\alpha$. In particular, we prove that Greedy enjoys a tight approximation guarantee of $\frac{1}{\alpha}(1- e^{-\gamma\alpha})$ for cardinality constrained maximization. In addition, we bound the submodularity ratio and curvature for several important real-world objectives, e.g., the Bayesian A-optimality objective, the determinantal function of a square submatrix and certain linear programs with combinatorial constraints. We experimentally validate our theoretical findings for several real-world applications.|['Andrew An Bian', 'Joachim M. Buhmann', 'Andreas Krause', 'Sebastian Tschiatschek']|['cs.DM', 'cs.AI', 'cs.DS', 'cs.LG', 'math.OC']
2017-03-16T23:28:56Z|2017-03-06T17:42:55Z|http://arxiv.org/abs/1703.02000v1|http://arxiv.org/pdf/1703.02000v1|Generative Adversarial Nets with Labeled Data by Activation Maximization|In this paper, we study the impact and role of multi-class labels on adversarial training for generative adversarial nets (GANs). Our derivation of the gradient shows that the current GAN model with labeled data still results in undesirable properties due to the overlay of the gradients from multiple classes. We thus argue that a better gradient should follow the intensity and direction that maximize each sample's activation on one and the only one class in each iteration, rather than weighted-averaging their gradients. We show, mathematically, that the proposed activation-maximized adversarial training (AM-GAN) is a general one covering two major complementary solutions exploring labeled information. Additionally, we investigate related metrics for evaluating generative models. Empirical experiments show that our approach has achieved the best Inception score (8.34) compared with previously reported results. Moreover, our adversarial training produces faster convergence with no mode collapse observed.|['Zhiming Zhou', 'Shu Rong', 'Han Cai', 'Weinan Zhang', 'Yong Yu', 'Jun Wang']|['cs.LG', 'cs.AI', 'cs.CV', 'stat.ML']
2017-03-16T23:28:56Z|2017-03-06T16:54:12Z|http://arxiv.org/abs/1703.01971v1|http://arxiv.org/pdf/1703.01971v1|Evidential supplier selection based on interval data fusion|Supplier selection is a typical multi-criteria decision making (MCDM) problem and lots of uncertain information exist inevitably. To address this issue, a new method was proposed based on interval data fusion. Our method follows the original way to generate classical basic probability assignment(BPA) determined by the distance among the evidences. However, the weights of criteria are kept as interval numbers to generate interval BPAs and do the fusion of interval BPAs. Finally, the order is ranked and the decision is made according to the obtained interval BPAs. In this paper, a numerical example of supplier selection is applied to verify the feasibility and validity of our method. The new method is presented aiming at solving multiple-criteria decision-making problems in which the weights of criteria or experts are described in fuzzy data like linguistic terms or interval data.|['Zichang He', 'Wen Jiang']|['cs.AI']
2017-03-16T23:28:56Z|2017-03-06T16:52:07Z|http://arxiv.org/abs/1703.02894v1|http://arxiv.org/pdf/1703.02894v1|A quantum dynamic belief model to explain the interference effects of   categorization on decision making|Categorization is necessary for many decision making tasks. However, the categorization process may interfere the decision making result and the law of total probability can be violated in some situations. To predict the interference effect of categorization, some model based on quantum probability has been proposed. In this paper, a new quantum dynamic belief (QDB) model is proposed. Considering the precise decision may not be made during the process, the concept of uncertainty is introduced in our model to simulate real human thinking process. Then the interference effect categorization can be predicted by handling the uncertain information. The proposed model is applied to a categorization decision-making experiment to explain the interference effect of categorization. Compared with other models, our model is relatively more succinct and the result shows the correctness and effectiveness of our model.|['Zichang He', 'Wen Jiang']|['cs.AI', 'quant-ph']
2017-03-16T23:28:56Z|2017-03-06T16:43:13Z|http://arxiv.org/abs/1703.01963v1|http://arxiv.org/pdf/1703.01963v1|A new belief Markov chain model and its application in inventory   prediction|Markov chain model is widely applied in many fields, especially the field of prediction. The classical Discrete-time Markov chain(DTMC) is a widely used method for prediction. However, the classical DTMC model has some limitation when the system is complex with uncertain information or state space is not discrete. To address it, a new belief Markov chain model is proposed by combining Dempster-Shafer evidence theory with Markov chain. In our model, the uncertain data is allowed to be handle in the form of interval number and the basic probability assignment(BPA) is generated based on the distance between interval numbers. The new belief Markov chain model overcomes the shortcomings of classical Markov chain and has an efficient ability in dealing with uncertain information. Moreover, an example of inventory prediction and the comparison between our model and classical DTMC model can show the effectiveness and rationality of our proposed model.|['Zichang He', 'Wen Jiang']|['cs.AI', 'cs.CE']
2017-03-16T23:28:56Z|2017-03-07T12:47:56Z|http://arxiv.org/abs/1703.01946v2|http://arxiv.org/pdf/1703.01946v2|Metric Learning for Generalizing Spatial Relations to New Objects|Human-centered environments are rich with a wide variety of spatial relations between everyday objects. For autonomous robots to operate effectively in such environments, they should be able to reason about these relations and generalize them to objects with different shapes and sizes. For example, having learned to place a toy inside a basket, a robot should be able to generalize this concept using a spoon and a cup. This requires a robot to have the flexibility to learn arbitrary relations in a lifelong manner, making it challenging for an expert to pre-program it with sufficient knowledge to do so beforehand. In this paper, we address the problem of learning spatial relations by introducing a novel method from the perspective of distance metric learning. Our approach enables a robot to reason about the similarity between pairwise spatial relations, thereby enabling it to use its previous knowledge when presented with a new relation to imitate. We show how this makes it possible to learn arbitrary spatial relations from non-expert users using a small number of examples and in an interactive manner. Our extensive evaluation with real-world data demonstrates the effectiveness of our method in reasoning about a continuous spectrum of spatial relations and generalizing them to new objects.|['Oier Mees', 'Nichola Abdo', 'Mladen Mazuran', 'Wolfram Burgard']|['cs.RO', 'cs.AI', 'cs.LG']
2017-03-16T23:29:00Z|2017-03-06T15:34:54Z|http://arxiv.org/abs/1703.01924v1|http://arxiv.org/pdf/1703.01924v1|Exchangeable choice functions|We investigate how to model exchangeability with choice functions. Exchangeability is a structural assessment on a sequence of uncertain variables. We show how such assessments are a special indifference assessment, and how that leads to a counterpart of de Finetti's Representation Theorem, both in a finite and a countable context.|['Arthur Van Camp', 'Gert de Cooman']|['cs.AI']
2017-03-16T23:29:00Z|2017-03-06T15:30:08Z|http://arxiv.org/abs/1703.02386v1|http://arxiv.org/pdf/1703.02386v1|A quantum dynamic belief decision making model|The sure thing principle and the law of total probability are basic laws in classic probability theory. A disjunction fallacy leads to the violation of these two classical probability laws. In this paper, a new quantum dynamic belief decision making model based on quantum dynamic modelling and Dempster-Shafer (D-S) evidence theory is proposed to address this issue and model the real human decision-making process. Some mathematical techniques are borrowed from quantum mathematics. Generally, belief and action are two parts in a decision making process. The uncertainty in belief part is represented by a superposition of certain states. The uncertainty in actions is represented as an extra uncertainty state. The interference effect is produced due to the entanglement between beliefs and actions. Basic probability assignment (BPA) of decisions is generated by quantum dynamic modelling. Then BPA of the extra uncertain state and an entanglement degree defined by an entropy function named Deng entropy are used to measure the interference effect. Compared the existing model, the number of free parameters is less in our model. Finally, a classical categorization decision-making experiment is illustrated to show the effectiveness of our model.|['Zichang He', 'Wen Jiang']|['cs.AI', 'q-bio.NC', 'quant-ph']
2017-03-16T23:29:00Z|2017-03-06T15:16:56Z|http://arxiv.org/abs/1703.01918v1|http://arxiv.org/pdf/1703.01918v1|High-Resolution Multispectral Dataset for Semantic Segmentation|Unmanned aircraft have decreased the cost required to collect remote sensing imagery, which has enabled researchers to collect high-spatial resolution data from multiple sensor modalities more frequently and easily. The increase in data will push the need for semantic segmentation frameworks that are able to classify non-RGB imagery, but this type of algorithmic development requires an increase in publicly available benchmark datasets with class labels. In this paper, we introduce a high-resolution multispectral dataset with image labels. This new benchmark dataset has been pre-split into training/testing folds in order to standardize evaluation and continue to push state-of-the-art classification frameworks for non-RGB imagery.|['Ronald Kemker', 'Carl Salvaggio', 'Christopher Kanan']|['cs.CV', 'cs.AI']
2017-03-16T23:29:00Z|2017-03-06T14:54:19Z|http://arxiv.org/abs/1703.01908v1|http://arxiv.org/pdf/1703.01908v1|A proposal for ethically traceable artificial intelligence|Although the problem of assigning a critique of robotic behavior in near-unanimous agreement to human norms seems intractable, a starting point of such a framework is of the collection of knowledge a priori and experience a posteriori categorized in a set of judgments available to the intelligence, translated into computer code. If such an intersection were successful, an algorithm with ethically traceable behavior and cogent equivalence to human cognition is established. The process of framework development itself reveals avenues of improvement and optimization. This paper will propose the application of Kant's critique of reason to current perceptions of autonomous intelligent systems.|['Christopher A. Tucker']|['cs.AI']
2017-03-16T23:29:00Z|2017-03-06T14:30:06Z|http://arxiv.org/abs/1703.01893v1|http://arxiv.org/pdf/1703.01893v1|Approximate Muscle Guided Beam Search for Three-Index Assignment Problem|As a well-known NP-hard problem, the Three-Index Assignment Problem (AP3) has attracted lots of research efforts for developing heuristics. However, existing heuristics either obtain less competitive solutions or consume too much time. In this paper, a new heuristic named Approximate Muscle guided Beam Search (AMBS) is developed to achieve a good trade-off between solution quality and running time. By combining the approximate muscle with beam search, the solution space size can be significantly decreased, thus the time for searching the solution can be sharply reduced. Extensive experimental results on the benchmark indicate that the new algorithm is able to obtain solutions with competitive quality and it can be employed on instances with largescale. Work of this paper not only proposes a new efficient heuristic, but also provides a promising method to improve the efficiency of beam search.|['He Jiang', 'Shuwei Zhang', 'Zhilei Ren', 'Xiaochen Lai', 'Yong Piao']|['cs.AI']
2017-03-16T23:29:00Z|2017-03-06T04:30:12Z|http://arxiv.org/abs/1703.01720v1|http://arxiv.org/pdf/1703.01720v1|Sound-Word2Vec: Learning Word Representations Grounded in Sounds|Sound and vision are the primary modalities that influence how we perceive the world around us. Thus, it is crucial to incorporate information from these modalities into language to help machines interact better with humans. While existing works have explored incorporating visual cues into language embeddings, the task of learning word representations that respect auditory grounding remains under-explored. In this work, we propose a new embedding scheme, sound-word2vec that learns language embeddings by grounding them in sound -- for example, two seemingly unrelated concepts, leaves and paper are closer in our embedding space as they produce similar rustling sounds. We demonstrate that the proposed embeddings perform better than language-only word representations, on two purely textual tasks that require reasoning about aural cues -- sound retrieval and foley-sound discovery. Finally, we analyze nearest neighbors to highlight the unique dependencies captured by sound-w2v as compared to language-only embeddings.|['Ashwin K Vijayakumar', 'Ramakrishna Vedantam', 'Devi Parikh']|['cs.CL', 'cs.AI', 'cs.SD']
2017-03-16T23:29:00Z|2017-03-06T00:53:04Z|http://arxiv.org/abs/1703.01697v1|http://arxiv.org/pdf/1703.01697v1|Principles and Examples of Plausible Reasoning and Propositional   Plausible Logic|Plausible reasoning concerns situations whose inherent lack of precision is not quantified; that is, there are no degrees or levels of precision, and hence no use of numbers like probabilities. A hopefully comprehensive set of principles that clarifies what it means for a formal logic to do plausible reasoning is presented. A new propositional logic, called Propositional Plausible Logic (PPL), is defined and applied to some important examples. PPL is the only non-numeric non-monotonic logic we know of that satisfies all the principles and correctly reasons with all the examples. Some important results about PPL are proved.|['David Billington']|['cs.AI', 'cs.LO', 'I.2.4']
2017-03-16T23:29:00Z|2017-03-05T21:57:25Z|http://arxiv.org/abs/1703.01671v1|http://arxiv.org/pdf/1703.01671v1|Controlling for Unobserved Confounds in Classification Using   Correlational Constraints|As statistical classifiers become integrated into real-world applications, it is important to consider not only their accuracy but also their robustness to changes in the data distribution. In this paper, we consider the case where there is an unobserved confounding variable $z$ that influences both the features $\mathbf{x}$ and the class variable $y$. When the influence of $z$ changes from training to testing data, we find that the classifier accuracy can degrade rapidly. In our approach, we assume that we can predict the value of $z$ at training time with some error. The prediction for $z$ is then fed to Pearl's back-door adjustment to build our model. Because of the attenuation bias caused by measurement error in $z$, standard approaches to controlling for $z$ are ineffective. In response, we propose a method to properly control for the influence of $z$ by first estimating its relationship with the class variable $y$, then updating predictions for $z$ to match that estimated relationship. By adjusting the influence of $z$, we show that we can build a model that exceeds competing baselines on accuracy as well as on robustness over a range of confounding relationships.|['Virgile Landeiro', 'Aron Culotta']|['cs.AI', 'cs.CL']
2017-03-16T23:29:00Z|2017-03-03T23:25:38Z|http://arxiv.org/abs/1703.01358v1|http://arxiv.org/pdf/1703.01358v1|Generalised Discount Functions applied to a Monte-Carlo AImu   Implementation|In recent years, work has been done to develop the theory of General Reinforcement Learning (GRL). However, there are few examples demonstrating these results in a concrete way. In particular, there are no examples demonstrating the known results regarding gener- alised discounting. We have added to the GRL simulation platform AIXIjs the functionality to assign an agent arbitrary discount functions, and an environment which can be used to determine the effect of discounting on an agent's policy. Using this, we investigate how geometric, hyperbolic and power discounting affect an informed agent in a simple MDP. We experimentally reproduce a number of theoretical results, and discuss some related subtleties. It was found that the agent's behaviour followed what is expected theoretically, assuming appropriate parameters were chosen for the Monte-Carlo Tree Search (MCTS) planning algorithm.|['Sean Lamont', 'John Aslanides', 'Jan Leike', 'Marcus Hutter']|['cs.AI']
2017-03-16T23:29:00Z|2017-03-03T21:39:56Z|http://arxiv.org/abs/1703.01347v1|http://arxiv.org/pdf/1703.01347v1|Contextual Multi-armed Bandits under Feature Uncertainty|We study contextual multi-armed bandit problems under linear realizability on rewards and uncertainty (or noise) on features. For the case of identical noise on features across actions, we propose an algorithm, coined {\em NLinRel}, having $O\left(T^{\frac{7}{8}} \left(\log{(dT)}+K\sqrt{d}\right)\right)$ regret bound for $T$ rounds, $K$ actions, and $d$-dimensional feature vectors. Next, for the case of non-identical noise, we observe that popular linear hypotheses including {\em NLinRel} are impossible to achieve such sub-linear regret. Instead, under assumption of Gaussian feature vectors, we prove that a greedy algorithm has $O\left(T^{\frac23}\sqrt{\log d}\right)$ regret bound with respect to the optimal linear hypothesis. Utilizing our theoretical understanding on the Gaussian case, we also design a practical variant of {\em NLinRel}, coined {\em Universal-NLinRel}, for arbitrary feature distributions. It first runs {\em NLinRel} for finding the `true' coefficient vector using feature uncertainties and then adjust it to minimize its regret using the statistical feature information. We justify the performance of {\em Universal-NLinRel} on both synthetic and real-world datasets.|['Se-Young Yun', 'Jun Hyun Nam', 'Sangwoo Mo', 'Jinwoo Shin']|['cs.AI', 'cs.LG', 'stat.ML']
2017-03-16T23:29:04Z|2017-03-03T20:36:38Z|http://arxiv.org/abs/1703.01333v1|http://arxiv.org/pdf/1703.01333v1|Analyzing Payment Based Question and Answering Service|Community based question answering (CQA) services receive a large volume of questions today. It is increasingly challenging to motivate domain experts to give timely answers. Recently, payment-based CQA services explore new incentive models to engage real-world experts and celebrities by allowing them to set a price on their answers. In this paper, we perform a data-driven analysis on Fenda, a payment-based CQA service that has gained initial success with this incentive model. Using a large dataset of 220K paid questions (worth 1 million USD) over two months, we examine how monetary incentives affect different players in the system and their over-time engagement. Our study reveals several key findings: while monetary incentive enables quick answers from experts, it also drives certain users to aggressively game the systems for profits. In addition, this incentive model turns CQA service into a supplier-driven marketplace where users need to proactively adjust their price as needed. We find famous people are unwilling to lower their price, which in turn hurts their income and engagement-level over time. Based on our results, we discuss the implications to future payment-based CQA design.|['Steve Jan', 'Chun Wang', 'Qing Zhang', 'Gang Wang']|['cs.AI', 'cs.HC']
2017-03-16T23:29:04Z|2017-03-03T20:19:08Z|http://arxiv.org/abs/1703.01327v1|http://arxiv.org/pdf/1703.01327v1|Multi-step Reinforcement Learning: A Unifying Algorithm|Unifying seemingly disparate algorithmic ideas to produce better performing algorithms has been a longstanding goal in reinforcement learning. As a primary example, TD($\lambda$) elegantly unifies one-step TD prediction with Monte Carlo methods through the use of eligibility traces and the trace-decay parameter $\lambda$. Currently, there are a multitude of algorithms that can be used to perform TD control, including Sarsa, $Q$-learning, and Expected Sarsa. These methods are often studied in the one-step case, but they can be extended across multiple time steps to achieve better performance. Each of these algorithms is seemingly distinct, and no one dominates the others for all problems. In this paper, we study a new multi-step action-value algorithm called $Q(\sigma)$ which unifies and generalizes these existing algorithms, while subsuming them as special cases. A new parameter, $\sigma$, is introduced to allow the degree of sampling performed by the algorithm at each step during its backup to be continuously varied, with Sarsa existing at one extreme (full sampling), and Expected Sarsa existing at the other (pure expectation). $Q(\sigma)$ is generally applicable to both on- and off-policy learning, but in this work we focus on experiments in the on-policy case. Our results show that an intermediate value of $\sigma$, which results in a mixture of the existing algorithms, performs better than either extreme. The mixture can also be varied dynamically which can result in even greater performance.|['Kristopher De Asis', 'J. Fernando Hernandez-Garcia', 'G. Zacharias Holland', 'Richard S. Sutton']|['cs.AI', 'cs.LG']
2017-03-16T23:29:04Z|2017-03-03T19:07:53Z|http://arxiv.org/abs/1703.01310v1|http://arxiv.org/pdf/1703.01310v1|Count-Based Exploration with Neural Density Models|Bellemare et al. (2016) introduced the notion of a pseudo-count to generalize count-based exploration to non-tabular reinforcement learning. This pseudo-count is derived from a density model which effectively replaces the count table used in the tabular setting. Using an exploration bonus based on this pseudo-count and a mixed Monte Carlo update applied to a DQN agent was sufficient to achieve state-of-the-art on the Atari 2600 game Montezuma's Revenge.   In this paper we consider two questions left open by their work: First, how important is the quality of the density model for exploration? Second, what role does the Monte Carlo update play in exploration? We answer the first question by demonstrating the use of PixelCNN, an advanced neural density model for images, to supply a pseudo-count. In particular, we examine the intrinsic difficulties in adapting Bellemare et al's approach when assumptions about the model are violated. The result is a more practical and general algorithm requiring no special apparatus. We combine PixelCNN pseudo-counts with different agent architectures to dramatically improve the state of the art on several hard Atari games. One surprising finding is that the mixed Monte Carlo update is a powerful facilitator of exploration in the sparsest of settings, including Montezuma's Revenge.|['Georg Ostrovski', 'Marc G. Bellemare', 'Aaron van den Oord', 'Remi Munos']|['cs.AI']
2017-03-16T23:29:04Z|2017-03-15T15:15:14Z|http://arxiv.org/abs/1703.01274v2|http://arxiv.org/pdf/1703.01274v2|Actor-Critic Reinforcement Learning with Simultaneous Human Control and   Feedback|This paper contributes a first study into how different human users deliver simultaneous control and feedback signals during human-robot interaction. As part of this work, we formalize and present a general interactive learning framework for online cooperation between humans and reinforcement learning agents. In many human-machine interaction settings, there is a growing gap between the degrees-of-freedom of complex semi-autonomous systems and the number of human control channels. Simple human control and feedback mechanisms are required to close this gap and allow for better collaboration between humans and machines on complex tasks. To better inform the design of concurrent control and feedback interfaces, we present experimental results from a human-robot collaborative domain wherein the human must simultaneously deliver both control and feedback signals to interactively train an actor-critic reinforcement learning robot. We compare three experimental conditions: 1) human delivered control signals, 2) reward-shaping feedback signals, and 3) simultaneous control and feedback. Our results suggest that subjects provide less feedback when simultaneously delivering feedback and control signals and that control signal quality is not significantly diminished. Our data suggest that subjects may also modify when and how they provide feedback. Through algorithmic development and tuning informed by this study, we expect semi-autonomous actions of robotic agents can be better shaped by human feedback, allowing for seamless collaboration and improved performance in difficult interactive domains.|['Kory W. Mathewson', 'Patrick M. Pilarski']|['cs.AI', 'cs.HC', 'cs.RO']
2017-03-16T23:29:04Z|2017-03-03T15:27:38Z|http://arxiv.org/abs/1703.01203v1|http://arxiv.org/pdf/1703.01203v1|Stochastic Separation Theorems|A set $S$ is linearly separable if each $x\in S$ can be separated from the rest of $S$ by a linear functional. We study random $N$-element sets in $\mathbb{R}^n$ for large $n$ and demonstrate that for $N<a\exp(b{n})$ they are linearly separable with probability $p$, $p>1-\vartheta$, for a given (small) $\vartheta>0$. Constants $a,b>0$ depend on the probability distribution and the constant $\vartheta$. The results are important for machine learning in high dimension, especially for correction of unavoidable mistakes of legacy Artificial Intelligence systems.|['A. N. Gorban', 'I. Y. Tyukin']|['cs.LG', 'cs.AI', '68T10', 'I.2.6']
2017-03-16T23:29:04Z|2017-03-06T18:17:18Z|http://arxiv.org/abs/1703.01161v2|http://arxiv.org/pdf/1703.01161v2|FeUdal Networks for Hierarchical Reinforcement Learning|We introduce FeUdal Networks (FuNs): a novel architecture for hierarchical reinforcement learning. Our approach is inspired by the feudal reinforcement learning proposal of Dayan and Hinton, and gains power and efficacy by decoupling end-to-end learning across multiple levels -- allowing it to utilise different resolutions of time. Our framework employs a Manager module and a Worker module. The Manager operates at a lower temporal resolution and sets abstract goals which are conveyed to and enacted by the Worker. The Worker generates primitive actions at every tick of the environment. The decoupled structure of FuN conveys several benefits -- in addition to facilitating very long timescale credit assignment it also encourages the emergence of sub-policies associated with different goals set by the Manager. These properties allow FuN to dramatically outperform a strong baseline agent on tasks that involve long-term credit assignment or memorisation. We demonstrate the performance of our proposed system on a range of tasks from the ATARI suite and also from a 3D DeepMind Lab environment.|['Alexander Sasha Vezhnevets', 'Simon Osindero', 'Tom Schaul', 'Nicolas Heess', 'Max Jaderberg', 'David Silver', 'Koray Kavukcuoglu']|['cs.AI']
2017-03-16T23:29:04Z|2017-03-10T14:22:30Z|http://arxiv.org/abs/1703.01127v2|http://arxiv.org/pdf/1703.01127v2|On the Behavior of Convolutional Nets for Feature Extraction|Convolutional neural networks (CNN) are representation learning techniques that achieve state-of-the-art performance on almost every image-related, machine learning task. Applying the representation languages build by these models to tasks beyond the one they were originally trained for is a field of interest known as transfer learning for feature extraction. Through this approach, one can apply the image descriptors learnt by a CNN after processing millions of images to any dataset, without an expensive training phase. Contributions to this field have so far focused on extracting CNN features from layers close to the output (e.g., fully connected layers), particularly because they work better when used out-of-the-box to feed a classifier. Nevertheless, the rest of CNN features is known to encode a wide variety of visual information, which could be potentially exploited on knowledge representation and reasoning tasks. In this paper we analyze the behavior of each feature individually, exploring their intra/inter class activations for all classes of three different datasets. From this study we learn that low and middle level features behave very differently to high level features, the former being more descriptive and the latter being more discriminant. We show how low and middle level features can be used for knowledge representation purposes both by their presence or by their absence. We also study how much noise these features may encode, and propose a thresholding approach to discard most of it. Finally, we discuss the potential implications of these results in the context of knowledge representation using features extracted from a CNN.|['Dario Garcia-Gasulla', 'Ferran Parés', 'Armand Vilalta', 'Jonatan Moreno', 'Eduard Ayguadé', 'Jesús Labarta', 'Ulises Cortés', 'Toyotaro Suzumura']|['cs.NE', 'cs.AI', 'cs.LG', 'stat.ML']
2017-03-16T23:29:04Z|2017-03-03T09:03:46Z|http://arxiv.org/abs/1703.01083v1|http://arxiv.org/pdf/1703.01083v1|Sequential Plan Recognition|Plan recognition algorithms infer agents' plans from their observed actions. Due to imperfect knowledge about the agent's behavior and the environment, it is often the case that there are multiple hypotheses about an agent's plans that are consistent with the observations, though only one of these hypotheses is correct. This paper addresses the problem of how to disambiguate between hypotheses, by querying the acting agent about whether a candidate plan in one of the hypotheses matches its intentions. This process is performed sequentially and used to update the set of possible hypotheses during the recognition process. The paper defines the sequential plan recognition process (SPRP), which seeks to reduce the number of hypotheses using a minimal number of queries. We propose a number of policies for the SPRP which use maximum likelihood and information gain to choose which plan to query. We show this approach works well in practice on two domains from the literature, significantly reducing the number of hypotheses using fewer queries than a baseline approach. Our results can inform the design of future plan recognition systems that interleave the recognition process with intelligent interventions of their users.|"['Reuth Mirsky', 'Roni Stern', ""Ya'akov"", 'Gal', 'Meir Kalech']"|['cs.AI']
2017-03-16T23:29:04Z|2017-03-03T05:41:30Z|http://arxiv.org/abs/1703.01041v1|http://arxiv.org/pdf/1703.01041v1|Large-Scale Evolution of Image Classifiers|Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Evolutionary algorithms provide a technique to discover such networks automatically. Despite significant computational requirements, we show that evolving models that rival large, hand-designed architectures is possible today. We employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions. To do this, we use novel and intuitive mutation operators that navigate large search spaces. We stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.|['Esteban Real', 'Sherry Moore', 'Andrew Selle', 'Saurabh Saxena', 'Yutaka Leon Suematsu', 'Quoc Le', 'Alex Kurakin']|['cs.NE', 'cs.AI', 'cs.CV', 'cs.DC', 'I.2.6; I.5.1; I.5.2']
2017-03-16T23:29:04Z|2017-03-03T05:27:50Z|http://arxiv.org/abs/1703.01040v1|http://arxiv.org/pdf/1703.01040v1|Learning Robot Activities from First-Person Human Videos Using   Convolutional Future Regression|We design a new approach that allows robot learning of new activities from unlabeled human example videos. Given videos of humans executing the same activity from a human's viewpoint (i.e., first-person videos), our objective is to make the robot learn the temporal structure of the activity as its future regression network, and learn to transfer such model for its own motor execution. We present a new deep learning model: We extend the state-of-the-art convolutional object detection network for the detection of human hands in training videos based on image information, and newly introduce the concept of using a fully convolutional network to regress (i.e., predict) the intermediate scene representation corresponding to the future frame (e.g., 1-2 seconds later). Combining these allows direct prediction of future locations of human hands and objects, which enables the robot to infer the motor control plan using our manipulation network. We experimentally confirm that our approach makes learning of robot activities from unlabeled human interaction videos possible, and demonstrate that our robot is able to execute the learned collaborative activities in real-time directly based on its camera input.|['Jangwon Lee', 'Michael S. Ryoo']|['cs.RO', 'cs.AI', 'cs.CV', 'cs.LG']
